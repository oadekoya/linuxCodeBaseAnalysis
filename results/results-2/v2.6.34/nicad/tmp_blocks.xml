<source file="/cmpt816/tmp/init/do_mounts_initrd.c.ifdefed" startline="20" endline="23">
{
    mount_initrd = 0;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_initrd.c.ifdefed" startline="28" endline="35">
{
    static char *argv [] = {"linuxrc", NULL,};
    extern char *envp_init [];
    sys_close (old_fd);
    sys_close (root_fd);
    sys_setsid ();
    return kernel_execve (shell, argv, envp_init);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_initrd.c.ifdefed" startline="38" endline="105">
{
    int error;
    int pid;
    real_root_dev = new_encode_dev (ROOT_DEV);
    create_dev ("/dev/root.old", Root_RAM0);
    mount_block_root ("/dev/root.old", root_mountflags & ~ MS_RDONLY);
    sys_mkdir ("/old", 0700);
    root_fd = sys_open ("/", 0, 0);
    old_fd = sys_open ("/old", 0, 0);
    sys_chdir ("/root");
    sys_mount (".", "/", NULL, MS_MOVE, NULL);
    sys_chroot (".");
    current->flags |= PF_FREEZER_SKIP;
    pid = kernel_thread (do_linuxrc, "/linuxrc", SIGCHLD);
    if (pid > 0)
        while (pid != sys_wait4 (-1, NULL, 0, NULL))
            yield ();
    current->flags &= ~PF_FREEZER_SKIP;
    sys_fchdir (old_fd);
    sys_mount ("/", ".", NULL, MS_MOVE, NULL);
    sys_fchdir (root_fd);
    sys_chroot (".");
    sys_close (old_fd);
    sys_close (root_fd);
    if (new_decode_dev (real_root_dev) == Root_RAM0) {
        sys_chdir ("/old");
        return;
    }
    ROOT_DEV = new_decode_dev (real_root_dev);
    mount_root ();
    printk (KERN_NOTICE "Trying to move old root to /initrd ... ");
    error = sys_mount ("/old", "/root/initrd", NULL, MS_MOVE, NULL);
    if (!error)
        printk ("okay\n");
    else {
        int fd = sys_open ("/dev/root.old", O_RDWR, 0);
        if (error == -ENOENT)
            printk ("/initrd does not exist. Ignored.\n");
        else
            printk ("failed\n");
        printk (KERN_NOTICE "Unmounting old root\n");
        sys_umount ("/old", MNT_DETACH);
        printk (KERN_NOTICE "Trying to free ramdisk memory ... ");
        if (fd < 0) {
            error = fd;
        }
        else {
            error = sys_ioctl (fd, BLKFLSBUF, 0);
            sys_close (fd);
        }
        printk (! error ? "okay\n" : "failed\n");
    }
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_initrd.c.ifdefed" startline="76" endline="79">
{
    sys_chdir ("/old");
    return;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_initrd.c.ifdefed" startline="88" endline="104">
{
    int fd = sys_open ("/dev/root.old", O_RDWR, 0);
    if (error == -ENOENT)
        printk ("/initrd does not exist. Ignored.\n");
    else
        printk ("failed\n");
    printk (KERN_NOTICE "Unmounting old root\n");
    sys_umount ("/old", MNT_DETACH);
    printk (KERN_NOTICE "Trying to free ramdisk memory ... ");
    if (fd < 0) {
        error = fd;
    }
    else {
        error = sys_ioctl (fd, BLKFLSBUF, 0);
        sys_close (fd);
    }
    printk (! error ? "okay\n" : "failed\n");
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_initrd.c.ifdefed" startline="97" endline="99">
{
    error = fd;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_initrd.c.ifdefed" startline="99" endline="102">
{
    error = sys_ioctl (fd, BLKFLSBUF, 0);
    sys_close (fd);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_initrd.c.ifdefed" startline="108" endline="125">
{
    if (mount_initrd) {
        create_dev ("/dev/ram", Root_RAM0);
        if (rd_load_image ("/initrd.image") && ROOT_DEV != Root_RAM0) {
            sys_unlink ("/initrd.image");
            handle_initrd ();
            return 1;
        }
    }
    sys_unlink ("/initrd.image");
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_initrd.c.ifdefed" startline="109" endline="122">
{
    create_dev ("/dev/ram", Root_RAM0);
    if (rd_load_image ("/initrd.image") && ROOT_DEV != Root_RAM0) {
        sys_unlink ("/initrd.image");
        handle_initrd ();
        return 1;
    }
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_initrd.c.ifdefed" startline="117" endline="121">
{
    sys_unlink ("/initrd.image");
    handle_initrd ();
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="21" endline="24">
{
    rd_prompt = simple_strtol (str, NULL, 0) & 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="30" endline="33">
{
    rd_image_start = simple_strtol (str, NULL, 0);
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="54" endline="156">
{
    const int size = 512;
    struct minix_super_block *minixsb;
    struct ext2_super_block *ext2sb;
    struct romfs_super_block *romfsb;
    struct cramfs_super *cramfsb;
    struct squashfs_super_block *squashfsb;
    int nblocks = -1;
    unsigned char *buf;
    const char *compress_name;
    buf = kmalloc (size, GFP_KERNEL);
    if (!buf)
        return -1;
    minixsb = (struct minix_super_block *) buf;
    ext2sb = (struct ext2_super_block *) buf;
    romfsb = (struct romfs_super_block *) buf;
    cramfsb = (struct cramfs_super *) buf;
    squashfsb = (struct squashfs_super_block *) buf;
    memset (buf, 0xe5, size);
    sys_lseek (fd, start_block * BLOCK_SIZE, 0);
    sys_read (fd, buf, size);
    *decompressor = decompress_method (buf, size, &compress_name);
    if (compress_name) {
        printk (KERN_NOTICE "RAMDISK: %s image found at block %d\n", compress_name, start_block);
        if (!*decompressor)
            printk (KERN_EMERG "RAMDISK: %s decompressor not configured!\n", compress_name);
        nblocks = 0;
        goto done;
    }
    if (romfsb->word0 == ROMSB_WORD0 && romfsb->word1 == ROMSB_WORD1) {
        printk (KERN_NOTICE "RAMDISK: romfs filesystem found at block %d\n", start_block);
        nblocks = (ntohl (romfsb->size) + BLOCK_SIZE - 1) >> BLOCK_SIZE_BITS;
        goto done;
    }
    if (cramfsb->magic == CRAMFS_MAGIC) {
        printk (KERN_NOTICE "RAMDISK: cramfs filesystem found at block %d\n", start_block);
        nblocks = (cramfsb->size + BLOCK_SIZE - 1) >> BLOCK_SIZE_BITS;
        goto done;
    }
    if (le32_to_cpu (squashfsb->s_magic) == SQUASHFS_MAGIC) {
        printk (KERN_NOTICE "RAMDISK: squashfs filesystem found at block %d\n", start_block);
        nblocks = (le64_to_cpu (squashfsb->bytes_used) + BLOCK_SIZE - 1) >> BLOCK_SIZE_BITS;
        goto done;
    }
    sys_lseek (fd, (start_block + 1) * BLOCK_SIZE, 0);
    sys_read (fd, buf, size);
    if (minixsb->s_magic == MINIX_SUPER_MAGIC || minixsb->s_magic == MINIX_SUPER_MAGIC2) {
        printk (KERN_NOTICE "RAMDISK: Minix filesystem found at block %d\n", start_block);
        nblocks = minixsb->s_nzones << minixsb->s_log_zone_size;
        goto done;
    }
    if (ext2sb->s_magic == cpu_to_le16 (EXT2_SUPER_MAGIC)) {
        printk (KERN_NOTICE "RAMDISK: ext2 filesystem found at block %d\n", start_block);
        nblocks = le32_to_cpu (ext2sb->s_blocks_count) << le32_to_cpu (ext2sb->s_log_block_size);
        goto done;
    }
    printk (KERN_NOTICE "RAMDISK: Couldn't find valid RAM disk image starting at %d.\n", start_block);
done :
    sys_lseek (fd, start_block *BLOCK_SIZE, 0);
    kfree (buf);
    return nblocks;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="83" endline="92">
{
    printk (KERN_NOTICE "RAMDISK: %s image found at block %d\n", compress_name, start_block);
    if (!*decompressor)
        printk (KERN_EMERG "RAMDISK: %s decompressor not configured!\n", compress_name);
    nblocks = 0;
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="96" endline="102">
{
    printk (KERN_NOTICE "RAMDISK: romfs filesystem found at block %d\n", start_block);
    nblocks = (ntohl (romfsb->size) + BLOCK_SIZE - 1) >> BLOCK_SIZE_BITS;
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="104" endline="110">
{
    printk (KERN_NOTICE "RAMDISK: cramfs filesystem found at block %d\n", start_block);
    nblocks = (cramfsb->size + BLOCK_SIZE - 1) >> BLOCK_SIZE_BITS;
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="113" endline="120">
{
    printk (KERN_NOTICE "RAMDISK: squashfs filesystem found at block %d\n", start_block);
    nblocks = (le64_to_cpu (squashfsb->bytes_used) + BLOCK_SIZE - 1) >> BLOCK_SIZE_BITS;
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="130" endline="136">
{
    printk (KERN_NOTICE "RAMDISK: Minix filesystem found at block %d\n", start_block);
    nblocks = minixsb->s_nzones << minixsb->s_log_zone_size;
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="139" endline="146">
{
    printk (KERN_NOTICE "RAMDISK: ext2 filesystem found at block %d\n", start_block);
    nblocks = le32_to_cpu (ext2sb->s_blocks_count) << le32_to_cpu (ext2sb->s_log_block_size);
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="159" endline="272">
{
    int res = 0;
    int in_fd, out_fd;
    unsigned long rd_blocks, devblocks;
    int nblocks, i, disk;
    char *buf = NULL;
    unsigned short rotate = 0;
    decompress_fn decompressor = NULL;
    out_fd = sys_open ("/dev/ram", O_RDWR, 0);
    if (out_fd < 0)
        goto out;
    in_fd = sys_open (from, O_RDONLY, 0);
    if (in_fd < 0)
        goto noclose_input;
    nblocks = identify_ramdisk_image (in_fd, rd_image_start, &decompressor);
    if (nblocks < 0)
        goto done;
    if (nblocks == 0) {
        if (crd_load (in_fd, out_fd, decompressor) == 0)
            goto successful_load;
        goto done;
    }
    if (sys_ioctl (out_fd, BLKGETSIZE, (unsigned long) &rd_blocks) < 0)
        rd_blocks = 0;
    else
        rd_blocks >>= 1;
    if (nblocks > rd_blocks) {
        printk ("RAMDISK: image too big! (%dKiB/%ldKiB)\n", nblocks, rd_blocks);
        goto done;
    }
    if (sys_ioctl (in_fd, BLKGETSIZE, (unsigned long) &devblocks) < 0)
        devblocks = 0;
    else
        devblocks >>= 1;
    if (strcmp (from, "/initrd.image") == 0)
        devblocks = nblocks;
    if (devblocks == 0) {
        printk (KERN_ERR "RAMDISK: could not determine device size\n");
        goto done;
    }
    buf = kmalloc (BLOCK_SIZE, GFP_KERNEL);
    if (!buf) {
        printk (KERN_ERR "RAMDISK: could not allocate buffer\n");
        goto done;
    }
    printk (KERN_NOTICE "RAMDISK: Loading %dKiB [%ld disk%s] into ram disk... ", nblocks, ((nblocks - 1) / devblocks) + 1, nblocks > devblocks ? "s" : "");
    for (i = 0, disk = 1; i < nblocks; i++) {
        if (i && (i % devblocks == 0)) {
            printk ("done disk #%d.\n", disk ++);
            rotate = 0;
            if (sys_close (in_fd)) {
                printk ("Error closing the disk.\n");
                goto noclose_input;
            }
            change_floppy ("disk #%d", disk);
            in_fd = sys_open (from, O_RDONLY, 0);
            if (in_fd < 0) {
                printk ("Error opening disk.\n");
                goto noclose_input;
            }
            printk ("Loading disk #%d... ", disk);
        }
        sys_read (in_fd, buf, BLOCK_SIZE);
        sys_write (out_fd, buf, BLOCK_SIZE);
    }
    printk ("done.\n");
successful_load :
    res = 1;
done :
    sys_close (in_fd);
noclose_input :
    sys_close (out_fd);
out :
    kfree (buf);
    sys_unlink ("/dev/ram");
    return res;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="183" endline="187">
{
    if (crd_load (in_fd, out_fd, decompressor) == 0)
        goto successful_load;
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="205" endline="209">
{
    printk ("RAMDISK: image too big! (%dKiB/%ldKiB)\n", nblocks, rd_blocks);
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="222" endline="225">
{
    printk (KERN_ERR "RAMDISK: could not determine device size\n");
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="228" endline="231">
{
    printk (KERN_ERR "RAMDISK: could not allocate buffer\n");
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="235" endline="259">
{
    if (i && (i % devblocks == 0)) {
        printk ("done disk #%d.\n", disk ++);
        rotate = 0;
        if (sys_close (in_fd)) {
            printk ("Error closing the disk.\n");
            goto noclose_input;
        }
        change_floppy ("disk #%d", disk);
        in_fd = sys_open (from, O_RDONLY, 0);
        if (in_fd < 0) {
            printk ("Error opening disk.\n");
            goto noclose_input;
        }
        printk ("Loading disk #%d... ", disk);
    }
    sys_read (in_fd, buf, BLOCK_SIZE);
    sys_write (out_fd, buf, BLOCK_SIZE);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="236" endline="250">
{
    printk ("done disk #%d.\n", disk ++);
    rotate = 0;
    if (sys_close (in_fd)) {
        printk ("Error closing the disk.\n");
        goto noclose_input;
    }
    change_floppy ("disk #%d", disk);
    in_fd = sys_open (from, O_RDONLY, 0);
    if (in_fd < 0) {
        printk ("Error opening disk.\n");
        goto noclose_input;
    }
    printk ("Loading disk #%d... ", disk);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="239" endline="242">
{
    printk ("Error closing the disk.\n");
    goto noclose_input;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="245" endline="248">
{
    printk ("Error opening disk.\n");
    goto noclose_input;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="275" endline="281">
{
    if (rd_prompt)
        change_floppy ("root floppy disk to be loaded into RAM disk");
    create_dev ("/dev/root", ROOT_DEV);
    create_dev ("/dev/ram", MKDEV (RAMDISK_MAJOR, n));
    return rd_load_image ("/dev/root");
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="288" endline="295">
{
    int r = sys_read (crd_infd, buf, len);
    if (r < 0)
        printk (KERN_ERR "RAMDISK: error while reading compressed data");
    else if (r == 0)
        printk (KERN_ERR "RAMDISK: EOF while reading compressed data");
    return r;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="298" endline="309">
{
    int written = sys_write (crd_outfd, window, outcnt);
    if (written != outcnt) {
        if (decompress_error == 0)
            printk (KERN_ERR "RAMDISK: incomplete write (%d != %d)\n", written, outcnt);
        decompress_error = 1;
        return -1;
    }
    return outcnt;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="300" endline="307">
{
    if (decompress_error == 0)
        printk (KERN_ERR "RAMDISK: incomplete write (%d != %d)\n", written, outcnt);
    decompress_error = 1;
    return -1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="312" endline="316">
{
    printk (KERN_ERR "%s\n", x);
    exit_code = 1;
    decompress_error = 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_rd.c.ifdefed" startline="319" endline="327">
{
    int result;
    crd_infd = in_fd;
    crd_outfd = out_fd;
    result = deco (NULL, 0, compr_fill, compr_flush, NULL, NULL, error);
    if (decompress_error)
        result = 1;
    return result;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="54" endline="114">
{
    int minor, level, factor, fault, partitioned = 0;
    char *pername = "";
    char *str1;
    int ent;
    if (*str == 'd') {
        partitioned = 1;
        str++;
    }
    if (get_option (&str, &minor) != 2) {
        printk (KERN_WARNING "md: Too few arguments supplied to md=.\n");
        return 0;
    }
    str1 = str;
    for (ent = 0; ent < md_setup_ents; ent++)
        if (md_setup_args[ent].minor == minor && md_setup_args[ent].partitioned == partitioned) {
            printk (KERN_WARNING "md: md=%s%d, Specified more than once. " "Replacing previous definition.\n", partitioned ? "d" : "", minor);
            break;
        }
    if (ent >= ARRAY_SIZE (md_setup_args)) {
        printk (KERN_WARNING "md: md=%s%d - too many md initialisations\n", partitioned ? "d" : "", minor);
        return 0;
    }
    if (ent >= md_setup_ents)
        md_setup_ents++;
    switch (get_option (&str, &level)) {
    case 2 :
        if (level == 0 || level == LEVEL_LINEAR) {
            if (get_option (&str, &factor) != 2 || get_option (&str, &fault) != 2) {
                printk (KERN_WARNING "md: Too few arguments supplied to md=.\n");
                return 0;
            }
            md_setup_args[ent].level = level;
            md_setup_args[ent].chunk = 1 << (factor + 12);
            if (level == LEVEL_LINEAR)
                pername = "linear";
            else
                pername = "raid0";
            break;
        }
    case 1 :
        str = str1;
    case 0 :
        md_setup_args[ent].level = LEVEL_NONE;
        pername = "super-block";
    }
    printk (KERN_INFO "md: Will configure md%d (%s) from %s, below.\n", minor, pername, str);
    md_setup_args[ent].device_names = str;
    md_setup_args[ent].partitioned = partitioned;
    md_setup_args[ent].minor = minor;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="60" endline="63">
{
    partitioned = 1;
    str++;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="64" endline="67">
{
    printk (KERN_WARNING "md: Too few arguments supplied to md=.\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="71" endline="75">
{
    printk (KERN_WARNING "md: md=%s%d, Specified more than once. " "Replacing previous definition.\n", partitioned ? "d" : "", minor);
    break;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="76" endline="79">
{
    printk (KERN_WARNING "md: md=%s%d - too many md initialisations\n", partitioned ? "d" : "", minor);
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="82" endline="105">
{
case 2 :
    if (level == 0 || level == LEVEL_LINEAR) {
        if (get_option (&str, &factor) != 2 || get_option (&str, &fault) != 2) {
            printk (KERN_WARNING "md: Too few arguments supplied to md=.\n");
            return 0;
        }
        md_setup_args[ent].level = level;
        md_setup_args[ent].chunk = 1 << (factor + 12);
        if (level == LEVEL_LINEAR)
            pername = "linear";
        else
            pername = "raid0";
        break;
    }
case 1 :
    str = str1;
case 0 :
    md_setup_args[ent].level = LEVEL_NONE;
    pername = "super-block";
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="84" endline="97">
{
    if (get_option (&str, &factor) != 2 || get_option (&str, &fault) != 2) {
        printk (KERN_WARNING "md: Too few arguments supplied to md=.\n");
        return 0;
    }
    md_setup_args[ent].level = level;
    md_setup_args[ent].chunk = 1 << (factor + 12);
    if (level == LEVEL_LINEAR)
        pername = "linear";
    else
        pername = "raid0";
    break;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="86" endline="89">
{
    printk (KERN_WARNING "md: Too few arguments supplied to md=.\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="117" endline="241">
{
    int minor, i, ent, partitioned;
    dev_t dev;
    dev_t devices [MD_SB_DISKS + 1];
    for (ent = 0; ent < md_setup_ents; ent++) {
        int fd;
        int err = 0;
        char *devname;
        mdu_disk_info_t dinfo;
        char name [16];
        minor = md_setup_args[ent].minor;
        partitioned = md_setup_args[ent].partitioned;
        devname = md_setup_args[ent].device_names;
        sprintf (name, "/dev/md%s%d", partitioned ? "_d" : "", minor);
        if (partitioned)
            dev = MKDEV (mdp_major, minor << MdpMinorShift);
        else
            dev = MKDEV (MD_MAJOR, minor);
        create_dev (name, dev);
        for (i = 0; i < MD_SB_DISKS && devname != NULL; i++) {
            char *p;
            char comp_name [64];
            u32 rdev;
            p = strchr (devname, ',');
            if (p)
                *p++ = 0;
            dev = name_to_dev_t (devname);
            if (strncmp (devname, "/dev/", 5) == 0)
                devname += 5;
            snprintf (comp_name, 63, "/dev/%s", devname);
            rdev = bstat (comp_name);
            if (rdev)
                dev = new_decode_dev (rdev);
            if (!dev) {
                printk (KERN_WARNING "md: Unknown device name: %s\n", devname);
                break;
            }
            devices[i] = dev;
            devname = p;
        }
        devices[i] = 0;
        if (!i)
            continue;
        printk (KERN_INFO "md: Loading md%s%d: %s\n", partitioned ? "_d" : "", minor, md_setup_args [ent].device_names);
        fd = sys_open (name, 0, 0);
        if (fd < 0) {
            printk (KERN_ERR "md: open failed - cannot start " "array %s\n", name);
            continue;
        }
        if (sys_ioctl (fd, SET_ARRAY_INFO, 0) == -EBUSY) {
            printk (KERN_WARNING "md: Ignoring md=%d, already autodetected. (Use raid=noautodetect)\n", minor);
            sys_close (fd);
            continue;
        }
        if (md_setup_args[ent].level != LEVEL_NONE) {
            mdu_array_info_t ainfo;
            ainfo.level = md_setup_args[ent].level;
            ainfo.size = 0;
            ainfo.nr_disks = 0;
            ainfo.raid_disks = 0;
            while (devices[ainfo.raid_disks])
                ainfo.raid_disks++;
            ainfo.md_minor = minor;
            ainfo.not_persistent = 1;
            ainfo.state = (1 << MD_SB_CLEAN);
            ainfo.layout = 0;
            ainfo.chunk_size = md_setup_args[ent].chunk;
            err = sys_ioctl (fd, SET_ARRAY_INFO, (long) &ainfo);
            for (i = 0; !err && i <= MD_SB_DISKS; i++) {
                dev = devices[i];
                if (!dev)
                    break;
                dinfo.number = i;
                dinfo.raid_disk = i;
                dinfo.state = (1 << MD_DISK_ACTIVE) | (1 << MD_DISK_SYNC);
                dinfo.major = MAJOR (dev);
                dinfo.minor = MINOR (dev);
                err = sys_ioctl (fd, ADD_NEW_DISK, (long) &dinfo);
            }
        }
        else {
            for (i = 0; i <= MD_SB_DISKS; i++) {
                dev = devices[i];
                if (!dev)
                    break;
                dinfo.major = MAJOR (dev);
                dinfo.minor = MINOR (dev);
                sys_ioctl (fd, ADD_NEW_DISK, (long) & dinfo);
            }
        }
        if (!err)
            err = sys_ioctl (fd, RUN_ARRAY, 0);
        if (err)
            printk (KERN_WARNING "md: starting md%d failed\n", minor);
        else {
            sys_close (fd);
            fd = sys_open (name, 0, 0);
            sys_ioctl (fd, BLKRRPART, 0);
        }
        sys_close (fd);
    }
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="122" endline="240">
{
    int fd;
    int err = 0;
    char *devname;
    mdu_disk_info_t dinfo;
    char name [16];
    minor = md_setup_args[ent].minor;
    partitioned = md_setup_args[ent].partitioned;
    devname = md_setup_args[ent].device_names;
    sprintf (name, "/dev/md%s%d", partitioned ? "_d" : "", minor);
    if (partitioned)
        dev = MKDEV (mdp_major, minor << MdpMinorShift);
    else
        dev = MKDEV (MD_MAJOR, minor);
    create_dev (name, dev);
    for (i = 0; i < MD_SB_DISKS && devname != NULL; i++) {
        char *p;
        char comp_name [64];
        u32 rdev;
        p = strchr (devname, ',');
        if (p)
            *p++ = 0;
        dev = name_to_dev_t (devname);
        if (strncmp (devname, "/dev/", 5) == 0)
            devname += 5;
        snprintf (comp_name, 63, "/dev/%s", devname);
        rdev = bstat (comp_name);
        if (rdev)
            dev = new_decode_dev (rdev);
        if (!dev) {
            printk (KERN_WARNING "md: Unknown device name: %s\n", devname);
            break;
        }
        devices[i] = dev;
        devname = p;
    }
    devices[i] = 0;
    if (!i)
        continue;
    printk (KERN_INFO "md: Loading md%s%d: %s\n", partitioned ? "_d" : "", minor, md_setup_args [ent].device_names);
    fd = sys_open (name, 0, 0);
    if (fd < 0) {
        printk (KERN_ERR "md: open failed - cannot start " "array %s\n", name);
        continue;
    }
    if (sys_ioctl (fd, SET_ARRAY_INFO, 0) == -EBUSY) {
        printk (KERN_WARNING "md: Ignoring md=%d, already autodetected. (Use raid=noautodetect)\n", minor);
        sys_close (fd);
        continue;
    }
    if (md_setup_args[ent].level != LEVEL_NONE) {
        mdu_array_info_t ainfo;
        ainfo.level = md_setup_args[ent].level;
        ainfo.size = 0;
        ainfo.nr_disks = 0;
        ainfo.raid_disks = 0;
        while (devices[ainfo.raid_disks])
            ainfo.raid_disks++;
        ainfo.md_minor = minor;
        ainfo.not_persistent = 1;
        ainfo.state = (1 << MD_SB_CLEAN);
        ainfo.layout = 0;
        ainfo.chunk_size = md_setup_args[ent].chunk;
        err = sys_ioctl (fd, SET_ARRAY_INFO, (long) &ainfo);
        for (i = 0; !err && i <= MD_SB_DISKS; i++) {
            dev = devices[i];
            if (!dev)
                break;
            dinfo.number = i;
            dinfo.raid_disk = i;
            dinfo.state = (1 << MD_DISK_ACTIVE) | (1 << MD_DISK_SYNC);
            dinfo.major = MAJOR (dev);
            dinfo.minor = MINOR (dev);
            err = sys_ioctl (fd, ADD_NEW_DISK, (long) &dinfo);
        }
    }
    else {
        for (i = 0; i <= MD_SB_DISKS; i++) {
            dev = devices[i];
            if (!dev)
                break;
            dinfo.major = MAJOR (dev);
            dinfo.minor = MINOR (dev);
            sys_ioctl (fd, ADD_NEW_DISK, (long) & dinfo);
        }
    }
    if (!err)
        err = sys_ioctl (fd, RUN_ARRAY, 0);
    if (err)
        printk (KERN_WARNING "md: starting md%d failed\n", minor);
    else {
        sys_close (fd);
        fd = sys_open (name, 0, 0);
        sys_ioctl (fd, BLKRRPART, 0);
    }
    sys_close (fd);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="139" endline="163">
{
    char *p;
    char comp_name [64];
    u32 rdev;
    p = strchr (devname, ',');
    if (p)
        *p++ = 0;
    dev = name_to_dev_t (devname);
    if (strncmp (devname, "/dev/", 5) == 0)
        devname += 5;
    snprintf (comp_name, 63, "/dev/%s", devname);
    rdev = bstat (comp_name);
    if (rdev)
        dev = new_decode_dev (rdev);
    if (!dev) {
        printk (KERN_WARNING "md: Unknown device name: %s\n", devname);
        break;
    }
    devices[i] = dev;
    devname = p;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="155" endline="158">
{
    printk (KERN_WARNING "md: Unknown device name: %s\n", devname);
    break;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="174" endline="178">
{
    printk (KERN_ERR "md: open failed - cannot start " "array %s\n", name);
    continue;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="179" endline="185">
{
    printk (KERN_WARNING "md: Ignoring md=%d, already autodetected. (Use raid=noautodetect)\n", minor);
    sys_close (fd);
    continue;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="187" endline="214">
{
    mdu_array_info_t ainfo;
    ainfo.level = md_setup_args[ent].level;
    ainfo.size = 0;
    ainfo.nr_disks = 0;
    ainfo.raid_disks = 0;
    while (devices[ainfo.raid_disks])
        ainfo.raid_disks++;
    ainfo.md_minor = minor;
    ainfo.not_persistent = 1;
    ainfo.state = (1 << MD_SB_CLEAN);
    ainfo.layout = 0;
    ainfo.chunk_size = md_setup_args[ent].chunk;
    err = sys_ioctl (fd, SET_ARRAY_INFO, (long) &ainfo);
    for (i = 0; !err && i <= MD_SB_DISKS; i++) {
        dev = devices[i];
        if (!dev)
            break;
        dinfo.number = i;
        dinfo.raid_disk = i;
        dinfo.state = (1 << MD_DISK_ACTIVE) | (1 << MD_DISK_SYNC);
        dinfo.major = MAJOR (dev);
        dinfo.minor = MINOR (dev);
        err = sys_ioctl (fd, ADD_NEW_DISK, (long) &dinfo);
    }
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="203" endline="213">
{
    dev = devices[i];
    if (!dev)
        break;
    dinfo.number = i;
    dinfo.raid_disk = i;
    dinfo.state = (1 << MD_DISK_ACTIVE) | (1 << MD_DISK_SYNC);
    dinfo.major = MAJOR (dev);
    dinfo.minor = MINOR (dev);
    err = sys_ioctl (fd, ADD_NEW_DISK, (long) &dinfo);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="214" endline="224">
{
    for (i = 0; i <= MD_SB_DISKS; i++) {
        dev = devices[i];
        if (!dev)
            break;
        dinfo.major = MAJOR (dev);
        dinfo.minor = MINOR (dev);
        sys_ioctl (fd, ADD_NEW_DISK, (long) & dinfo);
    }
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="216" endline="223">
{
    dev = devices[i];
    if (!dev)
        break;
    dinfo.major = MAJOR (dev);
    dinfo.minor = MINOR (dev);
    sys_ioctl (fd, ADD_NEW_DISK, (long) & dinfo);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="229" endline="238">
{
    sys_close (fd);
    fd = sys_open (name, 0, 0);
    sys_ioctl (fd, BLKRRPART, 0);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="244" endline="268">
{
    int len, pos;
    len = strlen (str) + 1;
    pos = 0;
    while (pos < len) {
        char *comma = strchr (str +pos, ',');
        int wlen;
        if (comma)
            wlen = (comma - str) - pos;
        else
            wlen = (len - 1) - pos;
        if (!strncmp (str, "noautodetect", wlen))
            raid_noautodetect = 1;
        if (!strncmp (str, "autodetect", wlen))
            raid_noautodetect = 0;
        if (strncmp (str, "partitionable", wlen) == 0)
            raid_autopart = 1;
        if (strncmp (str, "part", wlen) == 0)
            raid_autopart = 1;
        pos += wlen + 1;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="250" endline="266">
{
    char *comma = strchr (str +pos, ',');
    int wlen;
    if (comma)
        wlen = (comma - str) - pos;
    else
        wlen = (len - 1) - pos;
    if (!strncmp (str, "noautodetect", wlen))
        raid_noautodetect = 1;
    if (!strncmp (str, "autodetect", wlen))
        raid_noautodetect = 0;
    if (strncmp (str, "partitionable", wlen) == 0)
        raid_autopart = 1;
    if (strncmp (str, "part", wlen) == 0)
        raid_autopart = 1;
    pos += wlen + 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="274" endline="291">
{
    int fd;
    printk (KERN_INFO "md: Waiting for all devices to be available before autodetect\n");
    printk (KERN_INFO "md: If you don't use raid, use raid=noautodetect\n");
    wait_for_device_probe ();
    fd = sys_open ("/dev/md0", 0, 0);
    if (fd >= 0) {
        sys_ioctl (fd, RAID_AUTORUN, raid_autopart);
        sys_close (fd);
    }
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="287" endline="290">
{
    sys_ioctl (fd, RAID_AUTORUN, raid_autopart);
    sys_close (fd);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts_md.c.ifdefed" startline="294" endline="302">
{
    create_dev ("/dev/md0", MKDEV (MD_MAJOR, 0));
    if (raid_noautodetect)
        printk (KERN_INFO "md: Skipping autodetection of RAID arrays. (raid=autodetect will force)\n");
    else
        autodetect_raid ();
    md_setup_drive ();
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="14" endline="17">
{
    if (!message)
        message = x;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="31" endline="35">
{
    unsigned long tmp = ino + minor + (major << 3);
    tmp += tmp >> 5;
    return tmp & 31;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="39" endline="63">
{
    struct hash **p, *q;
    for (p = head + hash (major, minor, ino); *p; p = &(*p)->next) {
        if ((*p)->ino != ino)
            continue;
        if ((*p)->minor != minor)
            continue;
        if ((*p)->major != major)
            continue;
        if (((*p)->mode ^ mode) & S_IFMT)
            continue;
        return (*p)->name;
    }
    q = kmalloc (sizeof (struct hash), GFP_KERNEL);
    if (!q)
        panic ("can't allocate link hash entry");
    q->major = major;
    q->minor = minor;
    q->ino = ino;
    q->mode = mode;
    strcpy (q -> name, name);
    q->next = NULL;
    *p = q;
    return NULL;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="41" endline="51">
{
    if ((*p)->ino != ino)
        continue;
    if ((*p)->minor != minor)
        continue;
    if ((*p)->major != major)
        continue;
    if (((*p)->mode ^ mode) & S_IFMT)
        continue;
    return (*p)->name;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="66" endline="75">
{
    struct hash **p, *q;
    for (p = head; p < head + 32; p++) {
        while (*p) {
            q = *p;
            *p = q->next;
            kfree (q);
        }
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="68" endline="74">
{
    while (*p) {
        q = *p;
        *p = q->next;
        kfree (q);
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="69" endline="73">
{
    q = *p;
    *p = q->next;
    kfree (q);
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="78" endline="87">
{
    struct timespec t [2];
    t[0].tv_sec = mtime;
    t[0].tv_nsec = 0;
    t[1].tv_sec = mtime;
    t[1].tv_nsec = 0;
    return do_utimes (AT_FDCWD, filename, t, AT_SYMLINK_NOFOLLOW);
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="97" endline="105">
{
    struct dir_entry *de = kmalloc (sizeof (struct dir_entry), GFP_KERNEL);
    if (!de)
        panic ("can't allocate dir_entry buffer");
    INIT_LIST_HEAD (& de -> list);
    de->name = kstrdup (name, GFP_KERNEL);
    de->mtime = mtime;
    list_add (& de -> list, & dir_list);
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="108" endline="116">
{
    struct dir_entry *de, *tmp;
    list_for_each_entry_safe (de, tmp, &dir_list, list) {
        list_del (& de -> list);
        do_utime (de -> name, de -> mtime);
        kfree (de -> name);
        kfree (de);
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="110" endline="115">
{
    list_del (& de -> list);
    do_utime (de -> name, de -> mtime);
    kfree (de -> name);
    kfree (de);
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="130" endline="151">
{
    unsigned long parsed [12];
    char buf [9];
    int i;
    buf[8] = '\0';
    for (i = 0, s += 6; i < 12; i++, s += 8) {
        memcpy (buf, s, 8);
        parsed[i] = simple_strtoul (buf, NULL, 16);
    }
    ino = parsed[0];
    mode = parsed[1];
    uid = parsed[2];
    gid = parsed[3];
    nlink = parsed[4];
    mtime = parsed[5];
    body_len = parsed[6];
    major = parsed[7];
    minor = parsed[8];
    rdev = new_encode_dev (MKDEV (parsed[9], parsed[10]));
    name_len = parsed[11];
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="136" endline="139">
{
    memcpy (buf, s, 8);
    parsed[i] = simple_strtoul (buf, NULL, 16);
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="171" endline="175">
{
    victim += n;
    this_header += n;
    count -= n;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="183" endline="194">
{
    if (count >= size) {
        collected = victim;
        eat (size);
        state = next;
    }
    else {
        collect = collected = buf;
        remains = size;
        next_state = next;
        state = Collect;
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="184" endline="188">
{
    collected = victim;
    eat (size);
    state = next;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="188" endline="193">
{
    collect = collected = buf;
    remains = size;
    next_state = next;
    state = Collect;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="199" endline="202">
{
    read_into (header_buf, 110, GotHeader);
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="205" endline="216">
{
    unsigned n = remains;
    if (count < n)
        n = count;
    memcpy (collect, victim, n);
    eat (n);
    collect += n;
    if ((remains -= n) != 0)
        return 1;
    state = next_state;
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="219" endline="246">
{
    if (memcmp (collected, "070707", 6) == 0) {
        error ("incorrect cpio method used: use -H newc option");
        return 1;
    }
    if (memcmp (collected, "070701", 6)) {
        error ("no cpio magic");
        return 1;
    }
    parse_header (collected);
    next_header = this_header + N_ALIGN (name_len) + body_len;
    next_header = (next_header + 3) & ~3;
    state = SkipIt;
    if (name_len <= 0 || name_len > PATH_MAX)
        return 0;
    if (S_ISLNK (mode)) {
        if (body_len > PATH_MAX)
            return 0;
        collect = collected = symlink_buf;
        remains = N_ALIGN (name_len) + body_len;
        next_state = GotSymlink;
        state = Collect;
        return 0;
    }
    if (S_ISREG (mode) || !body_len)
        read_into (name_buf, N_ALIGN (name_len), GotName);
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="220" endline="223">
{
    error ("incorrect cpio method used: use -H newc option");
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="224" endline="227">
{
    error ("no cpio magic");
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="234" endline="242">
{
    if (body_len > PATH_MAX)
        return 0;
    collect = collected = symlink_buf;
    remains = N_ALIGN (name_len) + body_len;
    next_state = GotSymlink;
    state = Collect;
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="249" endline="258">
{
    if (this_header + count < next_header) {
        eat (count);
        return 1;
    }
    else {
        eat (next_header - this_header);
        state = next_state;
        return 0;
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="250" endline="253">
{
    eat (count);
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="253" endline="257">
{
    eat (next_header - this_header);
    state = next_state;
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="261" endline="267">
{
    while (count && *victim == '\0')
        eat (1);
    if (count && (this_header & 3))
        error ("broken padding");
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="270" endline="277">
{
    if (nlink >= 2) {
        char *old = find_link (major, minor, ino, mode, collected);
        if (old)
            return (sys_link (old, collected) < 0) ? -1 : 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="271" endline="275">
{
    char *old = find_link (major, minor, ino, mode, collected);
    if (old)
        return (sys_link (old, collected) < 0) ? -1 : 1;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="280" endline="289">
{
    struct stat st;
    if (!sys_newlstat (path, &st) && (st.st_mode ^ mode) & S_IFMT) {
        if (S_ISDIR (st.st_mode))
            sys_rmdir (path);
        else
            sys_unlink (path);
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="283" endline="288">
{
    if (S_ISDIR (st.st_mode))
        sys_rmdir (path);
    else
        sys_unlink (path);
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="294" endline="334">
{
    state = SkipIt;
    next_state = Reset;
    if (strcmp (collected, "TRAILER!!!") == 0) {
        free_hash ();
        return 0;
    }
    clean_path (collected, mode);
    if (S_ISREG (mode)) {
        int ml = maybe_link ();
        if (ml >= 0) {
            int openflags = O_WRONLY | O_CREAT;
            if (ml != 1)
                openflags |= O_TRUNC;
            wfd = sys_open (collected, openflags, mode);
            if (wfd >= 0) {
                sys_fchown (wfd, uid, gid);
                sys_fchmod (wfd, mode);
                if (body_len)
                    sys_ftruncate (wfd, body_len);
                vcollected = kstrdup (collected, GFP_KERNEL);
                state = CopyFile;
            }
        }
    }
    else if (S_ISDIR (mode)) {
        sys_mkdir (collected, mode);
        sys_chown (collected, uid, gid);
        sys_chmod (collected, mode);
        dir_add (collected, mtime);
    }
    else if (S_ISBLK (mode) || S_ISCHR (mode) || S_ISFIFO (mode) || S_ISSOCK (mode)) {
        if (maybe_link () == 0) {
            sys_mknod (collected, mode, rdev);
            sys_chown (collected, uid, gid);
            sys_chmod (collected, mode);
            do_utime (collected, mtime);
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="297" endline="300">
{
    free_hash ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="302" endline="319">
{
    int ml = maybe_link ();
    if (ml >= 0) {
        int openflags = O_WRONLY | O_CREAT;
        if (ml != 1)
            openflags |= O_TRUNC;
        wfd = sys_open (collected, openflags, mode);
        if (wfd >= 0) {
            sys_fchown (wfd, uid, gid);
            sys_fchmod (wfd, mode);
            if (body_len)
                sys_ftruncate (wfd, body_len);
            vcollected = kstrdup (collected, GFP_KERNEL);
            state = CopyFile;
        }
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="304" endline="318">
{
    int openflags = O_WRONLY | O_CREAT;
    if (ml != 1)
        openflags |= O_TRUNC;
    wfd = sys_open (collected, openflags, mode);
    if (wfd >= 0) {
        sys_fchown (wfd, uid, gid);
        sys_fchmod (wfd, mode);
        if (body_len)
            sys_ftruncate (wfd, body_len);
        vcollected = kstrdup (collected, GFP_KERNEL);
        state = CopyFile;
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="310" endline="317">
{
    sys_fchown (wfd, uid, gid);
    sys_fchmod (wfd, mode);
    if (body_len)
        sys_ftruncate (wfd, body_len);
    vcollected = kstrdup (collected, GFP_KERNEL);
    state = CopyFile;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="319" endline="324">
{
    sys_mkdir (collected, mode);
    sys_chown (collected, uid, gid);
    sys_chmod (collected, mode);
    dir_add (collected, mtime);
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="325" endline="332">
{
    if (maybe_link () == 0) {
        sys_mknod (collected, mode, rdev);
        sys_chown (collected, uid, gid);
        sys_chmod (collected, mode);
        do_utime (collected, mtime);
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="326" endline="331">
{
    sys_mknod (collected, mode, rdev);
    sys_chown (collected, uid, gid);
    sys_chmod (collected, mode);
    do_utime (collected, mtime);
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="337" endline="352">
{
    if (count >= body_len) {
        sys_write (wfd, victim, body_len);
        sys_close (wfd);
        do_utime (vcollected, mtime);
        kfree (vcollected);
        eat (body_len);
        state = SkipIt;
        return 0;
    }
    else {
        sys_write (wfd, victim, count);
        body_len -= count;
        eat (count);
        return 1;
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="338" endline="346">
{
    sys_write (wfd, victim, body_len);
    sys_close (wfd);
    do_utime (vcollected, mtime);
    kfree (vcollected);
    eat (body_len);
    state = SkipIt;
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="346" endline="351">
{
    sys_write (wfd, victim, count);
    body_len -= count;
    eat (count);
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="355" endline="364">
{
    collected[N_ALIGN (name_len) + body_len] = '\0';
    clean_path (collected, 0);
    sys_symlink (collected + N_ALIGN (name_len), collected);
    sys_lchown (collected, uid, gid);
    do_utime (collected, mtime);
    state = SkipIt;
    next_state = Reset;
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="378" endline="385">
{
    count = len;
    victim = buf;
    while (!actions[state] ())
        ;
    return len - count;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="388" endline="408">
{
    char *buf = (char *) bufv;
    int written;
    int origLen = len;
    if (message)
        return -1;
    while ((written = write_buffer (buf, len)) < len && !message) {
        char c = buf[written];
        if (c == '0') {
            buf += written;
            len -= written;
            state = Start;
        }
        else if (c == 0) {
            buf += written;
            len -= written;
            state = Reset;
        }
        else
            error ("junk in compressed archive");
    }
    return origLen;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="394" endline="406">
{
    char c = buf[written];
    if (c == '0') {
        buf += written;
        len -= written;
        state = Start;
    }
    else if (c == 0) {
        buf += written;
        len -= written;
        state = Reset;
    }
    else
        error ("junk in compressed archive");
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="396" endline="400">
{
    buf += written;
    len -= written;
    state = Start;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="400" endline="404">
{
    buf += written;
    len -= written;
    state = Reset;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="415" endline="473">
{
    int written, res;
    decompress_fn decompress;
    const char *compress_name;
    static __initdata char msg_buf [64];
    header_buf = kmalloc (110, GFP_KERNEL);
    symlink_buf = kmalloc (PATH_MAX +N_ALIGN (PATH_MAX) + 1, GFP_KERNEL);
    name_buf = kmalloc (N_ALIGN (PATH_MAX), GFP_KERNEL);
    if (!header_buf || !symlink_buf || !name_buf)
        panic ("can't allocate buffers");
    state = Start;
    this_header = 0;
    message = NULL;
    while (!message && len) {
        loff_t saved_offset = this_header;
        if (*buf == '0' && !(this_header & 3)) {
            state = Start;
            written = write_buffer (buf, len);
            buf += written;
            len -= written;
            continue;
        }
        if (!*buf) {
            buf++;
            len--;
            this_header++;
            continue;
        }
        this_header = 0;
        decompress = decompress_method (buf, len, &compress_name);
        if (decompress) {
            res = decompress (buf, len, NULL, flush_buffer, NULL, &my_inptr, error);
            if (res)
                error ("decompressor failed");
        }
        else if (compress_name) {
            if (!message) {
                snprintf (msg_buf, sizeof msg_buf, "compression method %s not configured", compress_name);
                message = msg_buf;
            }
        }
        else
            error ("junk in compressed archive");
        if (state != Reset)
            error ("junk in compressed archive");
        this_header = saved_offset + my_inptr;
        buf += my_inptr;
        len -= my_inptr;
    }
    dir_utime ();
    kfree (name_buf);
    kfree (symlink_buf);
    kfree (header_buf);
    return message;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="431" endline="467">
{
    loff_t saved_offset = this_header;
    if (*buf == '0' && !(this_header & 3)) {
        state = Start;
        written = write_buffer (buf, len);
        buf += written;
        len -= written;
        continue;
    }
    if (!*buf) {
        buf++;
        len--;
        this_header++;
        continue;
    }
    this_header = 0;
    decompress = decompress_method (buf, len, &compress_name);
    if (decompress) {
        res = decompress (buf, len, NULL, flush_buffer, NULL, &my_inptr, error);
        if (res)
            error ("decompressor failed");
    }
    else if (compress_name) {
        if (!message) {
            snprintf (msg_buf, sizeof msg_buf, "compression method %s not configured", compress_name);
            message = msg_buf;
        }
    }
    else
        error ("junk in compressed archive");
    if (state != Reset)
        error ("junk in compressed archive");
    this_header = saved_offset + my_inptr;
    buf += my_inptr;
    len -= my_inptr;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="433" endline="439">
{
    state = Start;
    written = write_buffer (buf, len);
    buf += written;
    len -= written;
    continue;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="440" endline="445">
{
    buf++;
    len--;
    this_header++;
    continue;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="448" endline="453">
{
    res = decompress (buf, len, NULL, flush_buffer, NULL, &my_inptr, error);
    if (res)
        error ("decompressor failed");
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="453" endline="460">
{
    if (!message) {
        snprintf (msg_buf, sizeof msg_buf, "compression method %s not configured", compress_name);
        message = msg_buf;
    }
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="454" endline="459">
{
    snprintf (msg_buf, sizeof msg_buf, "compression method %s not configured", compress_name);
    message = msg_buf;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="478" endline="483">
{
    if (*str)
        return 0;
    do_retain_initrd = 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="491" endline="520">
{
    if (do_retain_initrd)
        goto skip;
    free_initrd_mem (initrd_start, initrd_end);
skip :
    initrd_start = 0;
    initrd_end = 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="572" endline="610">
{
    char *err = unpack_to_rootfs (__initramfs_start, __initramfs_end -__initramfs_start);
    if (err)
        panic (err);
    if (initrd_start) {
        printk (KERN_INFO "Unpacking initramfs...\n");
        err = unpack_to_rootfs ((char *) initrd_start, initrd_end -initrd_start);
        if (err)
            printk (KERN_EMERG "Initramfs unpacking failed: %s\n", err);
        free_initrd ();
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/initramfs.c.ifdefed" startline="577" endline="608">
{
    printk (KERN_INFO "Unpacking initramfs...\n");
    err = unpack_to_rootfs ((char *) initrd_start, initrd_end -initrd_start);
    if (err)
        printk (KERN_EMERG "Initramfs unpacking failed: %s\n", err);
    free_initrd ();
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="36" endline="39">
{
    rd_doload = simple_strtol (str, NULL, 0) & 3;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="43" endline="48">
{
    if (*str)
        return 0;
    root_mountflags |= MS_RDONLY;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="51" endline="56">
{
    if (*str)
        return 0;
    root_mountflags &= ~MS_RDONLY;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="79" endline="146">
{
    char s [32];
    char *p;
    dev_t res = 0;
    int part;
    if (strncmp (name, "/dev/", 5) != 0) {
        unsigned maj, min;
        if (sscanf (name, "%u:%u", &maj, &min) == 2) {
            res = MKDEV (maj, min);
            if (maj != MAJOR (res) || min != MINOR (res))
                goto fail;
        }
        else {
            res = new_decode_dev (simple_strtoul (name, &p, 16));
            if (*p)
                goto fail;
        }
        goto done;
    }
    name += 5;
    res = Root_NFS;
    if (strcmp (name, "nfs") == 0)
        goto done;
    res = Root_RAM0;
    if (strcmp (name, "ram") == 0)
        goto done;
    if (strlen (name) > 31)
        goto fail;
    strcpy (s, name);
    for (p = s; *p; p++)
        if (*p == '/')
            *p = '!';
    res = blk_lookup_devt (s, 0);
    if (res)
        goto done;
    while (p > s && isdigit (p[-1]))
        p--;
    if (p == s || !*p || *p == '0')
        goto fail;
    part = simple_strtoul (p, NULL, 10);
    *p = '\0';
    res = blk_lookup_devt (s, part);
    if (res)
        goto done;
    if (p < s + 2 || !isdigit (p[-2]) || p[-1] != 'p')
        goto fail;
    p[-1] = '\0';
    res = blk_lookup_devt (s, part);
    if (res)
        goto done;
fail :
    return 0;
done :
    return res;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="85" endline="98">
{
    unsigned maj, min;
    if (sscanf (name, "%u:%u", &maj, &min) == 2) {
        res = MKDEV (maj, min);
        if (maj != MAJOR (res) || min != MINOR (res))
            goto fail;
    }
    else {
        res = new_decode_dev (simple_strtoul (name, &p, 16));
        if (*p)
            goto fail;
    }
    goto done;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="88" endline="92">
{
    res = MKDEV (maj, min);
    if (maj != MAJOR (res) || min != MINOR (res))
        goto fail;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="92" endline="96">
{
    res = new_decode_dev (simple_strtoul (name, &p, 16));
    if (*p)
        goto fail;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="149" endline="152">
{
    strlcpy (saved_root_name, line, sizeof (saved_root_name));
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="157" endline="162">
{
    if (*str)
        return 0;
    root_wait = 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="168" endline="171">
{
    root_mount_data = str;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="175" endline="178">
{
    root_fs_names = str;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="182" endline="185">
{
    root_delay = simple_strtoul (str, NULL, 0);
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="192" endline="216">
{
    char *s = page;
    if (root_fs_names) {
        strcpy (page, root_fs_names);
        while (*s++) {
            if (s[-1] == ',')
                s[-1] = '\0';
        }
    }
    else {
        int len = get_filesystem_list (page);
        char *p, *next;
        page[len] = '\0';
        for (p = page - 1; p; p = next) {
            next = strchr (++p, '\n');
            if (*p++ != '\t')
                continue;
            while ((*s++ = *p++) != '\n')
                ;
            s[-1] = '\0';
        }
    }
    *s = '\0';
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="195" endline="201">
{
    strcpy (page, root_fs_names);
    while (*s++) {
        if (s[-1] == ',')
            s[-1] = '\0';
    }
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="197" endline="200">
{
    if (s[-1] == ',')
        s[-1] = '\0';
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="201" endline="214">
{
    int len = get_filesystem_list (page);
    char *p, *next;
    page[len] = '\0';
    for (p = page - 1; p; p = next) {
        next = strchr (++p, '\n');
        if (*p++ != '\t')
            continue;
        while ((*s++ = *p++) != '\n')
            ;
        s[-1] = '\0';
    }
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="206" endline="213">
{
    next = strchr (++p, '\n');
    if (*p++ != '\t')
        continue;
    while ((*s++ = *p++) != '\n')
        ;
    s[-1] = '\0';
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="219" endline="231">
{
    int err = sys_mount (name, "/root", fs, flags, data);
    if (err)
        return err;
    sys_chdir ("/root");
    ROOT_DEV = current->fs->pwd.mnt->mnt_sb->s_dev;
    printk ("VFS: Mounted root (%s filesystem)%s on device %u:%u.\n", current -> fs -> pwd.mnt -> mnt_sb -> s_type -> name, current -> fs -> pwd.mnt -> mnt_sb -> s_flags & MS_RDONLY ? " readonly" : "", MAJOR (ROOT_DEV), MINOR (ROOT_DEV));
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="234" endline="289">
{
    char *fs_names = __getname_gfp (GFP_KERNEL | __GFP_NOTRACK_FALSE_POSITIVE);
    char *p;
    const char *b = name;
    get_fs_names (fs_names);
retry :
    for (p = fs_names; *p; p += strlen (p) + 1) {
        int err = do_mount_root (name, p, flags, root_mount_data);
        switch (err) {
        case 0 :
            goto out;
        case -EACCES :
            flags |= MS_RDONLY;
            goto retry;
        case -EINVAL :
            continue;
        }
        printk ("VFS: Cannot open root device \"%s\" or %s\n", root_device_name, b);
        printk ("Please append a correct \"root=\" boot option; here are the available partitions:\n");
        printk_all_partitions ();
        panic ("VFS: Unable to mount root fs on %s", b);
    }
    printk ("List of all partitions:\n");
    printk_all_partitions ();
    printk ("No filesystem could mount root, tried: ");
    for (p = fs_names; *p; p += strlen (p) + 1)
        printk (" %s", p);
    printk ("\n");
    panic ("VFS: Unable to mount root fs on %s", b);
out :
    putname (fs_names);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="246" endline="275">
{
    int err = do_mount_root (name, p, flags, root_mount_data);
    switch (err) {
    case 0 :
        goto out;
    case -EACCES :
        flags |= MS_RDONLY;
        goto retry;
    case -EINVAL :
        continue;
    }
    printk ("VFS: Cannot open root device \"%s\" or %s\n", root_device_name, b);
    printk ("Please append a correct \"root=\" boot option; here are the available partitions:\n");
    printk_all_partitions ();
    panic ("VFS: Unable to mount root fs on %s", b);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="248" endline="256">
{
case 0 :
    goto out;
case -EACCES :
    flags |= MS_RDONLY;
    goto retry;
case -EINVAL :
    continue;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="335" endline="361">
{
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="367" endline="422">
{
    int is_floppy;
    if (root_delay) {
        printk (KERN_INFO "Waiting %dsec before mounting root device...\n", root_delay);
        ssleep (root_delay);
    }
    wait_for_device_probe ();
    md_run_setup ();
    if (saved_root_name[0]) {
        root_device_name = saved_root_name;
        if (!strncmp (root_device_name, "mtd", 3) || !strncmp (root_device_name, "ubi", 3)) {
            mount_block_root (root_device_name, root_mountflags);
            goto out;
        }
        ROOT_DEV = name_to_dev_t (root_device_name);
        if (strncmp (root_device_name, "/dev/", 5) == 0)
            root_device_name += 5;
    }
    if (initrd_load ())
        goto out;
    if ((ROOT_DEV == 0) && root_wait) {
        printk (KERN_INFO "Waiting for root device %s...\n", saved_root_name);
        while (driver_probe_done () != 0 || (ROOT_DEV = name_to_dev_t (saved_root_name)) == 0)
            msleep (100);
        async_synchronize_full ();
    }
    is_floppy = MAJOR (ROOT_DEV) == FLOPPY_MAJOR;
    if (is_floppy && rd_doload && rd_load_disk (0))
        ROOT_DEV = Root_RAM0;
    mount_root ();
out :
    devtmpfs_mount ("dev");
    sys_mount (".", "/", NULL, MS_MOVE, NULL);
    sys_chroot (".");
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="370" endline="374">
{
    printk (KERN_INFO "Waiting %dsec before mounting root device...\n", root_delay);
    ssleep (root_delay);
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="387" endline="397">
{
    root_device_name = saved_root_name;
    if (!strncmp (root_device_name, "mtd", 3) || !strncmp (root_device_name, "ubi", 3)) {
        mount_block_root (root_device_name, root_mountflags);
        goto out;
    }
    ROOT_DEV = name_to_dev_t (root_device_name);
    if (strncmp (root_device_name, "/dev/", 5) == 0)
        root_device_name += 5;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="390" endline="393">
{
    mount_block_root (root_device_name, root_mountflags);
    goto out;
}
</source>
<source file="/cmpt816/tmp/init/do_mounts.c.ifdefed" startline="403" endline="410">
{
    printk (KERN_INFO "Waiting for root device %s...\n", saved_root_name);
    while (driver_probe_done () != 0 || (ROOT_DEV = name_to_dev_t (saved_root_name)) == 0)
        msleep (100);
    async_synchronize_full ();
}
</source>
<source file="/cmpt816/tmp/init/calibrate.c.ifdefed" startline="16" endline="19">
{
    preset_lpj = simple_strtoul (str, NULL, 0);
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/calibrate.c.ifdefed" startline="108" endline="108">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/calibrate.c.ifdefed" startline="123" endline="182">
{
    unsigned long ticks, loopbit;
    int lps_precision = LPS_PREC;
    static bool printed;
    if (preset_lpj) {
        loops_per_jiffy = preset_lpj;
        if (!printed)
            pr_info ("Calibrating delay loop (skipped) " "preset value.. ");
    }
    else if ((!printed) && lpj_fine) {
        loops_per_jiffy = lpj_fine;
        pr_info ("Calibrating delay loop (skipped), " "value calculated using timer frequency.. ");
    }
    else if ((loops_per_jiffy = calibrate_delay_direct ()) != 0) {
        if (!printed)
            pr_info ("Calibrating delay using timer " "specific routine.. ");
    }
    else {
        loops_per_jiffy = (1 << 12);
        if (!printed)
            pr_info ("Calibrating delay loop... ");
        while ((loops_per_jiffy <<= 1) != 0) {
            ticks = jiffies;
            while (ticks == jiffies)
                ;
            ticks = jiffies;
            __delay (loops_per_jiffy);
            ticks = jiffies - ticks;
            if (ticks)
                break;
        }
        loops_per_jiffy >>= 1;
        loopbit = loops_per_jiffy;
        while (lps_precision-- && (loopbit >>= 1)) {
            loops_per_jiffy |= loopbit;
            ticks = jiffies;
            while (ticks == jiffies)
                ;
            ticks = jiffies;
            __delay (loops_per_jiffy);
            if (jiffies != ticks)
                loops_per_jiffy &= ~loopbit;
        }
    }
    if (!printed)
        pr_cont ("%lu.%02lu BogoMIPS (lpj=%lu)\n", loops_per_jiffy / (500000 / HZ), (loops_per_jiffy / (5000 / HZ)) % 100, loops_per_jiffy);
    printed = true;
}
</source>
<source file="/cmpt816/tmp/init/calibrate.c.ifdefed" startline="128" endline="133">
{
    loops_per_jiffy = preset_lpj;
    if (!printed)
        pr_info ("Calibrating delay loop (skipped) " "preset value.. ");
}
</source>
<source file="/cmpt816/tmp/init/calibrate.c.ifdefed" startline="133" endline="137">
{
    loops_per_jiffy = lpj_fine;
    pr_info ("Calibrating delay loop (skipped), " "value calculated using timer frequency.. ");
}
</source>
<source file="/cmpt816/tmp/init/calibrate.c.ifdefed" startline="137" endline="141">
{
    if (!printed)
        pr_info ("Calibrating delay using timer " "specific routine.. ");
}
</source>
<source file="/cmpt816/tmp/init/calibrate.c.ifdefed" startline="141" endline="175">
{
    loops_per_jiffy = (1 << 12);
    if (!printed)
        pr_info ("Calibrating delay loop... ");
    while ((loops_per_jiffy <<= 1) != 0) {
        ticks = jiffies;
        while (ticks == jiffies)
            ;
        ticks = jiffies;
        __delay (loops_per_jiffy);
        ticks = jiffies - ticks;
        if (ticks)
            break;
    }
    loops_per_jiffy >>= 1;
    loopbit = loops_per_jiffy;
    while (lps_precision-- && (loopbit >>= 1)) {
        loops_per_jiffy |= loopbit;
        ticks = jiffies;
        while (ticks == jiffies)
            ;
        ticks = jiffies;
        __delay (loops_per_jiffy);
        if (jiffies != ticks)
            loops_per_jiffy &= ~loopbit;
    }
}
</source>
<source file="/cmpt816/tmp/init/calibrate.c.ifdefed" startline="146" endline="157">
{
    ticks = jiffies;
    while (ticks == jiffies)
        ;
    ticks = jiffies;
    __delay (loops_per_jiffy);
    ticks = jiffies - ticks;
    if (ticks)
        break;
}
</source>
<source file="/cmpt816/tmp/init/calibrate.c.ifdefed" startline="165" endline="174">
{
    loops_per_jiffy |= loopbit;
    ticks = jiffies;
    while (ticks == jiffies)
        ;
    ticks = jiffies;
    __delay (loops_per_jiffy);
    if (jiffies != ticks)
        loops_per_jiffy &= ~loopbit;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="94" endline="94">
{
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="193" endline="196">
{
    reset_devices = 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="207" endline="233">
{
    struct obs_kernel_param *p;
    int had_early_param = 0;
    p = __setup_start;
    do {
        int n = strlen (p->str);
        if (!strncmp (line, p->str, n)) {
            if (p->early) {
                if (line[n] == '\0' || line[n] == '=')
                    had_early_param = 1;
            }
            else if (!p->setup_func) {
                printk (KERN_WARNING "Parameter %s is obsolete," " ignored\n", p -> str);
                return 1;
            }
            else if (p->setup_func (line +n))
                return 1;
        }
        p++;
    }
    while (p < __setup_end);
    return had_early_param;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="212" endline="230">
{
    int n = strlen (p->str);
    if (!strncmp (line, p->str, n)) {
        if (p->early) {
            if (line[n] == '\0' || line[n] == '=')
                had_early_param = 1;
        }
        else if (!p->setup_func) {
            printk (KERN_WARNING "Parameter %s is obsolete," " ignored\n", p -> str);
            return 1;
        }
        else if (p->setup_func (line +n))
            return 1;
    }
    p++;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="214" endline="228">
{
    if (p->early) {
        if (line[n] == '\0' || line[n] == '=')
            had_early_param = 1;
    }
    else if (!p->setup_func) {
        printk (KERN_WARNING "Parameter %s is obsolete," " ignored\n", p -> str);
        return 1;
    }
    else if (p->setup_func (line +n))
        return 1;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="215" endline="222">
{
    if (line[n] == '\0' || line[n] == '=')
        had_early_param = 1;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="222" endline="226">
{
    printk (KERN_WARNING "Parameter %s is obsolete," " ignored\n", p -> str);
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="244" endline="247">
{
    console_loglevel = 10;
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="250" endline="253">
{
    console_loglevel = 4;
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="259" endline="262">
{
    get_option (& str, & console_loglevel);
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="271" endline="320">
{
    if (val) {
        if (val == param + strlen (param) + 1)
            val[-1] = '=';
        else if (val == param + strlen (param) + 2) {
            val[-2] = '=';
            memmove (val - 1, val, strlen (val) + 1);
            val--;
        }
        else
            BUG ();
    }
    if (obsolete_checksetup (param))
        return 0;
    if (strchr (param, '.') && (!val || strchr (param, '.') < val))
        return 0;
    if (panic_later)
        return 0;
    if (val) {
        unsigned int i;
        for (i = 0; envp_init[i]; i++) {
            if (i == MAX_INIT_ENVS) {
                panic_later = "Too many boot env vars at `%s'";
                panic_param = param;
            }
            if (!strncmp (param, envp_init[i], val -param))
                break;
        }
        envp_init[i] = param;
    }
    else {
        unsigned int i;
        for (i = 0; argv_init[i]; i++) {
            if (i == MAX_INIT_ARGS) {
                panic_later = "Too many boot init vars at `%s'";
                panic_param = param;
            }
        }
        argv_init[i] = param;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="273" endline="283">
{
    if (val == param + strlen (param) + 1)
        val[-1] = '=';
    else if (val == param + strlen (param) + 2) {
        val[-2] = '=';
        memmove (val - 1, val, strlen (val) + 1);
        val--;
    }
    else
        BUG ();
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="277" endline="281">
{
    val[-2] = '=';
    memmove (val - 1, val, strlen (val) + 1);
    val--;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="296" endline="308">
{
    unsigned int i;
    for (i = 0; envp_init[i]; i++) {
        if (i == MAX_INIT_ENVS) {
            panic_later = "Too many boot env vars at `%s'";
            panic_param = param;
        }
        if (!strncmp (param, envp_init[i], val -param))
            break;
    }
    envp_init[i] = param;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="299" endline="306">
{
    if (i == MAX_INIT_ENVS) {
        panic_later = "Too many boot env vars at `%s'";
        panic_param = param;
    }
    if (!strncmp (param, envp_init[i], val -param))
        break;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="300" endline="303">
{
    panic_later = "Too many boot env vars at `%s'";
    panic_param = param;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="308" endline="318">
{
    unsigned int i;
    for (i = 0; argv_init[i]; i++) {
        if (i == MAX_INIT_ARGS) {
            panic_later = "Too many boot init vars at `%s'";
            panic_param = param;
        }
    }
    argv_init[i] = param;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="311" endline="316">
{
    if (i == MAX_INIT_ARGS) {
        panic_later = "Too many boot init vars at `%s'";
        panic_param = param;
    }
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="312" endline="315">
{
    panic_later = "Too many boot init vars at `%s'";
    panic_param = param;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="327" endline="340">
{
    unsigned int i;
    execute_command = str;
    for (i = 1; i < MAX_INIT_ARGS; i++)
        argv_init[i] = NULL;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="344" endline="352">
{
    unsigned int i;
    ramdisk_execute_command = str;
    for (i = 1; i < MAX_INIT_ARGS; i++)
        argv_init[i] = NULL;
    return 1;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="366" endline="366">
{
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="367" endline="367">
{
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="408" endline="413">
{
    saved_command_line = alloc_bootmem (strlen (boot_command_line) +1);
    static_command_line = alloc_bootmem (strlen (command_line) +1);
    strcpy (saved_command_line, boot_command_line);
    strcpy (static_command_line, command_line);
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="426" endline="449">
{
    int pid;
    rcu_scheduler_starting ();
    kernel_thread (kernel_init, NULL, CLONE_FS | CLONE_SIGHAND);
    numa_default_policy ();
    pid = kernel_thread (kthreadd, NULL, CLONE_FS | CLONE_FILES);
    rcu_read_lock ();
    kthreadd_task = find_task_by_pid_ns (pid, &init_pid_ns);
    rcu_read_unlock ();
    unlock_kernel ();
    init_idle_bootup_task (current);
    preempt_enable_no_resched ();
    schedule ();
    preempt_disable ();
    cpu_idle ();
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="453" endline="468">
{
    struct obs_kernel_param *p;
    for (p = __setup_start; p < __setup_end; p++) {
        if ((p->early && strcmp (param, p->str) == 0) || (strcmp (param, "console") == 0 && strcmp (p->str, "earlycon") == 0)) {
            if (p->setup_func (val) != 0)
                printk (KERN_WARNING "Malformed early option '%s'\n", param);
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="456" endline="465">
{
    if ((p->early && strcmp (param, p->str) == 0) || (strcmp (param, "console") == 0 && strcmp (p->str, "earlycon") == 0)) {
        if (p->setup_func (val) != 0)
            printk (KERN_WARNING "Malformed early option '%s'\n", param);
    }
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="460" endline="464">
{
    if (p->setup_func (val) != 0)
        printk (KERN_WARNING "Malformed early option '%s'\n", param);
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="471" endline="473">
{
    parse_args ("early options", cmdline, NULL, 0, do_early_param);
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="477" endline="488">
{
    static __initdata int done = 0;
    static __initdata char tmp_cmdline [COMMAND_LINE_SIZE];
    if (done)
        return;
    strlcpy (tmp_cmdline, boot_command_line, COMMAND_LINE_SIZE);
    parse_early_options (tmp_cmdline);
    done = 1;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="495" endline="502">
{
    int cpu = smp_processor_id ();
    set_cpu_online (cpu, true);
    set_cpu_active (cpu, true);
    set_cpu_present (cpu, true);
    set_cpu_possible (cpu, true);
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="505" endline="506">
{
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="509" endline="510">
{
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="516" endline="526">
{
    page_cgroup_init_flatmem ();
    mem_init ();
    kmem_cache_init ();
    pgtable_cache_init ();
    vmalloc_init ();
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="529" endline="699">
{
    char *command_line;
    extern struct kernel_param __start___param [], __stop___param [];
    smp_setup_processor_id ();
    lockdep_init ();
    debug_objects_early_init ();
    boot_init_stack_canary ();
    cgroup_init_early ();
    local_irq_disable ();
    early_boot_irqs_off ();
    early_init_irq_lock_class ();
    lock_kernel ();
    tick_init ();
    boot_cpu_init ();
    page_address_init ();
    printk (KERN_NOTICE "%s", linux_banner);
    setup_arch (& command_line);
    mm_init_owner (& init_mm, & init_task);
    setup_command_line (command_line);
    setup_nr_cpu_ids ();
    setup_per_cpu_areas ();
    smp_prepare_boot_cpu ();
    build_all_zonelists ();
    page_alloc_init ();
    printk (KERN_NOTICE "Kernel command line: %s\n", boot_command_line);
    parse_early_param ();
    parse_args ("Booting kernel", static_command_line, __start___param, __stop___param - __start___param, & unknown_bootoption);
    pidhash_init ();
    vfs_caches_init_early ();
    sort_main_extable ();
    trap_init ();
    mm_init ();
    sched_init ();
    preempt_disable ();
    if (!irqs_disabled ()) {
        printk (KERN_WARNING "start_kernel(): bug: interrupts were " "enabled *very* early, fixing it\n");
        local_irq_disable ();
    }
    rcu_init ();
    radix_tree_init ();
    early_irq_init ();
    init_IRQ ();
    prio_tree_init ();
    init_timers ();
    hrtimers_init ();
    softirq_init ();
    timekeeping_init ();
    time_init ();
    profile_init ();
    if (!irqs_disabled ())
        printk (KERN_CRIT "start_kernel(): bug: interrupts were " "enabled early\n");
    early_boot_irqs_on ();
    local_irq_enable ();
    gfp_allowed_mask = __GFP_BITS_MASK;
    kmem_cache_init_late ();
    console_init ();
    if (panic_later)
        panic (panic_later, panic_param);
    lockdep_info ();
    locking_selftest ();
    page_cgroup_init ();
    enable_debug_pagealloc ();
    kmemtrace_init ();
    kmemleak_init ();
    debug_objects_mem_init ();
    idr_init_cache ();
    setup_per_cpu_pageset ();
    numa_policy_init ();
    if (late_time_init)
        late_time_init ();
    sched_clock_init ();
    calibrate_delay ();
    pidmap_init ();
    anon_vma_init ();
    thread_info_cache_init ();
    cred_init ();
    fork_init (totalram_pages);
    proc_caches_init ();
    buffer_init ();
    key_init ();
    security_init ();
    vfs_caches_init (totalram_pages);
    signals_init ();
    page_writeback_init ();
    cgroup_init ();
    cpuset_init ();
    taskstats_init_early ();
    delayacct_init ();
    check_bugs ();
    acpi_early_init ();
    sfi_init_late ();
    ftrace_init ();
    rest_init ();
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="597" endline="601">
{
    printk (KERN_WARNING "start_kernel(): bug: interrupts were " "enabled *very* early, fixing it\n");
    local_irq_disable ();
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="703" endline="710">
{
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="720" endline="762">
{
    int count = preempt_count ();
    ktime_t calltime, delta, rettime;
    if (initcall_debug) {
        call.caller = task_pid_nr (current);
        printk ("calling  %pF @ %i\n", fn, call.caller);
        calltime = ktime_get ();
        trace_boot_call (& call, fn);
        enable_boot_trace ();
    }
    ret.result = fn ();
    if (initcall_debug) {
        disable_boot_trace ();
        rettime = ktime_get ();
        delta = ktime_sub (rettime, calltime);
        ret.duration = (unsigned long long) ktime_to_ns (delta) >> 10;
        trace_boot_ret (& ret, fn);
        printk ("initcall %pF returned %d after %Ld usecs\n", fn, ret.result, ret.duration);
    }
    msgbuf[0] = 0;
    if (ret.result && ret.result != -ENODEV && initcall_debug)
        sprintf (msgbuf, "error code %d ", ret.result);
    if (preempt_count () != count) {
        strlcat (msgbuf, "preemption imbalance ", sizeof (msgbuf));
        preempt_count () = count;
    }
    if (irqs_disabled ()) {
        strlcat (msgbuf, "disabled interrupts ", sizeof (msgbuf));
        local_irq_enable ();
    }
    if (msgbuf[0]) {
        printk ("initcall %pF returned with %s\n", fn, msgbuf);
    }
    return ret.result;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="724" endline="730">
{
    call.caller = task_pid_nr (current);
    printk ("calling  %pF @ %i\n", fn, call.caller);
    calltime = ktime_get ();
    trace_boot_call (& call, fn);
    enable_boot_trace ();
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="734" endline="742">
{
    disable_boot_trace ();
    rettime = ktime_get ();
    delta = ktime_sub (rettime, calltime);
    ret.duration = (unsigned long long) ktime_to_ns (delta) >> 10;
    trace_boot_ret (& ret, fn);
    printk ("initcall %pF returned %d after %Ld usecs\n", fn, ret.result, ret.duration);
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="749" endline="752">
{
    strlcat (msgbuf, "preemption imbalance ", sizeof (msgbuf));
    preempt_count () = count;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="753" endline="756">
{
    strlcat (msgbuf, "disabled interrupts ", sizeof (msgbuf));
    local_irq_enable ();
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="757" endline="759">
{
    printk ("initcall %pF returned with %s\n", fn, msgbuf);
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="768" endline="776">
{
    initcall_t *fn;
    for (fn = __early_initcall_end; fn < __initcall_end; fn++)
        do_one_initcall (*fn);
    flush_scheduled_work ();
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="786" endline="795">
{
    init_workqueues ();
    cpuset_init_smp ();
    usermodehelper_init ();
    init_tmpfs ();
    driver_init ();
    init_irq_proc ();
    do_ctors ();
    do_initcalls ();
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="798" endline="803">
{
    initcall_t *fn;
    for (fn = __initcall_start; fn < __early_initcall_end; fn++)
        do_one_initcall (*fn);
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="806" endline="809">
{
    argv_init[0] = init_filename;
    kernel_execve (init_filename, argv_init, envp_init);
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="816" endline="852">
{
    async_synchronize_full ();
    free_initmem ();
    unlock_kernel ();
    mark_rodata_ro ();
    system_state = SYSTEM_RUNNING;
    numa_default_policy ();
    current->signal->flags |= SIGNAL_UNKILLABLE;
    if (ramdisk_execute_command) {
        run_init_process (ramdisk_execute_command);
        printk (KERN_WARNING "Failed to execute %s\n", ramdisk_execute_command);
    }
    if (execute_command) {
        run_init_process (execute_command);
        printk (KERN_WARNING "Failed to execute %s.  Attempting " "defaults...\n", execute_command);
    }
    run_init_process ("/sbin/init");
    run_init_process ("/etc/init");
    run_init_process ("/bin/init");
    run_init_process ("/bin/sh");
    panic ("No init found.  Try passing init= option to kernel. " "See Linux Documentation/init.txt for guidance.");
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="828" endline="832">
{
    run_init_process (ramdisk_execute_command);
    printk (KERN_WARNING "Failed to execute %s\n", ramdisk_execute_command);
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="840" endline="844">
{
    run_init_process (execute_command);
    printk (KERN_WARNING "Failed to execute %s.  Attempting " "defaults...\n", execute_command);
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="855" endline="915">
{
    lock_kernel ();
    set_mems_allowed (node_states [N_HIGH_MEMORY]);
    set_cpus_allowed_ptr (current, cpu_all_mask);
    init_pid_ns.child_reaper = current;
    cad_pid = task_pid (current);
    smp_prepare_cpus (setup_max_cpus);
    do_pre_smp_initcalls ();
    start_boot_trace ();
    smp_init ();
    sched_init_smp ();
    do_basic_setup ();
    if (sys_open ((const char __user *) "/dev/console", O_RDWR, 0) < 0)
        printk (KERN_WARNING "Warning: unable to open an initial console.\n");
    (void) sys_dup (0);
    (void) sys_dup (0);
    if (!ramdisk_execute_command)
        ramdisk_execute_command = "/init";
    if (sys_access ((const char __user *) ramdisk_execute_command, 0) != 0) {
        ramdisk_execute_command = NULL;
        prepare_namespace ();
    }
    init_post ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/init/main.c.ifdefed" startline="902" endline="905">
{
    ramdisk_execute_command = NULL;
    prepare_namespace ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vgetcpu.c.ifdefed" startline="18" endline="33">
{
    unsigned int p;
    if (*vdso_vgetcpu_mode == VGETCPU_RDTSCP) {
        native_read_tscp (& p);
    }
    else {
        asm ("lsl %1,%0"
            : "=r" (p)
            : "r" (__PER_CPU_SEG)
        )}
    if (cpu)
        *cpu = p & 0xfff;
    if (node)
        *node = p >> 12;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vgetcpu.c.ifdefed" startline="21" endline="24">
{
    native_read_tscp (& p);
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vgetcpu.c.ifdefed" startline="24" endline="27">
{
    asm ("lsl %1,%0"
        : "=r" (p)
        : "r" (__PER_CPU_SEG)
    )}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vma.c.ifdefed" startline="30" endline="36">
{
    if (*(void**) p != (void *) VMAGIC) {
        printk ("VDSO: variable %s broken\n", name);
        vdso_enabled = 0;
    }
    return p;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vma.c.ifdefed" startline="31" endline="34">
{
    printk ("VDSO: variable %s broken\n", name);
    vdso_enabled = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vma.c.ifdefed" startline="39" endline="76">
{
    int npages = (vdso_end - vdso_start + PAGE_SIZE - 1) / PAGE_SIZE;
    int i;
    char *vbase;
    vdso_size = npages << PAGE_SHIFT;
    vdso_pages = kmalloc (sizeof (struct page *) * npages, GFP_KERNEL);
    if (!vdso_pages)
        goto oom;
    for (i = 0; i < npages; i++) {
        struct page *p;
        p = alloc_page (GFP_KERNEL);
        if (!p)
            goto oom;
        vdso_pages[i] = p;
        copy_page (page_address (p), vdso_start + i * PAGE_SIZE);
    }
    vbase = vmap (vdso_pages, npages, 0, PAGE_KERNEL);
    if (!vbase)
        goto oom;
    if (memcmp (vbase, "\177ELF", 4)) {
        printk ("VDSO: I'm broken; not ELF\n");
        vdso_enabled = 0;
    }
    return 0;
oom :
    printk ("Cannot allocate vdso\n");
    vdso_enabled = 0;
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vma.c.ifdefed" startline="48" endline="55">
{
    struct page *p;
    p = alloc_page (GFP_KERNEL);
    if (!p)
        goto oom;
    vdso_pages[i] = p;
    copy_page (page_address (p), vdso_start + i * PAGE_SIZE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vma.c.ifdefed" startline="61" endline="64">
{
    printk ("VDSO: I'm broken; not ELF\n");
    vdso_enabled = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vma.c.ifdefed" startline="86" endline="99">
{
    unsigned long addr, end;
    unsigned offset;
    end = (start + PMD_SIZE - 1) & PMD_MASK;
    if (end >= TASK_SIZE_MAX)
        end = TASK_SIZE_MAX;
    end -= len;
    offset = get_random_int () & (PTRS_PER_PTE - 1);
    addr = start + (offset << PAGE_SHIFT);
    if (addr >= end)
        addr = end;
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vma.c.ifdefed" startline="104" endline="135">
{
    struct mm_struct *mm = current->mm;
    unsigned long addr;
    int ret;
    if (!vdso_enabled)
        return 0;
    down_write (& mm -> mmap_sem);
    addr = vdso_addr (mm->start_stack, vdso_size);
    addr = get_unmapped_area (NULL, addr, vdso_size, 0, 0);
    if (IS_ERR_VALUE (addr)) {
        ret = addr;
        goto up_fail;
    }
    current->mm->context.vdso = (void *) addr;
    ret = install_special_mapping (mm, addr, vdso_size, VM_READ | VM_EXEC | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC | VM_ALWAYSDUMP, vdso_pages);
    if (ret) {
        current->mm->context.vdso = NULL;
        goto up_fail;
    }
up_fail :
    up_write (&mm->mmap_sem);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vma.c.ifdefed" startline="115" endline="118">
{
    ret = addr;
    goto up_fail;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vma.c.ifdefed" startline="127" endline="130">
{
    current->mm->context.vdso = NULL;
    goto up_fail;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vma.c.ifdefed" startline="138" endline="141">
{
    vdso_enabled = simple_strtoul (s, NULL, 0);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="30" endline="35">
{
    long ret;
    asm ("syscall"
        : "=a" (ret)
        : "0" (__NR_clock_gettime), "D" (clock), "S" (ts)
        : "memory"
    ) return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="38" endline="44">
{
    long v;
    cycles_t (*vread) (void);
    vread = gtod->clock.vread;
    v = (vread () - gtod->clock.cycle_last) & gtod->clock.mask;
    return (v * gtod->clock.mult) >> gtod->clock.shift;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="47" endline="57">
{
    unsigned long seq, ns;
    do {
        seq = read_seqbegin (&gtod->lock);
        ts->tv_sec = gtod->wall_time_sec;
        ts->tv_nsec = gtod->wall_time_nsec;
        ns = vgetns ();
    }
    while (unlikely (read_seqretry (&gtod->lock, seq)));
    timespec_add_ns (ts, ns);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="49" endline="54">
{
    seq = read_seqbegin (&gtod->lock);
    ts->tv_sec = gtod->wall_time_sec;
    ts->tv_nsec = gtod->wall_time_nsec;
    ns = vgetns ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="62" endline="73">
{
    while (nsec >= NSEC_PER_SEC) {
        nsec -= NSEC_PER_SEC;
        ++sec;
    }
    while (nsec < 0) {
        nsec += NSEC_PER_SEC;
        --sec;
    }
    ts->tv_sec = sec;
    ts->tv_nsec = nsec;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="63" endline="66">
{
    nsec -= NSEC_PER_SEC;
    ++sec;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="67" endline="70">
{
    nsec += NSEC_PER_SEC;
    --sec;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="76" endline="87">
{
    unsigned long seq, ns, secs;
    do {
        seq = read_seqbegin (&gtod->lock);
        secs = gtod->wall_time_sec;
        ns = gtod->wall_time_nsec + vgetns ();
        secs += gtod->wall_to_monotonic.tv_sec;
        ns += gtod->wall_to_monotonic.tv_nsec;
    }
    while (unlikely (read_seqretry (&gtod->lock, seq)));
    vset_normalized_timespec (ts, secs, ns);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="78" endline="84">
{
    seq = read_seqbegin (&gtod->lock);
    secs = gtod->wall_time_sec;
    ns = gtod->wall_time_nsec + vgetns ();
    secs += gtod->wall_to_monotonic.tv_sec;
    ns += gtod->wall_to_monotonic.tv_nsec;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="90" endline="98">
{
    unsigned long seq;
    do {
        seq = read_seqbegin (&gtod->lock);
        ts->tv_sec = gtod->wall_time_coarse.tv_sec;
        ts->tv_nsec = gtod->wall_time_coarse.tv_nsec;
    }
    while (unlikely (read_seqretry (&gtod->lock, seq)));
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="92" endline="96">
{
    seq = read_seqbegin (&gtod->lock);
    ts->tv_sec = gtod->wall_time_coarse.tv_sec;
    ts->tv_nsec = gtod->wall_time_coarse.tv_nsec;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="101" endline="112">
{
    unsigned long seq, ns, secs;
    do {
        seq = read_seqbegin (&gtod->lock);
        secs = gtod->wall_time_coarse.tv_sec;
        ns = gtod->wall_time_coarse.tv_nsec;
        secs += gtod->wall_to_monotonic.tv_sec;
        ns += gtod->wall_to_monotonic.tv_nsec;
    }
    while (unlikely (read_seqretry (&gtod->lock, seq)));
    vset_normalized_timespec (ts, secs, ns);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="103" endline="109">
{
    seq = read_seqbegin (&gtod->lock);
    secs = gtod->wall_time_coarse.tv_sec;
    ns = gtod->wall_time_coarse.tv_nsec;
    secs += gtod->wall_to_monotonic.tv_sec;
    ns += gtod->wall_to_monotonic.tv_nsec;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="115" endline="132">
{
    if (likely (gtod->sysctl_enabled))
        switch (clock) {
        case CLOCK_REALTIME :
            if (likely (gtod->clock.vread))
                return do_realtime (ts);
            break;
        case CLOCK_MONOTONIC :
            if (likely (gtod->clock.vread))
                return do_monotonic (ts);
            break;
        case CLOCK_REALTIME_COARSE :
            return do_realtime_coarse (ts);
        case CLOCK_MONOTONIC_COARSE :
            return do_monotonic_coarse (ts);
        }
    return vdso_fallback_gettime (clock, ts);
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="117" endline="130">
{
case CLOCK_REALTIME :
    if (likely (gtod->clock.vread))
        return do_realtime (ts);
    break;
case CLOCK_MONOTONIC :
    if (likely (gtod->clock.vread))
        return do_monotonic (ts);
    break;
case CLOCK_REALTIME_COARSE :
    return do_realtime_coarse (ts);
case CLOCK_MONOTONIC_COARSE :
    return do_monotonic_coarse (ts);
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="137" endline="157">
{
    long ret;
    if (likely (gtod->sysctl_enabled && gtod->clock.vread)) {
        if (likely (tv != NULL)) {
            BUILD_BUG_ON (offsetof (struct timeval, tv_usec) != offsetof (struct timespec, tv_nsec) || sizeof (* tv) != sizeof (struct timespec));
            do_realtime ((struct timespec *) tv);
            tv->tv_usec /= 1000;
        }
        if (unlikely (tz != NULL)) {
            tz->tz_minuteswest = gtod->sys_tz.tz_minuteswest;
            tz->tz_dsttime = gtod->sys_tz.tz_dsttime;
        }
        return 0;
    }
    asm ("syscall"
        : "=a" (ret)
        : "0" (__NR_gettimeofday), "D" (tv), "S" (tz)
        : "memory"
    ) return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="139" endline="153">
{
    if (likely (tv != NULL)) {
        BUILD_BUG_ON (offsetof (struct timeval, tv_usec) != offsetof (struct timespec, tv_nsec) || sizeof (* tv) != sizeof (struct timespec));
        do_realtime ((struct timespec *) tv);
        tv->tv_usec /= 1000;
    }
    if (unlikely (tz != NULL)) {
        tz->tz_minuteswest = gtod->sys_tz.tz_minuteswest;
        tz->tz_dsttime = gtod->sys_tz.tz_dsttime;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="140" endline="146">
{
    BUILD_BUG_ON (offsetof (struct timeval, tv_usec) != offsetof (struct timespec, tv_nsec) || sizeof (* tv) != sizeof (struct timespec));
    do_realtime ((struct timespec *) tv);
    tv->tv_usec /= 1000;
}
</source>
<source file="/cmpt816/tmp/arch/x86/vdso/vclock_gettime.c.ifdefed" startline="147" endline="151">
{
    tz->tz_minuteswest = gtod->sys_tz.tz_minuteswest;
    tz->tz_dsttime = gtod->sys_tz.tz_dsttime;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="44" endline="65">
{
    u64 this_offset;
    if (unlikely (tsc_disabled)) {
        return (jiffies_64 - INITIAL_JIFFIES) * (1000000000 / HZ);
    }
    rdtscll (this_offset);
    return __cycles_2_ns (this_offset);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="55" endline="58">
{
    return (jiffies_64 - INITIAL_JIFFIES) * (1000000000 / HZ);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="80" endline="82">
{
    return tsc_unstable;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="99" endline="102">
{
    setup_clear_cpu_cap (X86_FEATURE_TSC);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="108" endline="112">
{
    if (!strcmp (str, "reliable"))
        tsc_clocksource_reliable = 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="123" endline="138">
{
    u64 t1, t2;
    int i;
    for (i = 0; i < MAX_RETRIES; i++) {
        t1 = get_cycles ();
        if (hpet)
            *p = hpet_readl (HPET_COUNTER) & 0xFFFFFFFF;
        else
            *p = acpi_pm_read_early ();
        t2 = get_cycles ();
        if ((t2 - t1) < SMI_TRESHOLD)
            return t2;
    }
    return ULLONG_MAX;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="127" endline="136">
{
    t1 = get_cycles ();
    if (hpet)
        *p = hpet_readl (HPET_COUNTER) & 0xFFFFFFFF;
    else
        *p = acpi_pm_read_early ();
    t2 = get_cycles ();
    if ((t2 - t1) < SMI_TRESHOLD)
        return t2;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="144" endline="155">
{
    u64 tmp;
    if (hpet2 < hpet1)
        hpet2 += 0x100000000ULL;
    hpet2 -= hpet1;
    tmp = ((u64) hpet2 * hpet_readl (HPET_PERIOD));
    do_div (tmp, 1000000);
    do_div (deltatsc, tmp);
    return (unsigned long) deltatsc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="161" endline="175">
{
    u64 tmp;
    if (!pm1 && !pm2)
        return ULONG_MAX;
    if (pm2 < pm1)
        pm2 += (u64) ACPI_PM_OVRRUN;
    pm2 -= pm1;
    tmp = pm2 * 1000000000LL;
    do_div (tmp, PMTMR_TICKS_PER_SEC);
    do_div (deltatsc, tmp);
    return (unsigned long) deltatsc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="194" endline="243">
{
    u64 tsc, t1, t2, delta;
    unsigned long tscmin, tscmax;
    int pitcnt;
    outb ((inb (0x61) & ~ 0x02) | 0x01, 0x61);
    outb (0xb0, 0x43);
    outb (latch & 0xff, 0x42);
    outb (latch >> 8, 0x42);
    tsc = t1 = t2 = get_cycles ();
    pitcnt = 0;
    tscmax = 0;
    tscmin = ULONG_MAX;
    while ((inb (0x61) & 0x20) == 0) {
        t2 = get_cycles ();
        delta = t2 - tsc;
        tsc = t2;
        if ((unsigned long) delta < tscmin)
            tscmin = (unsigned int) delta;
        if ((unsigned long) delta > tscmax)
            tscmax = (unsigned int) delta;
        pitcnt++;
    }
    if (pitcnt < loopmin || tscmax > 10 * tscmin)
        return ULONG_MAX;
    delta = t2 - t1;
    do_div (delta, ms);
    return delta;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="216" endline="225">
{
    t2 = get_cycles ();
    delta = t2 - tsc;
    tsc = t2;
    if ((unsigned long) delta < tscmin)
        tscmin = (unsigned int) delta;
    if ((unsigned long) delta > tscmax)
        tscmax = (unsigned int) delta;
    pitcnt++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="281" endline="285">
{
    inb (0x42);
    return inb (0x42) == val;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="288" endline="305">
{
    int count;
    u64 tsc = 0;
    for (count = 0; count < 50000; count++) {
        if (!pit_verify_msb (val))
            break;
        tsc = get_cycles ();
    }
    *deltap = get_cycles () - tsc;
    *tscp = tsc;
    return count > 5;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="292" endline="296">
{
    if (!pit_verify_msb (val))
        break;
    tsc = get_cycles ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="317" endline="396">
{
    int i;
    u64 tsc, delta;
    unsigned long d1, d2;
    outb ((inb (0x61) & ~ 0x02) | 0x01, 0x61);
    outb (0xb0, 0x43);
    outb (0xff, 0x42);
    outb (0xff, 0x42);
    pit_verify_msb (0);
    if (pit_expect_msb (0xff, &tsc, &d1)) {
        for (i = 1; i <= MAX_QUICK_PIT_ITERATIONS; i++) {
            if (!pit_expect_msb (0xff - i, &delta, &d2))
                break;
            delta -= tsc;
            if (d1 + d2 >= delta >> 11)
                continue;
            if (!pit_verify_msb (0xfe - i))
                break;
            goto success;
        }
    }
    printk ("Fast TSC calibration failed\n");
    return 0;
success :
    delta += (long) (d2 - d1) / 2;
    delta *= PIT_TICK_RATE;
    do_div (delta, i * 256 * 1000);
    printk ("Fast TSC calibration using PIT\n");
    return delta;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="348" endline="371">
{
    for (i = 1; i <= MAX_QUICK_PIT_ITERATIONS; i++) {
        if (!pit_expect_msb (0xff - i, &delta, &d2))
            break;
        delta -= tsc;
        if (d1 + d2 >= delta >> 11)
            continue;
        if (!pit_verify_msb (0xfe - i))
            break;
        goto success;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="349" endline="370">
{
    if (!pit_expect_msb (0xff - i, &delta, &d2))
        break;
    delta -= tsc;
    if (d1 + d2 >= delta >> 11)
        continue;
    if (!pit_verify_msb (0xfe - i))
        break;
    goto success;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="402" endline="557">
{
    u64 tsc1, tsc2, delta, ref1, ref2;
    unsigned long tsc_pit_min = ULONG_MAX, tsc_ref_min = ULONG_MAX;
    unsigned long flags, latch, ms, fast_calibrate;
    int hpet = is_hpet_enabled (), i, loopmin;
    local_irq_save (flags);
    fast_calibrate = quick_pit_calibrate ();
    local_irq_restore (flags);
    if (fast_calibrate)
        return fast_calibrate;
    latch = CAL_LATCH;
    ms = CAL_MS;
    loopmin = CAL_PIT_LOOPS;
    for (i = 0; i < 3; i++) {
        unsigned long tsc_pit_khz;
        local_irq_save (flags);
        tsc1 = tsc_read_refs (&ref1, hpet);
        tsc_pit_khz = pit_calibrate_tsc (latch, ms, loopmin);
        tsc2 = tsc_read_refs (&ref2, hpet);
        local_irq_restore (flags);
        tsc_pit_min = min (tsc_pit_min, tsc_pit_khz);
        if (!hpet && !ref1 && !ref2)
            continue;
        if (tsc1 == ULLONG_MAX || tsc2 == ULLONG_MAX)
            continue;
        tsc2 = (tsc2 - tsc1) * 1000000LL;
        if (hpet)
            tsc2 = calc_hpet_ref (tsc2, ref1, ref2);
        else
            tsc2 = calc_pmtimer_ref (tsc2, ref1, ref2);
        tsc_ref_min = min (tsc_ref_min, (unsigned long) tsc2);
        delta = ((u64) tsc_pit_min) * 100;
        do_div (delta, tsc_ref_min);
        if (delta >= 90 && delta <= 110) {
            printk (KERN_INFO "TSC: PIT calibration matches %s. %d loops\n", hpet ? "HPET" : "PMTIMER", i + 1);
            return tsc_ref_min;
        }
        if (i == 1 && tsc_pit_min == ULONG_MAX) {
            latch = CAL2_LATCH;
            ms = CAL2_MS;
            loopmin = CAL2_PIT_LOOPS;
        }
    }
    if (tsc_pit_min == ULONG_MAX) {
        printk (KERN_WARNING "TSC: Unable to calibrate against PIT\n");
        if (!hpet && !ref1 && !ref2) {
            printk ("TSC: No reference (HPET/PMTIMER) available\n");
            return 0;
        }
        if (tsc_ref_min == ULONG_MAX) {
            printk (KERN_WARNING "TSC: HPET/PMTIMER calibration " "failed.\n");
            return 0;
        }
        printk (KERN_INFO "TSC: using %s reference calibration\n", hpet ? "HPET" : "PMTIMER");
        return tsc_ref_min;
    }
    if (!hpet && !ref1 && !ref2) {
        printk (KERN_INFO "TSC: Using PIT calibration value\n");
        return tsc_pit_min;
    }
    if (tsc_ref_min == ULONG_MAX) {
        printk (KERN_WARNING "TSC: HPET/PMTIMER calibration failed. " "Using PIT calibration\n");
        return tsc_pit_min;
    }
    printk (KERN_WARNING "TSC: PIT calibration deviates from %s: %lu %lu.\n", hpet ? "HPET" : "PMTIMER", tsc_pit_min, tsc_ref_min);
    printk (KERN_INFO "TSC: Using PIT calibration value\n");
    return tsc_pit_min;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="444" endline="506">
{
    unsigned long tsc_pit_khz;
    local_irq_save (flags);
    tsc1 = tsc_read_refs (&ref1, hpet);
    tsc_pit_khz = pit_calibrate_tsc (latch, ms, loopmin);
    tsc2 = tsc_read_refs (&ref2, hpet);
    local_irq_restore (flags);
    tsc_pit_min = min (tsc_pit_min, tsc_pit_khz);
    if (!hpet && !ref1 && !ref2)
        continue;
    if (tsc1 == ULLONG_MAX || tsc2 == ULLONG_MAX)
        continue;
    tsc2 = (tsc2 - tsc1) * 1000000LL;
    if (hpet)
        tsc2 = calc_hpet_ref (tsc2, ref1, ref2);
    else
        tsc2 = calc_pmtimer_ref (tsc2, ref1, ref2);
    tsc_ref_min = min (tsc_ref_min, (unsigned long) tsc2);
    delta = ((u64) tsc_pit_min) * 100;
    do_div (delta, tsc_ref_min);
    if (delta >= 90 && delta <= 110) {
        printk (KERN_INFO "TSC: PIT calibration matches %s. %d loops\n", hpet ? "HPET" : "PMTIMER", i + 1);
        return tsc_ref_min;
    }
    if (i == 1 && tsc_pit_min == ULONG_MAX) {
        latch = CAL2_LATCH;
        ms = CAL2_MS;
        loopmin = CAL2_PIT_LOOPS;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="488" endline="493">
{
    printk (KERN_INFO "TSC: PIT calibration matches %s. %d loops\n", hpet ? "HPET" : "PMTIMER", i + 1);
    return tsc_ref_min;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="501" endline="505">
{
    latch = CAL2_LATCH;
    ms = CAL2_MS;
    loopmin = CAL2_PIT_LOOPS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="511" endline="533">
{
    printk (KERN_WARNING "TSC: Unable to calibrate against PIT\n");
    if (!hpet && !ref1 && !ref2) {
        printk ("TSC: No reference (HPET/PMTIMER) available\n");
        return 0;
    }
    if (tsc_ref_min == ULONG_MAX) {
        printk (KERN_WARNING "TSC: HPET/PMTIMER calibration " "failed.\n");
        return 0;
    }
    printk (KERN_INFO "TSC: using %s reference calibration\n", hpet ? "HPET" : "PMTIMER");
    return tsc_ref_min;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="516" endline="519">
{
    printk ("TSC: No reference (HPET/PMTIMER) available\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="522" endline="526">
{
    printk (KERN_WARNING "TSC: HPET/PMTIMER calibration " "failed.\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="536" endline="539">
{
    printk (KERN_INFO "TSC: Using PIT calibration value\n");
    return tsc_pit_min;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="542" endline="546">
{
    printk (KERN_WARNING "TSC: HPET/PMTIMER calibration failed. " "Using PIT calibration\n");
    return tsc_pit_min;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="560" endline="576">
{
    unsigned long cpu_khz_old = cpu_khz;
    if (cpu_has_tsc) {
        tsc_khz = x86_platform.calibrate_tsc ();
        cpu_khz = tsc_khz;
        cpu_data (0).loops_per_jiffy = cpufreq_scale (cpu_data (0).loops_per_jiffy, cpu_khz_old, cpu_khz);
        return 0;
    }
    else
        return -ENODEV;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="564" endline="571">
{
    tsc_khz = x86_platform.calibrate_tsc ();
    cpu_khz = tsc_khz;
    cpu_data (0).loops_per_jiffy = cpufreq_scale (cpu_data (0).loops_per_jiffy, cpu_khz_old, cpu_khz);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="607" endline="627">
{
    unsigned long long tsc_now, ns_now, *offset;
    unsigned long flags, *scale;
    local_irq_save (flags);
    sched_clock_idle_sleep_event ();
    scale = &per_cpu (cyc2ns, cpu);
    offset = &per_cpu (cyc2ns_offset, cpu);
    rdtscll (tsc_now);
    ns_now = __cycles_2_ns (tsc_now);
    if (cpu_khz) {
        *scale = (NSEC_PER_MSEC << CYC2NS_SCALE_FACTOR) / cpu_khz;
        *offset = ns_now - (tsc_now * *scale >> CYC2NS_SCALE_FACTOR);
    }
    sched_clock_idle_wakeup_event (0);
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="620" endline="623">
{
    *scale = (NSEC_PER_MSEC << CYC2NS_SCALE_FACTOR) / cpu_khz;
    *offset = ns_now - (tsc_now * *scale >> CYC2NS_SCALE_FACTOR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="717" endline="722">
{
    cycle_t ret = (cycle_t) get_cycles ();
    return ret >= clocksource_tsc.cycle_last ? ret : clocksource_tsc.cycle_last;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="744" endline="746">
{
    clocksource_tsc.cycle_last = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="763" endline="776">
{
    if (!tsc_unstable) {
        tsc_unstable = 1;
        sched_clock_stable = 0;
        printk (KERN_INFO "Marking TSC unstable due to %s\n", reason);
        if (clocksource_tsc.mult)
            clocksource_mark_unstable (&clocksource_tsc);
        else {
            clocksource_tsc.flags |= CLOCK_SOURCE_UNSTABLE;
            clocksource_tsc.rating = 0;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="764" endline="775">
{
    tsc_unstable = 1;
    sched_clock_stable = 0;
    printk (KERN_INFO "Marking TSC unstable due to %s\n", reason);
    if (clocksource_tsc.mult)
        clocksource_mark_unstable (&clocksource_tsc);
    else {
        clocksource_tsc.flags |= CLOCK_SOURCE_UNSTABLE;
        clocksource_tsc.rating = 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="771" endline="774">
{
    clocksource_tsc.flags |= CLOCK_SOURCE_UNSTABLE;
    clocksource_tsc.rating = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="781" endline="786">
{
    printk (KERN_NOTICE "%s detected: marking TSC unstable.\n", d -> ident);
    tsc_unstable = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="802" endline="815">
{
    if (boot_cpu_has (X86_FEATURE_TSC_RELIABLE))
        tsc_clocksource_reliable = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="822" endline="844">
{
    if (!cpu_has_tsc || tsc_unstable)
        return 1;
    if (boot_cpu_has (X86_FEATURE_CONSTANT_TSC))
        return 0;
    if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL) {
        if (num_possible_cpus () > 1)
            tsc_unstable = 1;
    }
    return tsc_unstable;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="837" endline="841">
{
    if (num_possible_cpus () > 1)
        tsc_unstable = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="847" endline="858">
{
    clocksource_tsc.mult = clocksource_khz2mult (tsc_khz, clocksource_tsc.shift);
    if (tsc_clocksource_reliable)
        clocksource_tsc.flags &= ~CLOCK_SOURCE_MUST_VERIFY;
    if (check_tsc_unstable ()) {
        clocksource_tsc.rating = 0;
        clocksource_tsc.flags &= ~CLOCK_SOURCE_IS_CONTINUOUS;
    }
    clocksource_register (& clocksource_tsc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="853" endline="856">
{
    clocksource_tsc.rating = 0;
    clocksource_tsc.flags &= ~CLOCK_SOURCE_IS_CONTINUOUS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="911" endline="911">
{
    return cpu_khz;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="915" endline="968">
{
    u64 lpj;
    int cpu;
    x86_init.timers.tsc_pre_init ();
    if (!cpu_has_tsc)
        return;
    tsc_khz = x86_platform.calibrate_tsc ();
    cpu_khz = tsc_khz;
    if (!tsc_khz) {
        mark_tsc_unstable ("could not calculate TSC khz");
        return;
    }
    if (cpu_has (&boot_cpu_data, X86_FEATURE_CONSTANT_TSC) && (boot_cpu_data.x86_vendor == X86_VENDOR_AMD))
        cpu_khz = calibrate_cpu ();
    printk ("Detected %lu.%03lu MHz processor.\n", (unsigned long) cpu_khz / 1000, (unsigned long) cpu_khz % 1000);
    for_each_possible_cpu (cpu)
    set_cyc2ns_scale (cpu_khz, cpu);
    if (tsc_disabled > 0)
        return;
    tsc_disabled = 0;
    lpj = ((u64) tsc_khz * 1000);
    do_div (lpj, HZ);
    lpj_fine = lpj;
    use_tsc_delay ();
    dmi_check_system (bad_tsc_dmi_table);
    if (unsynchronized_tsc ())
        mark_tsc_unstable ("TSCs unsynchronized");
    check_system_tsc_reliable ();
    init_tsc_clocksource ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc.c.ifdefed" startline="927" endline="930">
{
    mark_tsc_unstable ("could not calculate TSC khz");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/head.c.ifdefed" startline="20" endline="55">
{
    unsigned int lowmem, ebda_addr;
    if (paravirt_enabled ())
        return;
    lowmem = *(unsignedshort*) __va (BIOS_LOWMEM_KILOBYTES);
    lowmem <<= 10;
    ebda_addr = get_bios_ebda ();
    if ((lowmem - ebda_addr) <= 0x10000)
        lowmem = ebda_addr;
    if ((ebda_addr == 0) && (lowmem >= 0x9f000))
        lowmem = 0x9f000;
    if ((lowmem == 0) || (lowmem >= 0x100000))
        lowmem = 0x9f000;
    reserve_early_overlap_ok (lowmem, 0x100000, "BIOS reserved");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="70" endline="74">
{
    struct pci_dev *pdev = to_pci_dev (dev);
    return calc_devid (pdev->bus->number, pdev->devfn);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="77" endline="79">
{
    return dev->archdata.iommu;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="86" endline="107">
{
    struct dma_ops_domain *entry, *ret = NULL;
    unsigned long flags;
    u16 alias = amd_iommu_alias_table[devid];
    if (list_empty (&iommu_pd_list))
        return NULL;
    spin_lock_irqsave (& iommu_pd_list_lock, flags);
    list_for_each_entry (entry, &iommu_pd_list, list) {
        if (entry->target_dev == devid || entry->target_dev == alias) {
            ret = entry;
            break;
        }
    }
    spin_unlock_irqrestore (& iommu_pd_list_lock, flags);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="96" endline="102">
{
    if (entry->target_dev == devid || entry->target_dev == alias) {
        ret = entry;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="98" endline="101">
{
    ret = entry;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="114" endline="134">
{
    u16 devid;
    if (!dev || !dev->dma_mask)
        return false;
    if (dev->bus != &pci_bus_type)
        return false;
    devid = get_device_id (dev);
    if (devid > amd_iommu_last_bdf)
        return false;
    if (amd_iommu_rlookup_table[devid] == NULL)
        return false;
    return true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="137" endline="163">
{
    struct iommu_dev_data *dev_data;
    struct pci_dev *pdev;
    u16 devid, alias;
    if (dev->archdata.iommu)
        return 0;
    dev_data = kzalloc (sizeof (*dev_data), GFP_KERNEL);
    if (!dev_data)
        return -ENOMEM;
    dev_data->dev = dev;
    devid = get_device_id (dev);
    alias = amd_iommu_alias_table[devid];
    pdev = pci_get_bus_and_slot (PCI_BUS (alias), alias &0xff);
    if (pdev)
        dev_data->alias = &pdev->dev;
    atomic_set (& dev_data -> bind, 0);
    dev->archdata.iommu = dev_data;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="166" endline="168">
{
    kfree (dev -> archdata.iommu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="171" endline="181">
{
    struct pci_dev *pdev = NULL;

    for_each_pci_dev (pdev) {
        if (!check_device (&pdev->dev))
            continue;
        iommu_uninit_device (& pdev -> dev);
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="174" endline="180">
{
    if (!check_device (&pdev->dev))
        continue;
    iommu_uninit_device (& pdev -> dev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="184" endline="205">
{
    struct pci_dev *pdev = NULL;
    int ret = 0;

    for_each_pci_dev (pdev) {
        if (!check_device (&pdev->dev))
            continue;
        ret = iommu_init_device (&pdev->dev);
        if (ret)
            goto out_free;
    }

    return 0;
out_free :
    amd_iommu_uninit_devices ();
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="188" endline="196">
{
    if (!check_device (&pdev->dev))
        continue;
    ret = iommu_init_device (&pdev->dev);
    if (ret)
        goto out_free;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="269" endline="275">
{
    int i;
    for (i = 0; i < 8; ++i)
        pr_err ("AMD-Vi: DTE[%d]: %08x\n", i, amd_iommu_dev_table[devid].data[i]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="278" endline="284">
{
    struct iommu_cmd *cmd = phys_to_virt (phys_addr);
    int i;
    for (i = 0; i < 4; ++i)
        pr_err ("AMD-Vi: CMD[%d]: %08x\n", i, cmd->data[i]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="287" endline="348">
{
    u32 *event = __evt;
    int type = (event[1] >> EVENT_TYPE_SHIFT) & EVENT_TYPE_MASK;
    int devid = (event[0] >> EVENT_DEVID_SHIFT) & EVENT_DEVID_MASK;
    int domid = (event[1] >> EVENT_DOMID_SHIFT) & EVENT_DOMID_MASK;
    int flags = (event[1] >> EVENT_FLAGS_SHIFT) & EVENT_FLAGS_MASK;
    u64 address = (u64) (((u64) event[3]) << 32) | event[2];
    printk (KERN_ERR "AMD-Vi: Event logged [");
    switch (type) {
    case EVENT_TYPE_ILL_DEV :
        printk ("ILLEGAL_DEV_TABLE_ENTRY device=%02x:%02x.%x " "address=0x%016llx flags=0x%04x]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), address, flags);
        dump_dte_entry (devid);
        break;
    case EVENT_TYPE_IO_FAULT :
        printk ("IO_PAGE_FAULT device=%02x:%02x.%x " "domain=0x%04x address=0x%016llx flags=0x%04x]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), domid, address, flags);
        break;
    case EVENT_TYPE_DEV_TAB_ERR :
        printk ("DEV_TAB_HARDWARE_ERROR device=%02x:%02x.%x " "address=0x%016llx flags=0x%04x]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), address, flags);
        break;
    case EVENT_TYPE_PAGE_TAB_ERR :
        printk ("PAGE_TAB_HARDWARE_ERROR device=%02x:%02x.%x " "domain=0x%04x address=0x%016llx flags=0x%04x]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), domid, address, flags);
        break;
    case EVENT_TYPE_ILL_CMD :
        printk ("ILLEGAL_COMMAND_ERROR address=0x%016llx]\n", address);
        iommu->reset_in_progress = true;
        reset_iommu_command_buffer (iommu);
        dump_command (address);
        break;
    case EVENT_TYPE_CMD_HARD_ERR :
        printk ("COMMAND_HARDWARE_ERROR address=0x%016llx " "flags=0x%04x]\n", address, flags);
        break;
    case EVENT_TYPE_IOTLB_INV_TO :
        printk ("IOTLB_INV_TIMEOUT device=%02x:%02x.%x " "address=0x%016llx]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), address);
        break;
    case EVENT_TYPE_INV_DEV_REQ :
        printk ("INVALID_DEVICE_REQUEST device=%02x:%02x.%x " "address=0x%016llx flags=0x%04x]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), address, flags);
        break;
    default :
        printk (KERN_ERR "UNKNOWN type=0x%02x]\n", type);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="297" endline="347">
{
case EVENT_TYPE_ILL_DEV :
    printk ("ILLEGAL_DEV_TABLE_ENTRY device=%02x:%02x.%x " "address=0x%016llx flags=0x%04x]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), address, flags);
    dump_dte_entry (devid);
    break;
case EVENT_TYPE_IO_FAULT :
    printk ("IO_PAGE_FAULT device=%02x:%02x.%x " "domain=0x%04x address=0x%016llx flags=0x%04x]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), domid, address, flags);
    break;
case EVENT_TYPE_DEV_TAB_ERR :
    printk ("DEV_TAB_HARDWARE_ERROR device=%02x:%02x.%x " "address=0x%016llx flags=0x%04x]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), address, flags);
    break;
case EVENT_TYPE_PAGE_TAB_ERR :
    printk ("PAGE_TAB_HARDWARE_ERROR device=%02x:%02x.%x " "domain=0x%04x address=0x%016llx flags=0x%04x]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), domid, address, flags);
    break;
case EVENT_TYPE_ILL_CMD :
    printk ("ILLEGAL_COMMAND_ERROR address=0x%016llx]\n", address);
    iommu->reset_in_progress = true;
    reset_iommu_command_buffer (iommu);
    dump_command (address);
    break;
case EVENT_TYPE_CMD_HARD_ERR :
    printk ("COMMAND_HARDWARE_ERROR address=0x%016llx " "flags=0x%04x]\n", address, flags);
    break;
case EVENT_TYPE_IOTLB_INV_TO :
    printk ("IOTLB_INV_TIMEOUT device=%02x:%02x.%x " "address=0x%016llx]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), address);
    break;
case EVENT_TYPE_INV_DEV_REQ :
    printk ("INVALID_DEVICE_REQUEST device=%02x:%02x.%x " "address=0x%016llx flags=0x%04x]\n", PCI_BUS (devid), PCI_SLOT (devid), PCI_FUNC (devid), address, flags);
    break;
default :
    printk (KERN_ERR "UNKNOWN type=0x%02x]\n", type);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="351" endline="368">
{
    u32 head, tail;
    unsigned long flags;
    spin_lock_irqsave (& iommu -> lock, flags);
    head = readl (iommu->mmio_base + MMIO_EVT_HEAD_OFFSET);
    tail = readl (iommu->mmio_base + MMIO_EVT_TAIL_OFFSET);
    while (head != tail) {
        iommu_print_event (iommu, iommu -> evt_buf + head);
        head = (head + EVENT_ENTRY_SIZE) % iommu->evt_buf_size;
    }
    writel (head, iommu -> mmio_base + MMIO_EVT_HEAD_OFFSET);
    spin_unlock_irqrestore (& iommu -> lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="360" endline="363">
{
    iommu_print_event (iommu, iommu -> evt_buf + head);
    head = (head + EVENT_ENTRY_SIZE) % iommu->evt_buf_size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="371" endline="378">
{
    struct amd_iommu *iommu;
    for_each_iommu (iommu)
    iommu_poll_events (iommu);
    return IRQ_HANDLED;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="391" endline="406">
{
    u32 tail, head;
    u8 *target;
    WARN_ON (iommu -> cmd_buf_size & CMD_BUFFER_UNINITIALIZED);
    tail = readl (iommu->mmio_base + MMIO_CMD_TAIL_OFFSET);
    target = iommu->cmd_buf + tail;
    memcpy_toio (target, cmd, sizeof (* cmd));
    tail = (tail + sizeof (*cmd)) % iommu->cmd_buf_size;
    head = readl (iommu->mmio_base + MMIO_CMD_HEAD_OFFSET);
    if (tail == head)
        return -ENOMEM;
    writel (tail, iommu -> mmio_base + MMIO_CMD_TAIL_OFFSET);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="413" endline="424">
{
    unsigned long flags;
    int ret;
    spin_lock_irqsave (& iommu -> lock, flags);
    ret = __iommu_queue_command (iommu, cmd);
    if (!ret)
        iommu->need_sync = true;
    spin_unlock_irqrestore (& iommu -> lock, flags);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="431" endline="451">
{
    int ready = 0;
    unsigned status = 0;
    unsigned long i = 0;
    INC_STATS_COUNTER (compl_wait);
    while (!ready && (i < EXIT_LOOP_COUNT)) {
        ++i;
        status = readl (iommu->mmio_base + MMIO_STATUS_OFFSET);
        ready = status & MMIO_STATUS_COM_WAIT_INT_MASK;
    }
    status &= ~MMIO_STATUS_COM_WAIT_INT_MASK;
    writel (status, iommu -> mmio_base + MMIO_STATUS_OFFSET);
    if (unlikely (i == EXIT_LOOP_COUNT))
        iommu->reset_in_progress = true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="438" endline="443">
{
    ++i;
    status = readl (iommu->mmio_base + MMIO_STATUS_OFFSET);
    ready = status & MMIO_STATUS_COM_WAIT_INT_MASK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="458" endline="466">
{
    struct iommu_cmd cmd;
    memset (& cmd, 0, sizeof (cmd));
    cmd.data[0] = CMD_COMPL_WAIT_INT_MASK;
    CMD_SET_TYPE (& cmd, CMD_COMPL_WAIT);
    return __iommu_queue_command (iommu, &cmd);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="476" endline="501">
{
    int ret = 0;
    unsigned long flags;
    spin_lock_irqsave (& iommu -> lock, flags);
    if (!iommu->need_sync)
        goto out;
    ret = __iommu_completion_wait (iommu);
    iommu->need_sync = false;
    if (ret)
        goto out;
    __iommu_wait_for_completion (iommu);
out :
    spin_unlock_irqrestore (&iommu->lock, flags);
    if (iommu->reset_in_progress)
        reset_iommu_command_buffer (iommu);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="504" endline="517">
{
    int i;
    for (i = 0; i < amd_iommus_present; ++i) {
        if (!domain->dev_iommu[i])
            continue;
        iommu_completion_wait (amd_iommus [i]);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="507" endline="516">
{
    if (!domain->dev_iommu[i])
        continue;
    iommu_completion_wait (amd_iommus [i]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="523" endline="537">
{
    struct amd_iommu *iommu;
    struct iommu_cmd cmd;
    u16 devid;
    devid = get_device_id (dev);
    iommu = amd_iommu_rlookup_table[devid];
    memset (& cmd, 0, sizeof (cmd));
    CMD_SET_TYPE (& cmd, CMD_INV_DEV_ENTRY);
    cmd.data[0] = devid;
    return iommu_queue_command (iommu, &cmd);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="541" endline="552">
{
    memset (cmd, 0, sizeof (* cmd));
    address &= PAGE_MASK;
    CMD_SET_TYPE (cmd, CMD_INV_IOMMU_PAGES);
    cmd->data[1] |= domid;
    cmd->data[2] = lower_32_bits (address);
    cmd->data[3] = upper_32_bits (address);
    if (s)
        cmd->data[2] |= CMD_INV_IOMMU_PAGES_SIZE_MASK;
    if (pde)
        cmd->data[2] |= CMD_INV_IOMMU_PAGES_PDE_MASK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="559" endline="568">
{
    struct iommu_cmd cmd;
    int ret;
    __iommu_build_inv_iommu_pages (& cmd, address, domid, pde, s);
    ret = iommu_queue_command (iommu, &cmd);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="577" endline="606">
{
    int s = 0, i;
    unsigned long pages = iommu_num_pages (address, size, PAGE_SIZE);
    address &= PAGE_MASK;
    if (pages > 1) {
        address = CMD_INV_IOMMU_ALL_PAGES_ADDRESS;
        s = 1;
    }
    for (i = 0; i < amd_iommus_present; ++i) {
        if (!domain->dev_iommu[i])
            continue;
        iommu_queue_inv_iommu_pages (amd_iommus [i], address, domain -> id, pde, s);
    }
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="583" endline="590">
{
    address = CMD_INV_IOMMU_ALL_PAGES_ADDRESS;
    s = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="593" endline="603">
{
    if (!domain->dev_iommu[i])
        continue;
    iommu_queue_inv_iommu_pages (amd_iommus [i], address, domain -> id, pde, s);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="610" endline="612">
{
    __iommu_flush_pages (domain, address, size, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="616" endline="618">
{
    __iommu_flush_pages (domain, 0, CMD_INV_IOMMU_ALL_PAGES_ADDRESS, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="622" endline="624">
{
    __iommu_flush_pages (domain, 0, CMD_INV_IOMMU_ALL_PAGES_ADDRESS, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="631" endline="641">
{
    struct iommu_dev_data *dev_data;
    unsigned long flags;
    spin_lock_irqsave (& domain -> lock, flags);
    list_for_each_entry (dev_data, &domain->dev_list, list)
        iommu_flush_device (dev_data->dev);
    spin_unlock_irqrestore (& domain -> lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="644" endline="656">
{
    struct protection_domain *domain;
    unsigned long flags;
    spin_lock_irqsave (& amd_iommu_pd_lock, flags);
    list_for_each_entry (domain, &amd_iommu_pd_list, list) {
        iommu_flush_domain_devices (domain);
        iommu_flush_complete (domain);
    }
    spin_unlock_irqrestore (& amd_iommu_pd_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="650" endline="653">
{
    iommu_flush_domain_devices (domain);
    iommu_flush_complete (domain);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="659" endline="661">
{
    iommu_flush_all_domain_devices ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="668" endline="682">
{
    struct protection_domain *domain;
    unsigned long flags;
    spin_lock_irqsave (& amd_iommu_pd_lock, flags);
    list_for_each_entry (domain, &amd_iommu_pd_list, list) {
        spin_lock (& domain -> lock);
        iommu_flush_tlb_pde (domain);
        iommu_flush_complete (domain);
        spin_unlock (& domain -> lock);
    }
    spin_unlock_irqrestore (& amd_iommu_pd_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="674" endline="679">
{
    spin_lock (& domain -> lock);
    iommu_flush_tlb_pde (domain);
    iommu_flush_complete (domain);
    spin_unlock (& domain -> lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="685" endline="696">
{
    pr_err ("AMD-Vi: Resetting IOMMU command buffer\n");
    if (iommu->reset_in_progress)
        panic ("AMD-Vi: ILLEGAL_COMMAND_ERROR while resetting command buffer\n");
    amd_iommu_reset_cmd_buffer (iommu);
    amd_iommu_flush_all_devices ();
    amd_iommu_flush_all_domains ();
    iommu->reset_in_progress = false;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="712" endline="730">
{
    u64 *pte;
    if (domain->mode == PAGE_MODE_6_LEVEL)
        return false;
    pte = (void *) get_zeroed_page (gfp);
    if (!pte)
        return false;
    *pte = PM_LEVEL_PDE (domain->mode, virt_to_phys (domain->pt_root));
    domain->pt_root = pte;
    domain->mode += 1;
    domain->updated = true;
    return true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="737" endline="766">
{
    u64 *pte, *page;
    int level;
    while (address > PM_LEVEL_SIZE (domain->mode))
        increase_address_space (domain, gfp);
    level = domain->mode - 1;
    pte = &domain->pt_root[PM_LEVEL_INDEX (level, address)];
    while (level > end_lvl) {
        if (!IOMMU_PTE_PRESENT (*pte)) {
            page = (u64 *) get_zeroed_page (gfp);
            if (!page)
                return NULL;
            *pte = PM_LEVEL_PDE (level, virt_to_phys (page));
        }
        level -= 1;
        pte = IOMMU_PTE_PAGE (*pte);
        if (pte_page && level == end_lvl)
            *pte_page = pte;
        pte = &pte[PM_LEVEL_INDEX (level, address)];
    }
    return pte;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="747" endline="763">
{
    if (!IOMMU_PTE_PRESENT (*pte)) {
        page = (u64 *) get_zeroed_page (gfp);
        if (!page)
            return NULL;
        *pte = PM_LEVEL_PDE (level, virt_to_phys (page));
    }
    level -= 1;
    pte = IOMMU_PTE_PAGE (*pte);
    if (pte_page && level == end_lvl)
        *pte_page = pte;
    pte = &pte[PM_LEVEL_INDEX (level, address)];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="748" endline="753">
{
    page = (u64 *) get_zeroed_page (gfp);
    if (!page)
        return NULL;
    *pte = PM_LEVEL_PDE (level, virt_to_phys (page));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="774" endline="797">
{
    int level;
    u64 *pte;
    level = domain->mode - 1;
    pte = &domain->pt_root[PM_LEVEL_INDEX (level, address)];
    while (level > map_size) {
        if (!IOMMU_PTE_PRESENT (*pte))
            return NULL;
        level -= 1;
        pte = IOMMU_PTE_PAGE (*pte);
        pte = &pte[PM_LEVEL_INDEX (level, address)];
        if ((PM_PTE_LEVEL (*pte) == 0) && level != map_size) {
            pte = NULL;
            break;
        }
    }
    return pte;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="781" endline="794">
{
    if (!IOMMU_PTE_PRESENT (*pte))
        return NULL;
    level -= 1;
    pte = IOMMU_PTE_PAGE (*pte);
    pte = &pte[PM_LEVEL_INDEX (level, address)];
    if ((PM_PTE_LEVEL (*pte) == 0) && level != map_size) {
        pte = NULL;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="790" endline="793">
{
    pte = NULL;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="811" endline="839">
{
    u64 __pte, *pte;
    bus_addr = PAGE_ALIGN (bus_addr);
    phys_addr = PAGE_ALIGN (phys_addr);
    BUG_ON (! PM_ALIGNED (map_size, bus_addr));
    BUG_ON (! PM_ALIGNED (map_size, phys_addr));
    if (!(prot & IOMMU_PROT_MASK))
        return -EINVAL;
    pte = alloc_pte (dom, bus_addr, map_size, NULL, GFP_KERNEL);
    if (IOMMU_PTE_PRESENT (*pte))
        return -EBUSY;
    __pte = phys_addr | IOMMU_PTE_P;
    if (prot & IOMMU_PROT_IR)
        __pte |= IOMMU_PTE_IR;
    if (prot & IOMMU_PROT_IW)
        __pte |= IOMMU_PTE_IW;
    *pte = __pte;
    update_domain (dom);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="843" endline="848">
{
    u64 *pte = fetch_pte (dom, bus_addr, map_size);
    if (pte)
        *pte = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="856" endline="866">
{
    u16 bdf, i;
    for (i = entry->devid_start; i <= entry->devid_end; ++i) {
        bdf = amd_iommu_alias_table[i];
        if (amd_iommu_rlookup_table[bdf] == iommu)
            return 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="859" endline="863">
{
    bdf = amd_iommu_alias_table[i];
    if (amd_iommu_rlookup_table[bdf] == iommu)
        return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="874" endline="894">
{
    u64 addr;
    int ret;
    for (addr = e->address_start; addr < e->address_end; addr += PAGE_SIZE) {
        ret = iommu_map_page (&dma_dom->domain, addr, addr, e->prot, PM_MAP_4k);
        if (ret)
            return ret;
        if (addr < dma_dom->aperture_size)
            __set_bit (addr >> PAGE_SHIFT, dma_dom->aperture[0]->bitmap);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="879" endline="891">
{
    ret = iommu_map_page (&dma_dom->domain, addr, addr, e->prot, PM_MAP_4k);
    if (ret)
        return ret;
    if (addr < dma_dom->aperture_size)
        __set_bit (addr >> PAGE_SHIFT, dma_dom->aperture[0]->bitmap);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="903" endline="916">
{
    struct unity_map_entry *entry;
    int ret;
    list_for_each_entry (entry, &amd_iommu_unity_map, list) {
        if (!iommu_for_unity_map (iommu, entry))
            continue;
        ret = dma_ops_unity_map (iommu->default_dom, entry);
        if (ret)
            return ret;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="907" endline="913">
{
    if (!iommu_for_unity_map (iommu, entry))
        continue;
    ret = dma_ops_unity_map (iommu->default_dom, entry);
    if (ret)
        return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="923" endline="936">
{
    struct unity_map_entry *e;
    int ret;
    list_for_each_entry (e, &amd_iommu_unity_map, list) {
        if (!(devid >= e->devid_start && devid <= e->devid_end))
            continue;
        ret = dma_ops_unity_map (dma_dom, e);
        if (ret)
            return ret;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="927" endline="933">
{
    if (!(devid >= e->devid_start && devid <= e->devid_end))
        continue;
    ret = dma_ops_unity_map (dma_dom, e);
    if (ret)
        return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="961" endline="972">
{
    unsigned int i, last_page = dom->aperture_size >> PAGE_SHIFT;
    if (start_page + pages > last_page)
        pages = last_page - start_page;
    for (i = start_page; i < start_page + pages; ++i) {
        int index = i / APERTURE_RANGE_PAGES;
        int page = i % APERTURE_RANGE_PAGES;
        __set_bit (page, dom -> aperture [index] -> bitmap);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="967" endline="971">
{
    int index = i / APERTURE_RANGE_PAGES;
    int page = i % APERTURE_RANGE_PAGES;
    __set_bit (page, dom -> aperture [index] -> bitmap);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="981" endline="1065">
{
    int index = dma_dom->aperture_size >> APERTURE_RANGE_SHIFT;
    struct amd_iommu *iommu;
    unsigned long i;
    if (index >= APERTURE_MAX_RANGES)
        return -ENOMEM;
    dma_dom->aperture[index] = kzalloc (sizeof (struct aperture_range), gfp);
    if (!dma_dom->aperture[index])
        return -ENOMEM;
    dma_dom->aperture[index]->bitmap = (void *) get_zeroed_page (gfp);
    if (!dma_dom->aperture[index]->bitmap)
        goto out_free;
    dma_dom->aperture[index]->offset = dma_dom->aperture_size;
    if (populate) {
        unsigned long address = dma_dom->aperture_size;
        int i, num_ptes = APERTURE_RANGE_PAGES / 512;
        u64 *pte, *pte_page;
        for (i = 0; i < num_ptes; ++i) {
            pte = alloc_pte (&dma_dom->domain, address, PM_MAP_4k, &pte_page, gfp);
            if (!pte)
                goto out_free;
            dma_dom->aperture[index]->pte_pages[i] = pte_page;
            address += APERTURE_RANGE_SIZE / 64;
        }
    }
    dma_dom->aperture_size += APERTURE_RANGE_SIZE;

    for_each_iommu (iommu) {
        if (iommu->exclusion_start && iommu->exclusion_start >= dma_dom->aperture[index]->offset && iommu->exclusion_start < dma_dom->aperture_size) {
            unsigned long startpage;
            int pages = iommu_num_pages (iommu->exclusion_start, iommu->exclusion_length, PAGE_SIZE);
            startpage = iommu->exclusion_start >> PAGE_SHIFT;
            dma_ops_reserve_addresses (dma_dom, startpage, pages);
        }
    }

    for (i = dma_dom->aperture[index]->offset; i < dma_dom->aperture_size; i += PAGE_SIZE) {
        u64 *pte = fetch_pte (&dma_dom->domain, i, PM_MAP_4k);
        if (!pte || !IOMMU_PTE_PRESENT (*pte))
            continue;
        dma_ops_reserve_addresses (dma_dom, i << PAGE_SHIFT, 1);
    }
    update_domain (& dma_dom -> domain);
    return 0;
out_free :
    update_domain (&dma_dom->domain);
    free_page ((unsigned long) dma_dom -> aperture [index] -> bitmap);
    kfree (dma_dom -> aperture [index]);
    dma_dom->aperture[index] = NULL;
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1003" endline="1018">
{
    unsigned long address = dma_dom->aperture_size;
    int i, num_ptes = APERTURE_RANGE_PAGES / 512;
    u64 *pte, *pte_page;
    for (i = 0; i < num_ptes; ++i) {
        pte = alloc_pte (&dma_dom->domain, address, PM_MAP_4k, &pte_page, gfp);
        if (!pte)
            goto out_free;
        dma_dom->aperture[index]->pte_pages[i] = pte_page;
        address += APERTURE_RANGE_SIZE / 64;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1008" endline="1017">
{
    pte = alloc_pte (&dma_dom->domain, address, PM_MAP_4k, &pte_page, gfp);
    if (!pte)
        goto out_free;
    dma_dom->aperture[index]->pte_pages[i] = pte_page;
    address += APERTURE_RANGE_SIZE / 64;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1023" endline="1034">
{
    if (iommu->exclusion_start && iommu->exclusion_start >= dma_dom->aperture[index]->offset && iommu->exclusion_start < dma_dom->aperture_size) {
        unsigned long startpage;
        int pages = iommu_num_pages (iommu->exclusion_start, iommu->exclusion_length, PAGE_SIZE);
        startpage = iommu->exclusion_start >> PAGE_SHIFT;
        dma_ops_reserve_addresses (dma_dom, startpage, pages);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1026" endline="1033">
{
    unsigned long startpage;
    int pages = iommu_num_pages (iommu->exclusion_start, iommu->exclusion_length, PAGE_SIZE);
    startpage = iommu->exclusion_start >> PAGE_SHIFT;
    dma_ops_reserve_addresses (dma_dom, startpage, pages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1044" endline="1050">
{
    u64 *pte = fetch_pte (&dma_dom->domain, i, PM_MAP_4k);
    if (!pte || !IOMMU_PTE_PRESENT (*pte))
        continue;
    dma_ops_reserve_addresses (dma_dom, i << PAGE_SHIFT, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1073" endline="1109">
{
    unsigned long next_bit = dom->next_address % APERTURE_RANGE_SIZE;
    int max_index = dom->aperture_size >> APERTURE_RANGE_SHIFT;
    int i = start >> APERTURE_RANGE_SHIFT;
    unsigned long boundary_size;
    unsigned long address = -1;
    unsigned long limit;
    next_bit >>= PAGE_SHIFT;
    boundary_size = ALIGN (dma_get_seg_boundary (dev) +1, PAGE_SIZE) >> PAGE_SHIFT;
    for (; i < max_index; ++i) {
        unsigned long offset = dom->aperture[i]->offset >> PAGE_SHIFT;
        if (dom->aperture[i]->offset >= dma_mask)
            break;
        limit = iommu_device_max_index (APERTURE_RANGE_PAGES, offset, dma_mask >> PAGE_SHIFT);
        address = iommu_area_alloc (dom->aperture[i]->bitmap, limit, next_bit, pages, 0, boundary_size, align_mask);
        if (address != -1) {
            address = dom->aperture[i]->offset + (address << PAGE_SHIFT);
            dom->next_address = address + (pages << PAGE_SHIFT);
            break;
        }
        next_bit = 0;
    }
    return address;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1086" endline="1106">
{
    unsigned long offset = dom->aperture[i]->offset >> PAGE_SHIFT;
    if (dom->aperture[i]->offset >= dma_mask)
        break;
    limit = iommu_device_max_index (APERTURE_RANGE_PAGES, offset, dma_mask >> PAGE_SHIFT);
    address = iommu_area_alloc (dom->aperture[i]->bitmap, limit, next_bit, pages, 0, boundary_size, align_mask);
    if (address != -1) {
        address = dom->aperture[i]->offset + (address << PAGE_SHIFT);
        dom->next_address = address + (pages << PAGE_SHIFT);
        break;
    }
    next_bit = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1098" endline="1103">
{
    address = dom->aperture[i]->offset + (address << PAGE_SHIFT);
    dom->next_address = address + (pages << PAGE_SHIFT);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1116" endline="1140">
{
    unsigned long address;
    address = dma_ops_area_alloc (dev, dom, pages, align_mask, dma_mask, dom->next_address);
    if (address == -1) {
        dom->next_address = 0;
        address = dma_ops_area_alloc (dev, dom, pages, align_mask, dma_mask, 0);
        dom->need_flush = true;
    }
    if (unlikely (address == -1))
        address = DMA_ERROR_CODE;
    WARN_ON ((address + (PAGE_SIZE * pages)) > dom -> aperture_size);
    return address;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1127" endline="1132">
{
    dom->next_address = 0;
    address = dma_ops_area_alloc (dev, dom, pages, align_mask, dma_mask, 0);
    dom->need_flush = true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1150" endline="1168">
{
    unsigned i = address >> APERTURE_RANGE_SHIFT;
    struct aperture_range *range = dom->aperture[i];
    BUG_ON (i >= APERTURE_MAX_RANGES || range == NULL);
    if (address >= dom->next_address)
        dom->need_flush = true;
    address = (address % APERTURE_RANGE_SIZE) >> PAGE_SHIFT;
    bitmap_clear (range -> bitmap, address, pages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1184" endline="1190">
{
    unsigned long flags;
    spin_lock_irqsave (& amd_iommu_pd_lock, flags);
    list_add (& domain -> list, & amd_iommu_pd_list);
    spin_unlock_irqrestore (& amd_iommu_pd_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1197" endline="1203">
{
    unsigned long flags;
    spin_lock_irqsave (& amd_iommu_pd_lock, flags);
    list_del (& domain -> list);
    spin_unlock_irqrestore (& amd_iommu_pd_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1206" endline="1220">
{
    unsigned long flags;
    int id;
    write_lock_irqsave (& amd_iommu_devtable_lock, flags);
    id = find_first_zero_bit (amd_iommu_pd_alloc_bitmap, MAX_DOMAIN_ID);
    BUG_ON (id == 0);
    if (id > 0 && id < MAX_DOMAIN_ID)
        __set_bit (id, amd_iommu_pd_alloc_bitmap);
    else
        id = 0;
    write_unlock_irqrestore (& amd_iommu_devtable_lock, flags);
    return id;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1223" endline="1230">
{
    unsigned long flags;
    write_lock_irqsave (& amd_iommu_devtable_lock, flags);
    if (id > 0 && id < MAX_DOMAIN_ID)
        __clear_bit (id, amd_iommu_pd_alloc_bitmap);
    write_unlock_irqrestore (& amd_iommu_devtable_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1233" endline="1260">
{
    int i, j;
    u64 *p1, *p2, *p3;
    p1 = domain->pt_root;
    if (!p1)
        return;
    for (i = 0; i < 512; ++i) {
        if (!IOMMU_PTE_PRESENT (p1[i]))
            continue;
        p2 = IOMMU_PTE_PAGE (p1[i]);
        for (j = 0; j < 512; ++j) {
            if (!IOMMU_PTE_PRESENT (p2[j]))
                continue;
            p3 = IOMMU_PTE_PAGE (p2[j]);
            free_page ((unsigned long) p3);
        }
        free_page ((unsigned long) p2);
    }
    free_page ((unsigned long) p1);
    domain->pt_root = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1242" endline="1255">
{
    if (!IOMMU_PTE_PRESENT (p1[i]))
        continue;
    p2 = IOMMU_PTE_PAGE (p1[i]);
    for (j = 0; j < 512; ++j) {
        if (!IOMMU_PTE_PRESENT (p2[j]))
            continue;
        p3 = IOMMU_PTE_PAGE (p2[j]);
        free_page ((unsigned long) p3);
    }
    free_page ((unsigned long) p2);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1247" endline="1252">
{
    if (!IOMMU_PTE_PRESENT (p2[j]))
        continue;
    p3 = IOMMU_PTE_PAGE (p2[j]);
    free_page ((unsigned long) p3);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1267" endline="1285">
{
    int i;
    if (!dom)
        return;
    del_domain_from_list (& dom -> domain);
    free_pagetable (& dom -> domain);
    for (i = 0; i < APERTURE_MAX_RANGES; ++i) {
        if (!dom->aperture[i])
            continue;
        free_page ((unsigned long) dom -> aperture [i] -> bitmap);
        kfree (dom -> aperture [i]);
    }
    kfree (dom);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1277" endline="1282">
{
    if (!dom->aperture[i])
        continue;
    free_page ((unsigned long) dom -> aperture [i] -> bitmap);
    kfree (dom -> aperture [i]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1293" endline="1335">
{
    struct dma_ops_domain *dma_dom;
    dma_dom = kzalloc (sizeof (struct dma_ops_domain), GFP_KERNEL);
    if (!dma_dom)
        return NULL;
    spin_lock_init (& dma_dom -> domain.lock);
    dma_dom->domain.id = domain_id_alloc ();
    if (dma_dom->domain.id == 0)
        goto free_dma_dom;
    INIT_LIST_HEAD (& dma_dom -> domain.dev_list);
    dma_dom->domain.mode = PAGE_MODE_2_LEVEL;
    dma_dom->domain.pt_root = (void *) get_zeroed_page (GFP_KERNEL);
    dma_dom->domain.flags = PD_DMA_OPS_MASK;
    dma_dom->domain.priv = dma_dom;
    if (!dma_dom->domain.pt_root)
        goto free_dma_dom;
    dma_dom->need_flush = false;
    dma_dom->target_dev = 0xffff;
    add_domain_to_list (& dma_dom -> domain);
    if (alloc_new_range (dma_dom, true, GFP_KERNEL))
        goto free_dma_dom;
    dma_dom->aperture[0]->bitmap[0] = 1;
    dma_dom->next_address = 0;
    return dma_dom;
free_dma_dom :
    dma_ops_domain_free (dma_dom);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1342" endline="1344">
{
    return domain->flags & PD_DMA_OPS_MASK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1347" endline="1357">
{
    u64 pte_root = virt_to_phys (domain->pt_root);
    pte_root |= (domain->mode & DEV_ENTRY_MODE_MASK) << DEV_ENTRY_MODE_SHIFT;
    pte_root |= IOMMU_PTE_IR | IOMMU_PTE_IW | IOMMU_PTE_P | IOMMU_PTE_TV;
    amd_iommu_dev_table[devid].data[2] = domain->id;
    amd_iommu_dev_table[devid].data[1] = upper_32_bits (pte_root);
    amd_iommu_dev_table[devid].data[0] = lower_32_bits (pte_root);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1360" endline="1367">
{
    amd_iommu_dev_table[devid].data[0] = IOMMU_PTE_P | IOMMU_PTE_TV;
    amd_iommu_dev_table[devid].data[1] = 0;
    amd_iommu_dev_table[devid].data[2] = 0;
    amd_iommu_apply_erratum_63 (devid);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1370" endline="1390">
{
    struct iommu_dev_data *dev_data;
    struct amd_iommu *iommu;
    u16 devid;
    devid = get_device_id (dev);
    iommu = amd_iommu_rlookup_table[devid];
    dev_data = get_dev_data (dev);
    dev_data->domain = domain;
    list_add (& dev_data -> list, & domain -> dev_list);
    set_dte_entry (devid, domain);
    domain->dev_iommu[iommu->index] += 1;
    domain->dev_cnt += 1;
    iommu_flush_device (dev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1393" endline="1413">
{
    struct iommu_dev_data *dev_data;
    struct amd_iommu *iommu;
    u16 devid;
    devid = get_device_id (dev);
    iommu = amd_iommu_rlookup_table[devid];
    dev_data = get_dev_data (dev);
    dev_data->domain->dev_iommu[iommu->index] -= 1;
    dev_data->domain->dev_cnt -= 1;
    dev_data->domain = NULL;
    list_del (& dev_data -> list);
    clear_dte_entry (devid);
    iommu_flush_device (dev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1421" endline="1460">
{
    struct iommu_dev_data *dev_data, *alias_data;
    dev_data = get_dev_data (dev);
    alias_data = get_dev_data (dev_data->alias);
    if (!alias_data)
        return -EINVAL;
    spin_lock (& domain -> lock);
    if (alias_data->domain != NULL && alias_data->domain != domain)
        return -EBUSY;
    if (dev_data->domain != NULL && dev_data->domain != domain)
        return -EBUSY;
    if (dev_data->alias != dev) {
        alias_data = get_dev_data (dev_data->alias);
        if (alias_data->domain == NULL)
            do_attach (dev_data->alias, domain);
        atomic_inc (& alias_data -> bind);
    }
    if (dev_data->domain == NULL)
        do_attach (dev, domain);
    atomic_inc (& dev_data -> bind);
    spin_unlock (& domain -> lock);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1443" endline="1449">
{
    alias_data = get_dev_data (dev_data->alias);
    if (alias_data->domain == NULL)
        do_attach (dev_data->alias, domain);
    atomic_inc (& alias_data -> bind);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1468" endline="1484">
{
    unsigned long flags;
    int ret;
    write_lock_irqsave (& amd_iommu_devtable_lock, flags);
    ret = __attach_device (dev, domain);
    write_unlock_irqrestore (& amd_iommu_devtable_lock, flags);
    iommu_flush_tlb_pde (domain);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1490" endline="1521">
{
    struct iommu_dev_data *dev_data = get_dev_data (dev);
    struct iommu_dev_data *alias_data;
    struct protection_domain *domain;
    unsigned long flags;
    BUG_ON (! dev_data -> domain);
    domain = dev_data->domain;
    spin_lock_irqsave (& domain -> lock, flags);
    if (dev_data->alias != dev) {
        alias_data = get_dev_data (dev_data->alias);
        if (atomic_dec_and_test (&alias_data->bind))
            do_detach (dev_data->alias);
    }
    if (atomic_dec_and_test (&dev_data->bind))
        do_detach (dev);
    spin_unlock_irqrestore (& domain -> lock, flags);
    if (iommu_pass_through && (dev_data->domain == NULL && domain != pt_domain))
        __attach_device (dev, pt_domain);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1502" endline="1506">
{
    alias_data = get_dev_data (dev_data->alias);
    if (atomic_dec_and_test (&alias_data->bind))
        do_detach (dev_data->alias);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1527" endline="1534">
{
    unsigned long flags;
    write_lock_irqsave (& amd_iommu_devtable_lock, flags);
    __detach_device (dev);
    write_unlock_irqrestore (& amd_iommu_devtable_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1541" endline="1565">
{
    struct protection_domain *dom;
    struct iommu_dev_data *dev_data, *alias_data;
    unsigned long flags;
    u16 devid, alias;
    devid = get_device_id (dev);
    alias = amd_iommu_alias_table[devid];
    dev_data = get_dev_data (dev);
    alias_data = get_dev_data (dev_data->alias);
    if (!alias_data)
        return NULL;
    read_lock_irqsave (& amd_iommu_devtable_lock, flags);
    dom = dev_data->domain;
    if (dom == NULL && alias_data->domain != NULL) {
        __attach_device (dev, alias_data -> domain);
        dom = alias_data->domain;
    }
    read_unlock_irqrestore (& amd_iommu_devtable_lock, flags);
    return dom;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1557" endline="1560">
{
    __attach_device (dev, alias_data -> domain);
    dom = alias_data->domain;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1569" endline="1627">
{
    struct device *dev = data;
    u16 devid;
    struct protection_domain *domain;
    struct dma_ops_domain *dma_domain;
    struct amd_iommu *iommu;
    unsigned long flags;
    if (!check_device (dev))
        return 0;
    devid = get_device_id (dev);
    iommu = amd_iommu_rlookup_table[devid];
    switch (action) {
    case BUS_NOTIFY_UNBOUND_DRIVER :
        domain = domain_for_device (dev);
        if (!domain)
            goto out;
        if (iommu_pass_through)
            break;
        detach_device (dev);
        break;
    case BUS_NOTIFY_ADD_DEVICE :
        iommu_init_device (dev);
        domain = domain_for_device (dev);
        dma_domain = find_protection_domain (devid);
        if (dma_domain)
            goto out;
        dma_domain = dma_ops_domain_alloc ();
        if (!dma_domain)
            goto out;
        dma_domain->target_dev = devid;
        spin_lock_irqsave (& iommu_pd_list_lock, flags);
        list_add_tail (& dma_domain -> list, & iommu_pd_list);
        spin_unlock_irqrestore (& iommu_pd_list_lock, flags);
        break;
    case BUS_NOTIFY_DEL_DEVICE :
        iommu_uninit_device (dev);
    default :
        goto out;
    }
    iommu_flush_device (dev);
    iommu_completion_wait (iommu);
out :
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1583" endline="1620">
{
case BUS_NOTIFY_UNBOUND_DRIVER :
    domain = domain_for_device (dev);
    if (!domain)
        goto out;
    if (iommu_pass_through)
        break;
    detach_device (dev);
    break;
case BUS_NOTIFY_ADD_DEVICE :
    iommu_init_device (dev);
    domain = domain_for_device (dev);
    dma_domain = find_protection_domain (devid);
    if (dma_domain)
        goto out;
    dma_domain = dma_ops_domain_alloc ();
    if (!dma_domain)
        goto out;
    dma_domain->target_dev = devid;
    spin_lock_irqsave (& iommu_pd_list_lock, flags);
    list_add_tail (& dma_domain -> list, & iommu_pd_list);
    spin_unlock_irqrestore (& iommu_pd_list_lock, flags);
    break;
case BUS_NOTIFY_DEL_DEVICE :
    iommu_uninit_device (dev);
default :
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1634" endline="1636">
{
    bus_register_notifier (& pci_bus_type, & device_nb);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1652" endline="1676">
{
    struct protection_domain *domain;
    struct dma_ops_domain *dma_dom;
    u16 devid = get_device_id (dev);
    if (!check_device (dev))
        return ERR_PTR (-EINVAL);
    domain = domain_for_device (dev);
    if (domain != NULL && !dma_ops_domain (domain))
        return ERR_PTR (-EBUSY);
    if (domain != NULL)
        return domain;
    dma_dom = find_protection_domain (devid);
    if (!dma_dom)
        dma_dom = amd_iommu_rlookup_table[devid]->default_dom;
    attach_device (dev, & dma_dom -> domain);
    DUMP_printk ("Using protection domain %d for device %s\n", dma_dom -> domain.id, dev_name (dev));
    return &dma_dom->domain;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1679" endline="1686">
{
    struct iommu_dev_data *dev_data;
    list_for_each_entry (dev_data, &domain->dev_list, list) {
        u16 devid = get_device_id (dev_data->dev);
        set_dte_entry (devid, domain);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1682" endline="1685">
{
    u16 devid = get_device_id (dev_data->dev);
    set_dte_entry (devid, domain);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1689" endline="1698">
{
    if (!domain->updated)
        return;
    update_device_table (domain);
    iommu_flush_domain_devices (domain);
    iommu_flush_tlb_pde (domain);
    domain->updated = false;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1705" endline="1724">
{
    struct aperture_range *aperture;
    u64 *pte, *pte_page;
    aperture = dom->aperture[APERTURE_RANGE_INDEX (address)];
    if (!aperture)
        return NULL;
    pte = aperture->pte_pages[APERTURE_PAGE_INDEX (address)];
    if (!pte) {
        pte = alloc_pte (&dom->domain, address, PM_MAP_4k, &pte_page, GFP_ATOMIC);
        aperture->pte_pages[APERTURE_PAGE_INDEX (address)] = pte_page;
    }
    else
        pte += PM_LEVEL_INDEX (0, address);
    update_domain (& dom -> domain);
    return pte;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1714" endline="1718">
{
    pte = alloc_pte (&dom->domain, address, PM_MAP_4k, &pte_page, GFP_ATOMIC);
    aperture->pte_pages[APERTURE_PAGE_INDEX (address)] = pte_page;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1734" endline="1759">
{
    u64 *pte, __pte;
    WARN_ON (address > dom -> aperture_size);
    paddr &= PAGE_MASK;
    pte = dma_ops_get_pte (dom, address);
    if (!pte)
        return DMA_ERROR_CODE;
    __pte = paddr | IOMMU_PTE_P | IOMMU_PTE_FC;
    if (direction == DMA_TO_DEVICE)
        __pte |= IOMMU_PTE_IR;
    else if (direction == DMA_FROM_DEVICE)
        __pte |= IOMMU_PTE_IW;
    else if (direction == DMA_BIDIRECTIONAL)
        __pte |= IOMMU_PTE_IR | IOMMU_PTE_IW;
    WARN_ON (*pte);
    *pte = __pte;
    return (dma_addr_t) address;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1766" endline="1786">
{
    struct aperture_range *aperture;
    u64 *pte;
    if (address >= dom->aperture_size)
        return;
    aperture = dom->aperture[APERTURE_RANGE_INDEX (address)];
    if (!aperture)
        return;
    pte = aperture->pte_pages[APERTURE_PAGE_INDEX (address)];
    if (!pte)
        return;
    pte += PM_LEVEL_INDEX (0, address);
    WARN_ON (! * pte);
    *pte = 0ULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1801" endline="1872">
{
    dma_addr_t offset = paddr & ~PAGE_MASK;
    dma_addr_t address, start, ret;
    unsigned int pages;
    unsigned long align_mask = 0;
    int i;
    pages = iommu_num_pages (paddr, size, PAGE_SIZE);
    paddr &= PAGE_MASK;
    INC_STATS_COUNTER (total_map_requests);
    if (pages > 1)
        INC_STATS_COUNTER (cross_page);
    if (align)
        align_mask = (1UL << get_order (size)) - 1;
retry :
    address = dma_ops_alloc_addresses (dev, dma_dom, pages, align_mask, dma_mask);
    if (unlikely (address == DMA_ERROR_CODE)) {
        dma_dom->next_address = dma_dom->aperture_size;
        if (alloc_new_range (dma_dom, false, GFP_ATOMIC))
            goto out;
        goto retry;
    }
    start = address;
    for (i = 0; i < pages; ++i) {
        ret = dma_ops_domain_map (dma_dom, start, paddr, dir);
        if (ret == DMA_ERROR_CODE)
            goto out_unmap;
        paddr += PAGE_SIZE;
        start += PAGE_SIZE;
    }
    address += offset;
    ADD_STATS_COUNTER (alloced_io_mem, size);
    if (unlikely (dma_dom->need_flush && !amd_iommu_unmap_flush)) {
        iommu_flush_tlb (& dma_dom -> domain);
        dma_dom->need_flush = false;
    }
    else if (unlikely (amd_iommu_np_cache))
        iommu_flush_pages (&dma_dom->domain, address, size);
out :
    return address;
out_unmap :
    for (--i; i >= 0; --i) {
        start -= PAGE_SIZE;
        dma_ops_domain_unmap (dma_dom, start);
    }
    dma_ops_free_addresses (dma_dom, address, pages);
    return DMA_ERROR_CODE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1822" endline="1838">
{
    dma_dom->next_address = dma_dom->aperture_size;
    if (alloc_new_range (dma_dom, false, GFP_ATOMIC))
        goto out;
    goto retry;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1841" endline="1848">
{
    ret = dma_ops_domain_map (dma_dom, start, paddr, dir);
    if (ret == DMA_ERROR_CODE)
        goto out_unmap;
    paddr += PAGE_SIZE;
    start += PAGE_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1853" endline="1856">
{
    iommu_flush_tlb (& dma_dom -> domain);
    dma_dom->need_flush = false;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1864" endline="1867">
{
    start -= PAGE_SIZE;
    dma_ops_domain_unmap (dma_dom, start);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1882" endline="1907">
{
    dma_addr_t i, start;
    unsigned int pages;
    if ((dma_addr == DMA_ERROR_CODE) || (dma_addr + size > dma_dom->aperture_size))
        return;
    pages = iommu_num_pages (dma_addr, size, PAGE_SIZE);
    dma_addr &= PAGE_MASK;
    start = dma_addr;
    for (i = 0; i < pages; ++i) {
        dma_ops_domain_unmap (dma_dom, start);
        start += PAGE_SIZE;
    }
    SUB_STATS_COUNTER (alloced_io_mem, size);
    dma_ops_free_addresses (dma_dom, dma_addr, pages);
    if (amd_iommu_unmap_flush || dma_dom->need_flush) {
        iommu_flush_pages (& dma_dom -> domain, dma_addr, size);
        dma_dom->need_flush = false;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1894" endline="1897">
{
    dma_ops_domain_unmap (dma_dom, start);
    start += PAGE_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1903" endline="1906">
{
    iommu_flush_pages (& dma_dom -> domain, dma_addr, size);
    dma_dom->need_flush = false;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1916" endline="1946">
{
    unsigned long flags;
    struct protection_domain *domain;
    dma_addr_t addr;
    u64 dma_mask;
    phys_addr_t paddr = page_to_phys (page) + offset;
    INC_STATS_COUNTER (cnt_map_single);
    domain = get_domain (dev);
    if (PTR_ERR (domain) == -EINVAL)
        return (dma_addr_t) paddr;
    else if (IS_ERR (domain))
        return DMA_ERROR_CODE;
    dma_mask = *dev->dma_mask;
    spin_lock_irqsave (& domain -> lock, flags);
    addr = __map_single (dev, domain->priv, paddr, size, dir, false, dma_mask);
    if (addr == DMA_ERROR_CODE)
        goto out;
    iommu_flush_complete (domain);
out :
    spin_unlock_irqrestore (&domain->lock, flags);
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1953" endline="1970">
{
    unsigned long flags;
    struct protection_domain *domain;
    INC_STATS_COUNTER (cnt_unmap_single);
    domain = get_domain (dev);
    if (IS_ERR (domain))
        return;
    spin_lock_irqsave (& domain -> lock, flags);
    __unmap_single (domain -> priv, dma_addr, size, dir);
    iommu_flush_complete (domain);
    spin_unlock_irqrestore (& domain -> lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1978" endline="1988">
{
    struct scatterlist *s;
    int i;

    for_each_sg (sglist, s, nelems, i) {
        s->dma_address = (dma_addr_t) sg_phys (s);
        s->dma_length = s->length;
    }

    return nelems;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1982" endline="1985">
{
    s->dma_address = (dma_addr_t) sg_phys (s);
    s->dma_length = s->length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="1997" endline="2049">
{
    unsigned long flags;
    struct protection_domain *domain;
    int i;
    struct scatterlist *s;
    phys_addr_t paddr;
    int mapped_elems = 0;
    u64 dma_mask;
    INC_STATS_COUNTER (cnt_map_sg);
    domain = get_domain (dev);
    if (PTR_ERR (domain) == -EINVAL)
        return map_sg_no_iommu (dev, sglist, nelems, dir);
    else if (IS_ERR (domain))
        return 0;
    dma_mask = *dev->dma_mask;
    spin_lock_irqsave (& domain -> lock, flags);

    for_each_sg (sglist, s, nelems, i) {
        paddr = sg_phys (s);
        s->dma_address = __map_single (dev, domain->priv, paddr, s->length, dir, false, dma_mask);
        if (s->dma_address) {
            s->dma_length = s->length;
            mapped_elems++;
        }
        else
            goto unmap;
    }

    iommu_flush_complete (domain);
out :
    spin_unlock_irqrestore (&domain->lock, flags);
    return mapped_elems;
unmap :

    for_each_sg (sglist, s, mapped_elems, i) {
        if (s->dma_address)
            __unmap_single (domain->priv, s->dma_address, s->dma_length, dir);
        s->dma_address = s->dma_length = 0;
    }

    mapped_elems = 0;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2018" endline="2030">
{
    paddr = sg_phys (s);
    s->dma_address = __map_single (dev, domain->priv, paddr, s->length, dir, false, dma_mask);
    if (s->dma_address) {
        s->dma_length = s->length;
        mapped_elems++;
    }
    else
        goto unmap;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2025" endline="2028">
{
    s->dma_length = s->length;
    mapped_elems++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2039" endline="2044">
{
    if (s->dma_address)
        __unmap_single (domain->priv, s->dma_address, s->dma_length, dir);
    s->dma_address = s->dma_length = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2058" endline="2081">
{
    unsigned long flags;
    struct protection_domain *domain;
    struct scatterlist *s;
    int i;
    INC_STATS_COUNTER (cnt_unmap_sg);
    domain = get_domain (dev);
    if (IS_ERR (domain))
        return;
    spin_lock_irqsave (& domain -> lock, flags);

    for_each_sg (sglist, s, nelems, i) {
        __unmap_single (domain -> priv, s -> dma_address, s -> dma_length, dir);
        s->dma_address = s->dma_length = 0;
    }

    iommu_flush_complete (domain);
    spin_unlock_irqrestore (& domain -> lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2072" endline="2076">
{
    __unmap_single (domain -> priv, s -> dma_address, s -> dma_length, dir);
    s->dma_address = s->dma_length = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2088" endline="2139">
{
    unsigned long flags;
    void *virt_addr;
    struct protection_domain *domain;
    phys_addr_t paddr;
    u64 dma_mask = dev->coherent_dma_mask;
    INC_STATS_COUNTER (cnt_alloc_coherent);
    domain = get_domain (dev);
    if (PTR_ERR (domain) == -EINVAL) {
        virt_addr = (void *) __get_free_pages (flag, get_order (size));
        *dma_addr = __pa (virt_addr);
        return virt_addr;
    }
    else if (IS_ERR (domain))
        return NULL;
    dma_mask = dev->coherent_dma_mask;
    flag &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
    flag |= __GFP_ZERO;
    virt_addr = (void *) __get_free_pages (flag, get_order (size));
    if (!virt_addr)
        return NULL;
    paddr = virt_to_phys (virt_addr);
    if (!dma_mask)
        dma_mask = *dev->dma_mask;
    spin_lock_irqsave (& domain -> lock, flags);
    *dma_addr = __map_single (dev, domain->priv, paddr, size, DMA_BIDIRECTIONAL, true, dma_mask);
    if (*dma_addr == DMA_ERROR_CODE) {
        spin_unlock_irqrestore (& domain -> lock, flags);
        goto out_free;
    }
    iommu_flush_complete (domain);
    spin_unlock_irqrestore (& domain -> lock, flags);
    return virt_addr;
out_free :
    free_pages ((unsigned long) virt_addr, get_order (size));
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2098" endline="2102">
{
    virt_addr = (void *) __get_free_pages (flag, get_order (size));
    *dma_addr = __pa (virt_addr);
    return virt_addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2123" endline="2126">
{
    spin_unlock_irqrestore (& domain -> lock, flags);
    goto out_free;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2146" endline="2166">
{
    unsigned long flags;
    struct protection_domain *domain;
    INC_STATS_COUNTER (cnt_free_coherent);
    domain = get_domain (dev);
    if (IS_ERR (domain))
        goto free_mem;
    spin_lock_irqsave (& domain -> lock, flags);
    __unmap_single (domain -> priv, dma_addr, size, DMA_BIDIRECTIONAL);
    iommu_flush_complete (domain);
    spin_unlock_irqrestore (& domain -> lock, flags);
free_mem :
    free_pages ((unsigned long) virt_addr, get_order (size));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2173" endline="2175">
{
    return check_device (dev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2185" endline="2212">
{
    struct pci_dev *dev = NULL;
    struct dma_ops_domain *dma_dom;
    u16 devid;

    for_each_pci_dev (dev) {
        if (!check_device (&dev->dev))
            continue;
        if (domain_for_device (&dev->dev))
            continue;
        devid = get_device_id (&dev->dev);
        dma_dom = dma_ops_domain_alloc ();
        if (!dma_dom)
            continue;
        init_unity_mappings_for_device (dma_dom, devid);
        dma_dom->target_dev = devid;
        attach_device (& dev -> dev, & dma_dom -> domain);
        list_add_tail (& dma_dom -> list, & iommu_pd_list);
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2190" endline="2211">
{
    if (!check_device (&dev->dev))
        continue;
    if (domain_for_device (&dev->dev))
        continue;
    devid = get_device_id (&dev->dev);
    dma_dom = dma_ops_domain_alloc ();
    if (!dma_dom)
        continue;
    init_unity_mappings_for_device (dma_dom, devid);
    dma_dom->target_dev = devid;
    attach_device (& dev -> dev, & dma_dom -> domain);
    list_add_tail (& dma_dom -> list, & iommu_pd_list);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2229" endline="2231">
{
    register_iommu (& amd_iommu_ops);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2234" endline="2280">
{
    struct amd_iommu *iommu;
    int ret;

    for_each_iommu (iommu) {
        iommu->default_dom = dma_ops_domain_alloc ();
        if (iommu->default_dom == NULL)
            return -ENOMEM;
        iommu->default_dom->domain.flags |= PD_DEFAULT_MASK;
        ret = iommu_init_unity_mappings (iommu);
        if (ret)
            goto free_domains;
    }

    prealloc_protection_domains ();
    iommu_detected = 1;
    swiotlb = 0;
    dma_ops = &amd_iommu_dma_ops;
    amd_iommu_stats_init ();
    return 0;
free_domains :

    for_each_iommu (iommu) {
        if (iommu->default_dom)
            dma_ops_domain_free (iommu->default_dom);
    }

    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2243" endline="2251">
{
    iommu->default_dom = dma_ops_domain_alloc ();
    if (iommu->default_dom == NULL)
        return -ENOMEM;
    iommu->default_dom->domain.flags |= PD_DEFAULT_MASK;
    ret = iommu_init_unity_mappings (iommu);
    if (ret)
        goto free_domains;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2274" endline="2277">
{
    if (iommu->default_dom)
        dma_ops_domain_free (iommu->default_dom);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2293" endline="2307">
{
    struct iommu_dev_data *dev_data, *next;
    unsigned long flags;
    write_lock_irqsave (& amd_iommu_devtable_lock, flags);
    list_for_each_entry_safe (dev_data, next, &domain->dev_list, list) {
        struct device *dev = dev_data->dev;
        __detach_device (dev);
        atomic_set (& dev_data -> bind, 0);
    }
    write_unlock_irqrestore (& amd_iommu_devtable_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2299" endline="2304">
{
    struct device *dev = dev_data->dev;
    __detach_device (dev);
    atomic_set (& dev_data -> bind, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2310" endline="2320">
{
    if (!domain)
        return;
    del_domain_from_list (domain);
    if (domain->id)
        domain_id_free (domain->id);
    kfree (domain);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2323" endline="2345">
{
    struct protection_domain *domain;
    domain = kzalloc (sizeof (*domain), GFP_KERNEL);
    if (!domain)
        return NULL;
    spin_lock_init (& domain -> lock);
    mutex_init (& domain -> api_lock);
    domain->id = domain_id_alloc ();
    if (!domain->id)
        goto out_err;
    INIT_LIST_HEAD (& domain -> dev_list);
    add_domain_to_list (domain);
    return domain;
out_err :
    kfree (domain);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2348" endline="2368">
{
    struct protection_domain *domain;
    domain = protection_domain_alloc ();
    if (!domain)
        goto out_free;
    domain->mode = PAGE_MODE_3_LEVEL;
    domain->pt_root = (void *) get_zeroed_page (GFP_KERNEL);
    if (!domain->pt_root)
        goto out_free;
    dom->priv = domain;
    return 0;
out_free :
    protection_domain_free (domain);
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2371" endline="2387">
{
    struct protection_domain *domain = dom->priv;
    if (!domain)
        return;
    if (domain->dev_cnt > 0)
        cleanup_domain (domain);
    BUG_ON (domain -> dev_cnt != 0);
    free_pagetable (domain);
    protection_domain_free (domain);
    dom->priv = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2391" endline="2410">
{
    struct iommu_dev_data *dev_data = dev->archdata.iommu;
    struct amd_iommu *iommu;
    u16 devid;
    if (!check_device (dev))
        return;
    devid = get_device_id (dev);
    if (dev_data->domain != NULL)
        detach_device (dev);
    iommu = amd_iommu_rlookup_table[devid];
    if (!iommu)
        return;
    iommu_flush_device (dev);
    iommu_completion_wait (iommu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2414" endline="2440">
{
    struct protection_domain *domain = dom->priv;
    struct iommu_dev_data *dev_data;
    struct amd_iommu *iommu;
    int ret;
    u16 devid;
    if (!check_device (dev))
        return -EINVAL;
    dev_data = dev->archdata.iommu;
    devid = get_device_id (dev);
    iommu = amd_iommu_rlookup_table[devid];
    if (!iommu)
        return -EINVAL;
    if (dev_data->domain)
        detach_device (dev);
    ret = attach_device (dev, domain);
    iommu_completion_wait (iommu);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2445" endline="2473">
{
    struct protection_domain *domain = dom->priv;
    unsigned long i, npages = iommu_num_pages (paddr, size, PAGE_SIZE);
    int prot = 0;
    int ret;
    if (iommu_prot & IOMMU_READ)
        prot |= IOMMU_PROT_IR;
    if (iommu_prot & IOMMU_WRITE)
        prot |= IOMMU_PROT_IW;
    iova &= PAGE_MASK;
    paddr &= PAGE_MASK;
    mutex_lock (& domain -> api_lock);
    for (i = 0; i < npages; ++i) {
        ret = iommu_map_page (domain, iova, paddr, prot, PM_MAP_4k);
        if (ret)
            return ret;
        iova += PAGE_SIZE;
        paddr += PAGE_SIZE;
    }
    mutex_unlock (& domain -> api_lock);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2461" endline="2468">
{
    ret = iommu_map_page (domain, iova, paddr, prot, PM_MAP_4k);
    if (ret)
        return ret;
    iova += PAGE_SIZE;
    paddr += PAGE_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2477" endline="2494">
{
    struct protection_domain *domain = dom->priv;
    unsigned long i, npages = iommu_num_pages (iova, size, PAGE_SIZE);
    iova &= PAGE_MASK;
    mutex_lock (& domain -> api_lock);
    for (i = 0; i < npages; ++i) {
        iommu_unmap_page (domain, iova, PM_MAP_4k);
        iova += PAGE_SIZE;
    }
    iommu_flush_tlb_pde (domain);
    mutex_unlock (& domain -> api_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2486" endline="2489">
{
    iommu_unmap_page (domain, iova, PM_MAP_4k);
    iova += PAGE_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2498" endline="2513">
{
    struct protection_domain *domain = dom->priv;
    unsigned long offset = iova & ~PAGE_MASK;
    phys_addr_t paddr;
    u64 *pte;
    pte = fetch_pte (domain, iova, PM_MAP_4k);
    if (!pte || !IOMMU_PTE_PRESENT (*pte))
        return 0;
    paddr = *pte & IOMMU_PAGE_MASK;
    paddr |= offset;
    return paddr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2517" endline="2519">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2543" endline="2572">
{
    struct amd_iommu *iommu;
    struct pci_dev *dev = NULL;
    u16 devid;
    pt_domain = protection_domain_alloc ();
    if (!pt_domain)
        return -ENOMEM;
    pt_domain->mode |= PAGE_MODE_NONE;
    while ((dev = pci_get_device (PCI_ANY_ID, PCI_ANY_ID, dev)) != NULL) {
        if (!check_device (&dev->dev))
            continue;
        devid = get_device_id (&dev->dev);
        iommu = amd_iommu_rlookup_table[devid];
        if (!iommu)
            continue;
        attach_device (& dev -> dev, pt_domain);
    }
    pr_info ("AMD-Vi: Initialized for Passthrough Mode\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu.c.ifdefed" startline="2555" endline="2567">
{
    if (!check_device (&dev->dev))
        continue;
    devid = get_device_id (&dev->dev);
    iommu = amd_iommu_rlookup_table[devid];
    if (!iommu)
        continue;
    attach_device (& dev -> dev, pt_domain);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="86" endline="89">
{
    if (regs->flags & X86_EFLAGS_IF)
        local_irq_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="92" endline="96">
{
    inc_preempt_count ();
    if (regs->flags & X86_EFLAGS_IF)
        local_irq_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="99" endline="102">
{
    if (regs->flags & X86_EFLAGS_IF)
        local_irq_disable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="105" endline="109">
{
    if (regs->flags & X86_EFLAGS_IF)
        local_irq_disable ();
    dec_preempt_count ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="123" endline="189">
{
    struct task_struct *tsk = current;
    if (!user_mode (regs))
        goto kernel_trap;
    tsk->thread.error_code = error_code;
    tsk->thread.trap_no = trapnr;
    if (info)
        force_sig_info (signr, info, tsk);
    else
        force_sig (signr, tsk);
    return;
kernel_trap :
    if (!fixup_exception (regs)) {
        tsk->thread.error_code = error_code;
        tsk->thread.trap_no = trapnr;
        die (str, regs, error_code);
    }
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="175" endline="179">
{
    tsk->thread.error_code = error_code;
    tsk->thread.trap_no = trapnr;
    die (str, regs, error_code);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="262" endline="309">
{
    struct task_struct *tsk;
    conditional_sti (regs);
    tsk = current;
    if (!user_mode (regs))
        goto gp_in_kernel;
    tsk->thread.error_code = error_code;
    tsk->thread.trap_no = 13;
    if (show_unhandled_signals && unhandled_signal (tsk, SIGSEGV) && printk_ratelimit ()) {
        printk (KERN_INFO "%s[%d] general protection ip:%lx sp:%lx error:%lx", tsk -> comm, task_pid_nr (tsk), regs -> ip, regs -> sp, error_code);
        print_vma_addr (" in ", regs -> ip);
        printk ("\n");
    }
    force_sig (SIGSEGV, tsk);
    return;
gp_in_kernel :
    if (fixup_exception (regs))
        return;
    tsk->thread.error_code = error_code;
    tsk->thread.trap_no = 13;
    if (notify_die (DIE_GPF, "general protection fault", regs, error_code, 13, SIGSEGV) == NOTIFY_STOP)
        return;
    die ("general protection fault", regs, error_code);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="280" endline="287">
{
    printk (KERN_INFO "%s[%d] general protection ip:%lx sp:%lx error:%lx", tsk -> comm, task_pid_nr (tsk), regs -> ip, regs -> sp, error_code);
    print_vma_addr (" in ", regs -> ip);
    printk ("\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="313" endline="336">
{
    printk (KERN_EMERG "Uhhuh. NMI received for unknown reason %02x on CPU %d.\n", reason, smp_processor_id ());
    printk (KERN_EMERG "You have some hardware problem, likely on the PCI bus.\n");
    if (panic_on_unrecovered_nmi)
        panic ("NMI: Not continuing");
    printk (KERN_EMERG "Dazed and confused, but trying to continue\n");
    reason = (reason & 0xf) | 4;
    outb (reason, 0x61);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="340" endline="359">
{
    unsigned long i;
    printk (KERN_EMERG "NMI: IOCK error (debug interrupt?)\n");
    show_registers (regs);
    if (panic_on_io_nmi)
        panic ("NMI IOCK error: Not continuing");
    reason = (reason & 0xf) | 8;
    outb (reason, 0x61);
    i = 2000;
    while (--i)
        udelay (1000);
    reason &= ~8;
    outb (reason, 0x61);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="363" endline="386">
{
    if (notify_die (DIE_NMIUNKNOWN, "nmi", regs, reason, 2, SIGINT) == NOTIFY_STOP)
        return;
    printk (KERN_EMERG "Uhhuh. NMI received for unknown reason %02x on CPU %d.\n", reason, smp_processor_id ());
    printk (KERN_EMERG "Do you have a strange power saving mode enabled?\n");
    if (panic_on_unrecovered_nmi)
        panic ("NMI: Not continuing");
    printk (KERN_EMERG "Dazed and confused, but trying to continue\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="389" endline="433">
{
    unsigned char reason = 0;
    int cpu;
    cpu = smp_processor_id ();
    if (!cpu)
        reason = get_nmi_reason ();
    if (!(reason & 0xc0)) {
        if (notify_die (DIE_NMI_IPI, "nmi_ipi", regs, reason, 2, SIGINT) == NOTIFY_STOP)
            return;
        unknown_nmi_error (reason, regs);
        return;
    }
    if (notify_die (DIE_NMI, "nmi", regs, reason, 2, SIGINT) == NOTIFY_STOP)
        return;
    if (reason & 0x80)
        mem_parity_error (reason, regs);
    if (reason & 0x40)
        io_check_error (reason, regs);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="399" endline="417">
{
    if (notify_die (DIE_NMI_IPI, "nmi_ipi", regs, reason, 2, SIGINT) == NOTIFY_STOP)
        return;
    unknown_nmi_error (reason, regs);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="437" endline="446">
{
    nmi_enter ();
    inc_irq_stat (__nmi_count);
    if (!ignore_nmis)
        default_do_nmi (regs);
    nmi_exit ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="449" endline="452">
{
    acpi_nmi_disable ();
    ignore_nmis++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="455" endline="458">
{
    ignore_nmis--;
    acpi_nmi_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="462" endline="476">
{
    if (notify_die (DIE_TRAP, "int3", regs, error_code, 3, SIGTRAP) == NOTIFY_STOP)
        return;
    preempt_conditional_sti (regs);
    do_trap (3, SIGTRAP, "int3", regs, error_code, NULL);
    preempt_conditional_cli (regs);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="530" endline="586">
{
    struct task_struct *tsk = current;
    unsigned long dr6;
    int si_code;
    get_debugreg (dr6, 6);
    dr6 &= ~DR6_RESERVED;
    if ((dr6 & DR_STEP) && kmemcheck_trap (regs))
        return;
    set_debugreg (0, 6);
    clear_tsk_thread_flag (tsk, TIF_DEBUGCTLMSR);
    tsk->thread.debugctlmsr = 0;
    tsk->thread.debugreg6 = dr6;
    if (notify_die (DIE_DEBUG, "debug", regs, PTR_ERR (&dr6), error_code, SIGTRAP) == NOTIFY_STOP)
        return;
    preempt_conditional_sti (regs);
    if (regs->flags & X86_VM_MASK) {
        handle_vm86_trap ((struct kernel_vm86_regs *) regs, error_code, 1);
        return;
    }
    if ((dr6 & DR_STEP) && !user_mode (regs)) {
        tsk->thread.debugreg6 &= ~DR_STEP;
        set_tsk_thread_flag (tsk, TIF_SINGLESTEP);
        regs->flags &= ~X86_EFLAGS_TF;
    }
    si_code = get_si_code (tsk->thread.debugreg6);
    if (tsk->thread.debugreg6 & (DR_STEP | DR_TRAP_BITS))
        send_sigtrap (tsk, regs, error_code, si_code);
    preempt_conditional_cli (regs);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="562" endline="566">
{
    handle_vm86_trap ((struct kernel_vm86_regs *) regs, error_code, 1);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="575" endline="579">
{
    tsk->thread.debugreg6 &= ~DR_STEP;
    set_tsk_thread_flag (tsk, TIF_SINGLESTEP);
    regs->flags &= ~X86_EFLAGS_TF;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="608" endline="661">
{
    struct task_struct *task;
    siginfo_t info;
    unsigned short cwd, swd, err;
    task = current;
    save_init_fpu (task);
    task->thread.trap_no = 16;
    task->thread.error_code = 0;
    info.si_signo = SIGFPE;
    info.si_errno = 0;
    info.si_addr = ip;
    cwd = get_fpu_cwd (task);
    swd = get_fpu_swd (task);
    err = swd & ~cwd;
    if (err & 0x001) {
        info.si_code = FPE_FLTINV;
    }
    else if (err & 0x004) {
        info.si_code = FPE_FLTDIV;
    }
    else if (err & 0x008) {
        info.si_code = FPE_FLTOVF;
    }
    else if (err & 0x012) {
        info.si_code = FPE_FLTUND;
    }
    else if (err & 0x020) {
        info.si_code = FPE_FLTRES;
    }
    else {
        return;
    }
    force_sig_info (SIGFPE, & info, task);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="638" endline="645">
{
    info.si_code = FPE_FLTINV;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="645" endline="647">
{
    info.si_code = FPE_FLTDIV;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="647" endline="649">
{
    info.si_code = FPE_FLTOVF;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="649" endline="651">
{
    info.si_code = FPE_FLTUND;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="651" endline="653">
{
    info.si_code = FPE_FLTRES;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="653" endline="659">
{
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="664" endline="676">
{
    conditional_sti (regs);
    if (!user_mode (regs) && kernel_math_error (regs, "kernel x87 math error", 16))
        return;
    math_error ((void __user *) regs -> ip);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="679" endline="724">
{
    struct task_struct *task;
    siginfo_t info;
    unsigned short mxcsr;
    task = current;
    save_init_fpu (task);
    task->thread.trap_no = 19;
    task->thread.error_code = 0;
    info.si_signo = SIGFPE;
    info.si_errno = 0;
    info.si_code = __SI_FAULT;
    info.si_addr = ip;
    mxcsr = get_fpu_mxcsr (task);
    switch (~((mxcsr & 0x1f80) >> 7) & (mxcsr & 0x3f)) {
    case 0x000 :
    default :
        break;
    case 0x001 :
        info.si_code = FPE_FLTINV;
        break;
    case 0x002 :
    case 0x010 :
        info.si_code = FPE_FLTUND;
        break;
    case 0x004 :
        info.si_code = FPE_FLTDIV;
        break;
    case 0x008 :
        info.si_code = FPE_FLTOVF;
        break;
    case 0x020 :
        info.si_code = FPE_FLTRES;
        break;
    }
    force_sig_info (SIGFPE, & info, task);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="702" endline="722">
{
case 0x000 :
default :
    break;
case 0x001 :
    info.si_code = FPE_FLTINV;
    break;
case 0x002 :
case 0x010 :
    info.si_code = FPE_FLTUND;
    break;
case 0x004 :
    info.si_code = FPE_FLTDIV;
    break;
case 0x008 :
    info.si_code = FPE_FLTOVF;
    break;
case 0x020 :
    info.si_code = FPE_FLTRES;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="728" endline="756">
{
    conditional_sti (regs);
    if (!user_mode (regs) && kernel_math_error (regs, "kernel simd math error", 19))
        return;
    simd_math_error ((void __user *) regs -> ip);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="760" endline="766">
{
    conditional_sti (regs);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="769" endline="770">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="773" endline="774">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="781" endline="796">
{
    struct thread_info *thread = current_thread_info ();
    struct task_struct *tsk = thread->task;
    if (unlikely (restore_fpu_checking (tsk))) {
        stts ();
        force_sig (SIGSEGV, tsk);
        return;
    }
    thread->status |= TS_USEDFPU;
    tsk->fpu_counter++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="788" endline="792">
{
    stts ();
    force_sig (SIGSEGV, tsk);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="809" endline="831">
{
    struct thread_info *thread = current_thread_info ();
    struct task_struct *tsk = thread->task;
    if (!tsk_used_math (tsk)) {
        local_irq_enable ();
        if (init_fpu (tsk)) {
            do_group_exit (SIGKILL);
            return;
        }
        local_irq_disable ();
    }
    clts ();
    __math_state_restore ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="813" endline="826">
{
    local_irq_enable ();
    if (init_fpu (tsk)) {
        do_group_exit (SIGKILL);
        return;
    }
    local_irq_disable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="818" endline="824">
{
    do_group_exit (SIGKILL);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="836" endline="842">
{
    printk (KERN_EMERG "math-emulation not enabled and no coprocessor found.\n");
    printk (KERN_EMERG "killing %s.\n", current -> comm);
    force_sig (SIGFPE, current);
    schedule ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="847" endline="863">
{
    math_state_restore ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/traps.c.ifdefed" startline="883" endline="955">
{
    int i;
    set_intr_gate (0, & divide_error);
    set_intr_gate_ist (1, & debug, DEBUG_STACK);
    set_intr_gate_ist (2, & nmi, NMI_STACK);
    set_system_intr_gate_ist (3, & int3, DEBUG_STACK);
    set_system_intr_gate (4, & overflow);
    set_intr_gate (5, & bounds);
    set_intr_gate (6, & invalid_op);
    set_intr_gate (7, & device_not_available);
    set_intr_gate_ist (8, & double_fault, DOUBLEFAULT_STACK);
    set_intr_gate (9, & coprocessor_segment_overrun);
    set_intr_gate (10, & invalid_TSS);
    set_intr_gate (11, & segment_not_present);
    set_intr_gate_ist (12, & stack_segment, STACKFAULT_STACK);
    set_intr_gate (13, & general_protection);
    set_intr_gate (14, & page_fault);
    set_intr_gate (15, & spurious_interrupt_bug);
    set_intr_gate (16, & coprocessor_error);
    set_intr_gate (17, & alignment_check);
    set_intr_gate (19, & simd_coprocessor_error);
    for (i = 0; i < FIRST_EXTERNAL_VECTOR; i++)
        set_bit (i, used_vectors);
    cpu_init ();
    x86_init.irqs.trap_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/crash.c.ifdefed" startline="71" endline="73">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/crash.c.ifdefed" startline="77" endline="106">
{
    local_irq_disable ();
    kdump_nmi_shootdown_cpus ();
    cpu_emergency_vmxoff ();
    cpu_emergency_svm_disable ();
    lapic_shutdown ();
    crash_save_cpu (regs, safe_smp_processor_id ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="33" endline="87">
{
    void *oldldt, *newldt;
    int oldsize;
    if (mincount <= pc->size)
        return 0;
    oldsize = pc->size;
    mincount = (mincount + (PAGE_SIZE / LDT_ENTRY_SIZE - 1)) & (~(PAGE_SIZE / LDT_ENTRY_SIZE - 1));
    if (mincount * LDT_ENTRY_SIZE > PAGE_SIZE)
        newldt = vmalloc (mincount *LDT_ENTRY_SIZE);
    else
        newldt = (void *) __get_free_page (GFP_KERNEL);
    if (!newldt)
        return -ENOMEM;
    if (oldsize)
        memcpy (newldt, pc->ldt, oldsize *LDT_ENTRY_SIZE);
    oldldt = pc->ldt;
    memset (newldt + oldsize * LDT_ENTRY_SIZE, 0, (mincount - oldsize) * LDT_ENTRY_SIZE);
    paravirt_alloc_ldt (newldt, mincount);
    pc->ldt = newldt;
    wmb ();
    pc->size = mincount;
    wmb ();
    if (reload) {
        load_LDT (pc);
    }
    if (oldsize) {
        paravirt_free_ldt (oldldt, oldsize);
        if (oldsize * LDT_ENTRY_SIZE > PAGE_SIZE)
            vfree (oldldt);
        else
            put_page (virt_to_page (oldldt));
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="67" endline="78">
{
    load_LDT (pc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="79" endline="85">
{
    paravirt_free_ldt (oldldt, oldsize);
    if (oldsize * LDT_ENTRY_SIZE > PAGE_SIZE)
        vfree (oldldt);
    else
        put_page (virt_to_page (oldldt));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="90" endline="100">
{
    int err = alloc_ldt (new, old->size, 0);
    int i;
    if (err < 0)
        return err;
    for (i = 0; i < old->size; i++)
        write_ldt_entry (new->ldt, i, old->ldt + i * LDT_ENTRY_SIZE);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="107" endline="120">
{
    struct mm_struct *old_mm;
    int retval = 0;
    mutex_init (& mm -> context.lock);
    mm->context.size = 0;
    old_mm = current->mm;
    if (old_mm && old_mm->context.size > 0) {
        mutex_lock (& old_mm -> context.lock);
        retval = copy_ldt (&mm->context, &old_mm->context);
        mutex_unlock (& old_mm -> context.lock);
    }
    return retval;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="114" endline="118">
{
    mutex_lock (& old_mm -> context.lock);
    retval = copy_ldt (&mm->context, &old_mm->context);
    mutex_unlock (& old_mm -> context.lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="128" endline="142">
{
    if (mm->context.size) {
        paravirt_free_ldt (mm -> context.ldt, mm -> context.size);
        if (mm->context.size * LDT_ENTRY_SIZE > PAGE_SIZE)
            vfree (mm->context.ldt);
        else
            put_page (virt_to_page (mm->context.ldt));
        mm->context.size = 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="129" endline="141">
{
    paravirt_free_ldt (mm -> context.ldt, mm -> context.size);
    if (mm->context.size * LDT_ENTRY_SIZE > PAGE_SIZE)
        vfree (mm->context.ldt);
    else
        put_page (virt_to_page (mm->context.ldt));
    mm->context.size = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="145" endline="176">
{
    int err;
    unsigned long size;
    struct mm_struct *mm = current->mm;
    if (!mm->context.size)
        return 0;
    if (bytecount > LDT_ENTRY_SIZE * LDT_ENTRIES)
        bytecount = LDT_ENTRY_SIZE * LDT_ENTRIES;
    mutex_lock (& mm -> context.lock);
    size = mm->context.size * LDT_ENTRY_SIZE;
    if (size > bytecount)
        size = bytecount;
    err = 0;
    if (copy_to_user (ptr, mm->context.ldt, size))
        err = -EFAULT;
    mutex_unlock (& mm -> context.lock);
    if (err < 0)
        goto error_return;
    if (size != bytecount) {
        if (clear_user (ptr +size, bytecount -size) != 0) {
            err = -EFAULT;
            goto error_return;
        }
    }
    return bytecount;
error_return :
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="166" endline="172">
{
    if (clear_user (ptr +size, bytecount -size) != 0) {
        err = -EFAULT;
        goto error_return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="168" endline="171">
{
    err = -EFAULT;
    goto error_return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="179" endline="191">
{
    unsigned long size = 128;
    if (bytecount > size)
        bytecount = size;
    if (clear_user (ptr, bytecount))
        return -EFAULT;
    return bytecount;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="194" endline="246">
{
    struct mm_struct *mm = current->mm;
    struct desc_struct ldt;
    int error;
    struct user_desc ldt_info;
    error = -EINVAL;
    if (bytecount != sizeof (ldt_info))
        goto out;
    error = -EFAULT;
    if (copy_from_user (&ldt_info, ptr, sizeof (ldt_info)))
        goto out;
    error = -EINVAL;
    if (ldt_info.entry_number >= LDT_ENTRIES)
        goto out;
    if (ldt_info.contents == 3) {
        if (oldmode)
            goto out;
        if (ldt_info.seg_not_present == 0)
            goto out;
    }
    mutex_lock (& mm -> context.lock);
    if (ldt_info.entry_number >= mm->context.size) {
        error = alloc_ldt (&current->mm->context, ldt_info.entry_number + 1, 1);
        if (error < 0)
            goto out_unlock;
    }
    if (ldt_info.base_addr == 0 && ldt_info.limit == 0) {
        if (oldmode || LDT_empty (&ldt_info)) {
            memset (& ldt, 0, sizeof (ldt));
            goto install;
        }
    }
    fill_ldt (& ldt, & ldt_info);
    if (oldmode)
        ldt.avl = 0;
install :
    write_ldt_entry (mm->context.ldt, ldt_info.entry_number, &ldt);
    error = 0;
out_unlock :
    mutex_unlock (&mm->context.lock);
out :
    return error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="210" endline="215">
{
    if (oldmode)
        goto out;
    if (ldt_info.seg_not_present == 0)
        goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="218" endline="223">
{
    error = alloc_ldt (&current->mm->context, ldt_info.entry_number + 1, 1);
    if (error < 0)
        goto out_unlock;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="226" endline="231">
{
    if (oldmode || LDT_empty (&ldt_info)) {
        memset (& ldt, 0, sizeof (ldt));
        goto install;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="227" endline="230">
{
    memset (& ldt, 0, sizeof (ldt));
    goto install;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="250" endline="268">
{
    int ret = -ENOSYS;
    switch (func) {
    case 0 :
        ret = read_ldt (ptr, bytecount);
        break;
    case 1 :
        ret = write_ldt (ptr, bytecount, 1);
        break;
    case 2 :
        ret = read_default_ldt (ptr, bytecount);
        break;
    case 0x11 :
        ret = write_ldt (ptr, bytecount, 0);
        break;
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ldt.c.ifdefed" startline="253" endline="266">
{
case 0 :
    ret = read_ldt (ptr, bytecount);
    break;
case 1 :
    ret = write_ldt (ptr, bytecount, 1);
    break;
case 2 :
    ret = read_default_ldt (ptr, bytecount);
    break;
case 0x11 :
    ret = write_ldt (ptr, bytecount, 0);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="183" endline="186">
{
    if (devid > amd_iommu_last_bdf)
        amd_iommu_last_bdf = devid;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="189" endline="194">
{
    unsigned shift = PAGE_SHIFT + get_order (((int) amd_iommu_last_bdf + 1) * entry_size);
    return 1UL << shift;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="210" endline="225">
{
    u64 start = iommu->exclusion_start & PAGE_MASK;
    u64 limit = (start + iommu->exclusion_length) & PAGE_MASK;
    u64 entry;
    if (!iommu->exclusion_start)
        return;
    entry = start | MMIO_EXCL_ENABLE_MASK;
    memcpy_toio (iommu -> mmio_base + MMIO_EXCL_BASE_OFFSET, & entry, sizeof (entry));
    entry = limit;
    memcpy_toio (iommu -> mmio_base + MMIO_EXCL_LIMIT_OFFSET, & entry, sizeof (entry));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="229" endline="238">
{
    u64 entry;
    BUG_ON (iommu -> mmio_base == NULL);
    entry = virt_to_phys (amd_iommu_dev_table);
    entry |= (dev_table_size >> 12) - 1;
    memcpy_toio (iommu -> mmio_base + MMIO_DEV_TABLE_OFFSET, & entry, sizeof (entry));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="242" endline="248">
{
    u32 ctrl;
    ctrl = readl (iommu->mmio_base + MMIO_CONTROL_OFFSET);
    ctrl |= (1 << bit);
    writel (ctrl, iommu -> mmio_base + MMIO_CONTROL_OFFSET);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="251" endline="257">
{
    u32 ctrl;
    ctrl = readl (iommu->mmio_base + MMIO_CONTROL_OFFSET);
    ctrl &= ~(1 << bit);
    writel (ctrl, iommu -> mmio_base + MMIO_CONTROL_OFFSET);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="261" endline="266">
{
    printk (KERN_INFO "AMD-Vi: Enabling IOMMU at %s cap 0x%hx\n", dev_name (& iommu -> dev -> dev), iommu -> cap_ptr);
    iommu_feature_enable (iommu, CONTROL_IOMMU_EN);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="269" endline="279">
{
    iommu_feature_disable (iommu, CONTROL_CMDBUF_EN);
    iommu_feature_disable (iommu, CONTROL_EVT_INT_EN);
    iommu_feature_disable (iommu, CONTROL_EVT_LOG_EN);
    iommu_feature_disable (iommu, CONTROL_IOMMU_EN);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="286" endline="299">
{
    u8 *ret;
    if (!request_mem_region (address, MMIO_REGION_LENGTH, "amd_iommu"))
        return NULL;
    ret = ioremap_nocache (address, MMIO_REGION_LENGTH);
    if (ret != NULL)
        return ret;
    release_mem_region (address, MMIO_REGION_LENGTH);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="302" endline="306">
{
    if (iommu->mmio_base)
        iounmap (iommu->mmio_base);
    release_mem_region (iommu -> mmio_phys, MMIO_REGION_LENGTH);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="321" endline="323">
{
    return 0x04 << (*ivhd >> 6);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="330" endline="337">
{
    u32 cap;
    cap = read_pci_config (bus, dev, fn, cap_ptr +MMIO_RANGE_OFFSET);
    update_last_devid (calc_devid (MMIO_GET_BUS (cap), MMIO_GET_LD (cap)));
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="344" endline="375">
{
    u8 *p = (void *) h, *end = (void *) h;
    struct ivhd_entry *dev;
    p += sizeof (*h);
    end += h->length;
    find_last_devid_on_pci (PCI_BUS (h -> devid), PCI_SLOT (h -> devid), PCI_FUNC (h -> devid), h -> cap_ptr);
    while (p < end) {
        dev = (struct ivhd_entry *) p;
        switch (dev->type) {
        case IVHD_DEV_SELECT :
        case IVHD_DEV_RANGE_END :
        case IVHD_DEV_ALIAS :
        case IVHD_DEV_EXT_SELECT :
            update_last_devid (dev->devid);
            break;
        default :
            break;
        }
        p += ivhd_entry_length (p);
    }
    WARN_ON (p != end);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="356" endline="370">
{
    dev = (struct ivhd_entry *) p;
    switch (dev->type) {
    case IVHD_DEV_SELECT :
    case IVHD_DEV_RANGE_END :
    case IVHD_DEV_ALIAS :
    case IVHD_DEV_EXT_SELECT :
        update_last_devid (dev->devid);
        break;
    default :
        break;
    }
    p += ivhd_entry_length (p);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="358" endline="368">
{
case IVHD_DEV_SELECT :
case IVHD_DEV_RANGE_END :
case IVHD_DEV_ALIAS :
case IVHD_DEV_EXT_SELECT :
    update_last_devid (dev->devid);
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="383" endline="417">
{
    int i;
    u8 checksum = 0, *p = (u8 *) table, *end = (u8 *) table;
    struct ivhd_header *h;
    for (i = 0; i < table->length; ++i)
        checksum += p[i];
    if (checksum != 0) {
        amd_iommu_init_err = -ENODEV;
        return 0;
    }
    p += IVRS_HEADER_LENGTH;
    end += table->length;
    while (p < end) {
        h = (struct ivhd_header *) p;
        switch (h->type) {
        case ACPI_IVHD_TYPE :
            find_last_devid_from_ivhd (h);
            break;
        default :
            break;
        }
        p += h->length;
    }
    WARN_ON (p != end);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="394" endline="398">
{
    amd_iommu_init_err = -ENODEV;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="403" endline="413">
{
    h = (struct ivhd_header *) p;
    switch (h->type) {
    case ACPI_IVHD_TYPE :
        find_last_devid_from_ivhd (h);
        break;
    default :
        break;
    }
    p += h->length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="405" endline="411">
{
case ACPI_IVHD_TYPE :
    find_last_devid_from_ivhd (h);
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="434" endline="444">
{
    u8 *cmd_buf = (u8 *) __get_free_pages (GFP_KERNEL | __GFP_ZERO, get_order (CMD_BUFFER_SIZE));
    if (cmd_buf == NULL)
        return NULL;
    iommu->cmd_buf_size = CMD_BUFFER_SIZE | CMD_BUFFER_UNINITIALIZED;
    return cmd_buf;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="451" endline="458">
{
    iommu_feature_disable (iommu, CONTROL_CMDBUF_EN);
    writel (0x00, iommu -> mmio_base + MMIO_CMD_HEAD_OFFSET);
    writel (0x00, iommu -> mmio_base + MMIO_CMD_TAIL_OFFSET);
    iommu_feature_enable (iommu, CONTROL_CMDBUF_EN);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="465" endline="478">
{
    u64 entry;
    BUG_ON (iommu -> cmd_buf == NULL);
    entry = (u64) virt_to_phys (iommu->cmd_buf);
    entry |= MMIO_CMD_SIZE_512;
    memcpy_toio (iommu -> mmio_base + MMIO_CMD_BUF_OFFSET, & entry, sizeof (entry));
    amd_iommu_reset_cmd_buffer (iommu);
    iommu->cmd_buf_size &= ~(CMD_BUFFER_UNINITIALIZED);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="481" endline="484">
{
    free_pages ((unsigned long) iommu -> cmd_buf, get_order (iommu -> cmd_buf_size & ~ (CMD_BUFFER_UNINITIALIZED)));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="488" endline="498">
{
    iommu->evt_buf = (u8 *) __get_free_pages (GFP_KERNEL | __GFP_ZERO, get_order (EVT_BUFFER_SIZE));
    if (iommu->evt_buf == NULL)
        return NULL;
    iommu->evt_buf_size = EVT_BUFFER_SIZE;
    return iommu->evt_buf;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="501" endline="516">
{
    u64 entry;
    BUG_ON (iommu -> evt_buf == NULL);
    entry = (u64) virt_to_phys (iommu->evt_buf) | EVT_LEN_MASK;
    memcpy_toio (iommu -> mmio_base + MMIO_EVT_BUF_OFFSET, & entry, sizeof (entry));
    writel (0x00, iommu -> mmio_base + MMIO_EVT_HEAD_OFFSET);
    writel (0x00, iommu -> mmio_base + MMIO_EVT_TAIL_OFFSET);
    iommu_feature_enable (iommu, CONTROL_EVT_LOG_EN);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="519" endline="521">
{
    free_pages ((unsigned long) iommu -> evt_buf, get_order (EVT_BUFFER_SIZE));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="525" endline="530">
{
    int i = (bit >> 5) & 0x07;
    int _bit = bit & 0x1f;
    amd_iommu_dev_table[devid].data[i] |= (1 << _bit);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="533" endline="538">
{
    int i = (bit >> 5) & 0x07;
    int _bit = bit & 0x1f;
    return (amd_iommu_dev_table[devid].data[i] & (1 << _bit)) >> _bit;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="542" endline="550">
{
    int sysmgt;
    sysmgt = get_dev_entry_bit (devid, DEV_ENTRY_SYSMGT1) | (get_dev_entry_bit (devid, DEV_ENTRY_SYSMGT2) << 1);
    if (sysmgt == 0x01)
        set_dev_entry_bit (devid, DEV_ENTRY_IW);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="554" endline="556">
{
    amd_iommu_rlookup_table[devid] = iommu;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="564" endline="583">
{
    if (flags & ACPI_DEVFLAG_INITPASS)
        set_dev_entry_bit (devid, DEV_ENTRY_INIT_PASS);
    if (flags & ACPI_DEVFLAG_EXTINT)
        set_dev_entry_bit (devid, DEV_ENTRY_EINT_PASS);
    if (flags & ACPI_DEVFLAG_NMI)
        set_dev_entry_bit (devid, DEV_ENTRY_NMI_PASS);
    if (flags & ACPI_DEVFLAG_SYSMGT1)
        set_dev_entry_bit (devid, DEV_ENTRY_SYSMGT1);
    if (flags & ACPI_DEVFLAG_SYSMGT2)
        set_dev_entry_bit (devid, DEV_ENTRY_SYSMGT2);
    if (flags & ACPI_DEVFLAG_LINT0)
        set_dev_entry_bit (devid, DEV_ENTRY_LINT0_PASS);
    if (flags & ACPI_DEVFLAG_LINT1)
        set_dev_entry_bit (devid, DEV_ENTRY_LINT1_PASS);
    amd_iommu_apply_erratum_63 (devid);
    set_iommu_for_device (iommu, devid);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="590" endline="606">
{
    struct amd_iommu *iommu = amd_iommu_rlookup_table[devid];
    if (!(m->flags & IVMD_FLAG_EXCL_RANGE))
        return;
    if (iommu) {
        set_dev_entry_bit (m -> devid, DEV_ENTRY_EX);
        iommu->exclusion_start = m->range_start;
        iommu->exclusion_length = m->range_length;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="596" endline="605">
{
    set_dev_entry_bit (m -> devid, DEV_ENTRY_EX);
    iommu->exclusion_start = m->range_start;
    iommu->exclusion_length = m->range_length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="614" endline="630">
{
    int cap_ptr = iommu->cap_ptr;
    u32 range, misc;
    pci_read_config_dword (iommu -> dev, cap_ptr + MMIO_CAP_HDR_OFFSET, & iommu -> cap);
    pci_read_config_dword (iommu -> dev, cap_ptr + MMIO_RANGE_OFFSET, & range);
    pci_read_config_dword (iommu -> dev, cap_ptr + MMIO_MISC_OFFSET, & misc);
    iommu->first_device = calc_devid (MMIO_GET_BUS (range), MMIO_GET_FD (range));
    iommu->last_device = calc_devid (MMIO_GET_BUS (range), MMIO_GET_LD (range));
    iommu->evt_msi_num = MMIO_MSI_NUM (misc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="638" endline="812">
{
    u8 *p = (u8 *) h;
    u8 *end = p, flags = 0;
    u16 dev_i, devid = 0, devid_start = 0, devid_to = 0;
    u32 ext_flags = 0;
    bool alias = false;
    struct ivhd_entry *e;
    h->flags & IVHD_FLAG_HT_TUN_EN_MASK ? iommu_feature_enable (iommu, CONTROL_HT_TUN_EN) : iommu_feature_disable (iommu, CONTROL_HT_TUN_EN);
    h->flags & IVHD_FLAG_PASSPW_EN_MASK ? iommu_feature_enable (iommu, CONTROL_PASSPW_EN) : iommu_feature_disable (iommu, CONTROL_PASSPW_EN);
    h->flags & IVHD_FLAG_RESPASSPW_EN_MASK ? iommu_feature_enable (iommu, CONTROL_RESPASSPW_EN) : iommu_feature_disable (iommu, CONTROL_RESPASSPW_EN);
    h->flags & IVHD_FLAG_ISOC_EN_MASK ? iommu_feature_enable (iommu, CONTROL_ISOC_EN) : iommu_feature_disable (iommu, CONTROL_ISOC_EN);
    iommu_feature_enable (iommu, CONTROL_COHERENT_EN);
    p += sizeof (struct ivhd_header);
    end += h->length;
    while (p < end) {
        e = (struct ivhd_entry *) p;
        switch (e->type) {
        case IVHD_DEV_ALL :
            DUMP_printk ("  DEV_ALL\t\t\t first devid: %02x:%02x.%x" " last device %02x:%02x.%x flags: %02x\n", PCI_BUS (iommu->first_device), PCI_SLOT (iommu->first_device), PCI_FUNC (iommu->first_device), PCI_BUS (iommu->last_device), PCI_SLOT (iommu->last_device), PCI_FUNC (iommu->last_device), e->flags);
            for (dev_i = iommu->first_device; dev_i <= iommu->last_device; ++dev_i)
                set_dev_entry_from_acpi (iommu, dev_i, e->flags, 0);
            break;
        case IVHD_DEV_SELECT :
            DUMP_printk ("  DEV_SELECT\t\t\t devid: %02x:%02x.%x " "flags: %02x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags);
            devid = e->devid;
            set_dev_entry_from_acpi (iommu, devid, e -> flags, 0);
            break;
        case IVHD_DEV_SELECT_RANGE_START :
            DUMP_printk ("  DEV_SELECT_RANGE_START\t " "devid: %02x:%02x.%x flags: %02x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags);
            devid_start = e->devid;
            flags = e->flags;
            ext_flags = 0;
            alias = false;
            break;
        case IVHD_DEV_ALIAS :
            DUMP_printk ("  DEV_ALIAS\t\t\t devid: %02x:%02x.%x " "flags: %02x devid_to: %02x:%02x.%x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, PCI_BUS (e->ext >> 8), PCI_SLOT (e->ext >> 8), PCI_FUNC (e->ext >> 8));
            devid = e->devid;
            devid_to = e->ext >> 8;
            set_dev_entry_from_acpi (iommu, devid, e -> flags, 0);
            set_dev_entry_from_acpi (iommu, devid_to, e -> flags, 0);
            amd_iommu_alias_table[devid] = devid_to;
            break;
        case IVHD_DEV_ALIAS_RANGE :
            DUMP_printk ("  DEV_ALIAS_RANGE\t\t " "devid: %02x:%02x.%x flags: %02x " "devid_to: %02x:%02x.%x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, PCI_BUS (e->ext >> 8), PCI_SLOT (e->ext >> 8), PCI_FUNC (e->ext >> 8));
            devid_start = e->devid;
            flags = e->flags;
            devid_to = e->ext >> 8;
            ext_flags = 0;
            alias = true;
            break;
        case IVHD_DEV_EXT_SELECT :
            DUMP_printk ("  DEV_EXT_SELECT\t\t devid: %02x:%02x.%x " "flags: %02x ext: %08x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, e->ext);
            devid = e->devid;
            set_dev_entry_from_acpi (iommu, devid, e -> flags, e -> ext);
            break;
        case IVHD_DEV_EXT_SELECT_RANGE :
            DUMP_printk ("  DEV_EXT_SELECT_RANGE\t devid: " "%02x:%02x.%x flags: %02x ext: %08x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, e->ext);
            devid_start = e->devid;
            flags = e->flags;
            ext_flags = e->ext;
            alias = false;
            break;
        case IVHD_DEV_RANGE_END :
            DUMP_printk ("  DEV_RANGE_END\t\t devid: %02x:%02x.%x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid));
            devid = e->devid;
            for (dev_i = devid_start; dev_i <= devid; ++dev_i) {
                if (alias) {
                    amd_iommu_alias_table[dev_i] = devid_to;
                    set_dev_entry_from_acpi (iommu, devid_to, flags, ext_flags);
                }
                set_dev_entry_from_acpi (iommu, dev_i, flags, ext_flags);
            }
            break;
        default :
            break;
        }
        p += ivhd_entry_length (p);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="678" endline="811">
{
    e = (struct ivhd_entry *) p;
    switch (e->type) {
    case IVHD_DEV_ALL :
        DUMP_printk ("  DEV_ALL\t\t\t first devid: %02x:%02x.%x" " last device %02x:%02x.%x flags: %02x\n", PCI_BUS (iommu->first_device), PCI_SLOT (iommu->first_device), PCI_FUNC (iommu->first_device), PCI_BUS (iommu->last_device), PCI_SLOT (iommu->last_device), PCI_FUNC (iommu->last_device), e->flags);
        for (dev_i = iommu->first_device; dev_i <= iommu->last_device; ++dev_i)
            set_dev_entry_from_acpi (iommu, dev_i, e->flags, 0);
        break;
    case IVHD_DEV_SELECT :
        DUMP_printk ("  DEV_SELECT\t\t\t devid: %02x:%02x.%x " "flags: %02x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags);
        devid = e->devid;
        set_dev_entry_from_acpi (iommu, devid, e -> flags, 0);
        break;
    case IVHD_DEV_SELECT_RANGE_START :
        DUMP_printk ("  DEV_SELECT_RANGE_START\t " "devid: %02x:%02x.%x flags: %02x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags);
        devid_start = e->devid;
        flags = e->flags;
        ext_flags = 0;
        alias = false;
        break;
    case IVHD_DEV_ALIAS :
        DUMP_printk ("  DEV_ALIAS\t\t\t devid: %02x:%02x.%x " "flags: %02x devid_to: %02x:%02x.%x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, PCI_BUS (e->ext >> 8), PCI_SLOT (e->ext >> 8), PCI_FUNC (e->ext >> 8));
        devid = e->devid;
        devid_to = e->ext >> 8;
        set_dev_entry_from_acpi (iommu, devid, e -> flags, 0);
        set_dev_entry_from_acpi (iommu, devid_to, e -> flags, 0);
        amd_iommu_alias_table[devid] = devid_to;
        break;
    case IVHD_DEV_ALIAS_RANGE :
        DUMP_printk ("  DEV_ALIAS_RANGE\t\t " "devid: %02x:%02x.%x flags: %02x " "devid_to: %02x:%02x.%x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, PCI_BUS (e->ext >> 8), PCI_SLOT (e->ext >> 8), PCI_FUNC (e->ext >> 8));
        devid_start = e->devid;
        flags = e->flags;
        devid_to = e->ext >> 8;
        ext_flags = 0;
        alias = true;
        break;
    case IVHD_DEV_EXT_SELECT :
        DUMP_printk ("  DEV_EXT_SELECT\t\t devid: %02x:%02x.%x " "flags: %02x ext: %08x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, e->ext);
        devid = e->devid;
        set_dev_entry_from_acpi (iommu, devid, e -> flags, e -> ext);
        break;
    case IVHD_DEV_EXT_SELECT_RANGE :
        DUMP_printk ("  DEV_EXT_SELECT_RANGE\t devid: " "%02x:%02x.%x flags: %02x ext: %08x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, e->ext);
        devid_start = e->devid;
        flags = e->flags;
        ext_flags = e->ext;
        alias = false;
        break;
    case IVHD_DEV_RANGE_END :
        DUMP_printk ("  DEV_RANGE_END\t\t devid: %02x:%02x.%x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid));
        devid = e->devid;
        for (dev_i = devid_start; dev_i <= devid; ++dev_i) {
            if (alias) {
                amd_iommu_alias_table[dev_i] = devid_to;
                set_dev_entry_from_acpi (iommu, devid_to, flags, ext_flags);
            }
            set_dev_entry_from_acpi (iommu, dev_i, flags, ext_flags);
        }
        break;
    default :
        break;
    }
    p += ivhd_entry_length (p);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="680" endline="808">
{
case IVHD_DEV_ALL :
    DUMP_printk ("  DEV_ALL\t\t\t first devid: %02x:%02x.%x" " last device %02x:%02x.%x flags: %02x\n", PCI_BUS (iommu->first_device), PCI_SLOT (iommu->first_device), PCI_FUNC (iommu->first_device), PCI_BUS (iommu->last_device), PCI_SLOT (iommu->last_device), PCI_FUNC (iommu->last_device), e->flags);
    for (dev_i = iommu->first_device; dev_i <= iommu->last_device; ++dev_i)
        set_dev_entry_from_acpi (iommu, dev_i, e->flags, 0);
    break;
case IVHD_DEV_SELECT :
    DUMP_printk ("  DEV_SELECT\t\t\t devid: %02x:%02x.%x " "flags: %02x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags);
    devid = e->devid;
    set_dev_entry_from_acpi (iommu, devid, e -> flags, 0);
    break;
case IVHD_DEV_SELECT_RANGE_START :
    DUMP_printk ("  DEV_SELECT_RANGE_START\t " "devid: %02x:%02x.%x flags: %02x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags);
    devid_start = e->devid;
    flags = e->flags;
    ext_flags = 0;
    alias = false;
    break;
case IVHD_DEV_ALIAS :
    DUMP_printk ("  DEV_ALIAS\t\t\t devid: %02x:%02x.%x " "flags: %02x devid_to: %02x:%02x.%x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, PCI_BUS (e->ext >> 8), PCI_SLOT (e->ext >> 8), PCI_FUNC (e->ext >> 8));
    devid = e->devid;
    devid_to = e->ext >> 8;
    set_dev_entry_from_acpi (iommu, devid, e -> flags, 0);
    set_dev_entry_from_acpi (iommu, devid_to, e -> flags, 0);
    amd_iommu_alias_table[devid] = devid_to;
    break;
case IVHD_DEV_ALIAS_RANGE :
    DUMP_printk ("  DEV_ALIAS_RANGE\t\t " "devid: %02x:%02x.%x flags: %02x " "devid_to: %02x:%02x.%x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, PCI_BUS (e->ext >> 8), PCI_SLOT (e->ext >> 8), PCI_FUNC (e->ext >> 8));
    devid_start = e->devid;
    flags = e->flags;
    devid_to = e->ext >> 8;
    ext_flags = 0;
    alias = true;
    break;
case IVHD_DEV_EXT_SELECT :
    DUMP_printk ("  DEV_EXT_SELECT\t\t devid: %02x:%02x.%x " "flags: %02x ext: %08x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, e->ext);
    devid = e->devid;
    set_dev_entry_from_acpi (iommu, devid, e -> flags, e -> ext);
    break;
case IVHD_DEV_EXT_SELECT_RANGE :
    DUMP_printk ("  DEV_EXT_SELECT_RANGE\t devid: " "%02x:%02x.%x flags: %02x ext: %08x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid), e->flags, e->ext);
    devid_start = e->devid;
    flags = e->flags;
    ext_flags = e->ext;
    alias = false;
    break;
case IVHD_DEV_RANGE_END :
    DUMP_printk ("  DEV_RANGE_END\t\t devid: %02x:%02x.%x\n", PCI_BUS (e->devid), PCI_SLOT (e->devid), PCI_FUNC (e->devid));
    devid = e->devid;
    for (dev_i = devid_start; dev_i <= devid; ++dev_i) {
        if (alias) {
            amd_iommu_alias_table[dev_i] = devid_to;
            set_dev_entry_from_acpi (iommu, devid_to, flags, ext_flags);
        }
        set_dev_entry_from_acpi (iommu, dev_i, flags, ext_flags);
    }
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="796" endline="804">
{
    if (alias) {
        amd_iommu_alias_table[dev_i] = devid_to;
        set_dev_entry_from_acpi (iommu, devid_to, flags, ext_flags);
    }
    set_dev_entry_from_acpi (iommu, dev_i, flags, ext_flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="797" endline="801">
{
    amd_iommu_alias_table[dev_i] = devid_to;
    set_dev_entry_from_acpi (iommu, devid_to, flags, ext_flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="816" endline="823">
{
    u16 i;
    for (i = iommu->first_device; i <= iommu->last_device; ++i)
        set_iommu_for_device (iommu, i);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="826" endline="830">
{
    free_command_buffer (iommu);
    free_event_buffer (iommu);
    iommu_unmap_mmio_space (iommu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="833" endline="841">
{
    struct amd_iommu *iommu, *next;

    for_each_iommu_safe (iommu, next) {
        list_del (& iommu -> list);
        free_iommu_one (iommu);
        kfree (iommu);
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="836" endline="840">
{
    list_del (& iommu -> list);
    free_iommu_one (iommu);
    kfree (iommu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="849" endline="896">
{
    spin_lock_init (& iommu -> lock);
    list_add_tail (& iommu -> list, & amd_iommu_list);
    iommu->index = amd_iommus_present++;
    if (unlikely (iommu->index >= MAX_IOMMUS)) {
        WARN (1, "AMD-Vi: System has more IOMMUs than supported by this driver\n");
        return -ENOSYS;
    }
    amd_iommus[iommu->index] = iommu;
    iommu->dev = pci_get_bus_and_slot (PCI_BUS (h->devid), h->devid & 0xff);
    if (!iommu->dev)
        return 1;
    iommu->cap_ptr = h->cap_ptr;
    iommu->pci_seg = h->pci_seg;
    iommu->mmio_phys = h->mmio_phys;
    iommu->mmio_base = iommu_map_mmio_space (h->mmio_phys);
    if (!iommu->mmio_base)
        return -ENOMEM;
    iommu->cmd_buf = alloc_command_buffer (iommu);
    if (!iommu->cmd_buf)
        return -ENOMEM;
    iommu->evt_buf = alloc_event_buffer (iommu);
    if (!iommu->evt_buf)
        return -ENOMEM;
    iommu->int_enabled = false;
    init_iommu_from_pci (iommu);
    init_iommu_from_acpi (iommu, h);
    init_iommu_devices (iommu);
    if (iommu->cap & (1UL << IOMMU_CAP_NPCACHE))
        amd_iommu_np_cache = true;
    return pci_enable_device (iommu->dev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="856" endline="859">
{
    WARN (1, "AMD-Vi: System has more IOMMUs than supported by this driver\n");
    return -ENOSYS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="903" endline="946">
{
    u8 *p = (u8 *) table, *end = (u8 *) table;
    struct ivhd_header *h;
    struct amd_iommu *iommu;
    int ret;
    end += table->length;
    p += IVRS_HEADER_LENGTH;
    while (p < end) {
        h = (struct ivhd_header *) p;
        switch (*p) {
        case ACPI_IVHD_TYPE :
            DUMP_printk ("device: %02x:%02x.%01x cap: %04x " "seg: %d flags: %01x info %04x\n", PCI_BUS (h->devid), PCI_SLOT (h->devid), PCI_FUNC (h->devid), h->cap_ptr, h->pci_seg, h->flags, h->info);
            DUMP_printk ("       mmio-addr: %016llx\n", h -> mmio_phys);
            iommu = kzalloc (sizeof (struct amd_iommu), GFP_KERNEL);
            if (iommu == NULL) {
                amd_iommu_init_err = -ENOMEM;
                return 0;
            }
            ret = init_iommu_one (iommu, h);
            if (ret) {
                amd_iommu_init_err = ret;
                return 0;
            }
            break;
        default :
            break;
        }
        p += h->length;
    }
    WARN_ON (p != end);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="912" endline="942">
{
    h = (struct ivhd_header *) p;
    switch (*p) {
    case ACPI_IVHD_TYPE :
        DUMP_printk ("device: %02x:%02x.%01x cap: %04x " "seg: %d flags: %01x info %04x\n", PCI_BUS (h->devid), PCI_SLOT (h->devid), PCI_FUNC (h->devid), h->cap_ptr, h->pci_seg, h->flags, h->info);
        DUMP_printk ("       mmio-addr: %016llx\n", h -> mmio_phys);
        iommu = kzalloc (sizeof (struct amd_iommu), GFP_KERNEL);
        if (iommu == NULL) {
            amd_iommu_init_err = -ENOMEM;
            return 0;
        }
        ret = init_iommu_one (iommu, h);
        if (ret) {
            amd_iommu_init_err = ret;
            return 0;
        }
        break;
    default :
        break;
    }
    p += h->length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="914" endline="939">
{
case ACPI_IVHD_TYPE :
    DUMP_printk ("device: %02x:%02x.%01x cap: %04x " "seg: %d flags: %01x info %04x\n", PCI_BUS (h->devid), PCI_SLOT (h->devid), PCI_FUNC (h->devid), h->cap_ptr, h->pci_seg, h->flags, h->info);
    DUMP_printk ("       mmio-addr: %016llx\n", h -> mmio_phys);
    iommu = kzalloc (sizeof (struct amd_iommu), GFP_KERNEL);
    if (iommu == NULL) {
        amd_iommu_init_err = -ENOMEM;
        return 0;
    }
    ret = init_iommu_one (iommu, h);
    if (ret) {
        amd_iommu_init_err = ret;
        return 0;
    }
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="926" endline="929">
{
    amd_iommu_init_err = -ENOMEM;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="932" endline="935">
{
    amd_iommu_init_err = ret;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="958" endline="978">
{
    int r;
    if (pci_enable_msi (iommu->dev))
        return 1;
    r = request_irq (iommu->dev->irq, amd_iommu_int_handler, IRQF_SAMPLE_RANDOM, "AMD-Vi", NULL);
    if (r) {
        pci_disable_msi (iommu -> dev);
        return 1;
    }
    iommu->int_enabled = true;
    iommu_feature_enable (iommu, CONTROL_EVT_INT_EN);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="969" endline="972">
{
    pci_disable_msi (iommu -> dev);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="981" endline="989">
{
    if (iommu->int_enabled)
        return 0;
    if (pci_find_capability (iommu->dev, PCI_CAP_ID_MSI))
        return iommu_setup_msi (iommu);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1000" endline="1007">
{
    struct unity_map_entry *entry, *next;
    list_for_each_entry_safe (entry, next, &amd_iommu_unity_map, list) {
        list_del (& entry -> list);
        kfree (entry);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1003" endline="1006">
{
    list_del (& entry -> list);
    kfree (entry);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1011" endline="1031">
{
    int i;
    switch (m->type) {
    case ACPI_IVMD_TYPE :
        set_device_exclusion_range (m->devid, m);
        break;
    case ACPI_IVMD_TYPE_ALL :
        for (i = 0; i <= amd_iommu_last_bdf; ++i)
            set_device_exclusion_range (i, m);
        break;
    case ACPI_IVMD_TYPE_RANGE :
        for (i = m->devid; i <= m->aux; ++i)
            set_device_exclusion_range (i, m);
        break;
    default :
        break;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1014" endline="1028">
{
case ACPI_IVMD_TYPE :
    set_device_exclusion_range (m->devid, m);
    break;
case ACPI_IVMD_TYPE_ALL :
    for (i = 0; i <= amd_iommu_last_bdf; ++i)
        set_device_exclusion_range (i, m);
    break;
case ACPI_IVMD_TYPE_RANGE :
    for (i = m->devid; i <= m->aux; ++i)
        set_device_exclusion_range (i, m);
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1035" endline="1076">
{
    struct unity_map_entry *e = 0;
    char *s;
    e = kzalloc (sizeof (*e), GFP_KERNEL);
    if (e == NULL)
        return -ENOMEM;
    switch (m->type) {
    default :
        kfree (e);
        return 0;
    case ACPI_IVMD_TYPE :
        s = "IVMD_TYPEi\t\t\t";
        e->devid_start = e->devid_end = m->devid;
        break;
    case ACPI_IVMD_TYPE_ALL :
        s = "IVMD_TYPE_ALL\t\t";
        e->devid_start = 0;
        e->devid_end = amd_iommu_last_bdf;
        break;
    case ACPI_IVMD_TYPE_RANGE :
        s = "IVMD_TYPE_RANGE\t\t";
        e->devid_start = m->devid;
        e->devid_end = m->aux;
        break;
    }
    e->address_start = PAGE_ALIGN (m->range_start);
    e->address_end = e->address_start + PAGE_ALIGN (m->range_length);
    e->prot = m->flags >> 1;
    DUMP_printk ("%s devid_start: %02x:%02x.%x devid_end: %02x:%02x.%x" " range_start: %016llx range_end: %016llx flags: %x\n", s, PCI_BUS (e -> devid_start), PCI_SLOT (e -> devid_start), PCI_FUNC (e -> devid_start), PCI_BUS (e -> devid_end), PCI_SLOT (e -> devid_end), PCI_FUNC (e -> devid_end), e -> address_start, e -> address_end, m -> flags);
    list_add_tail (& e -> list, & amd_iommu_unity_map);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1043" endline="1061">
{
default :
    kfree (e);
    return 0;
case ACPI_IVMD_TYPE :
    s = "IVMD_TYPEi\t\t\t";
    e->devid_start = e->devid_end = m->devid;
    break;
case ACPI_IVMD_TYPE_ALL :
    s = "IVMD_TYPE_ALL\t\t";
    e->devid_start = 0;
    e->devid_end = amd_iommu_last_bdf;
    break;
case ACPI_IVMD_TYPE_RANGE :
    s = "IVMD_TYPE_RANGE\t\t";
    e->devid_start = m->devid;
    e->devid_end = m->aux;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1080" endline="1098">
{
    u8 *p = (u8 *) table, *end = (u8 *) table;
    struct ivmd_header *m;
    end += table->length;
    p += IVRS_HEADER_LENGTH;
    while (p < end) {
        m = (struct ivmd_header *) p;
        if (m->flags & IVMD_FLAG_EXCL_RANGE)
            init_exclusion_range (m);
        else if (m->flags & IVMD_FLAG_UNITY_MAP)
            init_unity_map_range (m);
        p += m->length;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1087" endline="1095">
{
    m = (struct ivmd_header *) p;
    if (m->flags & IVMD_FLAG_EXCL_RANGE)
        init_exclusion_range (m);
    else if (m->flags & IVMD_FLAG_UNITY_MAP)
        init_unity_map_range (m);
    p += m->length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1105" endline="1112">
{
    u16 devid;
    for (devid = 0; devid <= amd_iommu_last_bdf; ++devid) {
        set_dev_entry_bit (devid, DEV_ENTRY_VALID);
        set_dev_entry_bit (devid, DEV_ENTRY_TRANSLATION);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1108" endline="1111">
{
    set_dev_entry_bit (devid, DEV_ENTRY_VALID);
    set_dev_entry_bit (devid, DEV_ENTRY_TRANSLATION);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1119" endline="1131">
{
    struct amd_iommu *iommu;

    for_each_iommu (iommu) {
        iommu_disable (iommu);
        iommu_set_device_table (iommu);
        iommu_enable_command_buffer (iommu);
        iommu_enable_event_buffer (iommu);
        iommu_set_exclusion_range (iommu);
        iommu_init_msi (iommu);
        iommu_enable (iommu);
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1122" endline="1130">
{
    iommu_disable (iommu);
    iommu_set_device_table (iommu);
    iommu_enable_command_buffer (iommu);
    iommu_enable_event_buffer (iommu);
    iommu_set_exclusion_range (iommu);
    iommu_init_msi (iommu);
    iommu_enable (iommu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1134" endline="1139">
{
    struct amd_iommu *iommu;
    for_each_iommu (iommu)
    iommu_disable (iommu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1147" endline="1159">
{
    enable_iommus ();
    amd_iommu_flush_all_devices ();
    amd_iommu_flush_all_domains ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1162" endline="1167">
{
    disable_iommus ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1209" endline="1356">
{
    int i, ret = 0;
    if (acpi_table_parse ("IVRS", find_last_devid_acpi) != 0)
        return -ENODEV;
    ret = amd_iommu_init_err;
    if (ret)
        goto out;
    dev_table_size = tbl_size (DEV_TABLE_ENTRY_SIZE);
    alias_table_size = tbl_size (ALIAS_TABLE_ENTRY_SIZE);
    rlookup_table_size = tbl_size (RLOOKUP_TABLE_ENTRY_SIZE);
    ret = -ENOMEM;
    amd_iommu_dev_table = (void *) __get_free_pages (GFP_KERNEL | __GFP_ZERO, get_order (dev_table_size));
    if (amd_iommu_dev_table == NULL)
        goto out;
    amd_iommu_alias_table = (void *) __get_free_pages (GFP_KERNEL, get_order (alias_table_size));
    if (amd_iommu_alias_table == NULL)
        goto free;
    amd_iommu_rlookup_table = (void *) __get_free_pages (GFP_KERNEL | __GFP_ZERO, get_order (rlookup_table_size));
    if (amd_iommu_rlookup_table == NULL)
        goto free;
    amd_iommu_pd_alloc_bitmap = (void *) __get_free_pages (GFP_KERNEL | __GFP_ZERO, get_order (MAX_DOMAIN_ID / 8));
    if (amd_iommu_pd_alloc_bitmap == NULL)
        goto free;
    init_device_table ();
    for (i = 0; i <= amd_iommu_last_bdf; ++i)
        amd_iommu_alias_table[i] = i;
    amd_iommu_pd_alloc_bitmap[0] = 1;
    spin_lock_init (& amd_iommu_pd_lock);
    ret = -ENODEV;
    if (acpi_table_parse ("IVRS", init_iommu_all) != 0)
        goto free;
    if (amd_iommu_init_err) {
        ret = amd_iommu_init_err;
        goto free;
    }
    if (acpi_table_parse ("IVRS", init_memory_definitions) != 0)
        goto free;
    if (amd_iommu_init_err) {
        ret = amd_iommu_init_err;
        goto free;
    }
    ret = sysdev_class_register (&amd_iommu_sysdev_class);
    if (ret)
        goto free;
    ret = sysdev_register (&device_amd_iommu);
    if (ret)
        goto free;
    ret = amd_iommu_init_devices ();
    if (ret)
        goto free;
    enable_iommus ();
    if (iommu_pass_through)
        ret = amd_iommu_init_passthrough ();
    else
        ret = amd_iommu_init_dma_ops ();
    if (ret)
        goto free;
    amd_iommu_init_api ();
    amd_iommu_init_notifier ();
    if (iommu_pass_through)
        goto out;
    if (amd_iommu_unmap_flush)
        printk (KERN_INFO "AMD-Vi: IO/TLB flush on unmap enabled\n");
    else
        printk (KERN_INFO "AMD-Vi: Lazy IO/TLB flushing enabled\n");
    x86_platform.iommu_shutdown = disable_iommus;
out :
    return ret;
free :
    disable_iommus ();
    amd_iommu_uninit_devices ();
    free_pages ((unsigned long) amd_iommu_pd_alloc_bitmap, get_order (MAX_DOMAIN_ID / 8));
    free_pages ((unsigned long) amd_iommu_rlookup_table, get_order (rlookup_table_size));
    free_pages ((unsigned long) amd_iommu_alias_table, get_order (alias_table_size));
    free_pages ((unsigned long) amd_iommu_dev_table, get_order (dev_table_size));
    free_iommu_all ();
    free_unity_maps ();
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1283" endline="1286">
{
    ret = amd_iommu_init_err;
    goto free;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1291" endline="1294">
{
    ret = amd_iommu_init_err;
    goto free;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1366" endline="1368">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1371" endline="1383">
{
    if (no_iommu || (iommu_detected && !gart_iommu_aperture))
        return;
    if (acpi_table_parse ("IVRS", early_amd_iommu_detect) == 0) {
        iommu_detected = 1;
        amd_iommu_detected = 1;
        x86_init.iommu.iommu_init = amd_iommu_init;
        pci_request_acs ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1375" endline="1382">
{
    iommu_detected = 1;
    amd_iommu_detected = 1;
    x86_init.iommu.iommu_init = amd_iommu_init;
    pci_request_acs ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1393" endline="1397">
{
    amd_iommu_dump = true;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1400" endline="1407">
{
    for (; *str; ++str) {
        if (strncmp (str, "fullflush", 9) == 0)
            amd_iommu_unmap_flush = true;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/amd_iommu_init.c.ifdefed" startline="1401" endline="1404">
{
    if (strncmp (str, "fullflush", 9) == 0)
        amd_iommu_unmap_flush = true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="62" endline="65">
{
    efi_enabled = 0;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="72" endline="75">
{
    add_efi_memmap = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="80" endline="82">
{
    return efi_call_virt2 (get_time, tm, tc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="85" endline="87">
{
    return efi_call_virt1 (set_time, tm);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="92" endline="95">
{
    return efi_call_virt3 (get_wakeup_time, enabled, pending, tm);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="98" endline="101">
{
    return efi_call_virt2 (set_wakeup_time, enabled, tm);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="108" endline="112">
{
    return efi_call_virt5 (get_variable, name, vendor, attr, data_size, data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="117" endline="120">
{
    return efi_call_virt3 (get_next_variable, name_size, name, vendor);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="127" endline="131">
{
    return efi_call_virt5 (set_variable, name, vendor, attr, data_size, data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="134" endline="136">
{
    return efi_call_virt1 (get_next_high_mono_count, count);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="142" endline="145">
{
    efi_call_virt4 (reset_system, reset_type, status, data_size, data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="152" endline="156">
{
    return efi_call_virt4 (set_virtual_address_map, memory_map_size, descriptor_size, descriptor_version, virtual_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="163" endline="172">
{
    efi_status_t status;
    efi_call_phys_prelog ();
    status = efi_call_phys4 (efi_phys.set_virtual_address_map, memory_map_size, descriptor_size, descriptor_version, virtual_map);
    efi_call_phys_epilog ();
    return status;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="176" endline="183">
{
    efi_status_t status;
    efi_call_phys_prelog ();
    status = efi_call_phys2 (efi_phys.get_time, tm, tc);
    efi_call_phys_epilog ();
    return status;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="186" endline="212">
{
    int real_seconds, real_minutes;
    efi_status_t status;
    efi_time_t eft;
    efi_time_cap_t cap;
    status = efi.get_time (&eft, &cap);
    if (status != EFI_SUCCESS) {
        printk (KERN_ERR "Oops: efitime: can't read time!\n");
        return -1;
    }
    real_seconds = nowtime % 60;
    real_minutes = nowtime / 60;
    if (((abs (real_minutes -eft.minute) + 15) / 30) & 1)
        real_minutes += 30;
    real_minutes %= 60;
    eft.minute = real_minutes;
    eft.second = real_seconds;
    status = efi.set_time (&eft);
    if (status != EFI_SUCCESS) {
        printk (KERN_ERR "Oops: efitime: can't write time!\n");
        return -1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="193" endline="196">
{
    printk (KERN_ERR "Oops: efitime: can't read time!\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="207" endline="210">
{
    printk (KERN_ERR "Oops: efitime: can't write time!\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="215" endline="226">
{
    efi_status_t status;
    efi_time_t eft;
    efi_time_cap_t cap;
    status = efi.get_time (&eft, &cap);
    if (status != EFI_SUCCESS)
        printk (KERN_ERR "Oops: efitime: can't read time!\n");
    return mktime (eft.year, eft.month, eft.day, eft.hour, eft.minute, eft.second);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="235" endline="276">
{
    void *p;
    for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
        efi_memory_desc_t *md = p;
        unsigned long long start = md->phys_addr;
        unsigned long long size = md->num_pages << EFI_PAGE_SHIFT;
        int e820_type;
        switch (md->type) {
        case EFI_LOADER_CODE :
        case EFI_LOADER_DATA :
        case EFI_BOOT_SERVICES_CODE :
        case EFI_BOOT_SERVICES_DATA :
        case EFI_CONVENTIONAL_MEMORY :
            if (md->attribute & EFI_MEMORY_WB)
                e820_type = E820_RAM;
            else
                e820_type = E820_RESERVED;
            break;
        case EFI_ACPI_RECLAIM_MEMORY :
            e820_type = E820_ACPI;
            break;
        case EFI_ACPI_MEMORY_NVS :
            e820_type = E820_NVS;
            break;
        case EFI_UNUSABLE_MEMORY :
            e820_type = E820_UNUSABLE;
            break;
        default :
            e820_type = E820_RESERVED;
            break;
        }
        e820_add_region (start, size, e820_type);
    }
    sanitize_e820_map (e820.map, ARRAY_SIZE (e820.map), & e820.nr_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="238" endline="274">
{
    efi_memory_desc_t *md = p;
    unsigned long long start = md->phys_addr;
    unsigned long long size = md->num_pages << EFI_PAGE_SHIFT;
    int e820_type;
    switch (md->type) {
    case EFI_LOADER_CODE :
    case EFI_LOADER_DATA :
    case EFI_BOOT_SERVICES_CODE :
    case EFI_BOOT_SERVICES_DATA :
    case EFI_CONVENTIONAL_MEMORY :
        if (md->attribute & EFI_MEMORY_WB)
            e820_type = E820_RAM;
        else
            e820_type = E820_RESERVED;
        break;
    case EFI_ACPI_RECLAIM_MEMORY :
        e820_type = E820_ACPI;
        break;
    case EFI_ACPI_MEMORY_NVS :
        e820_type = E820_NVS;
        break;
    case EFI_UNUSABLE_MEMORY :
        e820_type = E820_UNUSABLE;
        break;
    default :
        e820_type = E820_RESERVED;
        break;
    }
    e820_add_region (start, size, e820_type);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="244" endline="272">
{
case EFI_LOADER_CODE :
case EFI_LOADER_DATA :
case EFI_BOOT_SERVICES_CODE :
case EFI_BOOT_SERVICES_DATA :
case EFI_CONVENTIONAL_MEMORY :
    if (md->attribute & EFI_MEMORY_WB)
        e820_type = E820_RAM;
    else
        e820_type = E820_RESERVED;
    break;
case EFI_ACPI_RECLAIM_MEMORY :
    e820_type = E820_ACPI;
    break;
case EFI_ACPI_MEMORY_NVS :
    e820_type = E820_NVS;
    break;
case EFI_UNUSABLE_MEMORY :
    e820_type = E820_UNUSABLE;
    break;
default :
    e820_type = E820_RESERVED;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="279" endline="295">
{
    unsigned long pmap;
    pmap = (boot_params.efi_info.efi_memmap | ((__u64) boot_params.efi_info.efi_memmap_hi << 32));
    memmap.phys_map = (void *) pmap;
    memmap.nr_map = boot_params.efi_info.efi_memmap_size / boot_params.efi_info.efi_memdesc_size;
    memmap.desc_version = boot_params.efi_info.efi_memdesc_version;
    memmap.desc_size = boot_params.efi_info.efi_memdesc_size;
    reserve_early (pmap, pmap + memmap.nr_map * memmap.desc_size, "EFI memmap");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="318" endline="468">
{
    efi_config_table_t *config_tables;
    efi_runtime_services_t *runtime;
    efi_char16_t *c16;
    char vendor [100] = "unknown";
    int i = 0;
    void *tmp;
    efi_phys.systab = (efi_system_table_t *) (boot_params.efi_info.efi_systab | ((__u64) boot_params.efi_info.efi_systab_hi << 32));
    efi.systab = early_ioremap ((unsigned long) efi_phys.systab, sizeof (efi_system_table_t));
    if (efi.systab == NULL)
        printk (KERN_ERR "Couldn't map the EFI system table!\n");
    memcpy (& efi_systab, efi.systab, sizeof (efi_system_table_t));
    early_iounmap (efi.systab, sizeof (efi_system_table_t));
    efi.systab = &efi_systab;
    if (efi.systab->hdr.signature != EFI_SYSTEM_TABLE_SIGNATURE)
        printk (KERN_ERR "EFI system table signature incorrect!\n");
    if ((efi.systab->hdr.revision >> 16) == 0)
        printk (KERN_ERR "Warning: EFI system table version " "%d.%02d, expected 1.00 or greater!\n", efi.systab->hdr.revision >> 16, efi.systab->hdr.revision & 0xffff);
    c16 = tmp = early_ioremap (efi.systab->fw_vendor, 2);
    if (c16) {
        for (i = 0; i < sizeof (vendor) - 1 && *c16; ++i)
            vendor[i] = *c16++;
        vendor[i] = '\0';
    }
    else
        printk (KERN_ERR PFX "Could not map the firmware vendor!\n");
    early_iounmap (tmp, 2);
    printk (KERN_INFO "EFI v%u.%.02u by %s\n", efi.systab -> hdr.revision >> 16, efi.systab -> hdr.revision & 0xffff, vendor);
    config_tables = early_ioremap (efi.systab->tables, efi.systab->nr_tables * sizeof (efi_config_table_t));
    if (config_tables == NULL)
        printk (KERN_ERR "Could not map EFI Configuration Table!\n");
    printk (KERN_INFO);
    for (i = 0; i < efi.systab->nr_tables; i++) {
        if (!efi_guidcmp (config_tables[i].guid, MPS_TABLE_GUID)) {
            efi.mps = config_tables[i].table;
            printk (" MPS=0x%lx ", config_tables [i].table);
        }
        else if (!efi_guidcmp (config_tables[i].guid, ACPI_20_TABLE_GUID)) {
            efi.acpi20 = config_tables[i].table;
            printk (" ACPI 2.0=0x%lx ", config_tables [i].table);
        }
        else if (!efi_guidcmp (config_tables[i].guid, ACPI_TABLE_GUID)) {
            efi.acpi = config_tables[i].table;
            printk (" ACPI=0x%lx ", config_tables [i].table);
        }
        else if (!efi_guidcmp (config_tables[i].guid, SMBIOS_TABLE_GUID)) {
            efi.smbios = config_tables[i].table;
            printk (" SMBIOS=0x%lx ", config_tables [i].table);
        }
        else if (!efi_guidcmp (config_tables[i].guid, HCDP_TABLE_GUID)) {
            efi.hcdp = config_tables[i].table;
            printk (" HCDP=0x%lx ", config_tables [i].table);
        }
        else if (!efi_guidcmp (config_tables[i].guid, UGA_IO_PROTOCOL_GUID)) {
            efi.uga = config_tables[i].table;
            printk (" UGA=0x%lx ", config_tables [i].table);
        }
    }
    printk ("\n");
    early_iounmap (config_tables, efi.systab -> nr_tables * sizeof (efi_config_table_t));
    runtime = early_ioremap ((unsigned long) efi.systab->runtime, sizeof (efi_runtime_services_t));
    if (runtime != NULL) {
        efi_phys.get_time = (efi_get_time_t *) runtime->get_time;
        efi_phys.set_virtual_address_map = (efi_set_virtual_address_map_t *) runtime->set_virtual_address_map;
        efi.get_time = phys_efi_get_time;
    }
    else
        printk (KERN_ERR "Could not map the EFI runtime service " "table!\n");
    early_iounmap (runtime, sizeof (efi_runtime_services_t));
    memmap.map = early_ioremap ((unsigned long) memmap.phys_map, memmap.nr_map * memmap.desc_size);
    if (memmap.map == NULL)
        printk (KERN_ERR "Could not map the EFI memory map!\n");
    memmap.map_end = memmap.map + (memmap.nr_map * memmap.desc_size);
    if (memmap.desc_size != sizeof (efi_memory_desc_t))
        printk (KERN_WARNING "Kernel-defined memdesc doesn't match the one from EFI!\n");
    if (add_efi_memmap)
        do_add_efi_memmap ();
    reboot_type = BOOT_EFI;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="357" endline="361">
{
    for (i = 0; i < sizeof (vendor) - 1 && *c16; ++i)
        vendor[i] = *c16++;
    vendor[i] = '\0';
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="379" endline="410">
{
    if (!efi_guidcmp (config_tables[i].guid, MPS_TABLE_GUID)) {
        efi.mps = config_tables[i].table;
        printk (" MPS=0x%lx ", config_tables [i].table);
    }
    else if (!efi_guidcmp (config_tables[i].guid, ACPI_20_TABLE_GUID)) {
        efi.acpi20 = config_tables[i].table;
        printk (" ACPI 2.0=0x%lx ", config_tables [i].table);
    }
    else if (!efi_guidcmp (config_tables[i].guid, ACPI_TABLE_GUID)) {
        efi.acpi = config_tables[i].table;
        printk (" ACPI=0x%lx ", config_tables [i].table);
    }
    else if (!efi_guidcmp (config_tables[i].guid, SMBIOS_TABLE_GUID)) {
        efi.smbios = config_tables[i].table;
        printk (" SMBIOS=0x%lx ", config_tables [i].table);
    }
    else if (!efi_guidcmp (config_tables[i].guid, HCDP_TABLE_GUID)) {
        efi.hcdp = config_tables[i].table;
        printk (" HCDP=0x%lx ", config_tables [i].table);
    }
    else if (!efi_guidcmp (config_tables[i].guid, UGA_IO_PROTOCOL_GUID)) {
        efi.uga = config_tables[i].table;
        printk (" UGA=0x%lx ", config_tables [i].table);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="380" endline="383">
{
    efi.mps = config_tables[i].table;
    printk (" MPS=0x%lx ", config_tables [i].table);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="384" endline="387">
{
    efi.acpi20 = config_tables[i].table;
    printk (" ACPI 2.0=0x%lx ", config_tables [i].table);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="388" endline="391">
{
    efi.acpi = config_tables[i].table;
    printk (" ACPI=0x%lx ", config_tables [i].table);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="392" endline="401">
{
    efi.smbios = config_tables[i].table;
    printk (" SMBIOS=0x%lx ", config_tables [i].table);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="402" endline="405">
{
    efi.hcdp = config_tables[i].table;
    printk (" HCDP=0x%lx ", config_tables [i].table);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="406" endline="409">
{
    efi.uga = config_tables[i].table;
    printk (" UGA=0x%lx ", config_tables [i].table);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="423" endline="438">
{
    efi_phys.get_time = (efi_get_time_t *) runtime->get_time;
    efi_phys.set_virtual_address_map = (efi_set_virtual_address_map_t *) runtime->set_virtual_address_map;
    efi.get_time = phys_efi_get_time;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="471" endline="488">
{
    efi_memory_desc_t *md;
    void *p;
    u64 addr, npages;
    for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
        md = p;
        if (md->type != EFI_RUNTIME_SERVICES_CODE)
            continue;
        addr = md->virt_addr;
        npages = md->num_pages;
        memrange_efi_to_native (& addr, & npages);
        set_memory_x (addr, npages);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="477" endline="487">
{
    md = p;
    if (md->type != EFI_RUNTIME_SERVICES_CODE)
        continue;
    addr = md->virt_addr;
    npages = md->num_pages;
    memrange_efi_to_native (& addr, & npages);
    set_memory_x (addr, npages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="499" endline="579">
{
    efi_memory_desc_t *md;
    efi_status_t status;
    unsigned long size;
    u64 end, systab, addr, npages, end_pfn;
    void *p, *va;
    efi.systab = NULL;
    for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
        md = p;
        if (!(md->attribute & EFI_MEMORY_RUNTIME))
            continue;
        size = md->num_pages << EFI_PAGE_SHIFT;
        end = md->phys_addr + size;
        end_pfn = PFN_UP (end);
        if (end_pfn <= max_low_pfn_mapped || (end_pfn > (1UL << (32 - PAGE_SHIFT)) && end_pfn <= max_pfn_mapped))
            va = __va (md->phys_addr);
        else
            va = efi_ioremap (md->phys_addr, size, md->type);
        md->virt_addr = (u64) (unsigned long) va;
        if (!va) {
            printk (KERN_ERR PFX "ioremap of 0x%llX failed!\n", (unsigned long long) md -> phys_addr);
            continue;
        }
        if (!(md->attribute & EFI_MEMORY_WB)) {
            addr = md->virt_addr;
            npages = md->num_pages;
            memrange_efi_to_native (& addr, & npages);
            set_memory_uc (addr, npages);
        }
        systab = (u64) (unsigned long) efi_phys.systab;
        if (md->phys_addr <= systab && systab < end) {
            systab += md->virt_addr - md->phys_addr;
            efi.systab = (efi_system_table_t *) (unsigned long) systab;
        }
    }
    BUG_ON (! efi.systab);
    status = phys_efi_set_virtual_address_map (memmap.desc_size * memmap.nr_map, memmap.desc_size, memmap.desc_version, memmap.phys_map);
    if (status != EFI_SUCCESS) {
        printk (KERN_ALERT "Unable to switch EFI into virtual mode " "(status=%lx)!\n", status);
        panic ("EFI call to SetVirtualAddressMap() failed!");
    }
    efi.get_time = virt_efi_get_time;
    efi.set_time = virt_efi_set_time;
    efi.get_wakeup_time = virt_efi_get_wakeup_time;
    efi.set_wakeup_time = virt_efi_set_wakeup_time;
    efi.get_variable = virt_efi_get_variable;
    efi.get_next_variable = virt_efi_get_next_variable;
    efi.set_variable = virt_efi_set_variable;
    efi.get_next_high_mono_count = virt_efi_get_next_high_mono_count;
    efi.reset_system = virt_efi_reset_system;
    efi.set_virtual_address_map = virt_efi_set_virtual_address_map;
    if (__supported_pte_mask & _PAGE_NX)
        runtime_code_page_mkexec ();
    early_iounmap (memmap.map, memmap.nr_map * memmap.desc_size);
    memmap.map = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="507" endline="543">
{
    md = p;
    if (!(md->attribute & EFI_MEMORY_RUNTIME))
        continue;
    size = md->num_pages << EFI_PAGE_SHIFT;
    end = md->phys_addr + size;
    end_pfn = PFN_UP (end);
    if (end_pfn <= max_low_pfn_mapped || (end_pfn > (1UL << (32 - PAGE_SHIFT)) && end_pfn <= max_pfn_mapped))
        va = __va (md->phys_addr);
    else
        va = efi_ioremap (md->phys_addr, size, md->type);
    md->virt_addr = (u64) (unsigned long) va;
    if (!va) {
        printk (KERN_ERR PFX "ioremap of 0x%llX failed!\n", (unsigned long long) md -> phys_addr);
        continue;
    }
    if (!(md->attribute & EFI_MEMORY_WB)) {
        addr = md->virt_addr;
        npages = md->num_pages;
        memrange_efi_to_native (& addr, & npages);
        set_memory_uc (addr, npages);
    }
    systab = (u64) (unsigned long) efi_phys.systab;
    if (md->phys_addr <= systab && systab < end) {
        systab += md->virt_addr - md->phys_addr;
        efi.systab = (efi_system_table_t *) (unsigned long) systab;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="525" endline="529">
{
    printk (KERN_ERR PFX "ioremap of 0x%llX failed!\n", (unsigned long long) md -> phys_addr);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="531" endline="536">
{
    addr = md->virt_addr;
    npages = md->num_pages;
    memrange_efi_to_native (& addr, & npages);
    set_memory_uc (addr, npages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="539" endline="542">
{
    systab += md->virt_addr - md->phys_addr;
    efi.systab = (efi_system_table_t *) (unsigned long) systab;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="553" endline="557">
{
    printk (KERN_ALERT "Unable to switch EFI into virtual mode " "(status=%lx)!\n", status);
    panic ("EFI call to SetVirtualAddressMap() failed!");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="585" endline="597">
{
    efi_memory_desc_t *md;
    void *p;
    for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
        md = p;
        if ((md->phys_addr <= phys_addr) && (phys_addr < (md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT))))
            return md->type;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="589" endline="595">
{
    md = p;
    if ((md->phys_addr <= phys_addr) && (phys_addr < (md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT))))
        return md->type;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="600" endline="612">
{
    efi_memory_desc_t *md;
    void *p;
    for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
        md = p;
        if ((md->phys_addr <= phys_addr) && (phys_addr < (md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT))))
            return md->attribute;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi.c.ifdefed" startline="604" endline="610">
{
    md = p;
    if ((md->phys_addr <= phys_addr) && (phys_addr < (md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT))))
        return md->attribute;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="56" endline="61">
{
    struct cpuid_regs *cmd = (struct cpuid_regs *) cmd_block;
    cpuid_count (cmd -> eax, cmd -> ecx, & cmd -> eax, & cmd -> ebx, & cmd -> ecx, & cmd -> edx);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="64" endline="83">
{
    loff_t ret;
    struct inode *inode = file->f_mapping->host;
    mutex_lock (& inode -> i_mutex);
    switch (orig) {
    case 0 :
        file->f_pos = offset;
        ret = file->f_pos;
        break;
    case 1 :
        file->f_pos += offset;
        ret = file->f_pos;
        break;
    default :
        ret = -EINVAL;
    }
    mutex_unlock (& inode -> i_mutex);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="69" endline="80">
{
case 0 :
    file->f_pos = offset;
    ret = file->f_pos;
    break;
case 1 :
    file->f_pos += offset;
    ret = file->f_pos;
    break;
default :
    ret = -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="87" endline="114">
{
    char __user *tmp = buf;
    struct cpuid_regs cmd;
    int cpu = iminor (file->f_path.dentry->d_inode);
    u64 pos = *ppos;
    ssize_t bytes = 0;
    int err = 0;
    if (count % 16)
        return -EINVAL;
    for (; count; count -= 16) {
        cmd.eax = pos;
        cmd.ecx = pos >> 32;
        err = smp_call_function_single (cpu, cpuid_smp_cpuid, &cmd, 1);
        if (err)
            break;
        if (copy_to_user (tmp, &cmd, 16)) {
            err = -EFAULT;
            break;
        }
        tmp += 16;
        bytes += 16;
        *ppos = ++pos;
    }
    return bytes ? bytes : err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="98" endline="111">
{
    cmd.eax = pos;
    cmd.ecx = pos >> 32;
    err = smp_call_function_single (cpu, cpuid_smp_cpuid, &cmd, 1);
    if (err)
        break;
    if (copy_to_user (tmp, &cmd, 16)) {
        err = -EFAULT;
        break;
    }
    tmp += 16;
    bytes += 16;
    *ppos = ++pos;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="104" endline="107">
{
    err = -EFAULT;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="117" endline="130">
{
    unsigned int cpu;
    struct cpuinfo_x86 *c;
    cpu = iminor (file->f_path.dentry->d_inode);
    if (cpu >= nr_cpu_ids || !cpu_online (cpu))
        return -ENXIO;
    c = &cpu_data (cpu);
    if (c->cpuid_level < 0)
        return -EIO;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="143" endline="149">
{
    struct device *dev;
    dev = device_create (cpuid_class, NULL, MKDEV (CPUID_MAJOR, cpu), NULL, "cpu%d", cpu);
    return IS_ERR (dev) ? PTR_ERR (dev) : 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="152" endline="154">
{
    device_destroy (cpuid_class, MKDEV (CPUID_MAJOR, cpu));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="159" endline="174">
{
    unsigned int cpu = (unsigned long) hcpu;
    int err = 0;
    switch (action) {
    case CPU_UP_PREPARE :
        err = cpuid_device_create (cpu);
        break;
    case CPU_UP_CANCELED :
    case CPU_UP_CANCELED_FROZEN :
    case CPU_DEAD :
        cpuid_device_destroy (cpu);
        break;
    }
    return err ? NOTIFY_BAD : NOTIFY_OK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="163" endline="172">
{
case CPU_UP_PREPARE :
    err = cpuid_device_create (cpu);
    break;
case CPU_UP_CANCELED :
case CPU_UP_CANCELED_FROZEN :
case CPU_DEAD :
    cpuid_device_destroy (cpu);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="182" endline="184">
{
    return kasprintf (GFP_KERNEL, "cpu/%u/cpuid", MINOR (dev->devt));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="187" endline="224">
{
    int i, err = 0;
    i = 0;
    if (__register_chrdev (CPUID_MAJOR, 0, NR_CPUS, "cpu/cpuid", &cpuid_fops)) {
        printk (KERN_ERR "cpuid: unable to get major %d for cpuid\n", CPUID_MAJOR);
        err = -EBUSY;
        goto out;
    }
    cpuid_class = class_create (THIS_MODULE, "cpuid");
    if (IS_ERR (cpuid_class)) {
        err = PTR_ERR (cpuid_class);
        goto out_chrdev;
    }
    cpuid_class->devnode = cpuid_devnode;

    for_each_online_cpu (i) {
        err = cpuid_device_create (i);
        if (err != 0)
            goto out_class;
    }

    register_hotcpu_notifier (& cpuid_class_cpu_notifier);
    err = 0;
    goto out;
out_class :
    i = 0;

    for_each_online_cpu (i) {
        cpuid_device_destroy (i);
    }

    class_destroy (cpuid_class);
out_chrdev :
    __unregister_chrdev (CPUID_MAJOR, 0, NR_CPUS, "cpu/cpuid");
out :
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="192" endline="197">
{
    printk (KERN_ERR "cpuid: unable to get major %d for cpuid\n", CPUID_MAJOR);
    err = -EBUSY;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="199" endline="202">
{
    err = PTR_ERR (cpuid_class);
    goto out_chrdev;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="204" endline="208">
{
    err = cpuid_device_create (i);
    if (err != 0)
        goto out_class;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="216" endline="218">
{
    cpuid_device_destroy (i);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpuid.c.ifdefed" startline="227" endline="235">
{
    int cpu = 0;
    for_each_online_cpu (cpu)
    cpuid_device_destroy (cpu);
    class_destroy (cpuid_class);
    __unregister_chrdev (CPUID_MAJOR, 0, NR_CPUS, "cpu/cpuid");
    unregister_hotcpu_notifier (& cpuid_class_cpu_notifier);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ioport.c.ifdefed" startline="22" endline="31">
{
    unsigned int i;
    for (i = base; i < base + extent; i++) {
        if (new_value)
            __set_bit (i, bitmap);
        else
            __clear_bit (i, bitmap);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ioport.c.ifdefed" startline="25" endline="30">
{
    if (new_value)
        __set_bit (i, bitmap);
    else
        __clear_bit (i, bitmap);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ioport.c.ifdefed" startline="37" endline="94">
{
    struct thread_struct *t = &current->thread;
    struct tss_struct *tss;
    unsigned int i, max_long, bytes, bytes_updated;
    if ((from + num <= from) || (from + num > IO_BITMAP_BITS))
        return -EINVAL;
    if (turn_on && !capable (CAP_SYS_RAWIO))
        return -EPERM;
    if (!t->io_bitmap_ptr) {
        unsigned long *bitmap = kmalloc (IO_BITMAP_BYTES, GFP_KERNEL);
        if (!bitmap)
            return -ENOMEM;
        memset (bitmap, 0xff, IO_BITMAP_BYTES);
        t->io_bitmap_ptr = bitmap;
        set_thread_flag (TIF_IO_BITMAP);
    }
    tss = &per_cpu (init_tss, get_cpu ());
    set_bitmap (t -> io_bitmap_ptr, from, num, ! turn_on);
    max_long = 0;
    for (i = 0; i < IO_BITMAP_LONGS; i++)
        if (t->io_bitmap_ptr[i] != ~0UL)
            max_long = i;
    bytes = (max_long + 1) * sizeof (unsigned long);
    bytes_updated = max (bytes, t->io_bitmap_max);
    t->io_bitmap_max = bytes;
    memcpy (tss -> io_bitmap, t -> io_bitmap_ptr, bytes_updated);
    put_cpu ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ioport.c.ifdefed" startline="52" endline="61">
{
    unsigned long *bitmap = kmalloc (IO_BITMAP_BYTES, GFP_KERNEL);
    if (!bitmap)
        return -ENOMEM;
    memset (bitmap, 0xff, IO_BITMAP_BYTES);
    t->io_bitmap_ptr = bitmap;
    set_thread_flag (TIF_IO_BITMAP);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ioport.c.ifdefed" startline="107" endline="123">
{
    unsigned int old = (regs->flags >> 12) & 3;
    struct thread_struct *t = &current->thread;
    if (level > 3)
        return -EINVAL;
    if (level > old) {
        if (!capable (CAP_SYS_RAWIO))
            return -EPERM;
    }
    regs->flags = (regs->flags & ~X86_EFLAGS_IOPL) | (level << 12);
    t->iopl = level << 12;
    set_iopl_mask (t -> iopl);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ioport.c.ifdefed" startline="114" endline="117">
{
    if (!capable (CAP_SYS_RAWIO))
        return -EPERM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="36" endline="45">
{
    const struct range *r1 = x1;
    const struct range *r2 = x2;
    int start1, start2;
    start1 = r1->start >> 32;
    start2 = r2->start >> 32;
    return start1 - start2;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="52" endline="172">
{
    int i;
    unsigned bus;
    unsigned slot;
    int found;
    u64 val;
    u32 address;
    u64 tom2;
    u64 base = FAM10H_PCI_MMCONF_BASE;
    int hi_mmio_num;
    struct range range [8];
    if (fam10h_pci_mmconf_base_status)
        return;
    if (!early_pci_allowed ())
        goto fail;
    found = 0;
    for (i = 0; i < ARRAY_SIZE (pci_probes); i++) {
        u32 id;
        u16 device;
        u16 vendor;
        bus = pci_probes[i].bus;
        slot = pci_probes[i].slot;
        id = read_pci_config (bus, slot, 0, PCI_VENDOR_ID);
        vendor = id & 0xffff;
        device = (id >> 16) & 0xffff;
        if (pci_probes[i].vendor == vendor && pci_probes[i].device == device) {
            found = 1;
            break;
        }
    }
    if (!found)
        goto fail;
    address = MSR_K8_SYSCFG;
    rdmsrl (address, val);
    if (!(val & (1 << 21))) {
        tom2 = 0;
    }
    else {
        address = MSR_K8_TOP_MEM2;
        rdmsrl (address, val);
        tom2 = val & (0xffffULL << 32);
    }
    if (base <= tom2)
        base = tom2 + (1ULL << 32);
    hi_mmio_num = 0;
    for (i = 0; i < 8; i++) {
        u32 reg;
        u64 start;
        u64 end;
        reg = read_pci_config (bus, slot, 1, 0x80 + (i << 3));
        if (!(reg & 3))
            continue;
        start = (((u64) reg) << 8) & (0xffULL << 32);
        reg = read_pci_config (bus, slot, 1, 0x84 + (i << 3));
        end = (((u64) reg) << 8) & (0xffULL << 32);
        if (!end)
            continue;
        range[hi_mmio_num].start = start;
        range[hi_mmio_num].end = end;
        hi_mmio_num++;
    }
    if (!hi_mmio_num)
        goto out;
    sort (range, hi_mmio_num, sizeof (struct range), cmp_range, NULL);
    if (range[hi_mmio_num - 1].end < base)
        goto out;
    if (range[0].start > base)
        goto out;
    base = range[0].start - (1ULL << 32);
    if ((base > tom2) && BASE_VALID (base))
        goto out;
    base = range[hi_mmio_num - 1].end + (1ULL << 32);
    if ((base > tom2) && BASE_VALID (base))
        goto out;
    if (hi_mmio_num > 1)
        for (i = 0; i < hi_mmio_num - 1; i++) {
            if (range[i + 1].start > (range[i].end + (1ULL << 32))) {
                base = range[i].end + (1ULL << 32);
                if ((base > tom2) && BASE_VALID (base))
                    goto out;
            }
        }
fail :
    fam10h_pci_mmconf_base_status = -1;
    return;
out :
    fam10h_pci_mmconf_base = base;
    fam10h_pci_mmconf_base_status = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="75" endline="91">
{
    u32 id;
    u16 device;
    u16 vendor;
    bus = pci_probes[i].bus;
    slot = pci_probes[i].slot;
    id = read_pci_config (bus, slot, 0, PCI_VENDOR_ID);
    vendor = id & 0xffff;
    device = (id >> 16) & 0xffff;
    if (pci_probes[i].vendor == vendor && pci_probes[i].device == device) {
        found = 1;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="87" endline="90">
{
    found = 1;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="101" endline="103">
{
    tom2 = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="103" endline="108">
{
    address = MSR_K8_TOP_MEM2;
    rdmsrl (address, val);
    tom2 = val & (0xffffULL << 32);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="118" endline="136">
{
    u32 reg;
    u64 start;
    u64 end;
    reg = read_pci_config (bus, slot, 1, 0x80 + (i << 3));
    if (!(reg & 3))
        continue;
    start = (((u64) reg) << 8) & (0xffULL << 32);
    reg = read_pci_config (bus, slot, 1, 0x84 + (i << 3));
    end = (((u64) reg) << 8) & (0xffULL << 32);
    if (!end)
        continue;
    range[hi_mmio_num].start = start;
    range[hi_mmio_num].end = end;
    hi_mmio_num++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="158" endline="164">
{
    if (range[i + 1].start > (range[i].end + (1ULL << 32))) {
        base = range[i].end + (1ULL << 32);
        if ((base > tom2) && BASE_VALID (base))
            goto out;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="159" endline="163">
{
    base = range[i].end + (1ULL << 32);
    if ((base > tom2) && BASE_VALID (base))
        goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="175" endline="218">
{
    u64 val;
    u32 address;
    if (!(pci_probe & PCI_CHECK_ENABLE_AMD_MMCONF))
        return;
    address = MSR_FAM10H_MMIO_CONF_BASE;
    rdmsrl (address, val);
    if (val & FAM10H_MMIO_CONF_ENABLE) {
        unsigned busnbits;
        busnbits = (val >> FAM10H_MMIO_CONF_BUSRANGE_SHIFT) & FAM10H_MMIO_CONF_BUSRANGE_MASK;
        if (!acpi_pci_disabled || busnbits >= 8) {
            u64 base;
            base = val & (0xffffULL << 32);
            if (fam10h_pci_mmconf_base_status <= 0) {
                fam10h_pci_mmconf_base = base;
                fam10h_pci_mmconf_base_status = 1;
                return;
            }
            else if (fam10h_pci_mmconf_base == base)
                return;
        }
    }
    get_fam10h_pci_mmconf_base ();
    if (fam10h_pci_mmconf_base_status <= 0)
        return;
    printk (KERN_INFO "Enable MMCONFIG on AMD Family 10h\n");
    val &= ~((FAM10H_MMIO_CONF_BASE_MASK << FAM10H_MMIO_CONF_BASE_SHIFT) | (FAM10H_MMIO_CONF_BUSRANGE_MASK << FAM10H_MMIO_CONF_BUSRANGE_SHIFT));
    val |= fam10h_pci_mmconf_base | (8 << FAM10H_MMIO_CONF_BUSRANGE_SHIFT) | FAM10H_MMIO_CONF_ENABLE;
    wrmsrl (address, val);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="186" endline="202">
{
    unsigned busnbits;
    busnbits = (val >> FAM10H_MMIO_CONF_BUSRANGE_SHIFT) & FAM10H_MMIO_CONF_BUSRANGE_MASK;
    if (!acpi_pci_disabled || busnbits >= 8) {
        u64 base;
        base = val & (0xffffULL << 32);
        if (fam10h_pci_mmconf_base_status <= 0) {
            fam10h_pci_mmconf_base = base;
            fam10h_pci_mmconf_base_status = 1;
            return;
        }
        else if (fam10h_pci_mmconf_base == base)
            return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="192" endline="201">
{
    u64 base;
    base = val & (0xffffULL << 32);
    if (fam10h_pci_mmconf_base_status <= 0) {
        fam10h_pci_mmconf_base = base;
        fam10h_pci_mmconf_base_status = 1;
        return;
    }
    else if (fam10h_pci_mmconf_base == base)
        return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="195" endline="199">
{
    fam10h_pci_mmconf_base = base;
    fam10h_pci_mmconf_base_status = 1;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="221" endline="224">
{
    pci_probe |= PCI_CHECK_ENABLE_AMD_MMCONF;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mmconf-fam10h_64.c.ifdefed" startline="238" endline="240">
{
    dmi_check_system (mmconf_dmi_table);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="41" endline="44">
{
    debug_alternative = 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="50" endline="53">
{
    noreplace_smp = 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="168" endline="177">
{
    if (boot_cpu_has (X86_FEATURE_K8))
        return k8_nops;
    else if (boot_cpu_has (X86_FEATURE_K7))
        return k7_nops;
    else if (boot_cpu_has (X86_FEATURE_NOPL))
        return p6_nops;
    else
        return intel_nops;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="183" endline="194">
{
    const unsigned char * const *noptable = find_nop_table ();
    while (len > 0) {
        unsigned int noplen = len;
        if (noplen > ASM_NOP_MAX)
            noplen = ASM_NOP_MAX;
        memcpy (insns, noptable [noplen], noplen);
        insns += noplen;
        len -= noplen;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="186" endline="193">
{
    unsigned int noplen = len;
    if (noplen > ASM_NOP_MAX)
        noplen = ASM_NOP_MAX;
    memcpy (insns, noptable [noplen], noplen);
    insns += noplen;
    len -= noplen;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="208" endline="234">
{
    struct alt_instr *a;
    u8 insnbuf [MAX_PATCH_LEN];
    DPRINTK ("%s: alt table %p -> %p\n", __func__, start, end);
    for (a = start; a < end; a++) {
        u8 *instr = a->instr;
        BUG_ON (a -> replacementlen > a -> instrlen);
        BUG_ON (a -> instrlen > sizeof (insnbuf));
        if (!boot_cpu_has (a->cpuid))
            continue;
        memcpy (insnbuf, a -> replacement, a -> replacementlen);
        if (*insnbuf == 0xe8 && a->replacementlen == 5)
            *(s32*) (insnbuf + 1) += a->replacement - a->instr;
        add_nops (insnbuf + a -> replacementlen, a -> instrlen - a -> replacementlen);
        text_poke_early (instr, insnbuf, a -> instrlen);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="213" endline="233">
{
    u8 *instr = a->instr;
    BUG_ON (a -> replacementlen > a -> instrlen);
    BUG_ON (a -> instrlen > sizeof (insnbuf));
    if (!boot_cpu_has (a->cpuid))
        continue;
    memcpy (insnbuf, a -> replacement, a -> replacementlen);
    if (*insnbuf == 0xe8 && a->replacementlen == 5)
        *(s32*) (insnbuf + 1) += a->replacement - a->instr;
    add_nops (insnbuf + a -> replacementlen, a -> instrlen - a -> replacementlen);
    text_poke_early (instr, insnbuf, a -> instrlen);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="448" endline="503">
{
    stop_nmi ();
    apply_alternatives (__alt_instructions, __alt_instructions_end);
    apply_paravirt (__parainstructions, __parainstructions_end);
    if (smp_alt_once)
        free_init_pages ("SMP alternatives", (unsigned long) __smp_locks, (unsigned long) __smp_locks_end);
    restart_nmi ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="519" endline="528">
{
    unsigned long flags;
    local_irq_save (flags);
    memcpy (addr, opcode, len);
    sync_core ();
    local_irq_restore (flags);
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="544" endline="576">
{
    unsigned long flags;
    char *vaddr;
    struct page *pages [2];
    int i;
    if (!core_kernel_text ((unsigned long) addr)) {
        pages[0] = vmalloc_to_page (addr);
        pages[1] = vmalloc_to_page (addr +PAGE_SIZE);
    }
    else {
        pages[0] = virt_to_page (addr);
        WARN_ON (! PageReserved (pages [0]));
        pages[1] = virt_to_page (addr +PAGE_SIZE);
    }
    BUG_ON (! pages [0]);
    local_irq_save (flags);
    set_fixmap (FIX_TEXT_POKE0, page_to_phys (pages [0]));
    if (pages[1])
        set_fixmap (FIX_TEXT_POKE1, page_to_phys (pages[1]));
    vaddr = (char *) fix_to_virt (FIX_TEXT_POKE0);
    memcpy (& vaddr [(unsigned long) addr & ~ PAGE_MASK], opcode, len);
    clear_fixmap (FIX_TEXT_POKE0);
    if (pages[1])
        clear_fixmap (FIX_TEXT_POKE1);
    local_flush_tlb ();
    sync_core ();
    for (i = 0; i < len; i++)
        BUG_ON (((char *) addr)[i] != ((char *) opcode)[i]);
    local_irq_restore (flags);
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="550" endline="553">
{
    pages[0] = vmalloc_to_page (addr);
    pages[1] = vmalloc_to_page (addr +PAGE_SIZE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="553" endline="557">
{
    pages[0] = virt_to_page (addr);
    WARN_ON (! PageReserved (pages [0]));
    pages[1] = virt_to_page (addr +PAGE_SIZE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="592" endline="608">
{
    struct text_poke_params *tpp = data;
    if (atomic_dec_and_test (&stop_machine_first)) {
        text_poke (tpp -> addr, tpp -> opcode, tpp -> len);
        smp_wmb ();
        wrote_text = 1;
    }
    else {
        while (!wrote_text)
            cpu_relax ();
        smp_mb ();
    }
    flush_icache_range ((unsigned long) tpp -> addr, (unsigned long) tpp -> addr + tpp -> len);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="595" endline="599">
{
    text_poke (tpp -> addr, tpp -> opcode, tpp -> len);
    smp_wmb ();
    wrote_text = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="599" endline="603">
{
    while (!wrote_text)
        cpu_relax ();
    smp_mb ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/alternative.c.ifdefed" startline="624" endline="634">
{
    struct text_poke_params tpp;
    tpp.addr = addr;
    tpp.opcode = opcode;
    tpp.len = len;
    atomic_set (& stop_machine_first, 1);
    wrote_text = 0;
    stop_machine (stop_machine_text_poke, (void *) & tpp, NULL);
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="13" endline="14">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="18" endline="19">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="22" endline="24">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="27" endline="37">
{
    struct stack_trace *trace = data;
    if (!reliable)
        return;
    if (trace->skip > 0) {
        trace->skip--;
        return;
    }
    if (trace->nr_entries < trace->max_entries)
        trace->entries[trace->nr_entries++] = addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="31" endline="34">
{
    trace->skip--;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="41" endline="53">
{
    struct stack_trace *trace = (struct stack_trace *) data;
    if (!reliable)
        return;
    if (in_sched_functions (addr))
        return;
    if (trace->skip > 0) {
        trace->skip--;
        return;
    }
    if (trace->nr_entries < trace->max_entries)
        trace->entries[trace->nr_entries++] = addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="47" endline="50">
{
    trace->skip--;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="75" endline="79">
{
    dump_trace (current, NULL, NULL, 0, & save_stack_ops, trace);
    if (trace->nr_entries < trace->max_entries)
        trace->entries[trace->nr_entries++] = ULONG_MAX;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="83" endline="87">
{
    dump_trace (current, NULL, NULL, bp, & save_stack_ops, trace);
    if (trace->nr_entries < trace->max_entries)
        trace->entries[trace->nr_entries++] = ULONG_MAX;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="90" endline="94">
{
    dump_trace (tsk, NULL, NULL, 0, & save_stack_ops_nosched, trace);
    if (trace->nr_entries < trace->max_entries)
        trace->entries[trace->nr_entries++] = ULONG_MAX;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="105" endline="118">
{
    int ret;
    if (!access_ok (VERIFY_READ, fp, sizeof (*frame)))
        return 0;
    ret = 1;
    pagefault_disable ();
    if (__copy_from_user_inatomic (frame, fp, sizeof (*frame)))
        ret = 0;
    pagefault_enable ();
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="121" endline="145">
{
    const struct pt_regs *regs = task_pt_regs (current);
    const void __user *fp = (const void __user *) regs->bp;
    if (trace->nr_entries < trace->max_entries)
        trace->entries[trace->nr_entries++] = regs->ip;
    while (trace->nr_entries < trace->max_entries) {
        struct stack_frame frame;
        frame.next_fp = NULL;
        frame.ret_addr = 0;
        if (!copy_stack_frame (fp, &frame))
            break;
        if ((unsigned long) fp < regs->sp)
            break;
        if (frame.ret_addr) {
            trace->entries[trace->nr_entries++] = frame.ret_addr;
        }
        if (fp == frame.next_fp)
            break;
        fp = frame.next_fp;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="128" endline="144">
{
    struct stack_frame frame;
    frame.next_fp = NULL;
    frame.ret_addr = 0;
    if (!copy_stack_frame (fp, &frame))
        break;
    if ((unsigned long) fp < regs->sp)
        break;
    if (frame.ret_addr) {
        trace->entries[trace->nr_entries++] = frame.ret_addr;
    }
    if (fp == frame.next_fp)
        break;
    fp = frame.next_fp;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="137" endline="140">
{
    trace->entries[trace->nr_entries++] = frame.ret_addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="148" endline="157">
{
    if (current->mm) {
        __save_stack_trace_user (trace);
    }
    if (trace->nr_entries < trace->max_entries)
        trace->entries[trace->nr_entries++] = ULONG_MAX;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/stacktrace.c.ifdefed" startline="152" endline="154">
{
    __save_stack_trace_user (trace);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi_64.c.ifdefed" startline="47" endline="57">
{
    unsigned long num_pages;
    start &= PMD_MASK;
    end = (end + PMD_SIZE - 1) & PMD_MASK;
    num_pages = (end - start) >> PAGE_SHIFT;
    if (executable)
        set_memory_x ((unsigned long) __va (start), num_pages);
    else
        set_memory_nx ((unsigned long) __va (start), num_pages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi_64.c.ifdefed" startline="60" endline="76">
{
    efi_memory_desc_t *md;
    void *p;
    if (!(__supported_pte_mask & _PAGE_NX))
        return;
    for (p = memmap.map; p < memmap.map_end; p += memmap.desc_size) {
        md = p;
        if (md->type == EFI_RUNTIME_SERVICES_CODE) {
            unsigned long end;
            end = md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT);
            early_mapping_set_exec (md -> phys_addr, end, executable);
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi_64.c.ifdefed" startline="68" endline="75">
{
    md = p;
    if (md->type == EFI_RUNTIME_SERVICES_CODE) {
        unsigned long end;
        end = md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT);
        early_mapping_set_exec (md -> phys_addr, end, executable);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi_64.c.ifdefed" startline="70" endline="74">
{
    unsigned long end;
    end = md->phys_addr + (md->num_pages << EFI_PAGE_SHIFT);
    early_mapping_set_exec (md -> phys_addr, end, executable);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi_64.c.ifdefed" startline="79" endline="88">
{
    unsigned long vaddress;
    early_runtime_code_mapping_set_exec (1);
    local_irq_save (efi_flags);
    vaddress = (unsigned long) __va (0x0UL);
    save_pgd = *pgd_offset_k (0x0UL);
    set_pgd (pgd_offset_k (0x0UL), * pgd_offset_k (vaddress));
    __flush_tlb_all ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi_64.c.ifdefed" startline="91" endline="99">
{
    set_pgd (pgd_offset_k (0x0UL), save_pgd);
    __flush_tlb_all ();
    local_irq_restore (efi_flags);
    early_runtime_code_mapping_set_exec (0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/efi_64.c.ifdefed" startline="103" endline="114">
{
    unsigned long last_map_pfn;
    if (type == EFI_MEMORY_MAPPED_IO)
        return ioremap (phys_addr, size);
    last_map_pfn = init_memory_mapping (phys_addr, phys_addr +size);
    if ((last_map_pfn << PAGE_SHIFT) < phys_addr + size)
        return NULL;
    return (void __iomem *) __va (phys_addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/x86_init.c.ifdefed" startline="22" endline="22">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/x86_init.c.ifdefed" startline="23" endline="23">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/x86_init.c.ifdefed" startline="24" endline="24">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/x86_init.c.ifdefed" startline="25" endline="25">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/x86_init.c.ifdefed" startline="26" endline="26">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/x86_init.c.ifdefed" startline="87" endline="87">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8253.c.ifdefed" startline="35" endline="66">
{
    spin_lock (& i8253_lock);
    switch (mode) {
    case CLOCK_EVT_MODE_PERIODIC :
        outb_pit (0x34, PIT_MODE);
        outb_pit (LATCH & 0xff, PIT_CH0);
        outb_pit (LATCH >> 8, PIT_CH0);
        break;
    case CLOCK_EVT_MODE_SHUTDOWN :
    case CLOCK_EVT_MODE_UNUSED :
        if (evt->mode == CLOCK_EVT_MODE_PERIODIC || evt->mode == CLOCK_EVT_MODE_ONESHOT) {
            outb_pit (0x30, PIT_MODE);
            outb_pit (0, PIT_CH0);
            outb_pit (0, PIT_CH0);
        }
        break;
    case CLOCK_EVT_MODE_ONESHOT :
        outb_pit (0x38, PIT_MODE);
        break;
    case CLOCK_EVT_MODE_RESUME :
        break;
    }
    spin_unlock (& i8253_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8253.c.ifdefed" startline="38" endline="64">
{
case CLOCK_EVT_MODE_PERIODIC :
    outb_pit (0x34, PIT_MODE);
    outb_pit (LATCH & 0xff, PIT_CH0);
    outb_pit (LATCH >> 8, PIT_CH0);
    break;
case CLOCK_EVT_MODE_SHUTDOWN :
case CLOCK_EVT_MODE_UNUSED :
    if (evt->mode == CLOCK_EVT_MODE_PERIODIC || evt->mode == CLOCK_EVT_MODE_ONESHOT) {
        outb_pit (0x30, PIT_MODE);
        outb_pit (0, PIT_CH0);
        outb_pit (0, PIT_CH0);
    }
    break;
case CLOCK_EVT_MODE_ONESHOT :
    outb_pit (0x38, PIT_MODE);
    break;
case CLOCK_EVT_MODE_RESUME :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8253.c.ifdefed" startline="49" endline="53">
{
    outb_pit (0x30, PIT_MODE);
    outb_pit (0, PIT_CH0);
    outb_pit (0, PIT_CH0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8253.c.ifdefed" startline="74" endline="81">
{
    spin_lock (& i8253_lock);
    outb_pit (delta & 0xff, PIT_CH0);
    outb_pit (delta >> 8, PIT_CH0);
    spin_unlock (& i8253_lock);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8253.c.ifdefed" startline="105" endline="117">
{
    pit_ce.cpumask = cpumask_of (smp_processor_id ());
    pit_ce.mult = div_sc (CLOCK_TICK_RATE, NSEC_PER_SEC, pit_ce.shift);
    pit_ce.max_delta_ns = clockevent_delta2ns (0x7FFF, &pit_ce);
    pit_ce.min_delta_ns = clockevent_delta2ns (0xF, &pit_ce);
    clockevents_register_device (& pit_ce);
    global_clock_event = &pit_ce;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8253.c.ifdefed" startline="126" endline="184">
{
    static int old_count;
    static u32 old_jifs;
    unsigned long flags;
    int count;
    u32 jifs;
    spin_lock_irqsave (& i8253_lock, flags);
    jifs = jiffies;
    outb_pit (0x00, PIT_MODE);
    count = inb_pit (PIT_CH0);
    count |= inb_pit (PIT_CH0) << 8;
    if (count > LATCH) {
        outb_pit (0x34, PIT_MODE);
        outb_pit (LATCH & 0xff, PIT_CH0);
        outb_pit (LATCH >> 8, PIT_CH0);
        count = LATCH - 1;
    }
    if (count > old_count && jifs == old_jifs)
        count = old_count;
    old_count = count;
    old_jifs = jifs;
    spin_unlock_irqrestore (& i8253_lock, flags);
    count = (LATCH - 1) - count;
    return (cycle_t) (jifs * LATCH) +count;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8253.c.ifdefed" startline="153" endline="158">
{
    outb_pit (0x34, PIT_MODE);
    outb_pit (LATCH & 0xff, PIT_CH0);
    outb_pit (LATCH >> 8, PIT_CH0);
    count = LATCH - 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8253.c.ifdefed" startline="196" endline="211">
{
    if (num_possible_cpus () > 1 || is_hpet_enabled () || pit_ce.mode != CLOCK_EVT_MODE_PERIODIC)
        return 0;
    pit_cs.mult = clocksource_hz2mult (CLOCK_TICK_RATE, pit_cs.shift);
    return clocksource_register (&pit_cs);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="41" endline="96">
{
    int real_seconds, real_minutes, cmos_minutes;
    unsigned char save_control, save_freq_select;
    int retval = 0;
    save_control = CMOS_READ (RTC_CONTROL);
    CMOS_WRITE ((save_control | RTC_SET), RTC_CONTROL);
    save_freq_select = CMOS_READ (RTC_FREQ_SELECT);
    CMOS_WRITE ((save_freq_select | RTC_DIV_RESET2), RTC_FREQ_SELECT);
    cmos_minutes = CMOS_READ (RTC_MINUTES);
    if (!(save_control & RTC_DM_BINARY) || RTC_ALWAYS_BCD)
        cmos_minutes = bcd2bin (cmos_minutes);
    real_seconds = nowtime % 60;
    real_minutes = nowtime / 60;
    if (((abs (real_minutes -cmos_minutes) + 15) / 30) & 1)
        real_minutes += 30;
    real_minutes %= 60;
    if (abs (real_minutes -cmos_minutes) < 30) {
        if (!(save_control & RTC_DM_BINARY) || RTC_ALWAYS_BCD) {
            real_seconds = bin2bcd (real_seconds);
            real_minutes = bin2bcd (real_minutes);
        }
        CMOS_WRITE (real_seconds, RTC_SECONDS);
        CMOS_WRITE (real_minutes, RTC_MINUTES);
    }
    else {
        printk (KERN_WARNING "set_rtc_mmss: can't update from %d to %d\n", cmos_minutes, real_minutes);
        retval = -1;
    }
    CMOS_WRITE (save_control, RTC_CONTROL);
    CMOS_WRITE (save_freq_select, RTC_FREQ_SELECT);
    return retval;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="71" endline="78">
{
    if (!(save_control & RTC_DM_BINARY) || RTC_ALWAYS_BCD) {
        real_seconds = bin2bcd (real_seconds);
        real_minutes = bin2bcd (real_minutes);
    }
    CMOS_WRITE (real_seconds, RTC_SECONDS);
    CMOS_WRITE (real_minutes, RTC_MINUTES);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="72" endline="75">
{
    real_seconds = bin2bcd (real_seconds);
    real_minutes = bin2bcd (real_minutes);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="78" endline="83">
{
    printk (KERN_WARNING "set_rtc_mmss: can't update from %d to %d\n", cmos_minutes, real_minutes);
    retval = -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="99" endline="144">
{
    unsigned int status, year, mon, day, hour, min, sec, century = 0;
    while ((CMOS_READ (RTC_FREQ_SELECT) & RTC_UIP))
        cpu_relax ();
    sec = CMOS_READ (RTC_SECONDS);
    min = CMOS_READ (RTC_MINUTES);
    hour = CMOS_READ (RTC_HOURS);
    day = CMOS_READ (RTC_DAY_OF_MONTH);
    mon = CMOS_READ (RTC_MONTH);
    year = CMOS_READ (RTC_YEAR);
    status = CMOS_READ (RTC_CONTROL);
    WARN_ON_ONCE (RTC_ALWAYS_BCD && (status & RTC_DM_BINARY));
    if (RTC_ALWAYS_BCD || !(status & RTC_DM_BINARY)) {
        sec = bcd2bin (sec);
        min = bcd2bin (min);
        hour = bcd2bin (hour);
        day = bcd2bin (day);
        mon = bcd2bin (mon);
        year = bcd2bin (year);
    }
    if (century) {
        century = bcd2bin (century);
        year += century * 100;
        printk (KERN_INFO "Extended CMOS year: %d\n", century * 100);
    }
    else
        year += CMOS_YEARS_OFFS;
    return mktime (year, mon, day, hour, min, sec);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="127" endline="134">
{
    sec = bcd2bin (sec);
    min = bcd2bin (min);
    hour = bcd2bin (hour);
    day = bcd2bin (day);
    mon = bcd2bin (mon);
    year = bcd2bin (year);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="136" endline="140">
{
    century = bcd2bin (century);
    year += century * 100;
    printk (KERN_INFO "Extended CMOS year: %d\n", century * 100);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="148" endline="157">
{
    unsigned char val;
    lock_cmos_prefix (addr);
    outb (addr, RTC_PORT (0));
    val = inb (RTC_PORT (1));
    lock_cmos_suffix (addr);
    return val;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="161" endline="166">
{
    lock_cmos_prefix (addr);
    outb (addr, RTC_PORT (0));
    outb (val, RTC_PORT (1));
    lock_cmos_suffix (addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="170" endline="179">
{
    unsigned long flags;
    int retval;
    spin_lock_irqsave (& rtc_lock, flags);
    retval = x86_platform.set_wallclock (now.tv_sec);
    spin_unlock_irqrestore (& rtc_lock, flags);
    return retval;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="183" endline="192">
{
    unsigned long retval, flags;
    spin_lock_irqsave (& rtc_lock, flags);
    retval = x86_platform.get_wallclock ();
    spin_unlock_irqrestore (& rtc_lock, flags);
    ts->tv_sec = retval;
    ts->tv_nsec = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="195" endline="197">
{
    return __native_read_tsc ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/rtc.c.ifdefed" startline="222" endline="245">
{
    platform_device_register (& rtc_device);
    dev_info (& rtc_device.dev, "registered platform RTC device (no PNP device found)\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="24" endline="33">
{
    long error;
    error = -EINVAL;
    if (off & ~PAGE_MASK)
        goto out;
    error = sys_mmap_pgoff (addr, len, prot, flags, fd, off >> PAGE_SHIFT);
out :
    return error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="37" endline="58">
{
    if (!test_thread_flag (TIF_IA32) && (flags & MAP_32BIT)) {
        unsigned long new_begin;
        *begin = 0x40000000;
        *end = 0x80000000;
        if (current->flags & PF_RANDOMIZE) {
            new_begin = randomize_range (*begin, *begin + 0x02000000, 0);
            if (new_begin)
                *begin = new_begin;
        }
    }
    else {
        *begin = TASK_UNMAPPED_BASE;
        *end = TASK_SIZE;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="38" endline="54">
{
    unsigned long new_begin;
    *begin = 0x40000000;
    *end = 0x80000000;
    if (current->flags & PF_RANDOMIZE) {
        new_begin = randomize_range (*begin, *begin + 0x02000000, 0);
        if (new_begin)
            *begin = new_begin;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="49" endline="53">
{
    new_begin = randomize_range (*begin, *begin + 0x02000000, 0);
    if (new_begin)
        *begin = new_begin;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="54" endline="57">
{
    *begin = TASK_UNMAPPED_BASE;
    *end = TASK_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="63" endline="121">
{
    struct mm_struct *mm = current->mm;
    struct vm_area_struct *vma;
    unsigned long start_addr;
    unsigned long begin, end;
    if (flags & MAP_FIXED)
        return addr;
    find_start_end (flags, & begin, & end);
    if (len > end)
        return -ENOMEM;
    if (addr) {
        addr = PAGE_ALIGN (addr);
        vma = find_vma (mm, addr);
        if (end - len >= addr && (!vma || addr + len <= vma->vm_start))
            return addr;
    }
    if (((flags & MAP_32BIT) || test_thread_flag (TIF_IA32)) && len <= mm->cached_hole_size) {
        mm->cached_hole_size = 0;
        mm->free_area_cache = begin;
    }
    addr = mm->free_area_cache;
    if (addr < begin)
        addr = begin;
    start_addr = addr;
full_search :
    for (vma = find_vma (mm, addr);; vma = vma->vm_next) {
        if (end - len < addr) {
            if (start_addr != begin) {
                start_addr = addr = begin;
                mm->cached_hole_size = 0;
                goto full_search;
            }
            return -ENOMEM;
        }
        if (!vma || addr + len <= vma->vm_start) {
            mm->free_area_cache = addr + len;
            return addr;
        }
        if (addr + mm->cached_hole_size < vma->vm_start)
            mm->cached_hole_size = vma->vm_start - addr;
        addr = vma->vm_end;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="77" endline="83">
{
    addr = PAGE_ALIGN (addr);
    vma = find_vma (mm, addr);
    if (end - len >= addr && (!vma || addr + len <= vma->vm_start))
        return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="85" endline="88">
{
    mm->cached_hole_size = 0;
    mm->free_area_cache = begin;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="95" endline="120">
{
    if (end - len < addr) {
        if (start_addr != begin) {
            start_addr = addr = begin;
            mm->cached_hole_size = 0;
            goto full_search;
        }
        return -ENOMEM;
    }
    if (!vma || addr + len <= vma->vm_start) {
        mm->free_area_cache = addr + len;
        return addr;
    }
    if (addr + mm->cached_hole_size < vma->vm_start)
        mm->cached_hole_size = vma->vm_start - addr;
    addr = vma->vm_end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="97" endline="108">
{
    if (start_addr != begin) {
        start_addr = addr = begin;
        mm->cached_hole_size = 0;
        goto full_search;
    }
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="102" endline="106">
{
    start_addr = addr = begin;
    mm->cached_hole_size = 0;
    goto full_search;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="109" endline="115">
{
    mm->free_area_cache = addr + len;
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="128" endline="211">
{
    struct vm_area_struct *vma;
    struct mm_struct *mm = current->mm;
    unsigned long addr = addr0;
    if (len > TASK_SIZE)
        return -ENOMEM;
    if (flags & MAP_FIXED)
        return addr;
    if (!test_thread_flag (TIF_IA32) && (flags & MAP_32BIT))
        goto bottomup;
    if (addr) {
        addr = PAGE_ALIGN (addr);
        vma = find_vma (mm, addr);
        if (TASK_SIZE - len >= addr && (!vma || addr + len <= vma->vm_start))
            return addr;
    }
    if (len <= mm->cached_hole_size) {
        mm->cached_hole_size = 0;
        mm->free_area_cache = mm->mmap_base;
    }
    addr = mm->free_area_cache;
    if (addr > len) {
        vma = find_vma (mm, addr -len);
        if (!vma || addr <= vma->vm_start)
            return mm->free_area_cache = addr - len;
    }
    if (mm->mmap_base < len)
        goto bottomup;
    addr = mm->mmap_base - len;
    do {
        vma = find_vma (mm, addr);
        if (!vma || addr + len <= vma->vm_start)
            return mm->free_area_cache = addr;
        if (addr + mm->cached_hole_size < vma->vm_start)
            mm->cached_hole_size = vma->vm_start - addr;
        addr = vma->vm_start - len;
    }
    while (len < vma->vm_start);
bottomup :
    mm->cached_hole_size = ~0UL;
    mm->free_area_cache = TASK_UNMAPPED_BASE;
    addr = arch_get_unmapped_area (filp, addr0, len, pgoff, flags);
    mm->free_area_cache = mm->mmap_base;
    mm->cached_hole_size = ~0UL;
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="145" endline="151">
{
    addr = PAGE_ALIGN (addr);
    vma = find_vma (mm, addr);
    if (TASK_SIZE - len >= addr && (!vma || addr + len <= vma->vm_start))
        return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="154" endline="157">
{
    mm->cached_hole_size = 0;
    mm->free_area_cache = mm->mmap_base;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="163" endline="168">
{
    vma = find_vma (mm, addr -len);
    if (!vma || addr <= vma->vm_start)
        return mm->free_area_cache = addr - len;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/sys_x86_64.c.ifdefed" startline="175" endline="192">
{
    vma = find_vma (mm, addr);
    if (!vma || addr + len <= vma->vm_start)
        return mm->free_area_cache = addr;
    if (addr + mm->cached_hole_size < vma->vm_start)
        mm->cached_hole_size = vma->vm_start - addr;
    addr = vma->vm_start - len;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pmtimer_64.c.ifdefed" startline="30" endline="40">
{
    cycles *= 286;
    return (cycles >> 10);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pmtimer_64.c.ifdefed" startline="43" endline="50">
{
    u32 a, b;
    for (a = b = inl (pmtmr_ioport) & ACPI_PM_MASK; a == b; b = inl (pmtmr_ioport) & ACPI_PM_MASK)
        cpu_relax ();
    return b;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pmtimer_64.c.ifdefed" startline="54" endline="61">
{
    u32 a, b;
    a = pmtimer_wait_tick ();
    do {
        b = inl (pmtmr_ioport);
        cpu_relax ();
    }
    while (cyc2us (b -a) < us);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pmtimer_64.c.ifdefed" startline="57" endline="60">
{
    b = inl (pmtmr_ioport);
    cpu_relax ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pmtimer_64.c.ifdefed" startline="64" endline="67">
{
    pmtmr_ioport = 0;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/sleep.c.ifdefed" startline="37" endline="108">
{
    struct wakeup_header *header;
    if (!acpi_realmode) {
        printk (KERN_ERR "Could not allocate memory during boot, " "S3 disabled\n");
        return -ENOMEM;
    }
    memcpy ((void *) acpi_realmode, & wakeup_code_start, WAKEUP_SIZE);
    header = (struct wakeup_header *) (acpi_realmode + HEADER_OFFSET);
    if (header->signature != 0x51ee1111) {
        printk (KERN_ERR "wakeup header does not match\n");
        return -EINVAL;
    }
    header->video_mode = saved_video_mode;
    header->wakeup_jmp_seg = acpi_wakeup_address >> 4;
    header->wakeup_gdt[0] = (u64) (sizeof (header->wakeup_gdt) - 1) + ((u64) (acpi_wakeup_address + ((char *) &header->wakeup_gdt - (char *) acpi_realmode)) << 16);
    header->wakeup_gdt[1] = GDT_ENTRY (0x809b, acpi_wakeup_address, 0xfffff);
    header->wakeup_gdt[2] = GDT_ENTRY (0x8093, acpi_wakeup_address, 0xfffff);
    store_gdt ((struct desc_ptr *) & header -> pmode_gdt);
    if (rdmsr_safe (MSR_EFER, &header->pmode_efer_low, &header->pmode_efer_high))
        header->pmode_efer_low = header->pmode_efer_high = 0;
    header->pmode_cr0 = read_cr0 ();
    header->pmode_cr4 = read_cr4_safe ();
    header->realmode_flags = acpi_realmode_flags;
    header->real_magic = 0x12345678;
    header->pmode_entry = (u32) &wakeup_pmode_return;
    header->pmode_cr3 = (u32) (swsusp_pg_dir - __PAGE_OFFSET);
    saved_magic = 0x12345678;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/sleep.c.ifdefed" startline="40" endline="44">
{
    printk (KERN_ERR "Could not allocate memory during boot, " "S3 disabled\n");
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/sleep.c.ifdefed" startline="48" endline="51">
{
    printk (KERN_ERR "wakeup header does not match\n");
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/sleep.c.ifdefed" startline="114" endline="115">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/sleep.c.ifdefed" startline="127" endline="145">
{
    unsigned long mem;
    if ((&wakeup_code_end - &wakeup_code_start) > WAKEUP_SIZE) {
        printk (KERN_ERR "ACPI: Wakeup code way too big, S3 disabled.\n");
        return;
    }
    mem = find_e820_area (0, 1 << 20, WAKEUP_SIZE, PAGE_SIZE);
    if (mem == -1L) {
        printk (KERN_ERR "ACPI: Cannot allocate lowmem, S3 disabled.\n");
        return;
    }
    acpi_realmode = (unsigned long) phys_to_virt (mem);
    acpi_wakeup_address = mem;
    reserve_early (mem, mem + WAKEUP_SIZE, "ACPI WAKEUP");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/sleep.c.ifdefed" startline="130" endline="134">
{
    printk (KERN_ERR "ACPI: Wakeup code way too big, S3 disabled.\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/sleep.c.ifdefed" startline="138" endline="141">
{
    printk (KERN_ERR "ACPI: Cannot allocate lowmem, S3 disabled.\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/sleep.c.ifdefed" startline="149" endline="172">
{
    while ((str != NULL) && (*str != '\0')) {
        if (strncmp (str, "s3_bios", 7) == 0)
            acpi_realmode_flags |= 1;
        if (strncmp (str, "s3_mode", 7) == 0)
            acpi_realmode_flags |= 2;
        if (strncmp (str, "s3_beep", 7) == 0)
            acpi_realmode_flags |= 4;
        if (strncmp (str, "old_ordering", 12) == 0)
            acpi_old_suspend_ordering ();
        if (strncmp (str, "sci_force_enable", 16) == 0)
            acpi_set_sci_en_on_resume ();
        str = strchr (str, ',');
        if (str != NULL)
            str += strspn (str, ", \t");
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/sleep.c.ifdefed" startline="150" endline="170">
{
    if (strncmp (str, "s3_bios", 7) == 0)
        acpi_realmode_flags |= 1;
    if (strncmp (str, "s3_mode", 7) == 0)
        acpi_realmode_flags |= 2;
    if (strncmp (str, "s3_beep", 7) == 0)
        acpi_realmode_flags |= 4;
    if (strncmp (str, "old_ordering", 12) == 0)
        acpi_old_suspend_ordering ();
    if (strncmp (str, "sci_force_enable", 16) == 0)
        acpi_set_sci_en_on_resume ();
    str = strchr (str, ',');
    if (str != NULL)
        str += strspn (str, ", \t");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="29" endline="53">
{
    struct cpuinfo_x86 *c = &cpu_data (cpu);
    flags->bm_check = 0;
    if (num_online_cpus () == 1)
        flags->bm_check = 1;
    else if (c->x86_vendor == X86_VENDOR_INTEL) {
        flags->bm_check = 1;
    }
    if (c->x86_vendor == X86_VENDOR_INTEL && (c->x86 > 0xf || (c->x86 == 6 && c->x86_model >= 0x0f)))
        flags->bm_control = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="35" endline="42">
{
    flags->bm_check = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="81" endline="121">
{
    struct acpi_processor_cx *cx = _cx;
    long retval;
    unsigned int eax, ebx, ecx, edx;
    unsigned int edx_part;
    unsigned int cstate_type;
    unsigned int num_cstate_subtype;
    cpuid (CPUID_MWAIT_LEAF, & eax, & ebx, & ecx, & edx);
    cstate_type = ((cx->address >> MWAIT_SUBSTATE_SIZE) & MWAIT_CSTATE_MASK) + 1;
    edx_part = edx >> (cstate_type * MWAIT_SUBSTATE_SIZE);
    num_cstate_subtype = edx_part & MWAIT_SUBSTATE_MASK;
    retval = 0;
    if (num_cstate_subtype < (cx->address & MWAIT_SUBSTATE_MASK)) {
        retval = -1;
        goto out;
    }
    if (!(ecx & CPUID5_ECX_EXTENSIONS_SUPPORTED) || !(ecx & CPUID5_ECX_INTERRUPT_BREAK)) {
        retval = -1;
        goto out;
    }
    if (!mwait_supported[cstate_type]) {
        mwait_supported[cstate_type] = 1;
        printk (KERN_DEBUG "Monitor-Mwait will be used to enter C-%d " "state\n", cx -> type);
    }
    snprintf (cx -> desc, ACPI_CX_DESC_LEN, "ACPI FFH INTEL MWAIT 0x%x", cx -> address);
out :
    return retval;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="98" endline="101">
{
    retval = -1;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="105" endline="108">
{
    retval = -1;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="110" endline="115">
{
    mwait_supported[cstate_type] = 1;
    printk (KERN_DEBUG "Monitor-Mwait will be used to enter C-%d " "state\n", cx -> type);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="125" endline="149">
{
    struct cstate_entry *percpu_entry;
    struct cpuinfo_x86 *c = &cpu_data (cpu);
    long retval;
    if (!cpu_cstate_entry || c->cpuid_level < CPUID_MWAIT_LEAF)
        return -1;
    if (reg->bit_offset != NATIVE_CSTATE_BEYOND_HALT)
        return -1;
    percpu_entry = per_cpu_ptr (cpu_cstate_entry, cpu);
    percpu_entry->states[cx->index].eax = 0;
    percpu_entry->states[cx->index].ecx = 0;
    retval = work_on_cpu (cpu, acpi_processor_ffh_cstate_probe_cpu, cx);
    if (retval == 0) {
        percpu_entry->states[cx->index].eax = cx->address;
        percpu_entry->states[cx->index].ecx = MWAIT_ECX_INTERRUPT_BREAK;
    }
    return retval;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="143" endline="147">
{
    percpu_entry->states[cx->index].eax = cx->address;
    percpu_entry->states[cx->index].ecx = MWAIT_ECX_INTERRUPT_BREAK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="153" endline="160">
{
    unsigned int cpu = smp_processor_id ();
    struct cstate_entry *percpu_entry;
    percpu_entry = per_cpu_ptr (cpu_cstate_entry, cpu);
    mwait_idle_with_hints (percpu_entry -> states [cx -> index].eax, percpu_entry -> states [cx -> index].ecx);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="164" endline="171">
{
    struct cpuinfo_x86 *c = &boot_cpu_data;
    if (c->x86_vendor != X86_VENDOR_INTEL)
        return -1;
    cpu_cstate_entry = alloc_percpu (struct cstate_entry);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/cstate.c.ifdefed" startline="174" endline="177">
{
    free_percpu (cpu_cstate_entry);
    cpu_cstate_entry = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/realmode/wakemain.c.ifdefed" startline="5" endline="8">
{
    while (loops--)
        io_delay ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/realmode/wakemain.c.ifdefed" startline="11" endline="32">
{
    u8 enable;
    if (!hz) {
        enable = 0x00;
    }
    else {
        u16 div = 1193181 / hz;
        outb (0xb6, 0x43);
        io_delay ();
        outb (div, 0x42);
        io_delay ();
        outb (div >> 8, 0x42);
        io_delay ();
        enable = 0x03;
    }
    inb (0x61);
    io_delay ();
    outb (enable, 0x61);
    io_delay ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/realmode/wakemain.c.ifdefed" startline="14" endline="16">
{
    enable = 0x00;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/realmode/wakemain.c.ifdefed" startline="16" endline="27">
{
    u16 div = 1193181 / hz;
    outb (0xb6, 0x43);
    io_delay ();
    outb (div, 0x42);
    io_delay ();
    outb (div >> 8, 0x42);
    io_delay ();
    enable = 0x03;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/realmode/wakemain.c.ifdefed" startline="40" endline="62">
{
    char s;
    while ((s = *pattern++)) {
        switch (s) {
        case '.' :
            beep (DOT_HZ);
            udelay (US_PER_DOT);
            beep (0);
            udelay (US_PER_DOT);
            break;
        case '-' :
            beep (DASH_HZ);
            udelay (US_PER_DOT * 3);
            beep (0);
            udelay (US_PER_DOT);
            break;
        default :
            udelay (US_PER_DOT *3);
            break;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/realmode/wakemain.c.ifdefed" startline="43" endline="61">
{
    switch (s) {
    case '.' :
        beep (DOT_HZ);
        udelay (US_PER_DOT);
        beep (0);
        udelay (US_PER_DOT);
        break;
    case '-' :
        beep (DASH_HZ);
        udelay (US_PER_DOT * 3);
        beep (0);
        udelay (US_PER_DOT);
        break;
    default :
        udelay (US_PER_DOT *3);
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/realmode/wakemain.c.ifdefed" startline="44" endline="60">
{
case '.' :
    beep (DOT_HZ);
    udelay (US_PER_DOT);
    beep (0);
    udelay (US_PER_DOT);
    break;
case '-' :
    beep (DASH_HZ);
    udelay (US_PER_DOT * 3);
    beep (0);
    udelay (US_PER_DOT);
    break;
default :
    udelay (US_PER_DOT *3);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/realmode/wakemain.c.ifdefed" startline="65" endline="81">
{
    if (wakeup_header.real_magic != 0x12345678)
        while (1)
            ;
    if (wakeup_header.realmode_flags & 4)
        send_morse ("...-");
    if (wakeup_header.realmode_flags & 1)
        asm volatile ("lcallw   $0xc000,$3"
        );
    if (wakeup_header.realmode_flags & 2) {
        probe_cards (0);
        set_mode (wakeup_header.video_mode);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/realmode/wakemain.c.ifdefed" startline="76" endline="80">
{
    probe_cards (0);
    set_mode (wakeup_header.video_mode);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="109" endline="115">
{
    if (!phys || !size)
        return NULL;
    return early_ioremap (phys, size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="117" endline="122">
{
    if (!map || !size)
        return;
    early_iounmap (map, size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="414" endline="447">
{
    unsigned int mask = 1 << irq;
    unsigned int old, new;
    old = inb (0x4d0) | (inb (0x4d1) << 8);
    new = acpi_noirq ? old : 0;
    switch (trigger) {
    case 1 :
        new &= ~mask;
        break;
    case 3 :
        new |= mask;
        break;
    }
    if (old == new)
        return;
    printk (PREFIX "setting ELCR to %04x (from %04x)\n", new, old);
    outb (new, 0x4d0);
    outb (new >> 8, 0x4d1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="432" endline="439">
{
case 1 :
    new &= ~mask;
    break;
case 3 :
    new |= mask;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="450" endline="459">
{
    *irq = gsi;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="466" endline="488">
{
    unsigned int irq;
    unsigned int plat_gsi = gsi;
    irq = plat_gsi;
    return irq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="608" endline="611">
{
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="616" endline="619">
{
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="624" endline="636">
{
    struct acpi_table_boot *sb;
    sb = (struct acpi_table_boot *) table;
    if (!sb) {
        printk (KERN_WARNING PREFIX "Unable to map SBF\n");
        return -ENODEV;
    }
    sbf_port = sb->cmos_index;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="628" endline="631">
{
    printk (KERN_WARNING PREFIX "Unable to map SBF\n");
    return -ENODEV;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="733" endline="760">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1175" endline="1177">
{
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1181" endline="1205">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1208" endline="1265">
{
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1268" endline="1275">
{
    if (!acpi_force) {
        printk (KERN_NOTICE "%s detected: force use of acpi=noirq\n", d -> ident);
        acpi_noirq_set ();
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1269" endline="1273">
{
    printk (KERN_NOTICE "%s detected: force use of acpi=noirq\n", d -> ident);
    acpi_noirq_set ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1278" endline="1285">
{
    if (!acpi_force) {
        printk (KERN_NOTICE "%s detected: force use of pci=noacpi\n", d -> ident);
        acpi_disable_pci ();
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1279" endline="1283">
{
    printk (KERN_NOTICE "%s detected: force use of pci=noacpi\n", d -> ident);
    acpi_disable_pci ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1288" endline="1297">
{
    if (!acpi_force) {
        printk (KERN_NOTICE "%s detected: acpi off\n", d -> ident);
        disable_acpi ();
    }
    else {
        printk (KERN_NOTICE "Warning: DMI blacklist says broken, but acpi forced\n");
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1289" endline="1292">
{
    printk (KERN_NOTICE "%s detected: acpi off\n", d -> ident);
    disable_acpi ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1292" endline="1295">
{
    printk (KERN_NOTICE "Warning: DMI blacklist says broken, but acpi forced\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1303" endline="1315">
{
    if (!acpi_skip_timer_override) {
        WARN (1, KERN_ERR "ati_ixp4x0 quirk not complete.\n");
        pr_notice ("%s detected: Ignoring BIOS IRQ0 pin2 override\n", d -> ident);
        acpi_skip_timer_override = 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1308" endline="1313">
{
    WARN (1, KERN_ERR "ati_ixp4x0 quirk not complete.\n");
    pr_notice ("%s detected: Ignoring BIOS IRQ0 pin2 override\n", d -> ident);
    acpi_skip_timer_override = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1462" endline="1494">
{
    dmi_check_system (acpi_dmi_table);
    if (acpi_disabled && !acpi_ht)
        return;
    if (acpi_table_init ()) {
        disable_acpi ();
        return;
    }
    acpi_table_parse (ACPI_SIG_BOOT, acpi_parse_sbf);
    if (acpi_blacklisted ()) {
        if (acpi_force) {
            printk (KERN_WARNING PREFIX "acpi=force override\n");
        }
        else {
            printk (KERN_WARNING PREFIX "Disabling ACPI support\n");
            disable_acpi ();
            return;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1475" endline="1478">
{
    disable_acpi ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1485" endline="1493">
{
    if (acpi_force) {
        printk (KERN_WARNING PREFIX "acpi=force override\n");
    }
    else {
        printk (KERN_WARNING PREFIX "Disabling ACPI support\n");
        disable_acpi ();
        return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1486" endline="1488">
{
    printk (KERN_WARNING PREFIX "acpi=force override\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1488" endline="1492">
{
    printk (KERN_WARNING PREFIX "Disabling ACPI support\n");
    disable_acpi ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1497" endline="1511">
{
    if (acpi_disabled && !acpi_ht)
        return 1;
    early_acpi_process_madt ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1514" endline="1543">
{
    dmi_check_system (acpi_dmi_table_late);
    if (acpi_disabled && !acpi_ht)
        return 1;
    acpi_table_parse (ACPI_SIG_BOOT, acpi_parse_sbf);
    acpi_table_parse (ACPI_SIG_FADT, acpi_parse_fadt);
    acpi_process_madt ();
    acpi_table_parse (ACPI_SIG_HPET, acpi_parse_hpet);
    if (!acpi_noirq)
        x86_init.pci.init = pci_acpi_init;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1546" endline="1584">
{
    if (!arg)
        return -EINVAL;
    if (strcmp (arg, "off") == 0) {
        disable_acpi ();
    }
    else if (strcmp (arg, "force") == 0) {
        acpi_force = 1;
        acpi_ht = 1;
        acpi_disabled = 0;
    }
    else if (strcmp (arg, "strict") == 0) {
        acpi_strict = 1;
    }
    else if (strcmp (arg, "ht") == 0) {
        if (!acpi_force) {
            printk (KERN_WARNING "acpi=ht will be removed in Linux-2.6.35\n");
            disable_acpi ();
        }
        acpi_ht = 1;
    }
    else if (strcmp (arg, "rsdt") == 0) {
        acpi_rsdt_forced = 1;
    }
    else if (strcmp (arg, "noirq") == 0) {
        acpi_noirq_set ();
    }
    else {
        return -EINVAL;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1551" endline="1553">
{
    disable_acpi ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1555" endline="1559">
{
    acpi_force = 1;
    acpi_ht = 1;
    acpi_disabled = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1561" endline="1563">
{
    acpi_strict = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1565" endline="1571">
{
    if (!acpi_force) {
        printk (KERN_WARNING "acpi=ht will be removed in Linux-2.6.35\n");
        disable_acpi ();
    }
    acpi_ht = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1566" endline="1569">
{
    printk (KERN_WARNING "acpi=ht will be removed in Linux-2.6.35\n");
    disable_acpi ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1573" endline="1575">
{
    acpi_rsdt_forced = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1577" endline="1579">
{
    acpi_noirq_set ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1579" endline="1582">
{
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1589" endline="1593">
{
    if (arg && strcmp (arg, "noacpi") == 0)
        acpi_disable_pci ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1597" endline="1608">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1627" endline="1645">
{
    if (!s)
        return -EINVAL;
    if (!strcmp (s, "edge"))
        acpi_sci_flags = ACPI_MADT_TRIGGER_EDGE | (acpi_sci_flags & ~ACPI_MADT_TRIGGER_MASK);
    else if (!strcmp (s, "level"))
        acpi_sci_flags = ACPI_MADT_TRIGGER_LEVEL | (acpi_sci_flags & ~ACPI_MADT_TRIGGER_MASK);
    else if (!strcmp (s, "high"))
        acpi_sci_flags = ACPI_MADT_POLARITY_ACTIVE_HIGH | (acpi_sci_flags & ~ACPI_MADT_POLARITY_MASK);
    else if (!strcmp (s, "low"))
        acpi_sci_flags = ACPI_MADT_POLARITY_ACTIVE_LOW | (acpi_sci_flags & ~ACPI_MADT_POLARITY_MASK);
    else
        return -EINVAL;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1649" endline="1657">
{
    unsigned int old, new, val;
    do {
        old = *lock;
        new = (((old & ~0x3) + 2) + ((old >> 1) & 0x1));
        val = cmpxchg (lock, old, new);
    }
    while (unlikely (val != old));
    return (new < 3) ? -1 : 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1651" endline="1655">
{
    old = *lock;
    new = (((old & ~0x3) + 2) + ((old >> 1) & 0x1));
    val = cmpxchg (lock, old, new);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1660" endline="1668">
{
    unsigned int old, new, val;
    do {
        old = *lock;
        new = old & ~0x3;
        val = cmpxchg (lock, old, new);
    }
    while (unlikely (val != old));
    return old & 0x1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/acpi/boot.c.ifdefed" startline="1662" endline="1666">
{
    old = *lock;
    new = old & ~0x3;
    val = cmpxchg (lock, old, new);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-swiotlb.c.ifdefed" startline="18" endline="26">
{
    void *vaddr;
    vaddr = dma_generic_alloc_coherent (hwdev, size, dma_handle, flags);
    if (vaddr)
        return vaddr;
    return swiotlb_alloc_coherent (hwdev, size, dma_handle, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-swiotlb.c.ifdefed" startline="52" endline="64">
{
    int use_swiotlb = swiotlb | swiotlb_force;
    if (swiotlb_force)
        swiotlb = 1;
    return use_swiotlb;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-swiotlb.c.ifdefed" startline="67" endline="72">
{
    if (swiotlb) {
        swiotlb_init (0);
        dma_ops = &swiotlb_dma_ops;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-swiotlb.c.ifdefed" startline="68" endline="71">
{
    swiotlb_init (0);
    dma_ops = &swiotlb_dma_ops;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="191" endline="194">
{
    return (tbl != NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="198" endline="218">
{
    unsigned long index;
    unsigned long end;
    unsigned long flags;
    index = start_addr >> PAGE_SHIFT;
    if (index >= tbl->it_size)
        return;
    end = index + npages;
    if (end > tbl->it_size)
        end = tbl->it_size;
    spin_lock_irqsave (& tbl -> it_lock, flags);
    bitmap_set (tbl -> it_map, index, npages);
    spin_unlock_irqrestore (& tbl -> it_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="223" endline="258">
{
    unsigned long flags;
    unsigned long offset;
    unsigned long boundary_size;
    boundary_size = ALIGN (dma_get_seg_boundary (dev) +1, PAGE_SIZE) >> PAGE_SHIFT;
    BUG_ON (npages == 0);
    spin_lock_irqsave (& tbl -> it_lock, flags);
    offset = iommu_area_alloc (tbl->it_map, tbl->it_size, tbl->it_hint, npages, 0, boundary_size, 0);
    if (offset == ~0UL) {
        tbl->chip_ops->tce_cache_blast (tbl);
        offset = iommu_area_alloc (tbl->it_map, tbl->it_size, 0, npages, 0, boundary_size, 0);
        if (offset == ~0UL) {
            printk (KERN_WARNING "Calgary: IOMMU full.\n");
            spin_unlock_irqrestore (& tbl -> it_lock, flags);
            if (panic_on_overflow)
                panic ("Calgary: fix the allocator.\n");
            else
                return DMA_ERROR_CODE;
        }
    }
    tbl->it_hint = offset + npages;
    BUG_ON (tbl -> it_hint > tbl -> it_size);
    spin_unlock_irqrestore (& tbl -> it_lock, flags);
    return offset;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="237" endline="250">
{
    tbl->chip_ops->tce_cache_blast (tbl);
    offset = iommu_area_alloc (tbl->it_map, tbl->it_size, 0, npages, 0, boundary_size, 0);
    if (offset == ~0UL) {
        printk (KERN_WARNING "Calgary: IOMMU full.\n");
        spin_unlock_irqrestore (& tbl -> it_lock, flags);
        if (panic_on_overflow)
            panic ("Calgary: fix the allocator.\n");
        else
            return DMA_ERROR_CODE;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="242" endline="249">
{
    printk (KERN_WARNING "Calgary: IOMMU full.\n");
    spin_unlock_irqrestore (& tbl -> it_lock, flags);
    if (panic_on_overflow)
        panic ("Calgary: fix the allocator.\n");
    else
        return DMA_ERROR_CODE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="262" endline="281">
{
    unsigned long entry;
    dma_addr_t ret;
    entry = iommu_range_alloc (dev, tbl, npages);
    if (unlikely (entry == DMA_ERROR_CODE)) {
        printk (KERN_WARNING "Calgary: failed to allocate %u pages in " "iommu %p\n", npages, tbl);
        return DMA_ERROR_CODE;
    }
    ret = (entry << PAGE_SHIFT) | ((unsigned long) vaddr & ~PAGE_MASK);
    tce_build (tbl, entry, npages, (unsigned long) vaddr & PAGE_MASK, direction);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="268" endline="272">
{
    printk (KERN_WARNING "Calgary: failed to allocate %u pages in " "iommu %p\n", npages, tbl);
    return DMA_ERROR_CODE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="285" endline="309">
{
    unsigned long entry;
    unsigned long badend;
    unsigned long flags;
    badend = DMA_ERROR_CODE + (EMERGENCY_PAGES * PAGE_SIZE);
    if (unlikely ((dma_addr >= DMA_ERROR_CODE) && (dma_addr < badend))) {
        WARN (1, KERN_ERR "Calgary: driver tried unmapping bad DMA " "address 0x%Lx\n", dma_addr);
        return;
    }
    entry = dma_addr >> PAGE_SHIFT;
    BUG_ON (entry + npages > tbl -> it_size);
    tce_free (tbl, entry, npages);
    spin_lock_irqsave (& tbl -> it_lock, flags);
    bitmap_clear (tbl -> it_map, entry, npages);
    spin_unlock_irqrestore (& tbl -> it_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="292" endline="296">
{
    WARN (1, KERN_ERR "Calgary: driver tried unmapping bad DMA " "address 0x%Lx\n", dma_addr);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="312" endline="332">
{
    struct pci_dev *pdev;
    struct pci_bus *pbus;
    struct iommu_table *tbl;
    pdev = to_pci_dev (dev);
    pbus = pdev->bus;
    do {
        tbl = pci_iommu (pbus);
        if (tbl && tbl->it_busno == pbus->number)
            break;
        tbl = NULL;
        pbus = pbus->parent;
    }
    while (pbus);
    BUG_ON (tbl && (tbl -> it_busno != pbus -> number));
    return tbl;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="321" endline="327">
{
    tbl = pci_iommu (pbus);
    if (tbl && tbl->it_busno == pbus->number)
        break;
    tbl = NULL;
    pbus = pbus->parent;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="337" endline="356">
{
    struct iommu_table *tbl = find_iommu_table (dev);
    struct scatterlist *s;
    int i;
    if (!translation_enabled (tbl))
        return;

    for_each_sg (sglist, s, nelems, i) {
        unsigned int npages;
        dma_addr_t dma = s->dma_address;
        unsigned int dmalen = s->dma_length;
        if (dmalen == 0)
            break;
        npages = iommu_num_pages (dma, dmalen, PAGE_SIZE);
        iommu_free (tbl, dma, npages);
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="345" endline="355">
{
    unsigned int npages;
    dma_addr_t dma = s->dma_address;
    unsigned int dmalen = s->dma_length;
    if (dmalen == 0)
        break;
    npages = iommu_num_pages (dma, dmalen, PAGE_SIZE);
    iommu_free (tbl, dma, npages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="361" endline="398">
{
    struct iommu_table *tbl = find_iommu_table (dev);
    struct scatterlist *s;
    unsigned long vaddr;
    unsigned int npages;
    unsigned long entry;
    int i;

    for_each_sg (sg, s, nelems, i) {
        BUG_ON (! sg_page (s));
        vaddr = (unsigned long) sg_virt (s);
        npages = iommu_num_pages (vaddr, s->length, PAGE_SIZE);
        entry = iommu_range_alloc (dev, tbl, npages);
        if (entry == DMA_ERROR_CODE) {
            s->dma_length = 0;
            goto error;
        }
        s->dma_address = (entry << PAGE_SHIFT) | s->offset;
        tce_build (tbl, entry, npages, vaddr & PAGE_MASK, dir);
        s->dma_length = s->length;
    }

    return nelems;
error :
    calgary_unmap_sg (dev, sg, nelems, dir, NULL);

    for_each_sg (sg, s, nelems, i) {
        sg->dma_address = DMA_ERROR_CODE;
        sg->dma_length = 0;
    }

    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="369" endline="388">
{
    BUG_ON (! sg_page (s));
    vaddr = (unsigned long) sg_virt (s);
    npages = iommu_num_pages (vaddr, s->length, PAGE_SIZE);
    entry = iommu_range_alloc (dev, tbl, npages);
    if (entry == DMA_ERROR_CODE) {
        s->dma_length = 0;
        goto error;
    }
    s->dma_address = (entry << PAGE_SHIFT) | s->offset;
    tce_build (tbl, entry, npages, vaddr & PAGE_MASK, dir);
    s->dma_length = s->length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="376" endline="380">
{
    s->dma_length = 0;
    goto error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="393" endline="396">
{
    sg->dma_address = DMA_ERROR_CODE;
    sg->dma_length = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="404" endline="414">
{
    void *vaddr = page_address (page) + offset;
    unsigned long uaddr;
    unsigned int npages;
    struct iommu_table *tbl = find_iommu_table (dev);
    uaddr = (unsigned long) vaddr;
    npages = iommu_num_pages (uaddr, size, PAGE_SIZE);
    return iommu_alloc (dev, tbl, vaddr, npages, dir);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="419" endline="425">
{
    struct iommu_table *tbl = find_iommu_table (dev);
    unsigned int npages;
    npages = iommu_num_pages (dma_addr, size, PAGE_SIZE);
    iommu_free (tbl, dma_addr, npages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="429" endline="458">
{
    void *ret = NULL;
    dma_addr_t mapping;
    unsigned int npages, order;
    struct iommu_table *tbl = find_iommu_table (dev);
    size = PAGE_ALIGN (size);
    npages = size >> PAGE_SHIFT;
    order = get_order (size);
    flag &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
    ret = (void *) __get_free_pages (flag, order);
    if (!ret)
        goto error;
    memset (ret, 0, size);
    mapping = iommu_alloc (dev, tbl, ret, npages, DMA_BIDIRECTIONAL);
    if (mapping == DMA_ERROR_CODE)
        goto free;
    *dma_handle = mapping;
    return ret;
free :
    free_pages ((unsigned long) ret, get_order (size));
    ret = NULL;
error :
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="462" endline="471">
{
    unsigned int npages;
    struct iommu_table *tbl = find_iommu_table (dev);
    size = PAGE_ALIGN (size);
    npages = size >> PAGE_SHIFT;
    iommu_free (tbl, dma_handle, npages);
    free_pages ((unsigned long) vaddr, get_order (size));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="483" endline="485">
{
    return bus_info[num].bbar;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="488" endline="490">
{
    return bus_info[num].phbid;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="493" endline="497">
{
    size_t idx = busno_to_phbid (num);
    return split_queue_offsets[idx];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="500" endline="504">
{
    size_t idx = busno_to_phbid (num);
    return tar_offsets[idx];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="507" endline="511">
{
    size_t idx = busno_to_phbid (num);
    return phb_offsets[idx];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="514" endline="517">
{
    unsigned long target = ((unsigned long) bar) | offset;
    return (void __iomem *) target;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="520" endline="522">
{
    return (device == PCI_DEVICE_ID_IBM_CALIOC2);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="525" endline="527">
{
    return (device == PCI_DEVICE_ID_IBM_CALGARY);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="530" endline="532">
{
    return (is_calgary (device) || is_calioc2 (device));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="535" endline="569">
{
    u64 val;
    u32 aer;
    int i = 0;
    void __iomem *bbar = tbl->bbar;
    void __iomem *target;
    target = calgary_reg (bbar, phb_offset (tbl->it_busno) | PHB_AER_OFFSET);
    aer = readl (target);
    writel (0, target);
    target = calgary_reg (bbar, phb_offset (tbl->it_busno) | PHB_PLSSR_OFFSET);
    val = readl (target);
    target = calgary_reg (bbar, split_queue_offset (tbl->it_busno));
    do {
        val = readq (target);
        i++;
    }
    while ((val & 0xff) != 0xff && i < 100);
    if (i == 100)
        printk (KERN_WARNING "Calgary: PCI bus not quiesced, " "continuing anyway\n");
    target = calgary_reg (bbar, tar_offset (tbl->it_busno));
    writeq (tbl -> tar_val, target);
    target = calgary_reg (bbar, phb_offset (tbl->it_busno) | PHB_AER_OFFSET);
    writel (aer, target);
    (void) readl (target);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="553" endline="556">
{
    val = readq (target);
    i++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="572" endline="648">
{
    void __iomem *bbar = tbl->bbar;
    void __iomem *target;
    u64 val64;
    u32 val;
    int i = 0;
    int count = 1;
    unsigned char bus = tbl->it_busno;
begin :
    printk (KERN_DEBUG "Calgary: CalIOC2 bus 0x%x entering tce cache blast " "sequence - count %d\n", bus, count);
    target = calgary_reg (bbar, phb_offset (bus) | PHB_PAGE_MIG_CTRL);
    val = be32_to_cpu (readl (target));
    printk (KERN_DEBUG "1a. read 0x%x [LE] from %p\n", val, target);
    val |= PMR_SOFTSTOP;
    printk (KERN_DEBUG "1b. writing 0x%x [LE] to %p\n", val, target);
    writel (cpu_to_be32 (val), target);
    printk (KERN_DEBUG "2a. starting to poll split queues\n");
    target = calgary_reg (bbar, split_queue_offset (bus));
    do {
        val64 = readq (target);
        i++;
    }
    while ((val64 & 0xff) != 0xff && i < 100);
    if (i == 100)
        printk (KERN_WARNING "CalIOC2: PCI bus not quiesced, " "continuing anyway\n");
    target = calgary_reg (bbar, phb_offset (bus) | PHB_PAGE_MIG_DEBUG);
    val = be32_to_cpu (readl (target));
    printk (KERN_DEBUG "3. read 0x%x [LE] from %p\n", val, target);
    if (val & PMR_SOFTSTOPFAULT) {
        if (++count < 100)
            goto begin;
        else {
            printk (KERN_WARNING "CalIOC2: too many SoftStopFaults, " "aborting TCE cache flush sequence!\n");
            return;
        }
    }
    target = calgary_reg (bbar, phb_offset (bus) | PHB_PAGE_MIG_CTRL);
    printk (KERN_DEBUG "5a. slamming into HardStop by reading %p\n", target);
    val = be32_to_cpu (readl (target));
    printk (KERN_DEBUG "5b. read 0x%x [LE] from %p\n", val, target);
    target = calgary_reg (bbar, phb_offset (bus) | PHB_PAGE_MIG_DEBUG);
    val = be32_to_cpu (readl (target));
    printk (KERN_DEBUG "5c. read 0x%x [LE] from %p (debug)\n", val, target);
    printk (KERN_DEBUG "6. invalidating TCE cache\n");
    target = calgary_reg (bbar, tar_offset (bus));
    writeq (tbl -> tar_val, target);
    printk (KERN_DEBUG "7a. Re-reading PMCR\n");
    target = calgary_reg (bbar, phb_offset (bus) | PHB_PAGE_MIG_CTRL);
    val = be32_to_cpu (readl (target));
    printk (KERN_DEBUG "7b. read 0x%x [LE] from %p\n", val, target);
    printk (KERN_DEBUG "8a. removing HardStop from PMCR\n");
    target = calgary_reg (bbar, phb_offset (bus) | PHB_PAGE_MIG_CTRL);
    val = 0;
    printk (KERN_DEBUG "8b. writing 0x%x [LE] to %p\n", val, target);
    writel (cpu_to_be32 (val), target);
    val = be32_to_cpu (readl (target));
    printk (KERN_DEBUG "8c. read 0x%x [LE] from %p\n", val, target);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="596" endline="599">
{
    val64 = readq (target);
    i++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="610" endline="618">
{
    if (++count < 100)
        goto begin;
    else {
        printk (KERN_WARNING "CalIOC2: too many SoftStopFaults, " "aborting TCE cache flush sequence!\n");
        return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="613" endline="617">
{
    printk (KERN_WARNING "CalIOC2: too many SoftStopFaults, " "aborting TCE cache flush sequence!\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="652" endline="660">
{
    unsigned int numpages;
    limit = limit | 0xfffff;
    limit++;
    numpages = ((limit - start) >> PAGE_SHIFT);
    iommu_range_reserve (pci_iommu (dev -> bus), start, numpages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="663" endline="683">
{
    void __iomem *target;
    u64 low, high, sizelow;
    u64 start, limit;
    struct iommu_table *tbl = pci_iommu (dev->bus);
    unsigned char busnum = dev->bus->number;
    void __iomem *bbar = tbl->bbar;
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_MEM_1_LOW);
    low = be32_to_cpu (readl (target));
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_MEM_1_HIGH);
    high = be32_to_cpu (readl (target));
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_MEM_1_SIZE);
    sizelow = be32_to_cpu (readl (target));
    start = (high << 32) | low;
    limit = sizelow;
    calgary_reserve_mem_region (dev, start, limit);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="686" endline="714">
{
    void __iomem *target;
    u32 val32;
    u64 low, high, sizelow, sizehigh;
    u64 start, limit;
    struct iommu_table *tbl = pci_iommu (dev->bus);
    unsigned char busnum = dev->bus->number;
    void __iomem *bbar = tbl->bbar;
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_CONFIG_RW_OFFSET);
    val32 = be32_to_cpu (readl (target));
    if (!(val32 & PHB_MEM2_ENABLE))
        return;
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_MEM_2_LOW);
    low = be32_to_cpu (readl (target));
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_MEM_2_HIGH);
    high = be32_to_cpu (readl (target));
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_MEM_2_SIZE_LOW);
    sizelow = be32_to_cpu (readl (target));
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_MEM_2_SIZE_HIGH);
    sizehigh = be32_to_cpu (readl (target));
    start = (high << 32) | low;
    limit = (sizehigh << 32) | sizelow;
    calgary_reserve_mem_region (dev, start, limit);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="724" endline="746">
{
    unsigned int npages;
    u64 start;
    struct iommu_table *tbl = pci_iommu (dev->bus);
    iommu_range_reserve (tbl, DMA_ERROR_CODE, EMERGENCY_PAGES);
    if (is_calgary (dev->device)) {
        start = (640 * 1024);
        npages = ((1024 - 640) * 1024) >> PAGE_SHIFT;
    }
    else {
        start = 0;
        npages = (1 * 1024 * 1024) >> PAGE_SHIFT;
    }
    iommu_range_reserve (tbl, start, npages);
    calgary_reserve_peripheral_mem_1 (dev);
    calgary_reserve_peripheral_mem_2 (dev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="734" endline="737">
{
    start = (640 * 1024);
    npages = ((1024 - 640) * 1024) >> PAGE_SHIFT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="737" endline="740">
{
    start = 0;
    npages = (1 * 1024 * 1024) >> PAGE_SHIFT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="749" endline="797">
{
    u64 val64;
    u64 table_phys;
    void __iomem *target;
    int ret;
    struct iommu_table *tbl;
    ret = build_tce_table (dev, bbar);
    if (ret)
        return ret;
    tbl = pci_iommu (dev->bus);
    tbl->it_base = (unsigned long) bus_info[dev->bus->number].tce_space;
    if (is_kdump_kernel ())
        calgary_init_bitmap_from_tce_table (tbl);
    else
        tce_free (tbl, 0, tbl->it_size);
    if (is_calgary (dev->device))
        tbl->chip_ops = &calgary_chip_ops;
    else if (is_calioc2 (dev->device))
        tbl->chip_ops = &calioc2_chip_ops;
    else
        BUG ();
    calgary_reserve_regions (dev);
    target = calgary_reg (bbar, tar_offset (dev->bus->number));
    val64 = be64_to_cpu (readq (target));
    val64 &= ~TAR_SW_BITS;
    table_phys = (u64) __pa (tbl->it_base);
    val64 |= table_phys;
    BUG_ON (specified_table_size > TCE_TABLE_SIZE_8M);
    val64 |= (u64) specified_table_size;
    tbl->tar_val = cpu_to_be64 (val64);
    writeq (tbl -> tar_val, target);
    readq (target);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="800" endline="822">
{
    u64 val64;
    struct iommu_table *tbl = pci_iommu (dev->bus);
    void __iomem *target;
    unsigned int bitmapsz;
    target = calgary_reg (tbl->bbar, tar_offset (dev->bus->number));
    val64 = be64_to_cpu (readq (target));
    val64 &= ~TAR_SW_BITS;
    writeq (cpu_to_be64 (val64), target);
    readq (target);
    bitmapsz = tbl->it_size / BITS_PER_BYTE;
    free_pages ((unsigned long) tbl -> it_map, get_order (bitmapsz));
    tbl->it_map = NULL;
    kfree (tbl);
    set_pci_iommu (dev -> bus, NULL);
    bus_info[dev->bus->number].tce_space = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="825" endline="839">
{
    void __iomem *bbar = tbl->bbar;
    void __iomem *target;
    u32 csr, plssr;
    target = calgary_reg (bbar, phb_offset (tbl->it_busno) | PHB_CSR_OFFSET);
    csr = be32_to_cpu (readl (target));
    target = calgary_reg (bbar, phb_offset (tbl->it_busno) | PHB_PLSSR_OFFSET);
    plssr = be32_to_cpu (readl (target));
    printk (KERN_EMERG "Calgary: DMA error on Calgary PHB 0x%x, " "0x%08x@CSR 0x%08x@PLSSR\n", tbl -> it_busno, csr, plssr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="842" endline="886">
{
    void __iomem *bbar = tbl->bbar;
    u32 csr, csmr, plssr, mck, rcstat;
    void __iomem *target;
    unsigned long phboff = phb_offset (tbl->it_busno);
    unsigned long erroff;
    u32 errregs [7];
    int i;
    target = calgary_reg (bbar, phboff | PHB_CSR_OFFSET);
    csr = be32_to_cpu (readl (target));
    target = calgary_reg (bbar, phboff | PHB_PLSSR_OFFSET);
    plssr = be32_to_cpu (readl (target));
    target = calgary_reg (bbar, phboff | 0x290);
    csmr = be32_to_cpu (readl (target));
    target = calgary_reg (bbar, phboff | 0x800);
    mck = be32_to_cpu (readl (target));
    printk (KERN_EMERG "Calgary: DMA error on CalIOC2 PHB 0x%x\n", tbl -> it_busno);
    printk (KERN_EMERG "Calgary: 0x%08x@CSR 0x%08x@PLSSR 0x%08x@CSMR 0x%08x@MCK\n", csr, plssr, csmr, mck);
    printk (KERN_EMERG "Calgary: ");
    for (i = 0; i < ARRAY_SIZE (errregs); i++) {
        erroff = (0x810 + (i * 0x10));
        target = calgary_reg (bbar, phboff | erroff);
        errregs[i] = be32_to_cpu (readl (target));
        printk ("0x%08x@0x%lx ", errregs [i], erroff);
    }
    printk ("\n");
    target = calgary_reg (bbar, phboff | PHB_ROOT_COMPLEX_STATUS);
    rcstat = be32_to_cpu (readl (target));
    printk (KERN_EMERG "Calgary: 0x%08x@0x%x\n", rcstat, PHB_ROOT_COMPLEX_STATUS);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="872" endline="878">
{
    erroff = (0x810 + (i * 0x10));
    target = calgary_reg (bbar, phboff | erroff);
    errregs[i] = be32_to_cpu (readl (target));
    printk ("0x%08x@0x%lx ", errregs [i], erroff);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="889" endline="917">
{
    struct pci_dev *dev = (struct pci_dev *) data;
    struct iommu_table *tbl = pci_iommu (dev->bus);
    void __iomem *bbar = tbl->bbar;
    u32 val32;
    void __iomem *target;
    target = calgary_reg (bbar, phb_offset (tbl->it_busno) | PHB_CSR_OFFSET);
    val32 = be32_to_cpu (readl (target));
    if (val32 & CSR_AGENT_MASK) {
        tbl->chip_ops->dump_error_regs (tbl);
        writel (0, target);
        target = calgary_reg (bbar, phb_offset (tbl->it_busno) | PHB_CONFIG_RW_OFFSET);
        val32 = be32_to_cpu (readl (target));
        val32 |= PHB_SLOT_DISABLE;
        writel (cpu_to_be32 (val32), target);
        readl (target);
    }
    else {
        mod_timer (& tbl -> watchdog_timer, jiffies + 2 * HZ);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="900" endline="913">
{
    tbl->chip_ops->dump_error_regs (tbl);
    writel (0, target);
    target = calgary_reg (bbar, phb_offset (tbl->it_busno) | PHB_CONFIG_RW_OFFSET);
    val32 = be32_to_cpu (readl (target));
    val32 |= PHB_SLOT_DISABLE;
    writel (cpu_to_be32 (val32), target);
    readl (target);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="913" endline="916">
{
    mod_timer (& tbl -> watchdog_timer, jiffies + 2 * HZ);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="921" endline="949">
{
    u64 val64;
    void __iomem *target;
    unsigned int phb_shift = ~0;
    u64 mask;
    switch (busno_to_phbid (busnum)) {
    case 0 :
        phb_shift = (63 - 19);
        break;
    case 1 :
        phb_shift = (63 - 23);
        break;
    case 2 :
        phb_shift = (63 - 27);
        break;
    case 3 :
        phb_shift = (63 - 35);
        break;
    default :
        BUG_ON (busno_to_phbid (busnum));
    }
    target = calgary_reg (bbar, CALGARY_CONFIG_REG);
    val64 = be64_to_cpu (readq (target));
    mask = ~(0xFUL << phb_shift);
    val64 &= mask;
    val64 |= (timeout << phb_shift);
    writeq (cpu_to_be64 (val64), target);
    readq (target);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="927" endline="938">
{
case 0 :
    phb_shift = (63 - 19);
    break;
case 1 :
    phb_shift = (63 - 23);
    break;
case 2 :
    phb_shift = (63 - 27);
    break;
case 3 :
    phb_shift = (63 - 35);
    break;
default :
    BUG_ON (busno_to_phbid (busnum));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="952" endline="965">
{
    unsigned char busnum = dev->bus->number;
    void __iomem *bbar = tbl->bbar;
    void __iomem *target;
    u32 val;
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_SAVIOR_L2);
    val = cpu_to_be32 (readl (target));
    val |= 0x00800000;
    writel (cpu_to_be32 (val), target);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="968" endline="978">
{
    unsigned char busnum = dev->bus->number;
    if (is_calgary (dev->device) && (busnum == 1))
        calgary_set_split_completion_timeout (tbl->bbar, busnum, CCR_2SEC_TIMEOUT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="981" endline="1010">
{
    u32 val32;
    unsigned char busnum;
    void __iomem *target;
    void __iomem *bbar;
    struct iommu_table *tbl;
    busnum = dev->bus->number;
    tbl = pci_iommu (dev->bus);
    bbar = tbl->bbar;
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_CONFIG_RW_OFFSET);
    val32 = be32_to_cpu (readl (target));
    val32 |= PHB_TCE_ENABLE | PHB_DAC_DISABLE | PHB_MCSR_ENABLE;
    printk (KERN_INFO "Calgary: enabling translation on %s PHB %#x\n", (dev -> device == PCI_DEVICE_ID_IBM_CALGARY) ? "Calgary" : "CalIOC2", busnum);
    printk (KERN_INFO "Calgary: errant DMAs will now be prevented on this " "bus.\n");
    writel (cpu_to_be32 (val32), target);
    readl (target);
    init_timer (& tbl -> watchdog_timer);
    tbl->watchdog_timer.function = &calgary_watchdog;
    tbl->watchdog_timer.data = (unsigned long) dev;
    mod_timer (& tbl -> watchdog_timer, jiffies);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1013" endline="1034">
{
    u32 val32;
    unsigned char busnum;
    void __iomem *target;
    void __iomem *bbar;
    struct iommu_table *tbl;
    busnum = dev->bus->number;
    tbl = pci_iommu (dev->bus);
    bbar = tbl->bbar;
    target = calgary_reg (bbar, phb_offset (busnum) | PHB_CONFIG_RW_OFFSET);
    val32 = be32_to_cpu (readl (target));
    val32 &= ~(PHB_TCE_ENABLE | PHB_DAC_DISABLE | PHB_MCSR_ENABLE);
    printk (KERN_INFO "Calgary: disabling translation on PHB %#x!\n", busnum);
    writel (cpu_to_be32 (val32), target);
    readl (target);
    del_timer_sync (& tbl -> watchdog_timer);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1037" endline="1046">
{
    pci_dev_get (dev);
    set_pci_iommu (dev -> bus, NULL);
    if (dev->bus->parent)
        dev->bus->parent->self = dev;
    else
        dev->bus->self = dev;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1049" endline="1080">
{
    void __iomem *bbar;
    struct iommu_table *tbl;
    int ret;
    BUG_ON (dev -> bus -> number >= MAX_PHB_BUS_NUM);
    bbar = busno_to_bbar (dev->bus->number);
    ret = calgary_setup_tar (dev, bbar);
    if (ret)
        goto done;
    pci_dev_get (dev);
    if (dev->bus->parent) {
        if (dev->bus->parent->self)
            printk (KERN_WARNING "Calgary: IEEEE, dev %p has " "bus->parent->self!\n", dev);
        dev->bus->parent->self = dev;
    }
    else
        dev->bus->self = dev;
    tbl = pci_iommu (dev->bus);
    tbl->chip_ops->handle_quirks (tbl, dev);
    calgary_enable_translation (dev);
    return 0;
done :
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1063" endline="1068">
{
    if (dev->bus->parent->self)
        printk (KERN_WARNING "Calgary: IEEEE, dev %p has " "bus->parent->self!\n", dev);
    dev->bus->parent->self = dev;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1083" endline="1134">
{
    int ret;
    int rioidx, phb, bus;
    void __iomem *bbar;
    void __iomem *target;
    unsigned long offset;
    u8 start_bus, end_bus;
    u32 val;
    ret = -ENODATA;
    for (rioidx = 0; rioidx < rio_table_hdr->num_rio_dev; rioidx++) {
        struct rio_detail *rio = rio_devs[rioidx];
        if ((rio->type != COMPAT_CALGARY) && (rio->type != ALT_CALGARY))
            continue;
        bbar = ioremap_nocache (rio->BBAR, 1024 * 1024);
        if (!bbar)
            goto error;
        for (phb = 0; phb < PHBS_PER_CALGARY; phb++) {
            offset = phb_debug_offsets[phb] | PHB_DEBUG_STUFF_OFFSET;
            target = calgary_reg (bbar, offset);
            val = be32_to_cpu (readl (target));
            start_bus = (u8) ((val & 0x00FF0000) >> 16);
            end_bus = (u8) ((val & 0x0000FF00) >> 8);
            if (end_bus) {
                for (bus = start_bus; bus <= end_bus; bus++) {
                    bus_info[bus].bbar = bbar;
                    bus_info[bus].phbid = phb;
                }
            }
            else {
                bus_info[start_bus].bbar = bbar;
                bus_info[start_bus].phbid = phb;
            }
        }
    }
    return 0;
error :
    for (bus = 0; bus < ARRAY_SIZE (bus_info); bus++)
        if (bus_info[bus].bbar)
            iounmap (bus_info[bus].bbar);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1093" endline="1123">
{
    struct rio_detail *rio = rio_devs[rioidx];
    if ((rio->type != COMPAT_CALGARY) && (rio->type != ALT_CALGARY))
        continue;
    bbar = ioremap_nocache (rio->BBAR, 1024 * 1024);
    if (!bbar)
        goto error;
    for (phb = 0; phb < PHBS_PER_CALGARY; phb++) {
        offset = phb_debug_offsets[phb] | PHB_DEBUG_STUFF_OFFSET;
        target = calgary_reg (bbar, offset);
        val = be32_to_cpu (readl (target));
        start_bus = (u8) ((val & 0x00FF0000) >> 16);
        end_bus = (u8) ((val & 0x0000FF00) >> 8);
        if (end_bus) {
            for (bus = start_bus; bus <= end_bus; bus++) {
                bus_info[bus].bbar = bbar;
                bus_info[bus].phbid = phb;
            }
        }
        else {
            bus_info[start_bus].bbar = bbar;
            bus_info[start_bus].phbid = phb;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1104" endline="1122">
{
    offset = phb_debug_offsets[phb] | PHB_DEBUG_STUFF_OFFSET;
    target = calgary_reg (bbar, offset);
    val = be32_to_cpu (readl (target));
    start_bus = (u8) ((val & 0x00FF0000) >> 16);
    end_bus = (u8) ((val & 0x0000FF00) >> 8);
    if (end_bus) {
        for (bus = start_bus; bus <= end_bus; bus++) {
            bus_info[bus].bbar = bbar;
            bus_info[bus].phbid = phb;
        }
    }
    else {
        bus_info[start_bus].bbar = bbar;
        bus_info[start_bus].phbid = phb;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1113" endline="1118">
{
    for (bus = start_bus; bus <= end_bus; bus++) {
        bus_info[bus].bbar = bbar;
        bus_info[bus].phbid = phb;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1114" endline="1117">
{
    bus_info[bus].bbar = bbar;
    bus_info[bus].phbid = phb;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1118" endline="1121">
{
    bus_info[start_bus].bbar = bbar;
    bus_info[start_bus].phbid = phb;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1137" endline="1206">
{
    int ret;
    struct pci_dev *dev = NULL;
    struct calgary_bus_info *info;
    ret = calgary_locate_bbars ();
    if (ret)
        return ret;
    if (is_kdump_kernel ())
        get_tce_space_from_tar ();
    do {
        dev = pci_get_device (PCI_VENDOR_ID_IBM, PCI_ANY_ID, dev);
        if (!dev)
            break;
        if (!is_cal_pci_dev (dev->device))
            continue;
        info = &bus_info[dev->bus->number];
        if (info->translation_disabled) {
            calgary_init_one_nontraslated (dev);
            continue;
        }
        if (!info->tce_space && !translate_empty_slots)
            continue;
        ret = calgary_init_one (dev);
        if (ret)
            goto error;
    }
    while (1);
    dev = NULL;

    for_each_pci_dev (dev) {
        struct iommu_table *tbl;
        tbl = find_iommu_table (&dev->dev);
        if (translation_enabled (tbl))
            dev->dev.archdata.dma_ops = &calgary_dma_ops;
    }

    return ret;
error :
    do {
        dev = pci_get_device (PCI_VENDOR_ID_IBM, PCI_ANY_ID, dev);
        if (!dev)
            break;
        if (!is_cal_pci_dev (dev->device))
            continue;
        info = &bus_info[dev->bus->number];
        if (info->translation_disabled) {
            pci_dev_put (dev);
            continue;
        }
        if (!info->tce_space && !translate_empty_slots)
            continue;
        calgary_disable_translation (dev);
        calgary_free_bus (dev);
        pci_dev_put (dev);
        dev->dev.archdata.dma_ops = NULL;
    }
    while (1);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1150" endline="1169">
{
    dev = pci_get_device (PCI_VENDOR_ID_IBM, PCI_ANY_ID, dev);
    if (!dev)
        break;
    if (!is_cal_pci_dev (dev->device))
        continue;
    info = &bus_info[dev->bus->number];
    if (info->translation_disabled) {
        calgary_init_one_nontraslated (dev);
        continue;
    }
    if (!info->tce_space && !translate_empty_slots)
        continue;
    ret = calgary_init_one (dev);
    if (ret)
        goto error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1158" endline="1161">
{
    calgary_init_one_nontraslated (dev);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1172" endline="1179">
{
    struct iommu_table *tbl;
    tbl = find_iommu_table (&dev->dev);
    if (translation_enabled (tbl))
        dev->dev.archdata.dma_ops = &calgary_dma_ops;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1184" endline="1203">
{
    dev = pci_get_device (PCI_VENDOR_ID_IBM, PCI_ANY_ID, dev);
    if (!dev)
        break;
    if (!is_cal_pci_dev (dev->device))
        continue;
    info = &bus_info[dev->bus->number];
    if (info->translation_disabled) {
        pci_dev_put (dev);
        continue;
    }
    if (!info->tce_space && !translate_empty_slots)
        continue;
    calgary_disable_translation (dev);
    calgary_free_bus (dev);
    pci_dev_put (dev);
    dev->dev.archdata.dma_ops = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1192" endline="1195">
{
    pci_dev_put (dev);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1209" endline="1227">
{
    int ret;
    if (specified_table_size != TCE_TABLE_SIZE_UNSPECIFIED)
        return specified_table_size;
    ret = get_order (ram >> 13);
    if (ret > TCE_TABLE_SIZE_8M)
        ret = TCE_TABLE_SIZE_8M;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1230" endline="1269">
{
    unsigned long ptr;
    unsigned numnodes, i;
    int scal_detail_size, rio_detail_size;
    numnodes = rio_table_hdr->num_scal_dev;
    if (numnodes > MAX_NUMNODES) {
        printk (KERN_WARNING "Calgary: MAX_NUMNODES too low! Defined as %d, " "but system has %d nodes.\n", MAX_NUMNODES, numnodes);
        return -ENODEV;
    }
    switch (rio_table_hdr->version) {
    case 2 :
        scal_detail_size = 11;
        rio_detail_size = 13;
        break;
    case 3 :
        scal_detail_size = 12;
        rio_detail_size = 15;
        break;
    default :
        printk (KERN_WARNING "Calgary: Invalid Rio Grande Table Version: %d\n", rio_table_hdr->version);
        return -EPROTO;
    }
    ptr = ((unsigned long) rio_table_hdr) + 3;
    for (i = 0; i < numnodes; i++, ptr += scal_detail_size)
        scal_devs[i] = (struct scal_detail *) ptr;
    for (i = 0; i < rio_table_hdr->num_rio_dev; i++, ptr += rio_detail_size)
        rio_devs[i] = (struct rio_detail *) ptr;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1236" endline="1242">
{
    printk (KERN_WARNING "Calgary: MAX_NUMNODES too low! Defined as %d, " "but system has %d nodes.\n", MAX_NUMNODES, numnodes);
    return -ENODEV;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1244" endline="1258">
{
case 2 :
    scal_detail_size = 11;
    rio_detail_size = 13;
    break;
case 3 :
    scal_detail_size = 12;
    rio_detail_size = 15;
    break;
default :
    printk (KERN_WARNING "Calgary: Invalid Rio Grande Table Version: %d\n", rio_table_hdr->version);
    return -EPROTO;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1272" endline="1290">
{
    int dev;
    u32 val;
    if (pci_dev == PCI_DEVICE_ID_IBM_CALIOC2) {
        return 1;
    }
    for (dev = 1; dev < 8; dev++) {
        val = read_pci_config (bus, dev, 0, 0);
        if (val != 0xffffffff)
            break;
    }
    return (val != 0xffffffff);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1276" endline="1282">
{
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1284" endline="1288">
{
    val = read_pci_config (bus, dev, 0, 0);
    if (val != 0xffffffff)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1298" endline="1307">
{
    u64 *tp;
    unsigned int index;
    tp = ((u64 *) tbl->it_base);
    for (index = 0; index < tbl->it_size; index++) {
        if (*tp != 0x0)
            set_bit (index, tbl->it_map);
        tp++;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1302" endline="1306">
{
    if (*tp != 0x0)
        set_bit (index, tbl->it_map);
    tp++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1315" endline="1345">
{
    int bus;
    void __iomem *target;
    unsigned long tce_space;
    for (bus = 0; bus < MAX_PHB_BUS_NUM; bus++) {
        struct calgary_bus_info *info = &bus_info[bus];
        unsigned short pci_device;
        u32 val;
        val = read_pci_config (bus, 0, 0, 0);
        pci_device = (val & 0xFFFF0000) >> 16;
        if (!is_cal_pci_dev (pci_device))
            continue;
        if (info->translation_disabled)
            continue;
        if (calgary_bus_has_devices (bus, pci_device) || translate_empty_slots) {
            target = calgary_reg (bus_info[bus].bbar, tar_offset (bus));
            tce_space = be64_to_cpu (readq (target));
            tce_space = tce_space & TAR_SW_BITS;
            tce_space = tce_space & (~specified_table_size);
            info->tce_space = (u64 *) __va (tce_space);
        }
    }
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1320" endline="1343">
{
    struct calgary_bus_info *info = &bus_info[bus];
    unsigned short pci_device;
    u32 val;
    val = read_pci_config (bus, 0, 0, 0);
    pci_device = (val & 0xFFFF0000) >> 16;
    if (!is_cal_pci_dev (pci_device))
        continue;
    if (info->translation_disabled)
        continue;
    if (calgary_bus_has_devices (bus, pci_device) || translate_empty_slots) {
        target = calgary_reg (bus_info[bus].bbar, tar_offset (bus));
        tce_space = be64_to_cpu (readq (target));
        tce_space = tce_space & TAR_SW_BITS;
        tce_space = tce_space & (~specified_table_size);
        info->tce_space = (u64 *) __va (tce_space);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1334" endline="1342">
{
    target = calgary_reg (bus_info[bus].bbar, tar_offset (bus));
    tce_space = be64_to_cpu (readq (target));
    tce_space = tce_space & TAR_SW_BITS;
    tce_space = tce_space & (~specified_table_size);
    info->tce_space = (u64 *) __va (tce_space);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1348" endline="1362">
{
    int ret;
    printk (KERN_INFO "PCI-DMA: Using Calgary IOMMU\n");
    ret = calgary_init ();
    if (ret) {
        printk (KERN_ERR "PCI-DMA: Calgary init failed %d, " "falling back to no_iommu\n", ret);
        return ret;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1355" endline="1359">
{
    printk (KERN_ERR "PCI-DMA: Calgary init failed %d, " "falling back to no_iommu\n", ret);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1365" endline="1473">
{
    int bus;
    void *tbl;
    int calgary_found = 0;
    unsigned long ptr;
    unsigned int offset, prev_offset;
    int ret;
    if (no_iommu || iommu_detected)
        return;
    if (!use_calgary)
        return;
    if (!early_pci_allowed ())
        return;
    printk (KERN_DEBUG "Calgary: detecting Calgary via BIOS EBDA area\n");
    ptr = (unsigned long) phys_to_virt (get_bios_ebda ());
    rio_table_hdr = NULL;
    prev_offset = 0;
    offset = 0x180;
    while (offset > prev_offset) {
        if (*((unsigned short *) (ptr + offset + 2)) == 0x4752) {
            rio_table_hdr = (struct rio_table_hdr *) (ptr + offset + 4);
            break;
        }
        prev_offset = offset;
        offset = *((unsigned short *) (ptr + offset));
    }
    if (!rio_table_hdr) {
        printk (KERN_DEBUG "Calgary: Unable to locate Rio Grande table " "in EBDA - bailing!\n");
        return;
    }
    ret = build_detail_arrays ();
    if (ret) {
        printk (KERN_DEBUG "Calgary: build_detail_arrays ret %d\n", ret);
        return;
    }
    specified_table_size = determine_tce_table_size ((is_kdump_kernel () ? saved_max_pfn : max_pfn) * PAGE_SIZE);
    for (bus = 0; bus < MAX_PHB_BUS_NUM; bus++) {
        struct calgary_bus_info *info = &bus_info[bus];
        unsigned short pci_device;
        u32 val;
        val = read_pci_config (bus, 0, 0, 0);
        pci_device = (val & 0xFFFF0000) >> 16;
        if (!is_cal_pci_dev (pci_device))
            continue;
        if (info->translation_disabled)
            continue;
        if (calgary_bus_has_devices (bus, pci_device) || translate_empty_slots) {
            if (!is_kdump_kernel ()) {
                tbl = alloc_tce_table ();
                if (!tbl)
                    goto cleanup;
                info->tce_space = tbl;
            }
            calgary_found = 1;
        }
    }
    printk (KERN_DEBUG "Calgary: finished detection, Calgary %s\n", calgary_found ? "found" : "not found");
    if (calgary_found) {
        iommu_detected = 1;
        calgary_detected = 1;
        printk (KERN_INFO "PCI-DMA: Calgary IOMMU detected.\n");
        printk (KERN_INFO "PCI-DMA: Calgary TCE table spec is %d\n", specified_table_size);
        x86_init.iommu.iommu_init = calgary_iommu_init;
    }
    return;
cleanup :
    for (--bus; bus >= 0; --bus) {
        struct calgary_bus_info *info = &bus_info[bus];
        if (info->tce_space)
            free_tce_table (info->tce_space);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1397" endline="1406">
{
    if (*((unsigned short *) (ptr + offset + 2)) == 0x4752) {
        rio_table_hdr = (struct rio_table_hdr *) (ptr + offset + 4);
        break;
    }
    prev_offset = offset;
    offset = *((unsigned short *) (ptr + offset));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1399" endline="1403">
{
    rio_table_hdr = (struct rio_table_hdr *) (ptr + offset + 4);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1407" endline="1411">
{
    printk (KERN_DEBUG "Calgary: Unable to locate Rio Grande table " "in EBDA - bailing!\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1414" endline="1417">
{
    printk (KERN_DEBUG "Calgary: build_detail_arrays ret %d\n", ret);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1422" endline="1450">
{
    struct calgary_bus_info *info = &bus_info[bus];
    unsigned short pci_device;
    u32 val;
    val = read_pci_config (bus, 0, 0, 0);
    pci_device = (val & 0xFFFF0000) >> 16;
    if (!is_cal_pci_dev (pci_device))
        continue;
    if (info->translation_disabled)
        continue;
    if (calgary_bus_has_devices (bus, pci_device) || translate_empty_slots) {
        if (!is_kdump_kernel ()) {
            tbl = alloc_tce_table ();
            if (!tbl)
                goto cleanup;
            info->tce_space = tbl;
        }
        calgary_found = 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1437" endline="1449">
{
    if (!is_kdump_kernel ()) {
        tbl = alloc_tce_table ();
        if (!tbl)
            goto cleanup;
        info->tce_space = tbl;
    }
    calgary_found = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1442" endline="1447">
{
    tbl = alloc_tce_table ();
    if (!tbl)
        goto cleanup;
    info->tce_space = tbl;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1455" endline="1463">
{
    iommu_detected = 1;
    calgary_detected = 1;
    printk (KERN_INFO "PCI-DMA: Calgary IOMMU detected.\n");
    printk (KERN_INFO "PCI-DMA: Calgary TCE table spec is %d\n", specified_table_size);
    x86_init.iommu.iommu_init = calgary_iommu_init;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1467" endline="1472">
{
    struct calgary_bus_info *info = &bus_info[bus];
    if (info->tce_space)
        free_tce_table (info->tce_space);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1476" endline="1528">
{
    unsigned int bridge;
    size_t len;
    char *endp;
    while (*p) {
        if (!strncmp (p, "64k", 3))
            specified_table_size = TCE_TABLE_SIZE_64K;
        else if (!strncmp (p, "128k", 4))
            specified_table_size = TCE_TABLE_SIZE_128K;
        else if (!strncmp (p, "256k", 4))
            specified_table_size = TCE_TABLE_SIZE_256K;
        else if (!strncmp (p, "512k", 4))
            specified_table_size = TCE_TABLE_SIZE_512K;
        else if (!strncmp (p, "1M", 2))
            specified_table_size = TCE_TABLE_SIZE_1M;
        else if (!strncmp (p, "2M", 2))
            specified_table_size = TCE_TABLE_SIZE_2M;
        else if (!strncmp (p, "4M", 2))
            specified_table_size = TCE_TABLE_SIZE_4M;
        else if (!strncmp (p, "8M", 2))
            specified_table_size = TCE_TABLE_SIZE_8M;
        len = strlen ("translate_empty_slots");
        if (!strncmp (p, "translate_empty_slots", len))
            translate_empty_slots = 1;
        len = strlen ("disable");
        if (!strncmp (p, "disable", len)) {
            p += len;
            if (*p == '=')
                ++p;
            if (*p == '\0')
                break;
            bridge = simple_strtoul (p, &endp, 0);
            if (p == endp)
                break;
            if (bridge < MAX_PHB_BUS_NUM) {
                printk (KERN_INFO "Calgary: disabling " "translation for PHB %#x\n", bridge);
                bus_info[bridge].translation_disabled = 1;
            }
        }
        p = strpbrk (p, ",");
        if (!p)
            break;
        p++;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1481" endline="1526">
{
    if (!strncmp (p, "64k", 3))
        specified_table_size = TCE_TABLE_SIZE_64K;
    else if (!strncmp (p, "128k", 4))
        specified_table_size = TCE_TABLE_SIZE_128K;
    else if (!strncmp (p, "256k", 4))
        specified_table_size = TCE_TABLE_SIZE_256K;
    else if (!strncmp (p, "512k", 4))
        specified_table_size = TCE_TABLE_SIZE_512K;
    else if (!strncmp (p, "1M", 2))
        specified_table_size = TCE_TABLE_SIZE_1M;
    else if (!strncmp (p, "2M", 2))
        specified_table_size = TCE_TABLE_SIZE_2M;
    else if (!strncmp (p, "4M", 2))
        specified_table_size = TCE_TABLE_SIZE_4M;
    else if (!strncmp (p, "8M", 2))
        specified_table_size = TCE_TABLE_SIZE_8M;
    len = strlen ("translate_empty_slots");
    if (!strncmp (p, "translate_empty_slots", len))
        translate_empty_slots = 1;
    len = strlen ("disable");
    if (!strncmp (p, "disable", len)) {
        p += len;
        if (*p == '=')
            ++p;
        if (*p == '\0')
            break;
        bridge = simple_strtoul (p, &endp, 0);
        if (p == endp)
            break;
        if (bridge < MAX_PHB_BUS_NUM) {
            printk (KERN_INFO "Calgary: disabling " "translation for PHB %#x\n", bridge);
            bus_info[bridge].translation_disabled = 1;
        }
    }
    p = strpbrk (p, ",");
    if (!p)
        break;
    p++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1504" endline="1519">
{
    p += len;
    if (*p == '=')
        ++p;
    if (*p == '\0')
        break;
    bridge = simple_strtoul (p, &endp, 0);
    if (p == endp)
        break;
    if (bridge < MAX_PHB_BUS_NUM) {
        printk (KERN_INFO "Calgary: disabling " "translation for PHB %#x\n", bridge);
        bus_info[bridge].translation_disabled = 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1514" endline="1518">
{
    printk (KERN_INFO "Calgary: disabling " "translation for PHB %#x\n", bridge);
    bus_info[bridge].translation_disabled = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1532" endline="1556">
{
    struct iommu_table *tbl;
    unsigned int npages;
    int i;
    tbl = pci_iommu (dev->bus);
    for (i = 0; i < 4; i++) {
        struct resource *r = &dev->resource[PCI_BRIDGE_RESOURCES + i];
        if (!(r->flags & IORESOURCE_MEM))
            continue;
        if (!r->start)
            continue;
        npages = (r->end - r->start) >> PAGE_SHIFT;
        npages++;
        iommu_range_reserve (tbl, r -> start, npages);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1539" endline="1555">
{
    struct resource *r = &dev->resource[PCI_BRIDGE_RESOURCES + i];
    if (!(r->flags & IORESOURCE_MEM))
        continue;
    if (!r->start)
        continue;
    npages = (r->end - r->start) >> PAGE_SHIFT;
    npages++;
    iommu_range_reserve (tbl, r -> start, npages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1559" endline="1587">
{
    struct pci_dev *dev = NULL;
    struct calgary_bus_info *info;
    if (no_iommu || swiotlb || !calgary_detected)
        return -ENODEV;
    printk (KERN_DEBUG "Calgary: fixing up tce spaces\n");
    do {
        dev = pci_get_device (PCI_VENDOR_ID_IBM, PCI_ANY_ID, dev);
        if (!dev)
            break;
        if (!is_cal_pci_dev (dev->device))
            continue;
        info = &bus_info[dev->bus->number];
        if (info->translation_disabled)
            continue;
        if (!info->tce_space)
            continue;
        calgary_fixup_one_tce_space (dev);
    }
    while (1);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-calgary_64.c.ifdefed" startline="1568" endline="1584">
{
    dev = pci_get_device (PCI_VENDOR_ID_IBM, PCI_ANY_ID, dev);
    if (!dev)
        break;
    if (!is_cal_pci_dev (dev->device))
        continue;
    info = &bus_info[dev->bus->number];
    if (info->translation_disabled)
        continue;
    if (!info->tce_space)
        continue;
    calgary_fixup_one_tce_space (dev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/head64.c.ifdefed" startline="30" endline="34">
{
    pgd_t *pgd = pgd_offset_k (0UL);
    pgd_clear (pgd);
    __flush_tlb_all ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/head64.c.ifdefed" startline="39" endline="42">
{
    memset (__bss_start, 0, (unsigned long) __bss_stop - (unsigned long) __bss_start);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/head64.c.ifdefed" startline="45" endline="53">
{
    char *command_line;
    memcpy (& boot_params, real_mode_data, sizeof boot_params);
    if (boot_params.hdr.cmd_line_ptr) {
        command_line = __va (boot_params.hdr.cmd_line_ptr);
        memcpy (boot_command_line, command_line, COMMAND_LINE_SIZE);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/head64.c.ifdefed" startline="49" endline="52">
{
    command_line = __va (boot_params.hdr.cmd_line_ptr);
    memcpy (boot_command_line, command_line, COMMAND_LINE_SIZE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/head64.c.ifdefed" startline="56" endline="95">
{
    int i;
    BUILD_BUG_ON (MODULES_VADDR < KERNEL_IMAGE_START);
    BUILD_BUG_ON (MODULES_VADDR - KERNEL_IMAGE_START < KERNEL_IMAGE_SIZE);
    BUILD_BUG_ON (MODULES_LEN + KERNEL_IMAGE_SIZE > 2 * PUD_SIZE);
    BUILD_BUG_ON ((KERNEL_IMAGE_START & ~ PMD_MASK) != 0);
    BUILD_BUG_ON ((MODULES_VADDR & ~ PMD_MASK) != 0);
    BUILD_BUG_ON (! (MODULES_VADDR > __START_KERNEL));
    BUILD_BUG_ON (! (((MODULES_END - 1) & PGDIR_MASK) == (__START_KERNEL & PGDIR_MASK)));
    BUILD_BUG_ON (__fix_to_virt (__end_of_fixed_addresses) <= MODULES_END);
    clear_bss ();
    zap_identity_mappings ();
    cleanup_highmap ();
    for (i = 0; i < NUM_EXCEPTION_VECTORS; i++) {
        set_intr_gate (i, early_idt_handler);
    }
    load_idt ((const struct desc_ptr *) & idt_descr);
    if (console_loglevel == 10)
        early_printk ("Kernel alive\n");
    x86_64_start_reservations (real_mode_data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/head64.c.ifdefed" startline="82" endline="88">
{
    set_intr_gate (i, early_idt_handler);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/head64.c.ifdefed" startline="98" endline="123">
{
    copy_bootdata (__va (real_mode_data));
    reserve_early (__pa_symbol (& _text), __pa_symbol (& __bss_stop), "TEXT DATA BSS");
    reserve_ebda_region ();
    start_kernel ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="30" endline="33">
{
    printk (" [<%p>] %s%pS\n", (void *) address, reliable ? "" : "? ", (void *) address);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="63" endline="63">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="75" endline="84">
{
    void *t = tinfo;
    if (end) {
        if (p < end && p >= (end - THREAD_SIZE))
            return 1;
        else
            return 0;
    }
    return p > t && p < t + THREAD_SIZE - size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="77" endline="82">
{
    if (p < end && p >= (end - THREAD_SIZE))
        return 1;
    else
        return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="91" endline="111">
{
    struct stack_frame *frame = (struct stack_frame *) bp;
    while (valid_stack_ptr (tinfo, stack, sizeof (*stack), end)) {
        unsigned long addr;
        addr = *stack;
        if (__kernel_text_address (addr)) {
            if ((unsigned long) stack == bp + sizeof (long)) {
                ops->address (data, addr, 1);
                frame = frame->next_frame;
                bp = (unsigned long) frame;
            }
            else {
                ops->address (data, addr, 0);
            }
            print_ftrace_graph_addr (addr, data, ops, tinfo, graph);
        }
        stack++;
    }
    return bp;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="94" endline="109">
{
    unsigned long addr;
    addr = *stack;
    if (__kernel_text_address (addr)) {
        if ((unsigned long) stack == bp + sizeof (long)) {
            ops->address (data, addr, 1);
            frame = frame->next_frame;
            bp = (unsigned long) frame;
        }
        else {
            ops->address (data, addr, 0);
        }
        print_ftrace_graph_addr (addr, data, ops, tinfo, graph);
    }
    stack++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="98" endline="107">
{
    if ((unsigned long) stack == bp + sizeof (long)) {
        ops->address (data, addr, 1);
        frame = frame->next_frame;
        bp = (unsigned long) frame;
    }
    else {
        ops->address (data, addr, 0);
    }
    print_ftrace_graph_addr (addr, data, ops, tinfo, graph);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="99" endline="103">
{
    ops->address (data, addr, 1);
    frame = frame->next_frame;
    bp = (unsigned long) frame;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="103" endline="105">
{
    ops->address (data, addr, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="119" endline="136">
{
    struct stack_frame *frame = (struct stack_frame *) bp;
    unsigned long *ret_addr = &frame->return_address;
    while (valid_stack_ptr (tinfo, ret_addr, sizeof (*ret_addr), end)) {
        unsigned long addr = *ret_addr;
        if (!__kernel_text_address (addr))
            break;
        ops->address (data, addr, 1);
        frame = frame->next_frame;
        ret_addr = &frame->return_address;
        print_ftrace_graph_addr (addr, data, ops, tinfo, graph);
    }
    return (unsigned long) frame;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="123" endline="133">
{
    unsigned long addr = *ret_addr;
    if (!__kernel_text_address (addr))
        break;
    ops->address (data, addr, 1);
    frame = frame->next_frame;
    ret_addr = &frame->return_address;
    print_ftrace_graph_addr (addr, data, ops, tinfo, graph);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="142" endline="146">
{
    printk (data);
    print_symbol (msg, symbol);
    printk ("\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="149" endline="151">
{
    printk ("%s%s\n", (char *) data, msg);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="154" endline="157">
{
    printk ("%s <%s> ", (char *) data, name);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="163" endline="167">
{
    touch_nmi_watchdog ();
    printk (data);
    printk_address (addr, reliable);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="180" endline="183">
{
    printk ("%sCall Trace:\n", log_lvl);
    dump_trace (task, regs, stack, bp, & print_trace_ops, log_lvl);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="187" endline="189">
{
    show_trace_log_lvl (task, regs, stack, bp, "");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="192" endline="194">
{
    show_stack_log_lvl (task, NULL, sp, 0, "");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="200" endline="215">
{
    unsigned long bp = 0;
    unsigned long stack;
    printk ("Pid: %d, comm: %.20s %s %s %.*s\n", current -> pid, current -> comm, print_tainted (), init_utsname () -> release, (int) strcspn (init_utsname () -> version, " "), init_utsname () -> version);
    show_trace (NULL, NULL, & stack, bp);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="223" endline="248">
{
    int cpu;
    unsigned long flags;
    trace_hw_branch_oops ();
    oops_enter ();
    raw_local_irq_save (flags);
    cpu = smp_processor_id ();
    if (!arch_spin_trylock (&die_lock)) {
        if (cpu == die_owner)
            ;
        else
            arch_spin_lock (&die_lock);
    }
    die_nest_count++;
    die_owner = cpu;
    console_verbose ();
    bust_spinlocks (1);
    return flags;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="237" endline="242">
{
    if (cpu == die_owner)
        ;
    else
        arch_spin_lock (&die_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="251" endline="272">
{
    if (regs && kexec_should_crash (current))
        crash_kexec (regs);
    bust_spinlocks (0);
    die_owner = -1;
    add_taint (TAINT_DIE);
    die_nest_count--;
    if (!die_nest_count)
        arch_spin_unlock (&die_lock);
    raw_local_irq_restore (flags);
    oops_exit ();
    if (!signr)
        return;
    if (in_interrupt ())
        panic ("Fatal exception in interrupt");
    if (panic_on_oops)
        panic ("Fatal exception");
    do_exit (signr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="275" endline="315">
{
    printk (KERN_EMERG "%s: %04lx [#%d] ", str, err & 0xffff, ++ die_counter);
    printk ("\n");
    sysfs_printk_last_file ();
    if (notify_die (DIE_OOPS, str, regs, err, current->thread.trap_no, SIGSEGV) == NOTIFY_STOP)
        return 1;
    show_registers (regs);
    printk (KERN_ALERT "RIP ");
    printk_address (regs -> ip, 1);
    printk (" RSP <%016lx>\n", regs -> sp);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="322" endline="332">
{
    unsigned long flags = oops_begin ();
    int sig = SIGSEGV;
    if (!user_mode_vm (regs))
        report_bug (regs->ip, regs);
    if (__die (str, regs, err))
        sig = 0;
    oops_end (flags, regs, sig);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="336" endline="357">
{
    unsigned long flags;
    if (notify_die (DIE_NMIWATCHDOG, str, regs, 0, 2, SIGINT) == NOTIFY_STOP)
        return;
    flags = oops_begin ();
    printk (KERN_EMERG "%s", str);
    printk (" on CPU%d, ip %08lx, registers:\n", smp_processor_id (), regs -> ip);
    show_registers (regs);
    oops_end (flags, regs, 0);
    if (do_panic || panic_on_oops)
        panic ("Non maskable interrupt");
    nmi_exit ();
    local_irq_enable ();
    do_exit (SIGBUS);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="360" endline="366">
{
    if (!s)
        return -EINVAL;
    if (!strcmp (s, "panic"))
        panic_on_oops = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="370" endline="375">
{
    if (!s)
        return -EINVAL;
    kstack_depth_to_print = simple_strtoul (s, NULL, 0);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack.c.ifdefed" startline="379" endline="385">
{
    code_bytes = simple_strtoul (s, NULL, 0);
    if (code_bytes > 8192)
        code_bytes = 8192;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="26" endline="57">
{
    pud_t *pud;
    pmd_t *pmd;
    struct page *page;
    int result = -ENOMEM;
    addr &= PMD_MASK;
    pgd += pgd_index (addr);
    if (!pgd_present (*pgd)) {
        page = kimage_alloc_control_pages (image, 0);
        if (!page)
            goto out;
        pud = (pud_t *) page_address (page);
        memset (pud, 0, PAGE_SIZE);
        set_pgd (pgd, __pgd (__pa (pud) | _KERNPG_TABLE));
    }
    pud = pud_offset (pgd, addr);
    if (!pud_present (*pud)) {
        page = kimage_alloc_control_pages (image, 0);
        if (!page)
            goto out;
        pmd = (pmd_t *) page_address (page);
        memset (pmd, 0, PAGE_SIZE);
        set_pud (pud, __pud (__pa (pmd) | _KERNPG_TABLE));
    }
    pmd = pmd_offset (pud, addr);
    if (!pmd_present (*pmd))
        set_pmd (pmd, __pmd (addr | __PAGE_KERNEL_LARGE_EXEC));
    result = 0;
out :
    return result;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="34" endline="41">
{
    page = kimage_alloc_control_pages (image, 0);
    if (!page)
        goto out;
    pud = (pud_t *) page_address (page);
    memset (pud, 0, PAGE_SIZE);
    set_pgd (pgd, __pgd (__pa (pud) | _KERNPG_TABLE));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="43" endline="50">
{
    page = kimage_alloc_control_pages (image, 0);
    if (!page)
        goto out;
    pmd = (pmd_t *) page_address (page);
    memset (pmd, 0, PAGE_SIZE);
    set_pud (pud, __pud (__pa (pmd) | _KERNPG_TABLE));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="60" endline="69">
{
    unsigned long end_addr;
    addr &= PAGE_MASK;
    end_addr = addr + PUD_SIZE;
    while (addr < end_addr) {
        set_pmd (level2p ++, __pmd (addr | __PAGE_KERNEL_LARGE_EXEC));
        addr += PMD_SIZE;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="65" endline="68">
{
    set_pmd (level2p ++, __pmd (addr | __PAGE_KERNEL_LARGE_EXEC));
    addr += PMD_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="73" endline="101">
{
    unsigned long end_addr;
    int result;
    result = 0;
    addr &= PAGE_MASK;
    end_addr = addr + PGDIR_SIZE;
    while ((addr < last_addr) && (addr < end_addr)) {
        struct page *page;
        pmd_t *level2p;
        page = kimage_alloc_control_pages (image, 0);
        if (!page) {
            result = -ENOMEM;
            goto out;
        }
        level2p = (pmd_t *) page_address (page);
        init_level2_page (level2p, addr);
        set_pud (level3p ++, __pud (__pa (level2p) | _KERNPG_TABLE));
        addr += PUD_SIZE;
    }
    while (addr < end_addr) {
        pud_clear (level3p ++);
        addr += PUD_SIZE;
    }
out :
    return result;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="80" endline="93">
{
    struct page *page;
    pmd_t *level2p;
    page = kimage_alloc_control_pages (image, 0);
    if (!page) {
        result = -ENOMEM;
        goto out;
    }
    level2p = (pmd_t *) page_address (page);
    init_level2_page (level2p, addr);
    set_pud (level3p ++, __pud (__pa (level2p) | _KERNPG_TABLE));
    addr += PUD_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="85" endline="88">
{
    result = -ENOMEM;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="95" endline="98">
{
    pud_clear (level3p ++);
    addr += PUD_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="106" endline="136">
{
    unsigned long end_addr;
    int result;
    result = 0;
    addr &= PAGE_MASK;
    end_addr = addr + (PTRS_PER_PGD * PGDIR_SIZE);
    while ((addr < last_addr) && (addr < end_addr)) {
        struct page *page;
        pud_t *level3p;
        page = kimage_alloc_control_pages (image, 0);
        if (!page) {
            result = -ENOMEM;
            goto out;
        }
        level3p = (pud_t *) page_address (page);
        result = init_level3_page (image, level3p, addr, last_addr);
        if (result)
            goto out;
        set_pgd (level4p ++, __pgd (__pa (level3p) | _KERNPG_TABLE));
        addr += PGDIR_SIZE;
    }
    while (addr < end_addr) {
        pgd_clear (level4p ++);
        addr += PGDIR_SIZE;
    }
out :
    return result;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="113" endline="128">
{
    struct page *page;
    pud_t *level3p;
    page = kimage_alloc_control_pages (image, 0);
    if (!page) {
        result = -ENOMEM;
        goto out;
    }
    level3p = (pud_t *) page_address (page);
    result = init_level3_page (image, level3p, addr, last_addr);
    if (result)
        goto out;
    set_pgd (level4p ++, __pgd (__pa (level3p) | _KERNPG_TABLE));
    addr += PGDIR_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="118" endline="121">
{
    result = -ENOMEM;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="130" endline="133">
{
    pgd_clear (level4p ++);
    addr += PGDIR_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="139" endline="143">
{
    free_page ((unsigned long) image -> arch.pud);
    free_page ((unsigned long) image -> arch.pmd);
    free_page ((unsigned long) image -> arch.pte);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="146" endline="185">
{
    pud_t *pud;
    pmd_t *pmd;
    pte_t *pte;
    unsigned long vaddr, paddr;
    int result = -ENOMEM;
    vaddr = (unsigned long) relocate_kernel;
    paddr = __pa (page_address (image->control_code_page) + PAGE_SIZE);
    pgd += pgd_index (vaddr);
    if (!pgd_present (*pgd)) {
        pud = (pud_t *) get_zeroed_page (GFP_KERNEL);
        if (!pud)
            goto err;
        image->arch.pud = pud;
        set_pgd (pgd, __pgd (__pa (pud) | _KERNPG_TABLE));
    }
    pud = pud_offset (pgd, vaddr);
    if (!pud_present (*pud)) {
        pmd = (pmd_t *) get_zeroed_page (GFP_KERNEL);
        if (!pmd)
            goto err;
        image->arch.pmd = pmd;
        set_pud (pud, __pud (__pa (pmd) | _KERNPG_TABLE));
    }
    pmd = pmd_offset (pud, vaddr);
    if (!pmd_present (*pmd)) {
        pte = (pte_t *) get_zeroed_page (GFP_KERNEL);
        if (!pte)
            goto err;
        image->arch.pte = pte;
        set_pmd (pmd, __pmd (__pa (pte) | _KERNPG_TABLE));
    }
    pte = pte_offset_kernel (pmd, vaddr);
    set_pte (pte, pfn_pte (paddr >> PAGE_SHIFT, PAGE_KERNEL_EXEC));
    return 0;
err :
    free_transition_pgtable (image);
    return result;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="156" endline="162">
{
    pud = (pud_t *) get_zeroed_page (GFP_KERNEL);
    if (!pud)
        goto err;
    image->arch.pud = pud;
    set_pgd (pgd, __pgd (__pa (pud) | _KERNPG_TABLE));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="164" endline="170">
{
    pmd = (pmd_t *) get_zeroed_page (GFP_KERNEL);
    if (!pmd)
        goto err;
    image->arch.pmd = pmd;
    set_pud (pud, __pud (__pa (pmd) | _KERNPG_TABLE));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="172" endline="178">
{
    pte = (pte_t *) get_zeroed_page (GFP_KERNEL);
    if (!pte)
        goto err;
    image->arch.pte = pte;
    set_pmd (pmd, __pmd (__pa (pte) | _KERNPG_TABLE));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="189" endline="204">
{
    pgd_t *level4p;
    int result;
    level4p = (pgd_t *) __va (start_pgtable);
    result = init_level4_page (image, level4p, 0, max_pfn << PAGE_SHIFT);
    if (result)
        return result;
    result = init_one_level2_page (image, level4p, image->start);
    if (result)
        return result;
    return init_transition_pgtable (image, level4p);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="207" endline="218">
{
    struct desc_ptr curidt;
    curidt.size = limit;
    curidt.address = (unsigned long) newidt;
    __asm__ __volatile__ ("lidtq %0\n" : : "m" (curidt));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="222" endline="233">
{
    struct desc_ptr curgdt;
    curgdt.size = limit;
    curgdt.address = (unsigned long) newgdt;
    __asm__ __volatile__ ("lgdtq %0\n" : : "m" (curgdt));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="236" endline="245">
{
    __asm__ __volatile__ ("\tmovl %0,%%ds\n" "\tmovl %0,%%es\n" "\tmovl %0,%%ss\n" "\tmovl %0,%%fs\n" "\tmovl %0,%%gs\n" : : "a" (__KERNEL_DS) : "memory");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="248" endline="261">
{
    unsigned long start_pgtable;
    int result;
    start_pgtable = page_to_pfn (image->control_code_page) << PAGE_SHIFT;
    result = init_pgtable (image, start_pgtable);
    if (result)
        return result;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="264" endline="266">
{
    free_transition_pgtable (image);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="273" endline="344">
{
    unsigned long page_list [PAGES_NR];
    void *control_page;
    int save_ftrace_enabled;
    save_ftrace_enabled = __ftrace_enabled_save ();
    local_irq_disable ();
    hw_breakpoint_disable ();
    if (image->preserve_context) {
    }
    control_page = page_address (image->control_code_page) + PAGE_SIZE;
    memcpy (control_page, relocate_kernel, KEXEC_CONTROL_CODE_MAX_SIZE);
    page_list[PA_CONTROL_PAGE] = virt_to_phys (control_page);
    page_list[VA_CONTROL_PAGE] = (unsigned long) control_page;
    page_list[PA_TABLE_PAGE] = (unsigned long) __pa (page_address (image->control_code_page));
    if (image->type == KEXEC_TYPE_DEFAULT)
        page_list[PA_SWAP_PAGE] = (page_to_pfn (image->swap_page) << PAGE_SHIFT);
    load_segments ();
    set_gdt (phys_to_virt (0), 0);
    set_idt (phys_to_virt (0), 0);
    image->start = relocate_kernel ((unsigned long) image->head, (unsigned long) page_list, image->start, image->preserve_context);
    __ftrace_enabled_restore (save_ftrace_enabled);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="289" endline="300">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/machine_kexec_64.c.ifdefed" startline="347" endline="355">
{
    VMCOREINFO_SYMBOL (phys_base);
    VMCOREINFO_SYMBOL (init_level4_pgt);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq_64.c.ifdefed" startline="37" endline="49">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq_64.c.ifdefed" startline="52" endline="63">
{
    struct irq_desc *desc;
    stack_overflow_check (regs);
    desc = irq_to_desc (irq);
    if (unlikely (!desc))
        return false;
    generic_handle_irq_desc (irq, desc);
    return true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq_64.c.ifdefed" startline="69" endline="84">
{
    __u32 pending;
    unsigned long flags;
    if (in_interrupt ())
        return;
    local_irq_save (flags);
    pending = local_softirq_pending ();
    if (pending) {
        call_softirq ();
        WARN_ON_ONCE (softirq_count ());
    }
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq_64.c.ifdefed" startline="79" endline="82">
{
    call_softirq ();
    WARN_ON_ONCE (softirq_count ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="66" endline="113">
{
    for (;;) {
        switch (*str) {
        case 'w' :
            reboot_mode = 0x1234;
            break;
        case 'c' :
            reboot_mode = 0;
            break;
        case 'a' :
        case 'k' :
        case 't' :
        case 'e' :
        case 'p' :
            reboot_type = *str;
            break;
        case 'f' :
            reboot_force = 1;
            break;
        }
        str = strchr (str, ',');
        if (str)
            str++;
        else
            break;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="67" endline="111">
{
    switch (*str) {
    case 'w' :
        reboot_mode = 0x1234;
        break;
    case 'c' :
        reboot_mode = 0;
        break;
    case 'a' :
    case 'k' :
    case 't' :
    case 'e' :
    case 'p' :
        reboot_type = *str;
        break;
    case 'f' :
        reboot_force = 1;
        break;
    }
    str = strchr (str, ',');
    if (str)
        str++;
    else
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="68" endline="104">
{
case 'w' :
    reboot_mode = 0x1234;
    break;
case 'c' :
    reboot_mode = 0;
    break;
case 'a' :
case 'k' :
case 't' :
case 'e' :
case 'p' :
    reboot_type = *str;
    break;
case 'f' :
    reboot_force = 1;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="430" endline="437">
{
    if (reboot_type != BOOT_CF9) {
        reboot_type = BOOT_CF9;
        printk (KERN_INFO "%s series board detected. " "Selecting PCI-method for reboots.\n", d -> ident);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="431" endline="435">
{
    reboot_type = BOOT_CF9;
    printk (KERN_INFO "%s series board detected. " "Selecting PCI-method for reboots.\n", d -> ident);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="476" endline="479">
{
    dmi_check_system (pci_reboot_dmi_table);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="483" endline="491">
{
    int i;
    for (i = 0; i < 0x10000; i++) {
        if ((inb (0x64) & 0x02) == 0)
            break;
        udelay (2);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="486" endline="490">
{
    if ((inb (0x64) & 0x02) == 0)
        break;
    udelay (2);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="494" endline="496">
{
    cpu_emergency_vmxoff ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="501" endline="532">
{
    local_irq_disable ();
    if (cpu_has_vmx () && cpu_vmx_enabled ()) {
        cpu_vmxoff ();
        nmi_shootdown_cpus (vmxoff_nmi);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="523" endline="531">
{
    cpu_vmxoff ();
    nmi_shootdown_cpus (vmxoff_nmi);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="536" endline="537">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="540" endline="609">
{
    int i;
    if (reboot_emergency)
        emergency_vmx_disable_all ();
    tboot_shutdown (TB_SHUTDOWN_REBOOT);
    *((unsigned short *) __va (0x472)) = reboot_mode;
    for (;;) {
        switch (reboot_type) {
        case BOOT_KBD :
            mach_reboot_fixups ();
            for (i = 0; i < 10; i++) {
                kb_wait ();
                udelay (50);
                outb (0xfe, 0x64);
                udelay (50);
            }
        case BOOT_TRIPLE :
            load_idt (&no_idt);
            __asm__ __volatile__ ("int3");
            reboot_type = BOOT_KBD;
            break;
        case BOOT_ACPI :
            acpi_reboot ();
            reboot_type = BOOT_KBD;
            break;
        case BOOT_EFI :
            if (efi_enabled)
                efi.reset_system (reboot_mode ? EFI_RESET_WARM : EFI_RESET_COLD, EFI_SUCCESS, 0, NULL);
            reboot_type = BOOT_KBD;
            break;
        case BOOT_CF9 :
            port_cf9_safe = true;
        case BOOT_CF9_COND :
            if (port_cf9_safe) {
                u8 cf9 = inb (0xcf9) & ~6;
                outb (cf9 | 2, 0xcf9);
                udelay (50);
                outb (cf9 | 6, 0xcf9);
                udelay (50);
            }
            reboot_type = BOOT_KBD;
            break;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="551" endline="608">
{
    switch (reboot_type) {
    case BOOT_KBD :
        mach_reboot_fixups ();
        for (i = 0; i < 10; i++) {
            kb_wait ();
            udelay (50);
            outb (0xfe, 0x64);
            udelay (50);
        }
    case BOOT_TRIPLE :
        load_idt (&no_idt);
        __asm__ __volatile__ ("int3");
        reboot_type = BOOT_KBD;
        break;
    case BOOT_ACPI :
        acpi_reboot ();
        reboot_type = BOOT_KBD;
        break;
    case BOOT_EFI :
        if (efi_enabled)
            efi.reset_system (reboot_mode ? EFI_RESET_WARM : EFI_RESET_COLD, EFI_SUCCESS, 0, NULL);
        reboot_type = BOOT_KBD;
        break;
    case BOOT_CF9 :
        port_cf9_safe = true;
    case BOOT_CF9_COND :
        if (port_cf9_safe) {
            u8 cf9 = inb (0xcf9) & ~6;
            outb (cf9 | 2, 0xcf9);
            udelay (50);
            outb (cf9 | 6, 0xcf9);
            udelay (50);
        }
        reboot_type = BOOT_KBD;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="553" endline="607">
{
case BOOT_KBD :
    mach_reboot_fixups ();
    for (i = 0; i < 10; i++) {
        kb_wait ();
        udelay (50);
        outb (0xfe, 0x64);
        udelay (50);
    }
case BOOT_TRIPLE :
    load_idt (&no_idt);
    __asm__ __volatile__ ("int3");
    reboot_type = BOOT_KBD;
    break;
case BOOT_ACPI :
    acpi_reboot ();
    reboot_type = BOOT_KBD;
    break;
case BOOT_EFI :
    if (efi_enabled)
        efi.reset_system (reboot_mode ? EFI_RESET_WARM : EFI_RESET_COLD, EFI_SUCCESS, 0, NULL);
    reboot_type = BOOT_KBD;
    break;
case BOOT_CF9 :
    port_cf9_safe = true;
case BOOT_CF9_COND :
    if (port_cf9_safe) {
        u8 cf9 = inb (0xcf9) & ~6;
        outb (cf9 | 2, 0xcf9);
        udelay (50);
        outb (cf9 | 6, 0xcf9);
        udelay (50);
    }
    reboot_type = BOOT_KBD;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="557" endline="562">
{
    kb_wait ();
    udelay (50);
    outb (0xfe, 0x64);
    udelay (50);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="598" endline="604">
{
    u8 cf9 = inb (0xcf9) & ~6;
    outb (cf9 | 2, 0xcf9);
    udelay (50);
    outb (cf9 | 6, 0xcf9);
    udelay (50);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="612" endline="652">
{
    lapic_shutdown ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="655" endline="658">
{
    reboot_emergency = emergency;
    machine_ops.emergency_restart ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="661" endline="667">
{
    printk ("machine restart\n");
    if (!reboot_force)
        machine_shutdown ();
    __machine_emergency_restart (0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="670" endline="678">
{
    machine_shutdown ();
    tboot_shutdown (TB_SHUTDOWN_HALT);
    stop_this_cpu (NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="681" endline="689">
{
    if (pm_power_off) {
        if (!reboot_force)
            machine_shutdown ();
        pm_power_off ();
    }
    tboot_shutdown (TB_SHUTDOWN_HALT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="682" endline="686">
{
    if (!reboot_force)
        machine_shutdown ();
    pm_power_off ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="703" endline="705">
{
    machine_ops.power_off ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="708" endline="710">
{
    machine_ops.shutdown ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="713" endline="715">
{
    __machine_emergency_restart (1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="718" endline="720">
{
    machine_ops.restart (cmd);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="723" endline="725">
{
    machine_ops.halt ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/reboot.c.ifdefed" startline="818" endline="820">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/io_delay.c.ifdefed" startline="23" endline="44">
{
    switch (io_delay_type) {
    default :
    case CONFIG_IO_DELAY_TYPE_0X80 :
        asm volatile ("outb %al, $0x80"
        );
        break;
    case CONFIG_IO_DELAY_TYPE_0XED :
        asm volatile ("outb %al, $0xed"
        );
        break;
    case CONFIG_IO_DELAY_TYPE_UDELAY :
        udelay (2);
    case CONFIG_IO_DELAY_TYPE_NONE :
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/io_delay.c.ifdefed" startline="24" endline="43">
{
default :
case CONFIG_IO_DELAY_TYPE_0X80 :
    asm volatile ("outb %al, $0x80"
    );
    break;
case CONFIG_IO_DELAY_TYPE_0XED :
    asm volatile ("outb %al, $0xed"
    );
    break;
case CONFIG_IO_DELAY_TYPE_UDELAY :
    udelay (2);
case CONFIG_IO_DELAY_TYPE_NONE :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/io_delay.c.ifdefed" startline="48" endline="55">
{
    if (io_delay_type == CONFIG_IO_DELAY_TYPE_0X80) {
        pr_notice ("%s: using 0xed I/O delay port\n", id -> ident);
        io_delay_type = CONFIG_IO_DELAY_TYPE_0XED;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/io_delay.c.ifdefed" startline="49" endline="52">
{
    pr_notice ("%s: using 0xed I/O delay port\n", id -> ident);
    io_delay_type = CONFIG_IO_DELAY_TYPE_0XED;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/io_delay.c.ifdefed" startline="106" endline="109">
{
    if (!io_delay_override)
        dmi_check_system (io_delay_0xed_port_dmi_table);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/io_delay.c.ifdefed" startline="112" endline="129">
{
    if (!s)
        return -EINVAL;
    if (!strcmp (s, "0x80"))
        io_delay_type = CONFIG_IO_DELAY_TYPE_0X80;
    else if (!strcmp (s, "0xed"))
        io_delay_type = CONFIG_IO_DELAY_TYPE_0XED;
    else if (!strcmp (s, "udelay"))
        io_delay_type = CONFIG_IO_DELAY_TYPE_UDELAY;
    else if (!strcmp (s, "none"))
        io_delay_type = CONFIG_IO_DELAY_TYPE_NONE;
    else
        return -EINVAL;
    io_delay_override = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="116" endline="122">
{
    if (unlikely (cpu_is_offline (cpu))) {
        WARN_ON (1);
        return;
    }
    apic->send_IPI_mask (cpumask_of (cpu), RESCHEDULE_VECTOR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="117" endline="120">
{
    WARN_ON (1);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="125" endline="127">
{
    apic->send_IPI_mask (cpumask_of (cpu), CALL_FUNCTION_SINGLE_VECTOR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="130" endline="148">
{
    cpumask_var_t allbutself;
    if (!alloc_cpumask_var (&allbutself, GFP_ATOMIC)) {
        apic->send_IPI_mask (mask, CALL_FUNCTION_VECTOR);
        return;
    }
    cpumask_copy (allbutself, cpu_online_mask);
    cpumask_clear_cpu (smp_processor_id (), allbutself);
    if (cpumask_equal (mask, allbutself) && cpumask_equal (cpu_online_mask, cpu_callout_mask))
        apic->send_IPI_allbutself (CALL_FUNCTION_VECTOR);
    else
        apic->send_IPI_mask (mask, CALL_FUNCTION_VECTOR);
    free_cpumask_var (allbutself);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="133" endline="136">
{
    apic->send_IPI_mask (mask, CALL_FUNCTION_VECTOR);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="155" endline="160">
{
    ack_APIC_irq ();
    irq_enter ();
    stop_this_cpu (NULL);
    irq_exit ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="163" endline="191">
{
    unsigned long flags;
    unsigned long wait;
    if (reboot_force)
        return;
    if (num_online_cpus () > 1) {
        apic->send_IPI_allbutself (REBOOT_VECTOR);
        wait = USEC_PER_SEC;
        while (num_online_cpus () > 1 && wait--)
            udelay (1);
    }
    local_irq_save (flags);
    disable_local_APIC ();
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="179" endline="186">
{
    apic->send_IPI_allbutself (REBOOT_VECTOR);
    wait = USEC_PER_SEC;
    while (num_online_cpus () > 1 && wait--)
        udelay (1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="199" endline="205">
{
    ack_APIC_irq ();
    inc_irq_stat (irq_resched_count);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="208" endline="214">
{
    ack_APIC_irq ();
    irq_enter ();
    generic_smp_call_function_interrupt ();
    inc_irq_stat (irq_call_count);
    irq_exit ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smp.c.ifdefed" startline="217" endline="223">
{
    ack_APIC_irq ();
    irq_enter ();
    generic_smp_call_function_single_interrupt ();
    inc_irq_stat (irq_call_count);
    irq_exit ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/time.c.ifdefed" startline="34" endline="55">
{
    unsigned long pc = instruction_pointer (regs);
    if (!user_mode_vm (regs) && in_lock_functions (pc)) {
        unsigned long *sp = (unsigned long *) kernel_stack_pointer (regs);
        if (sp[0] >> 22)
            return sp[0];
        if (sp[1] >> 22)
            return sp[1];
    }
    return pc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/time.c.ifdefed" startline="37" endline="53">
{
    unsigned long *sp = (unsigned long *) kernel_stack_pointer (regs);
    if (sp[0] >> 22)
        return sp[0];
    if (sp[1] >> 22)
        return sp[1];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/time.c.ifdefed" startline="62" endline="87">
{
    inc_irq_stat (irq0_irqs);
    if (timer_ack) {
        raw_spin_lock (& i8259A_lock);
        outb (0x0c, PIC_MASTER_OCW3);
        inb (PIC_MASTER_POLL);
        raw_spin_unlock (& i8259A_lock);
    }
    global_clock_event->event_handler (global_clock_event);
    if (MCA_bus)
        outb_p (inb_p (0x61) | 0x80, 0x61);
    return IRQ_HANDLED;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/time.c.ifdefed" startline="67" endline="78">
{
    raw_spin_lock (& i8259A_lock);
    outb (0x0c, PIC_MASTER_OCW3);
    inb (PIC_MASTER_POLL);
    raw_spin_unlock (& i8259A_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/time.c.ifdefed" startline="96" endline="98">
{
    setup_irq (0, & irq0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/time.c.ifdefed" startline="102" endline="106">
{
    if (!hpet_enable ())
        setup_pit_timer ();
    setup_default_timer_irq ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/time.c.ifdefed" startline="109" endline="112">
{
    x86_init.timers.timer_init ();
    tsc_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/time.c.ifdefed" startline="119" endline="121">
{
    late_time_init = x86_late_time_init;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="55" endline="57">
{
    return readl (hpet_virt_address +a);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="60" endline="62">
{
    writel (d, hpet_virt_address + a);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="69" endline="74">
{
    hpet_virt_address = ioremap_nocache (hpet_address, HPET_MMAP_SIZE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="77" endline="80">
{
    iounmap (hpet_virt_address);
    hpet_virt_address = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="90" endline="100">
{
    if (str) {
        if (!strncmp ("disable", str, 7))
            boot_hpet_disable = 1;
        if (!strncmp ("force", str, 5))
            hpet_force_user = 1;
        if (!strncmp ("verbose", str, 7))
            hpet_verbose = 1;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="91" endline="98">
{
    if (!strncmp ("disable", str, 7))
        boot_hpet_disable = 1;
    if (!strncmp ("force", str, 5))
        hpet_force_user = 1;
    if (!strncmp ("verbose", str, 7))
        hpet_verbose = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="104" endline="107">
{
    boot_hpet_disable = 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="111" endline="113">
{
    return !boot_hpet_disable && hpet_address;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="124" endline="126">
{
    return is_hpet_capable () && hpet_legacy_int_enabled;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="130" endline="158">
{
    u32 i, timers, l, h;
    printk (KERN_INFO "hpet: %s(%d):\n", function, line);
    l = hpet_readl (HPET_ID);
    h = hpet_readl (HPET_PERIOD);
    timers = ((l & HPET_ID_NUMBER) >> HPET_ID_NUMBER_SHIFT) + 1;
    printk (KERN_INFO "hpet: ID: 0x%x, PERIOD: 0x%x\n", l, h);
    l = hpet_readl (HPET_CFG);
    h = hpet_readl (HPET_STATUS);
    printk (KERN_INFO "hpet: CFG: 0x%x, STATUS: 0x%x\n", l, h);
    l = hpet_readl (HPET_COUNTER);
    h = hpet_readl (HPET_COUNTER +4);
    printk (KERN_INFO "hpet: COUNTER_l: 0x%x, COUNTER_h: 0x%x\n", l, h);
    for (i = 0; i < timers; i++) {
        l = hpet_readl (HPET_Tn_CFG (i));
        h = hpet_readl (HPET_Tn_CFG (i) +4);
        printk (KERN_INFO "hpet: T%d: CFG_l: 0x%x, CFG_h: 0x%x\n", i, l, h);
        l = hpet_readl (HPET_Tn_CMP (i));
        h = hpet_readl (HPET_Tn_CMP (i) +4);
        printk (KERN_INFO "hpet: T%d: CMP_l: 0x%x, CMP_h: 0x%x\n", i, l, h);
        l = hpet_readl (HPET_Tn_ROUTE (i));
        h = hpet_readl (HPET_Tn_ROUTE (i) +4);
        printk (KERN_INFO "hpet: T%d ROUTE_l: 0x%x, ROUTE_h: 0x%x\n", i, l, h);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="144" endline="157">
{
    l = hpet_readl (HPET_Tn_CFG (i));
    h = hpet_readl (HPET_Tn_CFG (i) +4);
    printk (KERN_INFO "hpet: T%d: CFG_l: 0x%x, CFG_h: 0x%x\n", i, l, h);
    l = hpet_readl (HPET_Tn_CMP (i));
    h = hpet_readl (HPET_Tn_CMP (i) +4);
    printk (KERN_INFO "hpet: T%d: CMP_l: 0x%x, CMP_h: 0x%x\n", i, l, h);
    l = hpet_readl (HPET_Tn_ROUTE (i));
    h = hpet_readl (HPET_Tn_ROUTE (i) +4);
    printk (KERN_INFO "hpet: T%d ROUTE_l: 0x%x, ROUTE_h: 0x%x\n", i, l, h);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="212" endline="212">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="239" endline="243">
{
    unsigned long cfg = hpet_readl (HPET_CFG);
    cfg &= ~HPET_CFG_ENABLE;
    hpet_writel (cfg, HPET_CFG);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="246" endline="249">
{
    hpet_writel (0, HPET_COUNTER);
    hpet_writel (0, HPET_COUNTER + 4);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="252" endline="256">
{
    unsigned int cfg = hpet_readl (HPET_CFG);
    cfg |= HPET_CFG_ENABLE;
    hpet_writel (cfg, HPET_CFG);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="259" endline="263">
{
    hpet_stop_counter ();
    hpet_reset_counter ();
    hpet_start_counter ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="266" endline="268">
{
    force_hpet_resume ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="271" endline="274">
{
    hpet_resume_device ();
    hpet_restart_counter ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="277" endline="283">
{
    unsigned int cfg = hpet_readl (HPET_CFG);
    cfg |= HPET_CFG_LEGACY;
    hpet_writel (cfg, HPET_CFG);
    hpet_legacy_int_enabled = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="286" endline="314">
{
    hpet_enable_legacy_int ();
    hpet_clockevent.mult = div_sc ((unsigned long) FSEC_PER_NSEC, hpet_period, hpet_clockevent.shift);
    hpet_clockevent.max_delta_ns = clockevent_delta2ns (0x7FFFFFFF, &hpet_clockevent);
    hpet_clockevent.min_delta_ns = 5000;
    hpet_clockevent.cpumask = cpumask_of (smp_processor_id ());
    clockevents_register_device (& hpet_clockevent);
    global_clock_event = &hpet_clockevent;
    printk (KERN_DEBUG "hpet clockevent registered\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="320" endline="378">
{
    unsigned int cfg, cmp, now;
    uint64_t delta;
    switch (mode) {
    case CLOCK_EVT_MODE_PERIODIC :
        hpet_stop_counter ();
        delta = ((uint64_t) (NSEC_PER_SEC / HZ)) * evt->mult;
        delta >>= evt->shift;
        now = hpet_readl (HPET_COUNTER);
        cmp = now + (unsigned int) delta;
        cfg = hpet_readl (HPET_Tn_CFG (timer));
        cfg &= ~HPET_TN_LEVEL;
        cfg |= HPET_TN_ENABLE | HPET_TN_PERIODIC | HPET_TN_SETVAL | HPET_TN_32BIT;
        hpet_writel (cfg, HPET_Tn_CFG (timer));
        hpet_writel (cmp, HPET_Tn_CMP (timer));
        udelay (1);
        hpet_writel ((unsigned int) delta, HPET_Tn_CMP (timer));
        hpet_start_counter ();
        hpet_print_config ();
        break;
    case CLOCK_EVT_MODE_ONESHOT :
        cfg = hpet_readl (HPET_Tn_CFG (timer));
        cfg &= ~HPET_TN_PERIODIC;
        cfg |= HPET_TN_ENABLE | HPET_TN_32BIT;
        hpet_writel (cfg, HPET_Tn_CFG (timer));
        break;
    case CLOCK_EVT_MODE_UNUSED :
    case CLOCK_EVT_MODE_SHUTDOWN :
        cfg = hpet_readl (HPET_Tn_CFG (timer));
        cfg &= ~HPET_TN_ENABLE;
        hpet_writel (cfg, HPET_Tn_CFG (timer));
        break;
    case CLOCK_EVT_MODE_RESUME :
        if (timer == 0) {
            hpet_enable_legacy_int ();
        }
        else {
            struct hpet_dev *hdev = EVT_TO_HPET_DEV (evt);
            hpet_setup_msi_irq (hdev -> irq);
            disable_irq (hdev -> irq);
            irq_set_affinity (hdev -> irq, cpumask_of (hdev -> cpu));
            enable_irq (hdev -> irq);
        }
        hpet_print_config ();
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="324" endline="377">
{
case CLOCK_EVT_MODE_PERIODIC :
    hpet_stop_counter ();
    delta = ((uint64_t) (NSEC_PER_SEC / HZ)) * evt->mult;
    delta >>= evt->shift;
    now = hpet_readl (HPET_COUNTER);
    cmp = now + (unsigned int) delta;
    cfg = hpet_readl (HPET_Tn_CFG (timer));
    cfg &= ~HPET_TN_LEVEL;
    cfg |= HPET_TN_ENABLE | HPET_TN_PERIODIC | HPET_TN_SETVAL | HPET_TN_32BIT;
    hpet_writel (cfg, HPET_Tn_CFG (timer));
    hpet_writel (cmp, HPET_Tn_CMP (timer));
    udelay (1);
    hpet_writel ((unsigned int) delta, HPET_Tn_CMP (timer));
    hpet_start_counter ();
    hpet_print_config ();
    break;
case CLOCK_EVT_MODE_ONESHOT :
    cfg = hpet_readl (HPET_Tn_CFG (timer));
    cfg &= ~HPET_TN_PERIODIC;
    cfg |= HPET_TN_ENABLE | HPET_TN_32BIT;
    hpet_writel (cfg, HPET_Tn_CFG (timer));
    break;
case CLOCK_EVT_MODE_UNUSED :
case CLOCK_EVT_MODE_SHUTDOWN :
    cfg = hpet_readl (HPET_Tn_CFG (timer));
    cfg &= ~HPET_TN_ENABLE;
    hpet_writel (cfg, HPET_Tn_CFG (timer));
    break;
case CLOCK_EVT_MODE_RESUME :
    if (timer == 0) {
        hpet_enable_legacy_int ();
    }
    else {
        struct hpet_dev *hdev = EVT_TO_HPET_DEV (evt);
        hpet_setup_msi_irq (hdev -> irq);
        disable_irq (hdev -> irq);
        irq_set_affinity (hdev -> irq, cpumask_of (hdev -> cpu));
        enable_irq (hdev -> irq);
    }
    hpet_print_config ();
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="366" endline="368">
{
    hpet_enable_legacy_int ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="368" endline="374">
{
    struct hpet_dev *hdev = EVT_TO_HPET_DEV (evt);
    hpet_setup_msi_irq (hdev -> irq);
    disable_irq (hdev -> irq);
    irq_set_affinity (hdev -> irq, cpumask_of (hdev -> cpu));
    enable_irq (hdev -> irq);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="382" endline="414">
{
    u32 cnt;
    cnt = hpet_readl (HPET_COUNTER);
    cnt += (u32) delta;
    hpet_writel (cnt, HPET_Tn_CMP (timer));
    if (unlikely ((u32) hpet_readl (HPET_Tn_CMP (timer)) != cnt)) {
        WARN_ONCE (hpet_readl (HPET_Tn_CMP (timer)) != cnt, KERN_WARNING "hpet: compare register read back failed.\n");
    }
    return (s32) (hpet_readl (HPET_COUNTER) - cnt) >= 0 ? -ETIME : 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="408" endline="411">
{
    WARN_ONCE (hpet_readl (HPET_Tn_CMP (timer)) != cnt, KERN_WARNING "hpet: compare register read back failed.\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="418" endline="420">
{
    hpet_set_mode (mode, evt, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="424" endline="426">
{
    return hpet_next_event (delta, evt, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="742" endline="744">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="746" endline="748">
{
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="759" endline="761">
{
    return NOTIFY_OK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="769" endline="771">
{
    return (cycle_t) hpet_readl (HPET_COUNTER);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="794" endline="835">
{
    u64 start, now;
    cycle_t t1;
    hpet_restart_counter ();
    t1 = hpet_readl (HPET_COUNTER);
    rdtscll (start);
    do {
        rep_nop ();
        rdtscll (now);
    }
    while ((now - start) < 200000UL);
    if (t1 == hpet_readl (HPET_COUNTER)) {
        printk (KERN_WARNING "HPET counter not counting. HPET disabled\n");
        return -ENODEV;
    }
    clocksource_hpet.mult = div_sc (hpet_period, FSEC_PER_NSEC, HPET_SHIFT);
    clocksource_register (& clocksource_hpet);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="811" endline="814">
{
    rep_nop ();
    rdtscll (now);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="816" endline="820">
{
    printk (KERN_WARNING "HPET counter not counting. HPET disabled\n");
    return -ENODEV;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="841" endline="909">
{
    unsigned int id;
    int i;
    if (!is_hpet_capable ())
        return 0;
    hpet_set_mapping ();
    hpet_period = hpet_readl (HPET_PERIOD);
    for (i = 0; hpet_readl (HPET_CFG) == 0xFFFFFFFF; i++) {
        if (i == 1000) {
            printk (KERN_WARNING "HPET config register value = 0xFFFFFFFF. " "Disabling HPET\n");
            goto out_nohpet;
        }
    }
    if (hpet_period < HPET_MIN_PERIOD || hpet_period > HPET_MAX_PERIOD)
        goto out_nohpet;
    id = hpet_readl (HPET_ID);
    hpet_print_config ();
    if (hpet_clocksource_register ())
        goto out_nohpet;
    if (id & HPET_ID_LEGSUP) {
        hpet_legacy_clockevent_register ();
        return 1;
    }
    return 0;
out_nohpet :
    hpet_clear_mapping ();
    hpet_address = 0;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="868" endline="875">
{
    if (i == 1000) {
        printk (KERN_WARNING "HPET config register value = 0xFFFFFFFF. " "Disabling HPET\n");
        goto out_nohpet;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="869" endline="874">
{
    printk (KERN_WARNING "HPET config register value = 0xFFFFFFFF. " "Disabling HPET\n");
    goto out_nohpet;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="899" endline="902">
{
    hpet_legacy_clockevent_register ();
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="918" endline="957">
{
    int cpu;
    if (boot_hpet_disable)
        return -ENODEV;
    if (!hpet_address) {
        if (!force_hpet_address)
            return -ENODEV;
        hpet_address = force_hpet_address;
        hpet_enable ();
    }
    if (!hpet_virt_address)
        return -ENODEV;
    if (hpet_readl (HPET_ID) & HPET_ID_LEGSUP)
        hpet_msi_capability_lookup (2);
    else
        hpet_msi_capability_lookup (0);
    hpet_reserve_platform_timers (hpet_readl (HPET_ID));
    hpet_print_config ();
    if (hpet_msi_disable)
        return 0;
    if (boot_cpu_has (X86_FEATURE_ARAT))
        return 0;

    for_each_online_cpu (cpu) {
        hpet_cpuhp_notify (NULL, CPU_ONLINE, (void *) (long) cpu);
    }

    hotcpu_notifier (hpet_cpuhp_notify, - 20);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="924" endline="930">
{
    if (!force_hpet_address)
        return -ENODEV;
    hpet_address = force_hpet_address;
    hpet_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="949" endline="951">
{
    hpet_cpuhp_notify (NULL, CPU_ONLINE, (void *) (long) cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="961" endline="972">
{
    if (is_hpet_capable ()) {
        unsigned int cfg = hpet_readl (HPET_CFG);
        if (hpet_legacy_int_enabled) {
            cfg &= ~HPET_CFG_LEGACY;
            hpet_legacy_int_enabled = 0;
        }
        cfg &= ~HPET_CFG_ENABLE;
        hpet_writel (cfg, HPET_CFG);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="962" endline="971">
{
    unsigned int cfg = hpet_readl (HPET_CFG);
    if (hpet_legacy_int_enabled) {
        cfg &= ~HPET_CFG_LEGACY;
        hpet_legacy_int_enabled = 0;
    }
    cfg &= ~HPET_CFG_ENABLE;
    hpet_writel (cfg, HPET_CFG);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hpet.c.ifdefed" startline="965" endline="968">
{
    cfg &= ~HPET_CFG_LEGACY;
    hpet_legacy_int_enabled = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="264" endline="265">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="269" endline="285">
{
    size_t mask = align - 1;
    void *ret;
    BUG_ON (_brk_start == 0);
    BUG_ON (align & mask);
    _brk_end = (_brk_end + mask) & ~mask;
    BUG_ON ((char *) (_brk_end + size) > __brk_limit);
    ret = (void *) _brk_end;
    _brk_end += size;
    memset (ret, 0, size);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="297" endline="298">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="302" endline="309">
{
    if (_brk_end > _brk_start)
        reserve_early (__pa (_brk_start), __pa (_brk_end), "BRK");
    _brk_start = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="419" endline="420">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="424" endline="443">
{
    struct setup_data *data;
    u64 pa_data;
    if (boot_params.hdr.version < 0x0209)
        return;
    pa_data = boot_params.hdr.setup_data;
    while (pa_data) {
        data = early_memremap (pa_data, PAGE_SIZE);
        switch (data->type) {
        case SETUP_E820_EXT :
            parse_e820_ext (data, pa_data);
            break;
        default :
            break;
        }
        pa_data = data->next;
        early_iounmap (data, PAGE_SIZE);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="431" endline="442">
{
    data = early_memremap (pa_data, PAGE_SIZE);
    switch (data->type) {
    case SETUP_E820_EXT :
        parse_e820_ext (data, pa_data);
        break;
    default :
        break;
    }
    pa_data = data->next;
    early_iounmap (data, PAGE_SIZE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="433" endline="439">
{
case SETUP_E820_EXT :
    parse_e820_ext (data, pa_data);
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="446" endline="469">
{
    struct setup_data *data;
    u64 pa_data;
    int found = 0;
    if (boot_params.hdr.version < 0x0209)
        return;
    pa_data = boot_params.hdr.setup_data;
    while (pa_data) {
        data = early_memremap (pa_data, sizeof (*data));
        e820_update_range (pa_data, sizeof (* data) + data -> len, E820_RAM, E820_RESERVED_KERN);
        found = 1;
        pa_data = data->next;
        early_iounmap (data, sizeof (* data));
    }
    if (!found)
        return;
    sanitize_e820_map (e820.map, ARRAY_SIZE (e820.map), & e820.nr_map);
    memcpy (& e820_saved, & e820, sizeof (struct e820map));
    printk (KERN_INFO "extended physical RAM map:\n");
    e820_print_map ("reserve setup_data");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="454" endline="461">
{
    data = early_memremap (pa_data, sizeof (*data));
    e820_update_range (pa_data, sizeof (* data) + data -> len, E820_RAM, E820_RESERVED_KERN);
    found = 1;
    pa_data = data->next;
    early_iounmap (data, sizeof (* data));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="472" endline="487">
{
    struct setup_data *data;
    u64 pa_data;
    char buf [32];
    if (boot_params.hdr.version < 0x0209)
        return;
    pa_data = boot_params.hdr.setup_data;
    while (pa_data) {
        data = early_memremap (pa_data, sizeof (*data));
        sprintf (buf, "setup data %x", data -> type);
        reserve_early (pa_data, pa_data + sizeof (* data) + data -> len, buf);
        pa_data = data->next;
        early_iounmap (data, sizeof (* data));
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="480" endline="486">
{
    data = early_memremap (pa_data, sizeof (*data));
    sprintf (buf, "setup data %x", data -> type);
    reserve_early (pa_data, pa_data + sizeof (* data) + data -> len, buf);
    pa_data = data->next;
    early_iounmap (data, sizeof (* data));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="551" endline="552">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="579" endline="586">
{
    int i;
    for (i = 0; i < ARRAY_SIZE (standard_io_resources); i++)
        request_resource (&ioport_resource, &standard_io_resources[i]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="611" endline="618">
{
    unsigned long addr, size = 0;
    addr = find_ibft_region (&size);
    if (size)
        reserve_early_overlap_ok (addr, addr +size, "ibft");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="684" endline="698">
{
    e820_update_range (0, PAGE_SIZE, E820_RAM, E820_RESERVED);
    e820_remove_range (BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
    sanitize_e820_map (e820.map, ARRAY_SIZE (e820.map), & e820.nr_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="714" endline="1054">
{
    int acpi = 0;
    int k8 = 0;
    printk (KERN_INFO "Command line: %s\n", boot_command_line);
    vmi_init ();
    early_cpu_init ();
    early_ioremap_init ();
    ROOT_DEV = old_decode_dev (boot_params.hdr.root_dev);
    screen_info = boot_params.screen_info;
    edid_info = boot_params.edid_info;
    saved_video_mode = boot_params.hdr.vid_mode;
    bootloader_type = boot_params.hdr.type_of_loader;
    if ((bootloader_type >> 4) == 0xe) {
        bootloader_type &= 0xf;
        bootloader_type |= (boot_params.hdr.ext_loader_type + 0x10) << 4;
    }
    bootloader_version = bootloader_type & 0xf;
    bootloader_version |= boot_params.hdr.ext_loader_ver << 4;
    x86_init.oem.arch_setup ();
    setup_memory_map ();
    parse_setup_data ();
    e820_reserve_setup_data ();
    copy_edd ();
    if (!boot_params.hdr.root_flags)
        root_mountflags &= ~MS_RDONLY;
    init_mm.start_code = (unsigned long) _text;
    init_mm.end_code = (unsigned long) _etext;
    init_mm.end_data = (unsigned long) _edata;
    init_mm.brk = _brk_end;
    code_resource.start = virt_to_phys (_text);
    code_resource.end = virt_to_phys (_etext) - 1;
    data_resource.start = virt_to_phys (_etext);
    data_resource.end = virt_to_phys (_edata) - 1;
    bss_resource.start = virt_to_phys (&__bss_start);
    bss_resource.end = virt_to_phys (&__bss_stop) - 1;
    strlcpy (command_line, boot_command_line, COMMAND_LINE_SIZE);
    *cmdline_p = command_line;
    x86_configure_nx ();
    parse_early_param ();
    x86_report_nx ();
    vmi_activate ();
    reserve_early_setup_data ();
    if (acpi_mps_check ()) {
        setup_clear_cpu_cap (X86_FEATURE_APIC);
    }
    finish_e820_parsing ();
    if (efi_enabled)
        efi_init ();
    dmi_scan_machine ();
    dmi_check_system (bad_bios_dmi_table);
    init_hypervisor_platform ();
    x86_init.resources.probe_roms ();
    insert_resource (& iomem_resource, & code_resource);
    insert_resource (& iomem_resource, & data_resource);
    insert_resource (& iomem_resource, & bss_resource);
    trim_bios_range ();
    early_gart_iommu_check ();
    max_pfn = e820_end_of_ram_pfn ();
    early_reserve_e820_mpc_new ();
    mtrr_bp_init ();
    if (mtrr_trim_uncached_memory (max_pfn))
        max_pfn = e820_end_of_ram_pfn ();
    num_physpages = max_pfn;
    check_x2apic ();
    if (max_pfn > (1UL << (32 - PAGE_SHIFT)))
        max_low_pfn = e820_end_of_low_ram_pfn ();
    else
        max_low_pfn = max_pfn;
    high_memory = (void *) __va (max_pfn *PAGE_SIZE - 1) + 1;
    max_pfn_mapped = KERNEL_IMAGE_SIZE >> PAGE_SHIFT;
    printk (KERN_DEBUG "initial memory mapped : 0 - %08lx\n", max_pfn_mapped << PAGE_SHIFT);
    reserve_brk ();
    find_smp_config ();
    reserve_ibft_region ();
    reserve_trampoline_memory ();
    init_gbpages ();
    max_low_pfn_mapped = init_memory_mapping (0, max_low_pfn << PAGE_SHIFT);
    max_pfn_mapped = max_low_pfn_mapped;
    reserve_initrd ();
    reserve_crashkernel ();
    vsmp_init ();
    io_delay_init ();
    acpi_boot_table_init ();
    early_acpi_boot_init ();
    initmem_init (0, max_pfn, acpi, k8);
    early_res_to_bootmem (0, max_low_pfn << PAGE_SHIFT);
    dma32_reserve_bootmem ();
    x86_init.paging.pagetable_setup_start (swapper_pg_dir);
    paging_init ();
    x86_init.paging.pagetable_setup_done (swapper_pg_dir);
    tboot_probe ();
    generic_apic_probe ();
    early_quirks ();
    acpi_boot_init ();
    sfi_init ();
    if (smp_found_config)
        get_smp_config ();
    prefill_possible_map ();
    init_apic_mappings ();
    ioapic_init_mappings ();
    probe_nr_irqs_gsi ();
    kvm_guest_init ();
    e820_reserve_resources ();
    e820_mark_nosave_regions (max_low_pfn);
    x86_init.resources.reserve_resources ();
    e820_setup_gap ();
    x86_init.oem.banner ();
    mcheck_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="746" endline="749">
{
    bootloader_type &= 0xf;
    bootloader_type |= (boot_params.hdr.ext_loader_type + 0x10) << 4;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup.c.ifdefed" startline="829" endline="834">
{
    setup_clear_cpu_cap (X86_FEATURE_APIC);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="182" endline="272">
{
    int cpuid, phys_id;
    unsigned long timeout;
    if (apic->wait_for_init_deassert)
        apic->wait_for_init_deassert (&init_deasserted);
    phys_id = read_apic_id ();
    cpuid = smp_processor_id ();
    if (cpumask_test_cpu (cpuid, cpu_callin_mask)) {
        panic ("%s: phys CPU#%d, CPU#%d already present??\n", __func__, phys_id, cpuid);
    }
    pr_debug ("CPU#%d (phys ID: %d) waiting for CALLOUT\n", cpuid, phys_id);
    timeout = jiffies + 2 * HZ;
    while (time_before (jiffies, timeout)) {
        if (cpumask_test_cpu (cpuid, cpu_callout_mask))
            break;
        cpu_relax ();
    }
    if (!time_before (jiffies, timeout)) {
        panic ("%s: CPU%d started up but did not get a callout!\n", __func__, cpuid);
    }
    pr_debug ("CALLIN, before setup_local_APIC().\n");
    if (apic->smp_callin_clear_local_apic)
        apic->smp_callin_clear_local_apic ();
    setup_local_APIC ();
    end_local_APIC_setup ();
    map_cpu_to_logical_apicid ();
    setup_vector_irq (smp_processor_id ());
    local_irq_enable ();
    calibrate_delay ();
    local_irq_disable ();
    pr_debug ("Stack at about %p\n", & cpuid);
    smp_store_cpu_info (cpuid);
    notify_cpu_starting (cpuid);
    cpumask_set_cpu (cpuid, cpu_callin_mask);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="200" endline="203">
{
    panic ("%s: phys CPU#%d, CPU#%d already present??\n", __func__, phys_id, cpuid);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="218" endline="225">
{
    if (cpumask_test_cpu (cpuid, cpu_callout_mask))
        break;
    cpu_relax ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="227" endline="230">
{
    panic ("%s: CPU%d started up but did not get a callout!\n", __func__, cpuid);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="278" endline="342">
{
    vmi_bringup ();
    cpu_init ();
    preempt_disable ();
    smp_callin ();
    barrier ();
    check_tsc_sync_target ();
    if (nmi_watchdog == NMI_IO_APIC) {
        legacy_pic->chip->mask (0);
        enable_NMI_through_LVT0 ();
        legacy_pic->chip->unmask (0);
    }
    set_cpu_sibling_map (raw_smp_processor_id ());
    wmb ();
    ipi_call_lock ();
    lock_vector_lock ();
    set_cpu_online (smp_processor_id (), true);
    unlock_vector_lock ();
    ipi_call_unlock ();
    per_cpu (cpu_state, smp_processor_id ()) = CPU_ONLINE;
    x86_platform.nmi_init ();
    local_irq_enable ();
    boot_init_stack_canary ();
    x86_cpuinit.setup_percpu_clockev ();
    wmb ();
    cpu_idle ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="296" endline="300">
{
    legacy_pic->chip->mask (0);
    enable_NMI_through_LVT0 ();
    legacy_pic->chip->unmask (0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="356" endline="358">
{
    *dst = *src;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="367" endline="374">
{
    struct cpuinfo_x86 *c = &cpu_data (id);
    copy_cpuinfo_x86 (c, & boot_cpu_data);
    c->cpu_index = id;
    if (id != 0)
        identify_secondary_cpu (c);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="378" endline="439">
{
    int i;
    struct cpuinfo_x86 *c = &cpu_data (cpu);
    cpumask_set_cpu (cpu, cpu_sibling_setup_mask);
    if (smp_num_siblings > 1) {

        for_each_cpu (i, cpu_sibling_setup_mask) {
            struct cpuinfo_x86 *o = &cpu_data (i);
            if (c->phys_proc_id == o->phys_proc_id && c->cpu_core_id == o->cpu_core_id) {
                cpumask_set_cpu (i, cpu_sibling_mask (cpu));
                cpumask_set_cpu (cpu, cpu_sibling_mask (i));
                cpumask_set_cpu (i, cpu_core_mask (cpu));
                cpumask_set_cpu (cpu, cpu_core_mask (i));
                cpumask_set_cpu (i, c -> llc_shared_map);
                cpumask_set_cpu (cpu, o -> llc_shared_map);
            }
        }

    }
    else {
        cpumask_set_cpu (cpu, cpu_sibling_mask (cpu));
    }
    cpumask_set_cpu (cpu, c -> llc_shared_map);
    if (current_cpu_data.x86_max_cores == 1) {
        cpumask_copy (cpu_core_mask (cpu), cpu_sibling_mask (cpu));
        c->booted_cores = 1;
        return;
    }

    for_each_cpu (i, cpu_sibling_setup_mask) {
        if (per_cpu (cpu_llc_id, cpu) != BAD_APICID && per_cpu (cpu_llc_id, cpu) == per_cpu (cpu_llc_id, i)) {
            cpumask_set_cpu (i, c -> llc_shared_map);
            cpumask_set_cpu (cpu, cpu_data (i).llc_shared_map);
        }
        if (c->phys_proc_id == cpu_data (i).phys_proc_id) {
            cpumask_set_cpu (i, cpu_core_mask (cpu));
            cpumask_set_cpu (cpu, cpu_core_mask (i));
            if (cpumask_weight (cpu_sibling_mask (cpu)) == 1) {
                if (cpumask_first (cpu_sibling_mask (i)) == i)
                    c->booted_cores++;
                if (i != cpu)
                    cpu_data (i).booted_cores++;
            }
            else if (i != cpu && !c->booted_cores)
                c->booted_cores = cpu_data (i).booted_cores;
        }
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="384" endline="398">
{

    for_each_cpu (i, cpu_sibling_setup_mask) {
        struct cpuinfo_x86 *o = &cpu_data (i);
        if (c->phys_proc_id == o->phys_proc_id && c->cpu_core_id == o->cpu_core_id) {
            cpumask_set_cpu (i, cpu_sibling_mask (cpu));
            cpumask_set_cpu (cpu, cpu_sibling_mask (i));
            cpumask_set_cpu (i, cpu_core_mask (cpu));
            cpumask_set_cpu (cpu, cpu_core_mask (i));
            cpumask_set_cpu (i, c -> llc_shared_map);
            cpumask_set_cpu (cpu, o -> llc_shared_map);
        }
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="385" endline="397">
{
    struct cpuinfo_x86 *o = &cpu_data (i);
    if (c->phys_proc_id == o->phys_proc_id && c->cpu_core_id == o->cpu_core_id) {
        cpumask_set_cpu (i, cpu_sibling_mask (cpu));
        cpumask_set_cpu (cpu, cpu_sibling_mask (i));
        cpumask_set_cpu (i, cpu_core_mask (cpu));
        cpumask_set_cpu (cpu, cpu_core_mask (i));
        cpumask_set_cpu (i, c -> llc_shared_map);
        cpumask_set_cpu (cpu, o -> llc_shared_map);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="389" endline="396">
{
    cpumask_set_cpu (i, cpu_sibling_mask (cpu));
    cpumask_set_cpu (cpu, cpu_sibling_mask (i));
    cpumask_set_cpu (i, cpu_core_mask (cpu));
    cpumask_set_cpu (cpu, cpu_core_mask (i));
    cpumask_set_cpu (i, c -> llc_shared_map);
    cpumask_set_cpu (cpu, o -> llc_shared_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="398" endline="400">
{
    cpumask_set_cpu (cpu, cpu_sibling_mask (cpu));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="404" endline="408">
{
    cpumask_copy (cpu_core_mask (cpu), cpu_sibling_mask (cpu));
    c->booted_cores = 1;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="410" endline="438">
{
    if (per_cpu (cpu_llc_id, cpu) != BAD_APICID && per_cpu (cpu_llc_id, cpu) == per_cpu (cpu_llc_id, i)) {
        cpumask_set_cpu (i, c -> llc_shared_map);
        cpumask_set_cpu (cpu, cpu_data (i).llc_shared_map);
    }
    if (c->phys_proc_id == cpu_data (i).phys_proc_id) {
        cpumask_set_cpu (i, cpu_core_mask (cpu));
        cpumask_set_cpu (cpu, cpu_core_mask (i));
        if (cpumask_weight (cpu_sibling_mask (cpu)) == 1) {
            if (cpumask_first (cpu_sibling_mask (i)) == i)
                c->booted_cores++;
            if (i != cpu)
                cpu_data (i).booted_cores++;
        }
        else if (i != cpu && !c->booted_cores)
            c->booted_cores = cpu_data (i).booted_cores;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="412" endline="415">
{
    cpumask_set_cpu (i, c -> llc_shared_map);
    cpumask_set_cpu (cpu, cpu_data (i).llc_shared_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="416" endline="437">
{
    cpumask_set_cpu (i, cpu_core_mask (cpu));
    cpumask_set_cpu (cpu, cpu_core_mask (i));
    if (cpumask_weight (cpu_sibling_mask (cpu)) == 1) {
        if (cpumask_first (cpu_sibling_mask (i)) == i)
            c->booted_cores++;
        if (i != cpu)
            cpu_data (i).booted_cores++;
    }
    else if (i != cpu && !c->booted_cores)
        c->booted_cores = cpu_data (i).booted_cores;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="422" endline="435">
{
    if (cpumask_first (cpu_sibling_mask (i)) == i)
        c->booted_cores++;
    if (i != cpu)
        cpu_data (i).booted_cores++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="443" endline="454">
{
    struct cpuinfo_x86 *c = &cpu_data (cpu);
    if ((sched_mc_power_savings || sched_smt_power_savings) && !(cpu_has (c, X86_FEATURE_AMD_DCM)))
        return cpu_core_mask (cpu);
    else
        return c->llc_shared_map;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="457" endline="474">
{
    int cpu;
    unsigned long bogosum = 0;
    pr_debug ("Before bogomips.\n");
    for_each_possible_cpu (cpu)
    if (cpumask_test_cpu (cpu, cpu_callout_mask))
        bogosum += cpu_data (cpu).loops_per_jiffy;
    printk (KERN_INFO "Total of %d processors activated (%lu.%02lu BogoMIPS).\n", num_online_cpus (), bogosum / (500000 / HZ), (bogosum / (5000 / HZ)) % 100);
    pr_debug ("Before bogocount - setting activated=1.\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="477" endline="513">
{
    unsigned i, regs [] = {APIC_ID >> 4, APIC_LVR >> 4, APIC_SPIV >> 4};
    char *names [] = {"ID", "VERSION", "SPIV"};
    int timeout;
    u32 status;
    printk (KERN_INFO "Inquiring remote APIC 0x%x...\n", apicid);
    for (i = 0; i < ARRAY_SIZE (regs); i++) {
        printk (KERN_INFO "... APIC 0x%x %s: ", apicid, names [i]);
        status = safe_apic_wait_icr_idle ();
        if (status)
            printk (KERN_CONT "a previous APIC delivery may have failed\n");
        apic_icr_write (APIC_DM_REMRD | regs [i], apicid);
        timeout = 0;
        do {
            udelay (100);
            status = apic_read (APIC_ICR) & APIC_ICR_RR_MASK;
        }
        while (status == APIC_ICR_RR_INPROG && timeout++ < 1000);
        switch (status) {
        case APIC_ICR_RR_VALID :
            status = apic_read (APIC_RRR);
            printk (KERN_CONT "%08x\n", status);
            break;
        default :
            printk (KERN_CONT "failed\n");
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="485" endline="512">
{
    printk (KERN_INFO "... APIC 0x%x %s: ", apicid, names [i]);
    status = safe_apic_wait_icr_idle ();
    if (status)
        printk (KERN_CONT "a previous APIC delivery may have failed\n");
    apic_icr_write (APIC_DM_REMRD | regs [i], apicid);
    timeout = 0;
    do {
        udelay (100);
        status = apic_read (APIC_ICR) & APIC_ICR_RR_MASK;
    }
    while (status == APIC_ICR_RR_INPROG && timeout++ < 1000);
    switch (status) {
    case APIC_ICR_RR_VALID :
        status = apic_read (APIC_RRR);
        printk (KERN_CONT "%08x\n", status);
        break;
    default :
        printk (KERN_CONT "failed\n");
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="499" endline="502">
{
    udelay (100);
    status = apic_read (APIC_ICR) & APIC_ICR_RR_MASK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="504" endline="511">
{
case APIC_ICR_RR_VALID :
    status = apic_read (APIC_RRR);
    printk (KERN_CONT "%08x\n", status);
    break;
default :
    printk (KERN_CONT "failed\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="522" endline="552">
{
    unsigned long send_status, accept_status = 0;
    int maxlvt;
    apic_icr_write (APIC_DM_NMI | apic -> dest_logical, logical_apicid);
    pr_debug ("Waiting for send to finish...\n");
    send_status = safe_apic_wait_icr_idle ();
    udelay (200);
    if (APIC_INTEGRATED (apic_version[boot_cpu_physical_apicid])) {
        maxlvt = lapic_get_maxlvt ();
        if (maxlvt > 3)
            apic_write (APIC_ESR, 0);
        accept_status = (apic_read (APIC_ESR) & 0xEF);
    }
    pr_debug ("NMI sent.\n");
    if (send_status)
        printk (KERN_ERR "APIC never delivered???\n");
    if (accept_status)
        printk (KERN_ERR "APIC delivery error (%lx).\n", accept_status);
    return (send_status | accept_status);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="538" endline="543">
{
    maxlvt = lapic_get_maxlvt ();
    if (maxlvt > 3)
        apic_write (APIC_ESR, 0);
    accept_status = (apic_read (APIC_ESR) & 0xEF);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="556" endline="667">
{
    unsigned long send_status, accept_status = 0;
    int maxlvt, num_starts, j;
    maxlvt = lapic_get_maxlvt ();
    if (APIC_INTEGRATED (apic_version[phys_apicid])) {
        if (maxlvt > 3)
            apic_write (APIC_ESR, 0);
        apic_read (APIC_ESR);
    }
    pr_debug ("Asserting INIT.\n");
    apic_icr_write (APIC_INT_LEVELTRIG | APIC_INT_ASSERT | APIC_DM_INIT, phys_apicid);
    pr_debug ("Waiting for send to finish...\n");
    send_status = safe_apic_wait_icr_idle ();
    mdelay (10);
    pr_debug ("Deasserting INIT.\n");
    apic_icr_write (APIC_INT_LEVELTRIG | APIC_DM_INIT, phys_apicid);
    pr_debug ("Waiting for send to finish...\n");
    send_status = safe_apic_wait_icr_idle ();
    mb ();
    atomic_set (& init_deasserted, 1);
    if (APIC_INTEGRATED (apic_version[phys_apicid]))
        num_starts = 2;
    else
        num_starts = 0;
    startup_ipi_hook (phys_apicid, (unsigned long) start_secondary, (unsigned long) stack_start.sp);
    pr_debug ("#startup loops: %d.\n", num_starts);
    for (j = 1; j <= num_starts; j++) {
        pr_debug ("Sending STARTUP #%d.\n", j);
        if (maxlvt > 3)
            apic_write (APIC_ESR, 0);
        apic_read (APIC_ESR);
        pr_debug ("After apic_write.\n");
        apic_icr_write (APIC_DM_STARTUP | (start_eip >> 12), phys_apicid);
        udelay (300);
        pr_debug ("Startup point 1.\n");
        pr_debug ("Waiting for send to finish...\n");
        send_status = safe_apic_wait_icr_idle ();
        udelay (200);
        if (maxlvt > 3)
            apic_write (APIC_ESR, 0);
        accept_status = (apic_read (APIC_ESR) & 0xEF);
        if (send_status || accept_status)
            break;
    }
    pr_debug ("After Startup.\n");
    if (send_status)
        printk (KERN_ERR "APIC never delivered???\n");
    if (accept_status)
        printk (KERN_ERR "APIC delivery error (%lx).\n", accept_status);
    return (send_status | accept_status);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="565" endline="569">
{
    if (maxlvt > 3)
        apic_write (APIC_ESR, 0);
    apic_read (APIC_ESR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="622" endline="658">
{
    pr_debug ("Sending STARTUP #%d.\n", j);
    if (maxlvt > 3)
        apic_write (APIC_ESR, 0);
    apic_read (APIC_ESR);
    pr_debug ("After apic_write.\n");
    apic_icr_write (APIC_DM_STARTUP | (start_eip >> 12), phys_apicid);
    udelay (300);
    pr_debug ("Startup point 1.\n");
    pr_debug ("Waiting for send to finish...\n");
    send_status = safe_apic_wait_icr_idle ();
    udelay (200);
    if (maxlvt > 3)
        apic_write (APIC_ESR, 0);
    accept_status = (apic_read (APIC_ESR) & 0xEF);
    if (send_status || accept_status)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="677" endline="683">
{
    struct create_idle *c_idle = container_of (work, struct create_idle, work);
    c_idle->idle = fork_idle (c_idle->cpu);
    complete (& c_idle -> done);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="687" endline="703">
{
    static int current_node = -1;
    int node = cpu_to_node (cpu);
    if (system_state == SYSTEM_BOOTING) {
        if (node != current_node) {
            if (current_node > (-1))
                pr_cont (" Ok.\n");
            current_node = node;
            pr_info ("Booting Node %3d, Processors ", node);
        }
        pr_cont (" #%d%s", cpu, cpu == (nr_cpu_ids - 1) ? " Ok.\n" : "");
        return;
    }
    else
        pr_info ("Booting Node %d Processor %d APIC 0x%x\n", node, cpu, apicid);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="691" endline="700">
{
    if (node != current_node) {
        if (current_node > (-1))
            pr_cont (" Ok.\n");
        current_node = node;
        pr_info ("Booting Node %3d, Processors ", node);
    }
    pr_cont (" #%d%s", cpu, cpu == (nr_cpu_ids - 1) ? " Ok.\n" : "");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="692" endline="697">
{
    if (current_node > (-1))
        pr_cont (" Ok.\n");
    current_node = node;
    pr_info ("Booting Node %3d, Processors ", node);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="712" endline="863">
{
    unsigned long boot_error = 0;
    unsigned long start_ip;
    int timeout;
    struct create_idle c_idle = {
        .cpu = cpu,
        .done = COMPLETION_INITIALIZER_ONSTACK (c_idle.done),
    };
    INIT_WORK_ON_STACK (& c_idle.work, do_fork_idle);
    alternatives_smp_switch (1);
    c_idle.idle = get_idle_for_cpu (cpu);
    if (c_idle.idle) {
        c_idle.idle->thread.sp = (unsigned long) (((struct pt_regs *) (THREAD_SIZE + task_stack_page (c_idle.idle))) - 1);
        init_idle (c_idle.idle, cpu);
        goto do_rest;
    }
    if (!keventd_up () || current_is_keventd ())
        c_idle.work.func (&c_idle.work);
    else {
        schedule_work (& c_idle.work);
        wait_for_completion (& c_idle.done);
    }
    if (IS_ERR (c_idle.idle)) {
        printk ("failed fork for CPU %d\n", cpu);
        destroy_work_on_stack (& c_idle.work);
        return PTR_ERR (c_idle.idle);
    }
    set_idle_for_cpu (cpu, c_idle.idle);
do_rest :
    per_cpu (current_task, cpu) = c_idle.idle;
    clear_tsk_thread_flag (c_idle.idle, TIF_FORK);
    initial_gs = per_cpu_offset (cpu);
    per_cpu (kernel_stack, cpu) = (unsigned long) task_stack_page (c_idle.idle) - KERNEL_STACK_OFFSET + THREAD_SIZE;
    early_gdt_descr.address = (unsigned long) get_cpu_gdt_table (cpu);
    initial_code = (unsigned long) start_secondary;
    stack_start.sp = (void *) c_idle.idle->thread.sp;
    start_ip = setup_trampoline ();
    announce_cpu (cpu, apicid);
    atomic_set (& init_deasserted, 0);
    if (get_uv_system_type () != UV_NON_UNIQUE_APIC) {
        pr_debug ("Setting warm reset code and vector.\n");
        smpboot_setup_warm_reset_vector (start_ip);
        if (APIC_INTEGRATED (apic_version[boot_cpu_physical_apicid])) {
            apic_write (APIC_ESR, 0);
            apic_read (APIC_ESR);
        }
    }
    if (apic->wakeup_secondary_cpu)
        boot_error = apic->wakeup_secondary_cpu (apicid, start_ip);
    else
        boot_error = wakeup_secondary_cpu_via_init (apicid, start_ip);
    if (!boot_error) {
        pr_debug ("Before Callout %d.\n", cpu);
        cpumask_set_cpu (cpu, cpu_callout_mask);
        pr_debug ("After Callout %d.\n", cpu);
        for (timeout = 0; timeout < 50000; timeout++) {
            if (cpumask_test_cpu (cpu, cpu_callin_mask))
                break;
            udelay (100);
        }
        if (cpumask_test_cpu (cpu, cpu_callin_mask))
            pr_debug ("CPU%d: has booted.\n", cpu);
        else {
            boot_error = 1;
            if (*((volatile unsigned char *) trampoline_base) == 0xA5)
                pr_err ("CPU%d: Stuck ??\n", cpu);
            else
                pr_err ("CPU%d: Not responding.\n", cpu);
            if (apic->inquire_remote_apic)
                apic->inquire_remote_apic (apicid);
        }
    }
    if (boot_error) {
        numa_remove_cpu (cpu);
        cpumask_clear_cpu (cpu, cpu_callout_mask);
        cpumask_clear_cpu (cpu, cpu_initialized_mask);
        set_cpu_present (cpu, false);
        per_cpu (x86_cpu_to_apicid, cpu) = BAD_APICID;
    }
    *((volatile unsigned long *) trampoline_base) = 0;
    if (get_uv_system_type () != UV_NON_UNIQUE_APIC) {
        smpboot_restore_warm_reset_vector ();
    }
    destroy_work_on_stack (& c_idle.work);
    return boot_error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="731" endline="736">
{
    c_idle.idle->thread.sp = (unsigned long) (((struct pt_regs *) (THREAD_SIZE + task_stack_page (c_idle.idle))) - 1);
    init_idle (c_idle.idle, cpu);
    goto do_rest;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="740" endline="743">
{
    schedule_work (& c_idle.work);
    wait_for_completion (& c_idle.done);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="745" endline="749">
{
    printk ("failed fork for CPU %d\n", cpu);
    destroy_work_on_stack (& c_idle.work);
    return PTR_ERR (c_idle.idle);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="781" endline="793">
{
    pr_debug ("Setting warm reset code and vector.\n");
    smpboot_setup_warm_reset_vector (start_ip);
    if (APIC_INTEGRATED (apic_version[boot_cpu_physical_apicid])) {
        apic_write (APIC_ESR, 0);
        apic_read (APIC_ESR);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="789" endline="792">
{
    apic_write (APIC_ESR, 0);
    apic_read (APIC_ESR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="804" endline="835">
{
    pr_debug ("Before Callout %d.\n", cpu);
    cpumask_set_cpu (cpu, cpu_callout_mask);
    pr_debug ("After Callout %d.\n", cpu);
    for (timeout = 0; timeout < 50000; timeout++) {
        if (cpumask_test_cpu (cpu, cpu_callin_mask))
            break;
        udelay (100);
    }
    if (cpumask_test_cpu (cpu, cpu_callin_mask))
        pr_debug ("CPU%d: has booted.\n", cpu);
    else {
        boot_error = 1;
        if (*((volatile unsigned char *) trampoline_base) == 0xA5)
            pr_err ("CPU%d: Stuck ??\n", cpu);
        else
            pr_err ("CPU%d: Not responding.\n", cpu);
        if (apic->inquire_remote_apic)
            apic->inquire_remote_apic (apicid);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="815" endline="819">
{
    if (cpumask_test_cpu (cpu, cpu_callin_mask))
        break;
    udelay (100);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="823" endline="834">
{
    boot_error = 1;
    if (*((volatile unsigned char *) trampoline_base) == 0xA5)
        pr_err ("CPU%d: Stuck ??\n", cpu);
    else
        pr_err ("CPU%d: Not responding.\n", cpu);
    if (apic->inquire_remote_apic)
        apic->inquire_remote_apic (apicid);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="837" endline="849">
{
    numa_remove_cpu (cpu);
    cpumask_clear_cpu (cpu, cpu_callout_mask);
    cpumask_clear_cpu (cpu, cpu_initialized_mask);
    set_cpu_present (cpu, false);
    per_cpu (x86_cpu_to_apicid, cpu) = BAD_APICID;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="854" endline="859">
{
    smpboot_restore_warm_reset_vector ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="866" endline="930">
{
    int apicid = apic->cpu_present_to_apicid (cpu);
    unsigned long flags;
    int err;
    WARN_ON (irqs_disabled ());
    pr_debug ("++++++++++++++++++++=_---CPU UP  %u\n", cpu);
    if (apicid == BAD_APICID || apicid == boot_cpu_physical_apicid || !physid_isset (apicid, phys_cpu_present_map)) {
        printk (KERN_ERR "%s: bad cpu %d\n", __func__, cpu);
        return -EINVAL;
    }
    if (cpumask_test_cpu (cpu, cpu_callin_mask)) {
        pr_debug ("do_boot_cpu %d Already started\n", cpu);
        return -ENOSYS;
    }
    mtrr_save_state ();
    per_cpu (cpu_state, cpu) = CPU_UP_PREPARE;
    err = do_boot_cpu (apicid, cpu);
    if (err) {
        pr_debug ("do_boot_cpu failed %d\n", err);
        return -EIO;
    }
    local_irq_save (flags);
    check_tsc_sync_source (cpu);
    local_irq_restore (flags);
    while (!cpu_online (cpu)) {
        cpu_relax ();
        touch_nmi_watchdog ();
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="876" endline="879">
{
    printk (KERN_ERR "%s: bad cpu %d\n", __func__, cpu);
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="884" endline="887">
{
    pr_debug ("do_boot_cpu %d Already started\n", cpu);
    return -ENOSYS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="911" endline="914">
{
    pr_debug ("do_boot_cpu failed %d\n", err);
    return -EIO;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="924" endline="927">
{
    cpu_relax ();
    touch_nmi_watchdog ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="938" endline="950">
{
    init_cpu_present (cpumask_of (0));
    init_cpu_possible (cpumask_of (0));
    smpboot_clear_io_apic_irqs ();
    if (smp_found_config)
        physid_set_mask_of_physid (boot_cpu_physical_apicid, &phys_cpu_present_map);
    else
        physid_set_mask_of_physid (0, &phys_cpu_present_map);
    map_cpu_to_logical_apicid ();
    cpumask_set_cpu (0, cpu_sibling_mask (0));
    cpumask_set_cpu (0, cpu_core_mask (0));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="956" endline="1054">
{
    preempt_disable ();
    if (!physid_isset (hard_smp_processor_id (), phys_cpu_present_map)) {
        printk (KERN_WARNING "weird, boot CPU (#%d) not listed by the BIOS.\n", hard_smp_processor_id ());
        physid_set (hard_smp_processor_id (), phys_cpu_present_map);
    }
    if (!smp_found_config && !acpi_lapic) {
        preempt_enable ();
        printk (KERN_NOTICE "SMP motherboard not detected.\n");
        disable_smp ();
        if (APIC_init_uniprocessor ())
            printk (KERN_NOTICE "Local APIC not detected." " Using dummy APIC emulation.\n");
        return -1;
    }
    if (!apic->check_phys_apicid_present (boot_cpu_physical_apicid)) {
        printk (KERN_NOTICE "weird, boot CPU (#%d) not listed by the BIOS.\n", boot_cpu_physical_apicid);
        physid_set (hard_smp_processor_id (), phys_cpu_present_map);
    }
    preempt_enable ();
    if (APIC_INTEGRATED (apic_version[boot_cpu_physical_apicid]) && !cpu_has_apic) {
        if (!disable_apic) {
            pr_err ("BIOS bug, local APIC #%d not detected!...\n", boot_cpu_physical_apicid);
            pr_err ("... forcing use of dummy APIC emulation." "(tell your hw vendor)\n");
        }
        smpboot_clear_io_apic ();
        arch_disable_smp_support ();
        return -1;
    }
    verify_local_APIC ();
    if (!max_cpus) {
        printk (KERN_INFO "SMP mode deactivated.\n");
        smpboot_clear_io_apic ();
        localise_nmi_watchdog ();
        connect_bsp_APIC ();
        setup_local_APIC ();
        end_local_APIC_setup ();
        return -1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="986" endline="992">
{
    printk (KERN_WARNING "weird, boot CPU (#%d) not listed by the BIOS.\n", hard_smp_processor_id ());
    physid_set (hard_smp_processor_id (), phys_cpu_present_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="998" endline="1006">
{
    preempt_enable ();
    printk (KERN_NOTICE "SMP motherboard not detected.\n");
    disable_smp ();
    if (APIC_init_uniprocessor ())
        printk (KERN_NOTICE "Local APIC not detected." " Using dummy APIC emulation.\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1012" endline="1017">
{
    printk (KERN_NOTICE "weird, boot CPU (#%d) not listed by the BIOS.\n", boot_cpu_physical_apicid);
    physid_set (hard_smp_processor_id (), phys_cpu_present_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1024" endline="1034">
{
    if (!disable_apic) {
        pr_err ("BIOS bug, local APIC #%d not detected!...\n", boot_cpu_physical_apicid);
        pr_err ("... forcing use of dummy APIC emulation." "(tell your hw vendor)\n");
    }
    smpboot_clear_io_apic ();
    arch_disable_smp_support ();
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1025" endline="1030">
{
    pr_err ("BIOS bug, local APIC #%d not detected!...\n", boot_cpu_physical_apicid);
    pr_err ("... forcing use of dummy APIC emulation." "(tell your hw vendor)\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1041" endline="1051">
{
    printk (KERN_INFO "SMP mode deactivated.\n");
    smpboot_clear_io_apic ();
    localise_nmi_watchdog ();
    connect_bsp_APIC ();
    setup_local_APIC ();
    end_local_APIC_setup ();
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1057" endline="1066">
{
    int i;
    struct cpuinfo_x86 *c;

    for_each_possible_cpu (i) {
        c = &cpu_data (i);
        c->cpu_index = nr_cpu_ids;
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1061" endline="1065">
{
    c = &cpu_data (i);
    c->cpu_index = nr_cpu_ids;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1073" endline="1148">
{
    unsigned int i;
    preempt_disable ();
    smp_cpu_index_default ();
    current_cpu_data = boot_cpu_data;
    cpumask_copy (cpu_callin_mask, cpumask_of (0));
    mb ();
    smp_store_cpu_info (0);
    current_thread_info ()->cpu = 0;

    for_each_possible_cpu (i) {
        zalloc_cpumask_var (& per_cpu (cpu_sibling_map, i), GFP_KERNEL);
        zalloc_cpumask_var (& per_cpu (cpu_core_map, i), GFP_KERNEL);
        zalloc_cpumask_var (& cpu_data (i).llc_shared_map, GFP_KERNEL);
    }

    set_cpu_sibling_map (0);
    enable_IR_x2apic ();
    default_setup_apic_routing ();
    if (smp_sanity_check (max_cpus) < 0) {
        printk (KERN_INFO "SMP disabled\n");
        disable_smp ();
        goto out;
    }
    preempt_disable ();
    if (read_apic_id () != boot_cpu_physical_apicid) {
        panic ("Boot APIC ID in local APIC unexpected (%d vs %d)", read_apic_id (), boot_cpu_physical_apicid);
    }
    preempt_enable ();
    connect_bsp_APIC ();
    setup_local_APIC ();
    if (!skip_ioapic_setup && nr_ioapics)
        enable_IO_APIC ();
    end_local_APIC_setup ();
    map_cpu_to_logical_apicid ();
    if (apic->setup_portio_remap)
        apic->setup_portio_remap ();
    smpboot_setup_io_apic ();
    printk (KERN_INFO "CPU%d: ", 0);
    print_cpu_info (& cpu_data (0));
    x86_init.timers.setup_percpu_clockev ();
    if (is_uv_system ())
        uv_system_init ();
    set_mtrr_aps_delayed_init ();
out :
    preempt_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1089" endline="1093">
{
    zalloc_cpumask_var (& per_cpu (cpu_sibling_map, i), GFP_KERNEL);
    zalloc_cpumask_var (& per_cpu (cpu_core_map, i), GFP_KERNEL);
    zalloc_cpumask_var (& cpu_data (i).llc_shared_map, GFP_KERNEL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1099" endline="1103">
{
    printk (KERN_INFO "SMP disabled\n");
    disable_smp ();
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1106" endline="1110">
{
    panic ("Boot APIC ID in local APIC unexpected (%d vs %d)", read_apic_id (), boot_cpu_physical_apicid);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1151" endline="1153">
{
    set_mtrr_aps_delayed_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1156" endline="1158">
{
    mtrr_aps_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1164" endline="1170">
{
    int me = smp_processor_id ();
    switch_to_new_gdt (me);
    cpumask_set_cpu (me, cpu_callout_mask);
    per_cpu (cpu_state, me) = CPU_ONLINE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1173" endline="1182">
{
    pr_debug ("Boot done.\n");
    impress_friends ();
    check_nmi_watchdog ();
    mtrr_aps_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1186" endline="1189">
{
    get_option (& str, & setup_possible_cpus);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1211" endline="1240">
{
    int i, possible;
    if (!num_processors)
        num_processors = 1;
    if (setup_possible_cpus == -1)
        possible = num_processors + disabled_cpus;
    else
        possible = setup_possible_cpus;
    total_cpus = max_t (int, possible, num_processors +disabled_cpus);
    if (possible > nr_cpu_ids) {
        printk (KERN_WARNING "%d Processors exceeds NR_CPUS limit of %d\n", possible, nr_cpu_ids);
        possible = nr_cpu_ids;
    }
    printk (KERN_INFO "SMP: Allowing %d CPUs, %d hotplug CPUs\n", possible, max_t (int, possible - num_processors, 0));
    for (i = 0; i < possible; i++)
        set_cpu_possible (i, true);
    nr_cpu_ids = possible;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1226" endline="1231">
{
    printk (KERN_WARNING "%d Processors exceeds NR_CPUS limit of %d\n", possible, nr_cpu_ids);
    possible = nr_cpu_ids;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1359" endline="1361">
{
    return -ENOSYS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1364" endline="1367">
{
    BUG ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/smpboot.c.ifdefed" startline="1370" endline="1372">
{
    BUG ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/test_nx.c.ifdefed" startline="46" endline="63">
{
    struct module *mod = THIS_MODULE;
    struct exception_table_entry *extable;
    if (mod->num_exentries > 1) {
        printk (KERN_ERR "test_nx: too many exception table entries!\n");
        printk (KERN_ERR "test_nx: test results are not reliable.\n");
        return;
    }
    extable = (struct exception_table_entry *) mod->extable;
    extable[0].insn = (unsigned long) new;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/test_nx.c.ifdefed" startline="56" endline="60">
{
    printk (KERN_ERR "test_nx: too many exception table entries!\n");
    printk (KERN_ERR "test_nx: test results are not reliable.\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/test_nx.c.ifdefed" startline="81" endline="105">
{
    unsigned long result;
    fudze_exception_table (& foo_label, address);
    result = 1;
    asm volatile ("foo_label:\n"
        "0:	call *%[fake_code]\n"
        "1:\n"
        ".section .fixup,\"ax\"\n"
        "2:	mov %[zero], %[rslt]\n"
        "	ret\n"
        ".previous\n"
        _ASM_EXTABLE (0b, 2b)
        : [rslt] "=r" (result)
        : [fake_code] "r" (address), [zero] "r" (0UL), "0" (result)
    ) fudze_exception_table (address, & foo_label);
    if (result)
        return -ENODEV;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/test_nx.c.ifdefed" startline="110" endline="165">
{
    int ret = 0;
    char stackcode [] = {0xC3, 0x90, 0};
    char *heap;
    test_data = 0xC3;
    printk (KERN_INFO "Testing NX protection\n");
    if (test_address (&stackcode)) {
        printk (KERN_ERR "test_nx: stack was executable\n");
        ret = -ENODEV;
    }
    heap = kmalloc (64, GFP_KERNEL);
    if (!heap)
        return -ENOMEM;
    heap[0] = 0xC3;
    if (test_address (heap)) {
        printk (KERN_ERR "test_nx: heap was executable\n");
        ret = -ENODEV;
    }
    kfree (heap);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/test_nx.c.ifdefed" startline="121" endline="124">
{
    printk (KERN_ERR "test_nx: stack was executable\n");
    ret = -ENODEV;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/test_nx.c.ifdefed" startline="133" endline="136">
{
    printk (KERN_ERR "test_nx: heap was executable\n");
    ret = -ENODEV;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/test_nx.c.ifdefed" startline="168" endline="169">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="27" endline="57">
{
    char c;
    int i, k, j;
    while ((c = *str++) != '\0' && n-- > 0) {
        if (current_ypos >= max_ypos) {
            for (k = 1, j = 0; k < max_ypos; k++, j++) {
                for (i = 0; i < max_xpos; i++) {
                    writew (readw (VGABASE + 2 * (max_xpos * k + i)), VGABASE + 2 * (max_xpos * j + i));
                }
            }
            for (i = 0; i < max_xpos; i++)
                writew (0x720, VGABASE +2 * (max_xpos * j + i));
            current_ypos = max_ypos - 1;
        }
        if (c == '\n') {
            current_xpos = 0;
            current_ypos++;
        }
        else if (c != '\r') {
            writew (((0x7 << 8) | (unsigned short) c), VGABASE + 2 * (max_xpos * current_ypos + current_xpos ++));
            if (current_xpos >= max_xpos) {
                current_xpos = 0;
                current_ypos++;
            }
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="31" endline="56">
{
    if (current_ypos >= max_ypos) {
        for (k = 1, j = 0; k < max_ypos; k++, j++) {
            for (i = 0; i < max_xpos; i++) {
                writew (readw (VGABASE + 2 * (max_xpos * k + i)), VGABASE + 2 * (max_xpos * j + i));
            }
        }
        for (i = 0; i < max_xpos; i++)
            writew (0x720, VGABASE +2 * (max_xpos * j + i));
        current_ypos = max_ypos - 1;
    }
    if (c == '\n') {
        current_xpos = 0;
        current_ypos++;
    }
    else if (c != '\r') {
        writew (((0x7 << 8) | (unsigned short) c), VGABASE + 2 * (max_xpos * current_ypos + current_xpos ++));
        if (current_xpos >= max_xpos) {
            current_xpos = 0;
            current_ypos++;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="32" endline="43">
{
    for (k = 1, j = 0; k < max_ypos; k++, j++) {
        for (i = 0; i < max_xpos; i++) {
            writew (readw (VGABASE + 2 * (max_xpos * k + i)), VGABASE + 2 * (max_xpos * j + i));
        }
    }
    for (i = 0; i < max_xpos; i++)
        writew (0x720, VGABASE +2 * (max_xpos * j + i));
    current_ypos = max_ypos - 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="34" endline="39">
{
    for (i = 0; i < max_xpos; i++) {
        writew (readw (VGABASE + 2 * (max_xpos * k + i)), VGABASE + 2 * (max_xpos * j + i));
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="35" endline="38">
{
    writew (readw (VGABASE + 2 * (max_xpos * k + i)), VGABASE + 2 * (max_xpos * j + i));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="44" endline="47">
{
    current_xpos = 0;
    current_ypos++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="47" endline="55">
{
    writew (((0x7 << 8) | (unsigned short) c), VGABASE + 2 * (max_xpos * current_ypos + current_xpos ++));
    if (current_xpos >= max_xpos) {
        current_xpos = 0;
        current_ypos++;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="51" endline="54">
{
    current_xpos = 0;
    current_ypos++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="87" endline="94">
{
    unsigned timeout = 0xffff;
    while ((inb (early_serial_base +LSR) & XMTRDY) == 0 && --timeout)
        cpu_relax ();
    outb (ch, early_serial_base + TXR);
    return timeout ? 0 : -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="97" endline="104">
{
    while (*s && n-- > 0) {
        if (*s == '\n')
            early_serial_putc ('\r');
        early_serial_putc (*s);
        s++;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="98" endline="103">
{
    if (*s == '\n')
        early_serial_putc ('\r');
    early_serial_putc (*s);
    s++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="109" endline="154">
{
    unsigned char c;
    unsigned divisor;
    unsigned baud = DEFAULT_BAUD;
    char *e;
    if (*s == ',')
        ++s;
    if (*s) {
        unsigned port;
        if (!strncmp (s, "0x", 2)) {
            early_serial_base = simple_strtoul (s, &e, 16);
        }
        else {
            static const int __initconst bases [] = {0x3f8, 0x2f8};
            if (!strncmp (s, "ttyS", 4))
                s += 4;
            port = simple_strtoul (s, &e, 10);
            if (port > 1 || s == e)
                port = 0;
            early_serial_base = bases[port];
        }
        s += strcspn (s, ",");
        if (*s == ',')
            s++;
    }
    outb (0x3, early_serial_base + LCR);
    outb (0, early_serial_base + IER);
    outb (0, early_serial_base + FCR);
    outb (0x3, early_serial_base + MCR);
    if (*s) {
        baud = simple_strtoul (s, &e, 0);
        if (baud == 0 || s == e)
            baud = DEFAULT_BAUD;
    }
    divisor = 115200 / baud;
    c = inb (early_serial_base +LCR);
    outb (c | DLAB, early_serial_base + LCR);
    outb (divisor & 0xff, early_serial_base + DLL);
    outb ((divisor >> 8) & 0xff, early_serial_base + DLH);
    outb (c & ~ DLAB, early_serial_base + LCR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="118" endline="135">
{
    unsigned port;
    if (!strncmp (s, "0x", 2)) {
        early_serial_base = simple_strtoul (s, &e, 16);
    }
    else {
        static const int __initconst bases [] = {0x3f8, 0x2f8};
        if (!strncmp (s, "ttyS", 4))
            s += 4;
        port = simple_strtoul (s, &e, 10);
        if (port > 1 || s == e)
            port = 0;
        early_serial_base = bases[port];
    }
    s += strcspn (s, ",");
    if (*s == ',')
        s++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="120" endline="122">
{
    early_serial_base = simple_strtoul (s, &e, 16);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="122" endline="131">
{
    static const int __initconst bases [] = {0x3f8, 0x2f8};
    if (!strncmp (s, "ttyS", 4))
        s += 4;
    port = simple_strtoul (s, &e, 10);
    if (port > 1 || s == e)
        port = 0;
    early_serial_base = bases[port];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="142" endline="146">
{
    baud = simple_strtoul (s, &e, 0);
    if (baud == 0 || s == e)
        baud = DEFAULT_BAUD;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="168" endline="177">
{
    char buf [512];
    int n;
    va_list ap;
    va_start (ap, fmt);
    n = vscnprintf (buf, sizeof (buf), fmt, ap);
    early_console->write (early_console, buf, n);
    va_end (ap);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="180" endline="192">
{
    if (early_console->index != -1) {
        printk (KERN_CRIT "ERROR: earlyprintk= %s already used\n", con -> name);
        return;
    }
    early_console = con;
    if (keep_early)
        early_console->flags &= ~CON_BOOT;
    else
        early_console->flags |= CON_BOOT;
    register_console (early_console);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="181" endline="185">
{
    printk (KERN_CRIT "ERROR: earlyprintk= %s already used\n", con -> name);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="195" endline="237">
{
    int keep;
    if (!buf)
        return 0;
    if (early_console_initialized)
        return 0;
    early_console_initialized = 1;
    keep = (strstr (buf, "keep") != NULL);
    while (*buf != '\0') {
        if (!strncmp (buf, "serial", 6)) {
            buf += 6;
            early_serial_init (buf);
            early_console_register (& early_serial_console, keep);
            if (!strncmp (buf, ",ttyS", 5))
                buf += 5;
        }
        if (!strncmp (buf, "ttyS", 4)) {
            early_serial_init (buf + 4);
            early_console_register (& early_serial_console, keep);
        }
        if (!strncmp (buf, "vga", 3) && boot_params.screen_info.orig_video_isVGA == 1) {
            max_xpos = boot_params.screen_info.orig_video_cols;
            max_ypos = boot_params.screen_info.orig_video_lines;
            current_ypos = boot_params.screen_info.orig_y;
            early_console_register (& early_vga_console, keep);
        }
        buf++;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="207" endline="235">
{
    if (!strncmp (buf, "serial", 6)) {
        buf += 6;
        early_serial_init (buf);
        early_console_register (& early_serial_console, keep);
        if (!strncmp (buf, ",ttyS", 5))
            buf += 5;
    }
    if (!strncmp (buf, "ttyS", 4)) {
        early_serial_init (buf + 4);
        early_console_register (& early_serial_console, keep);
    }
    if (!strncmp (buf, "vga", 3) && boot_params.screen_info.orig_video_isVGA == 1) {
        max_xpos = boot_params.screen_info.orig_video_cols;
        max_ypos = boot_params.screen_info.orig_video_lines;
        current_ypos = boot_params.screen_info.orig_y;
        early_console_register (& early_vga_console, keep);
    }
    buf++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="208" endline="214">
{
    buf += 6;
    early_serial_init (buf);
    early_console_register (& early_serial_console, keep);
    if (!strncmp (buf, ",ttyS", 5))
        buf += 5;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="215" endline="218">
{
    early_serial_init (buf + 4);
    early_console_register (& early_serial_console, keep);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early_printk.c.ifdefed" startline="220" endline="225">
{
    max_xpos = boot_params.screen_info.orig_video_cols;
    max_ypos = boot_params.screen_info.orig_video_lines;
    current_ypos = boot_params.screen_info.orig_y;
    early_console_register (& early_vga_console, keep);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="10" endline="48">
{
    unsigned long addr, seg;
    addr = regs->ip;
    seg = regs->cs & 0xffff;
    if (v8086_mode (regs)) {
        addr = (addr & 0xffff) + (seg << 4);
        return addr;
    }
    if ((seg & SEGMENT_TI_MASK) == SEGMENT_LDT) {
        struct desc_struct *desc;
        unsigned long base;
        seg &= ~7UL;
        mutex_lock (& child -> mm -> context.lock);
        if (unlikely ((seg >> 3) >= child->mm->context.size))
            addr = -1L;
        else {
            desc = child->mm->context.ldt + seg;
            base = get_desc_base (desc);
            if (!desc->d)
                addr &= 0xffff;
            addr += base;
        }
        mutex_unlock (& child -> mm -> context.lock);
    }
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="15" endline="18">
{
    addr = (addr & 0xffff) + (seg << 4);
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="26" endline="45">
{
    struct desc_struct *desc;
    unsigned long base;
    seg &= ~7UL;
    mutex_lock (& child -> mm -> context.lock);
    if (unlikely ((seg >> 3) >= child->mm->context.size))
        addr = -1L;
    else {
        desc = child->mm->context.ldt + seg;
        base = get_desc_base (desc);
        if (!desc->d)
            addr &= 0xffff;
        addr += base;
    }
    mutex_unlock (& child -> mm -> context.lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="35" endline="43">
{
    desc = child->mm->context.ldt + seg;
    base = get_desc_base (desc);
    if (!desc->d)
        addr &= 0xffff;
    addr += base;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="51" endline="99">
{
    int i, copied;
    unsigned char opcode [15];
    unsigned long addr = convert_ip_to_linear (child, regs);
    copied = access_process_vm (child, addr, opcode, sizeof (opcode), 0);
    for (i = 0; i < copied; i++) {
        switch (opcode[i]) {
        case 0x9d :
        case 0xcf :
            return 1;
        case 0x66 :
        case 0x67 :
            continue;
        case 0x26 :
        case 0x2e :
        case 0x36 :
        case 0x3e :
        case 0x64 :
        case 0x65 :
        case 0xf0 :
        case 0xf2 :
        case 0xf3 :
            continue;
        case 0x9c :
        default :
            return 0;
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="57" endline="97">
{
    switch (opcode[i]) {
    case 0x9d :
    case 0xcf :
        return 1;
    case 0x66 :
    case 0x67 :
        continue;
    case 0x26 :
    case 0x2e :
    case 0x36 :
    case 0x3e :
    case 0x64 :
    case 0x65 :
    case 0xf0 :
    case 0xf2 :
    case 0xf3 :
        continue;
    case 0x9c :
    default :
        return 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="58" endline="96">
{
case 0x9d :
case 0xcf :
    return 1;
case 0x66 :
case 0x67 :
    continue;
case 0x26 :
case 0x2e :
case 0x36 :
case 0x3e :
case 0x64 :
case 0x65 :
case 0xf0 :
case 0xf2 :
case 0xf3 :
    continue;
case 0x9c :
default :
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="105" endline="158">
{
    struct pt_regs *regs = task_pt_regs (child);
    unsigned long oflags;
    if (unlikely (test_tsk_thread_flag (child, TIF_SINGLESTEP)))
        regs->flags |= X86_EFLAGS_TF;
    set_tsk_thread_flag (child, TIF_SINGLESTEP);
    oflags = regs->flags;
    regs->flags |= X86_EFLAGS_TF;
    if (is_setting_trap_flag (child, regs)) {
        clear_tsk_thread_flag (child, TIF_FORCED_TF);
        return 0;
    }
    if (oflags & X86_EFLAGS_TF)
        return test_tsk_thread_flag (child, TIF_FORCED_TF);
    set_tsk_thread_flag (child, TIF_FORCED_TF);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="143" endline="146">
{
    clear_tsk_thread_flag (child, TIF_FORCED_TF);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="164" endline="174">
{
    if (child->thread.debugctlmsr == val)
        return;
    child->thread.debugctlmsr = val;
    if (child != current)
        return;
    update_debugctlmsr (val);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="180" endline="199">
{
    if (enable_single_step (child) && block) {
        set_tsk_thread_flag (child, TIF_DEBUGCTLMSR);
        write_debugctlmsr (child, child -> thread.debugctlmsr | DEBUGCTLMSR_BTF);
    }
    else {
        write_debugctlmsr (child, child -> thread.debugctlmsr & ~ DEBUGCTLMSR_BTF);
        if (!child->thread.debugctlmsr)
            clear_tsk_thread_flag (child, TIF_DEBUGCTLMSR);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="188" endline="192">
{
    set_tsk_thread_flag (child, TIF_DEBUGCTLMSR);
    write_debugctlmsr (child, child -> thread.debugctlmsr | DEBUGCTLMSR_BTF);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="192" endline="198">
{
    write_debugctlmsr (child, child -> thread.debugctlmsr & ~ DEBUGCTLMSR_BTF);
    if (!child->thread.debugctlmsr)
        clear_tsk_thread_flag (child, TIF_DEBUGCTLMSR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="202" endline="204">
{
    enable_step (child, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="207" endline="209">
{
    enable_step (child, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/step.c.ifdefed" startline="212" endline="228">
{
    write_debugctlmsr (child, child -> thread.debugctlmsr & ~ DEBUGCTLMSR_BTF);
    if (!child->thread.debugctlmsr)
        clear_tsk_thread_flag (child, TIF_DEBUGCTLMSR);
    clear_tsk_thread_flag (child, TIF_SINGLESTEP);
    if (test_and_clear_tsk_thread_flag (child, TIF_FORCED_TF))
        task_pt_regs (child)->flags &= ~X86_EFLAGS_TF;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="63" endline="65">
{
    atomic_notifier_chain_register (& idle_notifier, n);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="69" endline="71">
{
    atomic_notifier_chain_unregister (& idle_notifier, n);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="75" endline="78">
{
    percpu_write (is_idle, 1);
    atomic_notifier_call_chain (& idle_notifier, IDLE_START, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="81" endline="85">
{
    if (x86_test_and_clear_bit_percpu (0, is_idle) == 0)
        return;
    atomic_notifier_call_chain (& idle_notifier, IDLE_END, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="89" endline="94">
{
    if (current->pid)
        return;
    __exit_idle ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="98" endline="100">
{
    BUG ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="110" endline="153">
{
    current_thread_info ()->status |= TS_POLLING;
    boot_init_stack_canary ();
    while (1) {
        tick_nohz_stop_sched_tick (1);
        while (!need_resched ()) {
            rmb ();
            if (cpu_is_offline (smp_processor_id ()))
                play_dead ();
            local_irq_disable ();
            enter_idle ();
            stop_critical_timings ();
            pm_idle ();
            start_critical_timings ();
            __exit_idle ();
        }
        tick_nohz_restart_sched_tick ();
        preempt_enable_no_resched ();
        schedule ();
        preempt_disable ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="123" endline="152">
{
    tick_nohz_stop_sched_tick (1);
    while (!need_resched ()) {
        rmb ();
        if (cpu_is_offline (smp_processor_id ()))
            play_dead ();
        local_irq_disable ();
        enter_idle ();
        stop_critical_timings ();
        pm_idle ();
        start_critical_timings ();
        __exit_idle ();
    }
    tick_nohz_restart_sched_tick ();
    preempt_enable_no_resched ();
    schedule ();
    preempt_disable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="125" endline="146">
{
    rmb ();
    if (cpu_is_offline (smp_processor_id ()))
        play_dead ();
    local_irq_disable ();
    enter_idle ();
    stop_critical_timings ();
    pm_idle ();
    start_critical_timings ();
    __exit_idle ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="157" endline="212">
{
    unsigned long cr0 = 0L, cr2 = 0L, cr3 = 0L, cr4 = 0L, fs, gs, shadowgs;
    unsigned long d0, d1, d2, d3, d6, d7;
    unsigned int fsindex, gsindex;
    unsigned int ds, cs, es;
    show_regs_common ();
    printk (KERN_DEFAULT "RIP: %04lx:[<%016lx>] ", regs -> cs & 0xffff, regs -> ip);
    printk_address (regs -> ip, 1);
    printk (KERN_DEFAULT "RSP: %04lx:%016lx  EFLAGS: %08lx\n", regs -> ss, regs -> sp, regs -> flags);
    printk (KERN_DEFAULT "RAX: %016lx RBX: %016lx RCX: %016lx\n", regs -> ax, regs -> bx, regs -> cx);
    printk (KERN_DEFAULT "RDX: %016lx RSI: %016lx RDI: %016lx\n", regs -> dx, regs -> si, regs -> di);
    printk (KERN_DEFAULT "RBP: %016lx R08: %016lx R09: %016lx\n", regs -> bp, regs -> r8, regs -> r9);
    printk (KERN_DEFAULT "R10: %016lx R11: %016lx R12: %016lx\n", regs -> r10, regs -> r11, regs -> r12);
    printk (KERN_DEFAULT "R13: %016lx R14: %016lx R15: %016lx\n", regs -> r13, regs -> r14, regs -> r15);
    asm ("movl %%ds,%0"
        : "=r" (ds)
    ) asm ("movl %%cs,%0"
        : "=r" (cs)
    ) asm ("movl %%es,%0"
        : "=r" (es)
    ) asm ("movl %%fs,%0"
        : "=r" (fsindex)
    ) asm ("movl %%gs,%0"
        : "=r" (gsindex)
    ) rdmsrl (MSR_FS_BASE, fs);
    rdmsrl (MSR_GS_BASE, gs);
    rdmsrl (MSR_KERNEL_GS_BASE, shadowgs);
    if (!all)
        return;
    cr0 = read_cr0 ();
    cr2 = read_cr2 ();
    cr3 = read_cr3 ();
    cr4 = read_cr4 ();
    printk (KERN_DEFAULT "FS:  %016lx(%04x) GS:%016lx(%04x) knlGS:%016lx\n", fs, fsindex, gs, gsindex, shadowgs);
    printk (KERN_DEFAULT "CS:  %04x DS: %04x ES: %04x CR0: %016lx\n", cs, ds, es, cr0);
    printk (KERN_DEFAULT "CR2: %016lx CR3: %016lx CR4: %016lx\n", cr2, cr3, cr4);
    get_debugreg (d0, 0);
    get_debugreg (d1, 1);
    get_debugreg (d2, 2);
    printk (KERN_DEFAULT "DR0: %016lx DR1: %016lx DR2: %016lx\n", d0, d1, d2);
    get_debugreg (d3, 3);
    get_debugreg (d6, 6);
    get_debugreg (d7, 7);
    printk (KERN_DEFAULT "DR3: %016lx DR6: %016lx DR7: %016lx\n", d3, d6, d7);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="215" endline="225">
{
    if (dead_task->mm) {
        if (dead_task->mm->context.size) {
            printk ("WARNING: dead process %8s still has LDT? <%p/%d>\n", dead_task -> comm, dead_task -> mm -> context.ldt, dead_task -> mm -> context.size);
            BUG ();
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="216" endline="224">
{
    if (dead_task->mm->context.size) {
        printk ("WARNING: dead process %8s still has LDT? <%p/%d>\n", dead_task -> comm, dead_task -> mm -> context.ldt, dead_task -> mm -> context.size);
        BUG ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="217" endline="223">
{
    printk ("WARNING: dead process %8s still has LDT? <%p/%d>\n", dead_task -> comm, dead_task -> mm -> context.ldt, dead_task -> mm -> context.size);
    BUG ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="228" endline="239">
{
    struct user_desc ud = {
        .base_addr = addr,
        .limit = 0xfffff,
        .seg_32bit = 1,
        .limit_in_pages = 1,
        .useable = 1,
    };
    struct desc_struct *desc = t->thread.tls_array;
    desc += tls;
    fill_ldt (desc, & ud);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="242" endline="244">
{
    return get_desc_base (&t->thread.tls_array[tls]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="251" endline="253">
{
    unlazy_fpu (tsk);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="258" endline="331">
{
    int err;
    struct pt_regs *childregs;
    struct task_struct *me = current;
    childregs = ((struct pt_regs *) (THREAD_SIZE + task_stack_page (p))) - 1;
    *childregs = *regs;
    childregs->ax = 0;
    if (user_mode (regs))
        childregs->sp = sp;
    else
        childregs->sp = (unsigned long) childregs;
    p->thread.sp = (unsigned long) childregs;
    p->thread.sp0 = (unsigned long) (childregs + 1);
    p->thread.usersp = me->thread.usersp;
    set_tsk_thread_flag (p, TIF_FORK);
    p->thread.io_bitmap_ptr = NULL;
    savesegment (gs, p -> thread.gsindex);
    p->thread.gs = p->thread.gsindex ? 0 : me->thread.gs;
    savesegment (fs, p -> thread.fsindex);
    p->thread.fs = p->thread.fsindex ? 0 : me->thread.fs;
    savesegment (es, p -> thread.es);
    savesegment (ds, p -> thread.ds);
    err = -ENOMEM;
    memset (p -> thread.ptrace_bps, 0, sizeof (p -> thread.ptrace_bps));
    if (unlikely (test_tsk_thread_flag (me, TIF_IO_BITMAP))) {
        p->thread.io_bitmap_ptr = kmalloc (IO_BITMAP_BYTES, GFP_KERNEL);
        if (!p->thread.io_bitmap_ptr) {
            p->thread.io_bitmap_max = 0;
            return -ENOMEM;
        }
        memcpy (p -> thread.io_bitmap_ptr, me -> thread.io_bitmap_ptr, IO_BITMAP_BYTES);
        set_tsk_thread_flag (p, TIF_IO_BITMAP);
    }
    if (clone_flags & CLONE_SETTLS) {
        err = do_arch_prctl (p, ARCH_SET_FS, childregs->r8);
        if (err)
            goto out;
    }
    clear_tsk_thread_flag (p, TIF_DS_AREA_MSR);
    p->thread.ds_ctx = NULL;
    clear_tsk_thread_flag (p, TIF_DEBUGCTLMSR);
    p->thread.debugctlmsr = 0;
    err = 0;
out :
    if (err && p->thread.io_bitmap_ptr) {
        kfree (p -> thread.io_bitmap_ptr);
        p->thread.io_bitmap_max = 0;
    }
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="291" endline="300">
{
    p->thread.io_bitmap_ptr = kmalloc (IO_BITMAP_BYTES, GFP_KERNEL);
    if (!p->thread.io_bitmap_ptr) {
        p->thread.io_bitmap_max = 0;
        return -ENOMEM;
    }
    memcpy (p -> thread.io_bitmap_ptr, me -> thread.io_bitmap_ptr, IO_BITMAP_BYTES);
    set_tsk_thread_flag (p, TIF_IO_BITMAP);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="293" endline="296">
{
    p->thread.io_bitmap_max = 0;
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="305" endline="315">
{
    err = do_arch_prctl (p, ARCH_SET_FS, childregs->r8);
    if (err)
        goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="325" endline="328">
{
    kfree (p -> thread.io_bitmap_ptr);
    p->thread.io_bitmap_max = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="337" endline="353">
{
    loadsegment (fs, 0);
    loadsegment (es, _ds);
    loadsegment (ds, _ds);
    load_gs_index (0);
    regs->ip = new_ip;
    regs->sp = new_sp;
    percpu_write (old_rsp, new_sp);
    regs->cs = _cs;
    regs->ss = _ss;
    regs->flags = X86_EFLAGS_IF;
    set_fs (USER_DS);
    free_thread_xstate (current);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="357" endline="360">
{
    start_thread_common (regs, new_ip, new_sp, __USER_CS, __USER_DS, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="382" endline="502">
{
    struct thread_struct *prev = &prev_p->thread;
    struct thread_struct *next = &next_p->thread;
    int cpu = smp_processor_id ();
    struct tss_struct *tss = &per_cpu (init_tss, cpu);
    unsigned fsindex, gsindex;
    bool preload_fpu;
    preload_fpu = tsk_used_math (next_p) && next_p->fpu_counter > 5;
    if (preload_fpu)
        prefetch (next->xstate);
    load_sp0 (tss, next);
    savesegment (es, prev -> es);
    if (unlikely (next->es | prev->es))
        loadsegment (es, next->es);
    savesegment (ds, prev -> ds);
    if (unlikely (next->ds | prev->ds))
        loadsegment (ds, next->ds);
    savesegment (fs, fsindex);
    savesegment (gs, gsindex);
    load_TLS (next, cpu);
    unlazy_fpu (prev_p);
    if (preload_fpu)
        clts ();
    arch_end_context_switch (next_p);
    if (unlikely (fsindex | next->fsindex | prev->fs)) {
        loadsegment (fs, next -> fsindex);
        if (fsindex)
            prev->fs = 0;
    }
    if (next->fs)
        wrmsrl (MSR_FS_BASE, next->fs);
    prev->fsindex = fsindex;
    if (unlikely (gsindex | next->gsindex | prev->gs)) {
        load_gs_index (next -> gsindex);
        if (gsindex)
            prev->gs = 0;
    }
    if (next->gs)
        wrmsrl (MSR_KERNEL_GS_BASE, next->gs);
    prev->gsindex = gsindex;
    prev->usersp = percpu_read (old_rsp);
    percpu_write (old_rsp, next -> usersp);
    percpu_write (current_task, next_p);
    percpu_write (kernel_stack, (unsigned long) task_stack_page (next_p) + THREAD_SIZE - KERNEL_STACK_OFFSET);
    if (unlikely (task_thread_info (next_p)->flags & _TIF_WORK_CTXSW_NEXT || task_thread_info (prev_p)->flags & _TIF_WORK_CTXSW_PREV))
        __switch_to_xtra (prev_p, next_p, tss);
    if (preload_fpu)
        __math_state_restore ();
    return prev_p;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="452" endline="461">
{
    loadsegment (fs, next -> fsindex);
    if (fsindex)
        prev->fs = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="467" endline="471">
{
    load_gs_index (next -> gsindex);
    if (gsindex)
        prev->gs = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="505" endline="516">
{
    clear_thread_flag (TIF_IA32);
    current->personality &= ~READ_IMPLIES_EXEC;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="519" endline="528">
{
    set_thread_flag (TIF_IA32);
    current->personality |= force_personality32;
    current_thread_info ()->status |= TS_COMPAT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="531" endline="552">
{
    unsigned long stack;
    u64 fp, ip;
    int count = 0;
    if (!p || p == current || p->state == TASK_RUNNING)
        return 0;
    stack = (unsigned long) task_stack_page (p);
    if (p->thread.sp < stack || p->thread.sp >= stack + THREAD_SIZE)
        return 0;
    fp = *(u64*) (p->thread.sp);
    do {
        if (fp < (unsigned long) stack || fp >= (unsigned long) stack + THREAD_SIZE)
            return 0;
        ip = *(u64*) (fp + 8);
        if (!in_sched_functions (ip))
            return ip;
        fp = *(u64*) fp;
    }
    while (count++ < 16);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="542" endline="550">
{
    if (fp < (unsigned long) stack || fp >= (unsigned long) stack + THREAD_SIZE)
        return 0;
    ip = *(u64*) (fp + 8);
    if (!in_sched_functions (ip))
        return ip;
    fp = *(u64*) fp;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="555" endline="647">
{
    int ret = 0;
    int doit = task == current;
    int cpu;
    switch (code) {
    case ARCH_SET_GS :
        if (addr >= TASK_SIZE_OF (task))
            return -EPERM;
        cpu = get_cpu ();
        if (addr <= 0xffffffff) {
            set_32bit_tls (task, GS_TLS, addr);
            if (doit) {
                load_TLS (& task -> thread, cpu);
                load_gs_index (GS_TLS_SEL);
            }
            task->thread.gsindex = GS_TLS_SEL;
            task->thread.gs = 0;
        }
        else {
            task->thread.gsindex = 0;
            task->thread.gs = addr;
            if (doit) {
                load_gs_index (0);
                ret = checking_wrmsrl (MSR_KERNEL_GS_BASE, addr);
            }
        }
        put_cpu ();
        break;
    case ARCH_SET_FS :
        if (addr >= TASK_SIZE_OF (task))
            return -EPERM;
        cpu = get_cpu ();
        if (addr <= 0xffffffff) {
            set_32bit_tls (task, FS_TLS, addr);
            if (doit) {
                load_TLS (& task -> thread, cpu);
                loadsegment (fs, FS_TLS_SEL);
            }
            task->thread.fsindex = FS_TLS_SEL;
            task->thread.fs = 0;
        }
        else {
            task->thread.fsindex = 0;
            task->thread.fs = addr;
            if (doit) {
                loadsegment (fs, 0);
                ret = checking_wrmsrl (MSR_FS_BASE, addr);
            }
        }
        put_cpu ();
        break;
    case ARCH_GET_FS :
        {
            unsigned long base;
            if (task->thread.fsindex == FS_TLS_SEL)
                base = read_32bit_tls (task, FS_TLS);
            else if (doit)
                rdmsrl (MSR_FS_BASE, base);
            else
                base = task->thread.fs;
            ret = put_user (base, (unsigned long __user *) addr);
            break;
        }
    case ARCH_GET_GS :
        {
            unsigned long base;
            unsigned gsindex;
            if (task->thread.gsindex == GS_TLS_SEL)
                base = read_32bit_tls (task, GS_TLS);
            else if (doit) {
                savesegment (gs, gsindex);
                if (gsindex)
                    rdmsrl (MSR_KERNEL_GS_BASE, base);
                else
                    base = task->thread.gs;
            }
            else
                base = task->thread.gs;
            ret = put_user (base, (unsigned long __user *) addr);
            break;
        }
    default :
        ret = -EINVAL;
        break;
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="560" endline="644">
{
case ARCH_SET_GS :
    if (addr >= TASK_SIZE_OF (task))
        return -EPERM;
    cpu = get_cpu ();
    if (addr <= 0xffffffff) {
        set_32bit_tls (task, GS_TLS, addr);
        if (doit) {
            load_TLS (& task -> thread, cpu);
            load_gs_index (GS_TLS_SEL);
        }
        task->thread.gsindex = GS_TLS_SEL;
        task->thread.gs = 0;
    }
    else {
        task->thread.gsindex = 0;
        task->thread.gs = addr;
        if (doit) {
            load_gs_index (0);
            ret = checking_wrmsrl (MSR_KERNEL_GS_BASE, addr);
        }
    }
    put_cpu ();
    break;
case ARCH_SET_FS :
    if (addr >= TASK_SIZE_OF (task))
        return -EPERM;
    cpu = get_cpu ();
    if (addr <= 0xffffffff) {
        set_32bit_tls (task, FS_TLS, addr);
        if (doit) {
            load_TLS (& task -> thread, cpu);
            loadsegment (fs, FS_TLS_SEL);
        }
        task->thread.fsindex = FS_TLS_SEL;
        task->thread.fs = 0;
    }
    else {
        task->thread.fsindex = 0;
        task->thread.fs = addr;
        if (doit) {
            loadsegment (fs, 0);
            ret = checking_wrmsrl (MSR_FS_BASE, addr);
        }
    }
    put_cpu ();
    break;
case ARCH_GET_FS :
    {
        unsigned long base;
        if (task->thread.fsindex == FS_TLS_SEL)
            base = read_32bit_tls (task, FS_TLS);
        else if (doit)
            rdmsrl (MSR_FS_BASE, base);
        else
            base = task->thread.fs;
        ret = put_user (base, (unsigned long __user *) addr);
        break;
    }
case ARCH_GET_GS :
    {
        unsigned long base;
        unsigned gsindex;
        if (task->thread.gsindex == GS_TLS_SEL)
            base = read_32bit_tls (task, GS_TLS);
        else if (doit) {
            savesegment (gs, gsindex);
            if (gsindex)
                rdmsrl (MSR_KERNEL_GS_BASE, base);
            else
                base = task->thread.gs;
        }
        else
            base = task->thread.gs;
        ret = put_user (base, (unsigned long __user *) addr);
        break;
    }
default :
    ret = -EINVAL;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="567" endline="575">
{
    set_32bit_tls (task, GS_TLS, addr);
    if (doit) {
        load_TLS (& task -> thread, cpu);
        load_gs_index (GS_TLS_SEL);
    }
    task->thread.gsindex = GS_TLS_SEL;
    task->thread.gs = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="569" endline="572">
{
    load_TLS (& task -> thread, cpu);
    load_gs_index (GS_TLS_SEL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="575" endline="582">
{
    task->thread.gsindex = 0;
    task->thread.gs = addr;
    if (doit) {
        load_gs_index (0);
        ret = checking_wrmsrl (MSR_KERNEL_GS_BASE, addr);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="578" endline="581">
{
    load_gs_index (0);
    ret = checking_wrmsrl (MSR_KERNEL_GS_BASE, addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="593" endline="601">
{
    set_32bit_tls (task, FS_TLS, addr);
    if (doit) {
        load_TLS (& task -> thread, cpu);
        loadsegment (fs, FS_TLS_SEL);
    }
    task->thread.fsindex = FS_TLS_SEL;
    task->thread.fs = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="595" endline="598">
{
    load_TLS (& task -> thread, cpu);
    loadsegment (fs, FS_TLS_SEL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="601" endline="610">
{
    task->thread.fsindex = 0;
    task->thread.fs = addr;
    if (doit) {
        loadsegment (fs, 0);
        ret = checking_wrmsrl (MSR_FS_BASE, addr);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="604" endline="609">
{
    loadsegment (fs, 0);
    ret = checking_wrmsrl (MSR_FS_BASE, addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="613" endline="623">
{
    unsigned long base;
    if (task->thread.fsindex == FS_TLS_SEL)
        base = read_32bit_tls (task, FS_TLS);
    else if (doit)
        rdmsrl (MSR_FS_BASE, base);
    else
        base = task->thread.fs;
    ret = put_user (base, (unsigned long __user *) addr);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="624" endline="639">
{
    unsigned long base;
    unsigned gsindex;
    if (task->thread.gsindex == GS_TLS_SEL)
        base = read_32bit_tls (task, GS_TLS);
    else if (doit) {
        savesegment (gs, gsindex);
        if (gsindex)
            rdmsrl (MSR_KERNEL_GS_BASE, base);
        else
            base = task->thread.gs;
    }
    else
        base = task->thread.gs;
    ret = put_user (base, (unsigned long __user *) addr);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="629" endline="635">
{
    savesegment (gs, gsindex);
    if (gsindex)
        rdmsrl (MSR_KERNEL_GS_BASE, base);
    else
        base = task->thread.gs;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="650" endline="652">
{
    return do_arch_prctl (current, code, addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process_64.c.ifdefed" startline="655" endline="658">
{
    return (test_tsk_thread_flag (task, TIF_IA32)) ? (task_pt_regs (task)->sp) : ((task)->thread.usersp);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc_sync.c.ifdefed" startline="46" endline="99">
{
    cycles_t start, now, prev, end;
    int i;
    rdtsc_barrier ();
    start = get_cycles ();
    rdtsc_barrier ();
    end = start + tsc_khz * 20ULL;
    now = start;
    for (i = 0;; i++) {
        arch_spin_lock (& sync_lock);
        prev = last_tsc;
        rdtsc_barrier ();
        now = get_cycles ();
        rdtsc_barrier ();
        last_tsc = now;
        arch_spin_unlock (& sync_lock);
        if (unlikely (!(i & 7))) {
            if (now > end || i > 10000000)
                break;
            cpu_relax ();
            touch_nmi_watchdog ();
        }
        if (unlikely (prev > now)) {
            arch_spin_lock (& sync_lock);
            max_warp = max (max_warp, prev -now);
            nr_warps++;
            arch_spin_unlock (& sync_lock);
        }
    }
    WARN (! (now - start), "Warning: zero tsc calibration delta: %Ld [max: %Ld]\n", now - start, end - start);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc_sync.c.ifdefed" startline="59" endline="95">
{
    arch_spin_lock (& sync_lock);
    prev = last_tsc;
    rdtsc_barrier ();
    now = get_cycles ();
    rdtsc_barrier ();
    last_tsc = now;
    arch_spin_unlock (& sync_lock);
    if (unlikely (!(i & 7))) {
        if (now > end || i > 10000000)
            break;
        cpu_relax ();
        touch_nmi_watchdog ();
    }
    if (unlikely (prev > now)) {
        arch_spin_lock (& sync_lock);
        max_warp = max (max_warp, prev -now);
        nr_warps++;
        arch_spin_unlock (& sync_lock);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc_sync.c.ifdefed" startline="79" endline="84">
{
    if (now > end || i > 10000000)
        break;
    cpu_relax ();
    touch_nmi_watchdog ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc_sync.c.ifdefed" startline="89" endline="94">
{
    arch_spin_lock (& sync_lock);
    max_warp = max (max_warp, prev -now);
    nr_warps++;
    arch_spin_unlock (& sync_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc_sync.c.ifdefed" startline="106" endline="166">
{
    int cpus = 2;
    if (unsynchronized_tsc ())
        return;
    if (boot_cpu_has (X86_FEATURE_TSC_RELIABLE)) {
        if (cpu == (nr_cpu_ids - 1) || system_state != SYSTEM_BOOTING)
            pr_info ("Skipped synchronization checks as TSC is reliable.\n");
        return;
    }
    atomic_set (& stop_count, 0);
    while (atomic_read (&start_count) != cpus - 1)
        cpu_relax ();
    atomic_inc (& start_count);
    check_tsc_warp ();
    while (atomic_read (&stop_count) != cpus - 1)
        cpu_relax ();
    if (nr_warps) {
        pr_warning ("TSC synchronization [CPU#%d -> CPU#%d]:\n", smp_processor_id (), cpu);
        pr_warning ("Measured %Ld cycles TSC warp between CPUs, " "turning off TSC clock.\n", max_warp);
        mark_tsc_unstable ("check_tsc_sync_source failed");
    }
    else {
        pr_debug ("TSC synchronization [CPU#%d -> CPU#%d]: passed\n", smp_processor_id (), cpu);
    }
    atomic_set (& start_count, 0);
    nr_warps = 0;
    max_warp = 0;
    last_tsc = 0;
    atomic_inc (& stop_count);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc_sync.c.ifdefed" startline="116" endline="121">
{
    if (cpu == (nr_cpu_ids - 1) || system_state != SYSTEM_BOOTING)
        pr_info ("Skipped synchronization checks as TSC is reliable.\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc_sync.c.ifdefed" startline="143" endline="149">
{
    pr_warning ("TSC synchronization [CPU#%d -> CPU#%d]:\n", smp_processor_id (), cpu);
    pr_warning ("Measured %Ld cycles TSC warp between CPUs, " "turning off TSC clock.\n", max_warp);
    mark_tsc_unstable ("check_tsc_sync_source failed");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc_sync.c.ifdefed" startline="149" endline="152">
{
    pr_debug ("TSC synchronization [CPU#%d -> CPU#%d]: passed\n", smp_processor_id (), cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tsc_sync.c.ifdefed" startline="172" endline="198">
{
    int cpus = 2;
    if (unsynchronized_tsc () || boot_cpu_has (X86_FEATURE_TSC_RELIABLE))
        return;
    atomic_inc (& start_count);
    while (atomic_read (&start_count) != cpus)
        cpu_relax ();
    check_tsc_warp ();
    atomic_inc (& stop_count);
    while (atomic_read (&stop_count) != cpus)
        cpu_relax ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="49" endline="68">
{
    loff_t ret;
    struct inode *inode = file->f_mapping->host;
    mutex_lock (& inode -> i_mutex);
    switch (orig) {
    case 0 :
        file->f_pos = offset;
        ret = file->f_pos;
        break;
    case 1 :
        file->f_pos += offset;
        ret = file->f_pos;
        break;
    default :
        ret = -EINVAL;
    }
    mutex_unlock (& inode -> i_mutex);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="54" endline="65">
{
case 0 :
    file->f_pos = offset;
    ret = file->f_pos;
    break;
case 1 :
    file->f_pos += offset;
    ret = file->f_pos;
    break;
default :
    ret = -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="72" endline="96">
{
    u32 __user *tmp = (u32 __user *) buf;
    u32 data [2];
    u32 reg = *ppos;
    int cpu = iminor (file->f_path.dentry->d_inode);
    int err = 0;
    ssize_t bytes = 0;
    if (count % 8)
        return -EINVAL;
    for (; count; count -= 8) {
        err = rdmsr_safe_on_cpu (cpu, reg, &data[0], &data[1]);
        if (err)
            break;
        if (copy_to_user (tmp, &data, 8)) {
            err = -EFAULT;
            break;
        }
        tmp += 2;
        bytes += 8;
    }
    return bytes ? bytes : err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="83" endline="93">
{
    err = rdmsr_safe_on_cpu (cpu, reg, &data[0], &data[1]);
    if (err)
        break;
    if (copy_to_user (tmp, &data, 8)) {
        err = -EFAULT;
        break;
    }
    tmp += 2;
    bytes += 8;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="87" endline="90">
{
    err = -EFAULT;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="100" endline="124">
{
    const u32 __user *tmp = (const u32 __user *) buf;
    u32 data [2];
    u32 reg = *ppos;
    int cpu = iminor (file->f_path.dentry->d_inode);
    int err = 0;
    ssize_t bytes = 0;
    if (count % 8)
        return -EINVAL;
    for (; count; count -= 8) {
        if (copy_from_user (&data, tmp, 8)) {
            err = -EFAULT;
            break;
        }
        err = wrmsr_safe_on_cpu (cpu, reg, data[0], data[1]);
        if (err)
            break;
        tmp += 2;
        bytes += 8;
    }
    return bytes ? bytes : err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="111" endline="121">
{
    if (copy_from_user (&data, tmp, 8)) {
        err = -EFAULT;
        break;
    }
    err = wrmsr_safe_on_cpu (cpu, reg, data[0], data[1]);
    if (err)
        break;
    tmp += 2;
    bytes += 8;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="112" endline="115">
{
    err = -EFAULT;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="127" endline="172">
{
    u32 __user *uregs = (u32 __user *) arg;
    u32 regs [8];
    int cpu = iminor (file->f_path.dentry->d_inode);
    int err;
    switch (ioc) {
    case X86_IOC_RDMSR_REGS :
        if (!(file->f_mode & FMODE_READ)) {
            err = -EBADF;
            break;
        }
        if (copy_from_user (&regs, uregs, sizeof regs)) {
            err = -EFAULT;
            break;
        }
        err = rdmsr_safe_regs_on_cpu (cpu, regs);
        if (err)
            break;
        if (copy_to_user (uregs, &regs, sizeof regs))
            err = -EFAULT;
        break;
    case X86_IOC_WRMSR_REGS :
        if (!(file->f_mode & FMODE_WRITE)) {
            err = -EBADF;
            break;
        }
        if (copy_from_user (&regs, uregs, sizeof regs)) {
            err = -EFAULT;
            break;
        }
        err = wrmsr_safe_regs_on_cpu (cpu, regs);
        if (err)
            break;
        if (copy_to_user (uregs, &regs, sizeof regs))
            err = -EFAULT;
        break;
    default :
        err = -ENOTTY;
        break;
    }
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="133" endline="169">
{
case X86_IOC_RDMSR_REGS :
    if (!(file->f_mode & FMODE_READ)) {
        err = -EBADF;
        break;
    }
    if (copy_from_user (&regs, uregs, sizeof regs)) {
        err = -EFAULT;
        break;
    }
    err = rdmsr_safe_regs_on_cpu (cpu, regs);
    if (err)
        break;
    if (copy_to_user (uregs, &regs, sizeof regs))
        err = -EFAULT;
    break;
case X86_IOC_WRMSR_REGS :
    if (!(file->f_mode & FMODE_WRITE)) {
        err = -EBADF;
        break;
    }
    if (copy_from_user (&regs, uregs, sizeof regs)) {
        err = -EFAULT;
        break;
    }
    err = wrmsr_safe_regs_on_cpu (cpu, regs);
    if (err)
        break;
    if (copy_to_user (uregs, &regs, sizeof regs))
        err = -EFAULT;
    break;
default :
    err = -ENOTTY;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="135" endline="138">
{
    err = -EBADF;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="139" endline="142">
{
    err = -EFAULT;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="151" endline="154">
{
    err = -EBADF;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="155" endline="158">
{
    err = -EFAULT;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="175" endline="188">
{
    unsigned int cpu;
    struct cpuinfo_x86 *c;
    cpu = iminor (file->f_path.dentry->d_inode);
    if (cpu >= nr_cpu_ids || !cpu_online (cpu))
        return -ENXIO;
    c = &cpu_data (cpu);
    if (!cpu_has (c, X86_FEATURE_MSR))
        return -EIO;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="204" endline="210">
{
    struct device *dev;
    dev = device_create (msr_class, NULL, MKDEV (MSR_MAJOR, cpu), NULL, "msr%d", cpu);
    return IS_ERR (dev) ? PTR_ERR (dev) : 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="213" endline="215">
{
    device_destroy (msr_class, MKDEV (MSR_MAJOR, cpu));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="219" endline="234">
{
    unsigned int cpu = (unsigned long) hcpu;
    int err = 0;
    switch (action) {
    case CPU_UP_PREPARE :
        err = msr_device_create (cpu);
        break;
    case CPU_UP_CANCELED :
    case CPU_UP_CANCELED_FROZEN :
    case CPU_DEAD :
        msr_device_destroy (cpu);
        break;
    }
    return err ? NOTIFY_BAD : NOTIFY_OK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="223" endline="232">
{
case CPU_UP_PREPARE :
    err = msr_device_create (cpu);
    break;
case CPU_UP_CANCELED :
case CPU_UP_CANCELED_FROZEN :
case CPU_DEAD :
    msr_device_destroy (cpu);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="241" endline="243">
{
    return kasprintf (GFP_KERNEL, "cpu/%u/msr", MINOR (dev->devt));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="246" endline="281">
{
    int i, err = 0;
    i = 0;
    if (__register_chrdev (MSR_MAJOR, 0, NR_CPUS, "cpu/msr", &msr_fops)) {
        printk (KERN_ERR "msr: unable to get major %d for msr\n", MSR_MAJOR);
        err = -EBUSY;
        goto out;
    }
    msr_class = class_create (THIS_MODULE, "msr");
    if (IS_ERR (msr_class)) {
        err = PTR_ERR (msr_class);
        goto out_chrdev;
    }
    msr_class->devnode = msr_devnode;

    for_each_online_cpu (i) {
        err = msr_device_create (i);
        if (err != 0)
            goto out_class;
    }

    register_hotcpu_notifier (& msr_class_cpu_notifier);
    err = 0;
    goto out;
out_class :
    i = 0;
    for_each_online_cpu (i)
    msr_device_destroy (i);
    class_destroy (msr_class);
out_chrdev :
    __unregister_chrdev (MSR_MAJOR, 0, NR_CPUS, "cpu/msr");
out :
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="250" endline="255">
{
    printk (KERN_ERR "msr: unable to get major %d for msr\n", MSR_MAJOR);
    err = -EBUSY;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="257" endline="260">
{
    err = PTR_ERR (msr_class);
    goto out_chrdev;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="262" endline="266">
{
    err = msr_device_create (i);
    if (err != 0)
        goto out_class;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/msr.c.ifdefed" startline="284" endline="291">
{
    int cpu = 0;
    for_each_online_cpu (cpu)
    msr_device_destroy (cpu);
    class_destroy (msr_class);
    __unregister_chrdev (MSR_MAJOR, 0, NR_CPUS, "cpu/msr");
    unregister_hotcpu_notifier (& msr_class_cpu_notifier);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="39" endline="54">
{
    struct vm_struct *area;
    if (!size)
        return NULL;
    size = PAGE_ALIGN (size);
    if (size > MODULES_LEN)
        return NULL;
    area = __get_vm_area (size, VM_ALLOC, MODULES_VADDR, MODULES_END);
    if (!area)
        return NULL;
    return __vmalloc_area (area, GFP_KERNEL | __GFP_HIGHMEM, PAGE_KERNEL_EXEC);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="58" endline="60">
{
    vfree (module_region);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="67" endline="69">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="128" endline="191">
{
    unsigned int i;
    Elf64_Rela *rel = (void *) sechdrs[relsec].sh_addr;
    Elf64_Sym *sym;
    void *loc;
    u64 val;
    DEBUGP ("Applying relocate section %u to %u\n", relsec, sechdrs [relsec].sh_info);
    for (i = 0; i < sechdrs[relsec].sh_size / sizeof (*rel); i++) {
        loc = (void *) sechdrs[sechdrs[relsec].sh_info].sh_addr + rel[i].r_offset;
        sym = (Elf64_Sym *) sechdrs[symindex].sh_addr + ELF64_R_SYM (rel[i].r_info);
        DEBUGP ("type %d st_value %Lx r_addend %Lx loc %Lx\n", (int) ELF64_R_TYPE (rel [i].r_info), sym -> st_value, rel [i].r_addend, (u64) loc);
        val = sym->st_value + rel[i].r_addend;
        switch (ELF64_R_TYPE (rel[i].r_info)) {
        case R_X86_64_NONE :
            break;
        case R_X86_64_64 :
            *(u64*) loc = val;
            break;
        case R_X86_64_32 :
            *(u32*) loc = val;
            if (val != *(u32*) loc)
                goto overflow;
            break;
        case R_X86_64_32S :
            *(s32*) loc = val;
            if ((s64) val != *(s32*) loc)
                goto overflow;
            break;
        case R_X86_64_PC32 :
            val -= (u64) loc;
            *(u32*) loc = val;
            break;
        default :
            printk (KERN_ERR "module %s: Unknown rela relocation: %llu\n", me->name, ELF64_R_TYPE (rel[i].r_info));
            return -ENOEXEC;
        }
    }
    return 0;
overflow :
    printk (KERN_ERR "overflow in relocation type %d val %Lx\n", (int) ELF64_R_TYPE (rel[i].r_info), val);
    printk (KERN_ERR "`%s' likely not compiled with -mcmodel=kernel\n", me -> name);
    return -ENOEXEC;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="137" endline="182">
{
    loc = (void *) sechdrs[sechdrs[relsec].sh_info].sh_addr + rel[i].r_offset;
    sym = (Elf64_Sym *) sechdrs[symindex].sh_addr + ELF64_R_SYM (rel[i].r_info);
    DEBUGP ("type %d st_value %Lx r_addend %Lx loc %Lx\n", (int) ELF64_R_TYPE (rel [i].r_info), sym -> st_value, rel [i].r_addend, (u64) loc);
    val = sym->st_value + rel[i].r_addend;
    switch (ELF64_R_TYPE (rel[i].r_info)) {
    case R_X86_64_NONE :
        break;
    case R_X86_64_64 :
        *(u64*) loc = val;
        break;
    case R_X86_64_32 :
        *(u32*) loc = val;
        if (val != *(u32*) loc)
            goto overflow;
        break;
    case R_X86_64_32S :
        *(s32*) loc = val;
        if ((s64) val != *(s32*) loc)
            goto overflow;
        break;
    case R_X86_64_PC32 :
        val -= (u64) loc;
        *(u32*) loc = val;
        break;
    default :
        printk (KERN_ERR "module %s: Unknown rela relocation: %llu\n", me->name, ELF64_R_TYPE (rel[i].r_info));
        return -ENOEXEC;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="153" endline="181">
{
case R_X86_64_NONE :
    break;
case R_X86_64_64 :
    *(u64*) loc = val;
    break;
case R_X86_64_32 :
    *(u32*) loc = val;
    if (val != *(u32*) loc)
        goto overflow;
    break;
case R_X86_64_32S :
    *(s32*) loc = val;
    if ((s64) val != *(s32*) loc)
        goto overflow;
    break;
case R_X86_64_PC32 :
    val -= (u64) loc;
    *(u32*) loc = val;
    break;
default :
    printk (KERN_ERR "module %s: Unknown rela relocation: %llu\n", me->name, ELF64_R_TYPE (rel[i].r_info));
    return -ENOEXEC;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="198" endline="201">
{
    printk (KERN_ERR "non add relocation not supported\n");
    return -ENOSYS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="208" endline="243">
{
    const Elf_Shdr *s, *text = NULL, *alt = NULL, *locks = NULL, *para = NULL;
    char *secstrings = (void *) hdr + sechdrs[hdr->e_shstrndx].sh_offset;
    for (s = sechdrs; s < sechdrs + hdr->e_shnum; s++) {
        if (!strcmp (".text", secstrings +s->sh_name))
            text = s;
        if (!strcmp (".altinstructions", secstrings +s->sh_name))
            alt = s;
        if (!strcmp (".smp_locks", secstrings +s->sh_name))
            locks = s;
        if (!strcmp (".parainstructions", secstrings +s->sh_name))
            para = s;
    }
    if (alt) {
        void *aseg = (void *) alt->sh_addr;
        apply_alternatives (aseg, aseg + alt -> sh_size);
    }
    if (locks && text) {
        void *lseg = (void *) locks->sh_addr;
        void *tseg = (void *) text->sh_addr;
        alternatives_smp_module_add (me, me -> name, lseg, lseg + locks -> sh_size, tseg, tseg + text -> sh_size);
    }
    if (para) {
        void *pseg = (void *) para->sh_addr;
        apply_paravirt (pseg, pseg + para -> sh_size);
    }
    return module_bug_finalize (hdr, sechdrs, me);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="213" endline="222">
{
    if (!strcmp (".text", secstrings +s->sh_name))
        text = s;
    if (!strcmp (".altinstructions", secstrings +s->sh_name))
        alt = s;
    if (!strcmp (".smp_locks", secstrings +s->sh_name))
        locks = s;
    if (!strcmp (".parainstructions", secstrings +s->sh_name))
        para = s;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="224" endline="228">
{
    void *aseg = (void *) alt->sh_addr;
    apply_alternatives (aseg, aseg + alt -> sh_size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="229" endline="235">
{
    void *lseg = (void *) locks->sh_addr;
    void *tseg = (void *) text->sh_addr;
    alternatives_smp_module_add (me, me -> name, lseg, lseg + locks -> sh_size, tseg, tseg + text -> sh_size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="237" endline="240">
{
    void *pseg = (void *) para->sh_addr;
    apply_paravirt (pseg, pseg + para -> sh_size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/module.c.ifdefed" startline="246" endline="249">
{
    alternatives_smp_module_del (mod);
    module_bug_cleanup (mod);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="28" endline="42">
{
    if (printk_ratelimit ())
        pr_err ("unexpected IRQ trap at vector %02x\n", irq);
    ack_APIC_irq ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="49" endline="122">
{
    int j;
    seq_printf (p, "%*s: ", prec, "NMI");
    for_each_online_cpu (j)
    seq_printf (p, "%10u ", irq_stats (j) -> __nmi_count);
    seq_printf (p, "  Non-maskable interrupts\n");
    if (x86_platform_ipi_callback) {
        seq_printf (p, "%*s: ", prec, "PLT");
        for_each_online_cpu (j)
        seq_printf (p, "%10u ", irq_stats (j) -> x86_platform_ipis);
        seq_printf (p, "  Platform interrupts\n");
    }
    seq_printf (p, "%*s: %10u\n", prec, "ERR", atomic_read (& irq_err_count));
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="75" endline="80">
{
    seq_printf (p, "%*s: ", prec, "PLT");
    for_each_online_cpu (j)
    seq_printf (p, "%10u ", irq_stats (j) -> x86_platform_ipis);
    seq_printf (p, "  Platform interrupts\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="125" endline="175">
{
    unsigned long flags, any_count = 0;
    int i = *(loff_t*) v, j, prec;
    struct irqaction *action;
    struct irq_desc *desc;
    if (i > nr_irqs)
        return 0;
    for (prec = 3, j = 1000; prec < 10 && j <= nr_irqs; ++prec)
        j *= 10;
    if (i == nr_irqs)
        return show_other_interrupts (p, prec);
    if (i == 0) {
        seq_printf (p, "%*s", prec + 8, "");
        for_each_online_cpu (j)
        seq_printf (p, "CPU%-8d", j);
        seq_putc (p, '\n');
    }
    desc = irq_to_desc (i);
    if (!desc)
        return 0;
    raw_spin_lock_irqsave (& desc -> lock, flags);
    for_each_online_cpu (j)
    any_count |= kstat_irqs_cpu (i, j);
    action = desc->action;
    if (!action && !any_count)
        goto out;
    seq_printf (p, "%*d: ", prec, i);
    for_each_online_cpu (j)
    seq_printf (p, "%10u ", kstat_irqs_cpu (i, j));
    seq_printf (p, " %8s", desc -> chip -> name);
    seq_printf (p, "-%-8s", desc -> name);
    if (action) {
        seq_printf (p, "  %s", action -> name);
        while ((action = action->next) != NULL)
            seq_printf (p, ", %s", action->name);
    }
    seq_putc (p, '\n');
out :
    raw_spin_unlock_irqrestore (&desc->lock, flags);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="141" endline="146">
{
    seq_printf (p, "%*s", prec + 8, "");
    for_each_online_cpu (j)
    seq_printf (p, "CPU%-8d", j);
    seq_putc (p, '\n');
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="165" endline="169">
{
    seq_printf (p, "  %s", action -> name);
    while ((action = action->next) != NULL)
        seq_printf (p, ", %s", action->name);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="181" endline="208">
{
    u64 sum = irq_stats (cpu)->__nmi_count;
    if (x86_platform_ipi_callback)
        sum += irq_stats (cpu)->x86_platform_ipis;
    return sum;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="211" endline="218">
{
    u64 sum = atomic_read (&irq_err_count);
    return sum;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="227" endline="251">
{
    struct pt_regs *old_regs = set_irq_regs (regs);
    unsigned vector = ~regs->orig_ax;
    unsigned irq;
    exit_idle ();
    irq_enter ();
    irq = __get_cpu_var (vector_irq)[vector];
    if (!handle_irq (irq, regs)) {
        ack_APIC_irq ();
        if (printk_ratelimit ())
            pr_emerg ("%s: %d.%d No irq handler for vector (irq %d)\n", __func__, smp_processor_id (), vector, irq);
    }
    irq_exit ();
    set_irq_regs (old_regs);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="239" endline="245">
{
    ack_APIC_irq ();
    if (printk_ratelimit ())
        pr_emerg ("%s: %d.%d No irq handler for vector (irq %d)\n", __func__, smp_processor_id (), vector, irq);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irq.c.ifdefed" startline="257" endline="274">
{
    struct pt_regs *old_regs = set_irq_regs (regs);
    ack_APIC_irq ();
    exit_idle ();
    irq_enter ();
    inc_irq_stat (x86_platform_ipis);
    if (x86_platform_ipi_callback)
        x86_platform_ipi_callback ();
    irq_exit ();
    set_irq_regs (old_regs);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="144" endline="174">
{
    struct cpuinfo_x86 *c = &cpu_data (cpu_num);
    unsigned int val [2];
    memset (csig, 0, sizeof (* csig));
    if (c->x86_vendor != X86_VENDOR_INTEL || c->x86 < 6 || cpu_has (c, X86_FEATURE_IA64)) {
        pr_err ("CPU%d not a capable Intel processor\n", cpu_num);
        return -1;
    }
    csig->sig = cpuid_eax (0x00000001);
    if ((c->x86_model >= 5) || (c->x86 > 6)) {
        rdmsr (MSR_IA32_PLATFORM_ID, val [0], val [1]);
        csig->pf = 1 << ((val[1] >> 18) & 7);
    }
    wrmsr (MSR_IA32_UCODE_REV, 0, 0);
    sync_core ();
    rdmsr (MSR_IA32_UCODE_REV, val [0], csig -> rev);
    pr_info ("CPU%d sig=0x%x, pf=0x%x, revision=0x%x\n", cpu_num, csig -> sig, csig -> pf, csig -> rev);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="151" endline="154">
{
    pr_err ("CPU%d not a capable Intel processor\n", cpu_num);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="158" endline="162">
{
    rdmsr (MSR_IA32_PLATFORM_ID, val [0], val [1]);
    csig->pf = 1 << ((val[1] >> 18) & 7);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="177" endline="179">
{
    return (!sigmatch (sig, csig->sig, pf, csig->pf)) ? 0 : 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="183" endline="185">
{
    return (mc_header->rev <= rev) ? 0 : 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="188" endline="260">
{
    unsigned long total_size, data_size, ext_table_size;
    struct microcode_header_intel *mc_header = mc;
    struct extended_sigtable *ext_header = NULL;
    int sum, orig_sum, ext_sigcount = 0, i;
    struct extended_signature *ext_sig;
    total_size = get_totalsize (mc_header);
    data_size = get_datasize (mc_header);
    if (data_size + MC_HEADER_SIZE > total_size) {
        pr_err ("error! Bad data size in microcode data file\n");
        return -EINVAL;
    }
    if (mc_header->ldrver != 1 || mc_header->hdrver != 1) {
        pr_err ("error! Unknown microcode update format\n");
        return -EINVAL;
    }
    ext_table_size = total_size - (MC_HEADER_SIZE + data_size);
    if (ext_table_size) {
        if ((ext_table_size < EXT_HEADER_SIZE) || ((ext_table_size - EXT_HEADER_SIZE) % EXT_SIGNATURE_SIZE)) {
            pr_err ("error! Small exttable size in microcode data file\n");
            return -EINVAL;
        }
        ext_header = mc + MC_HEADER_SIZE + data_size;
        if (ext_table_size != exttable_size (ext_header)) {
            pr_err ("error! Bad exttable size in microcode data file\n");
            return -EFAULT;
        }
        ext_sigcount = ext_header->count;
    }
    if (ext_table_size) {
        int ext_table_sum = 0;
        int *ext_tablep = (int *) ext_header;
        i = ext_table_size / DWSIZE;
        while (i--)
            ext_table_sum += ext_tablep[i];
        if (ext_table_sum) {
            pr_warning ("aborting, bad extended signature table checksum\n");
            return -EINVAL;
        }
    }
    orig_sum = 0;
    i = (MC_HEADER_SIZE + data_size) / DWSIZE;
    while (i--)
        orig_sum += ((int *) mc)[i];
    if (orig_sum) {
        pr_err ("aborting, bad checksum\n");
        return -EINVAL;
    }
    if (!ext_table_size)
        return 0;
    for (i = 0; i < ext_sigcount; i++) {
        ext_sig = (void *) ext_header + EXT_HEADER_SIZE + EXT_SIGNATURE_SIZE * i;
        sum = orig_sum - (mc_header->sig + mc_header->pf + mc_header->cksum) + (ext_sig->sig + ext_sig->pf + ext_sig->cksum);
        if (sum) {
            pr_err ("aborting, bad checksum\n");
            return -EINVAL;
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="198" endline="201">
{
    pr_err ("error! Bad data size in microcode data file\n");
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="203" endline="206">
{
    pr_err ("error! Unknown microcode update format\n");
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="208" endline="220">
{
    if ((ext_table_size < EXT_HEADER_SIZE) || ((ext_table_size - EXT_HEADER_SIZE) % EXT_SIGNATURE_SIZE)) {
        pr_err ("error! Small exttable size in microcode data file\n");
        return -EINVAL;
    }
    ext_header = mc + MC_HEADER_SIZE + data_size;
    if (ext_table_size != exttable_size (ext_header)) {
        pr_err ("error! Bad exttable size in microcode data file\n");
        return -EFAULT;
    }
    ext_sigcount = ext_header->count;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="210" endline="213">
{
    pr_err ("error! Small exttable size in microcode data file\n");
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="215" endline="218">
{
    pr_err ("error! Bad exttable size in microcode data file\n");
    return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="223" endline="234">
{
    int ext_table_sum = 0;
    int *ext_tablep = (int *) ext_header;
    i = ext_table_size / DWSIZE;
    while (i--)
        ext_table_sum += ext_tablep[i];
    if (ext_table_sum) {
        pr_warning ("aborting, bad extended signature table checksum\n");
        return -EINVAL;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="230" endline="233">
{
    pr_warning ("aborting, bad extended signature table checksum\n");
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="241" endline="244">
{
    pr_err ("aborting, bad checksum\n");
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="248" endline="258">
{
    ext_sig = (void *) ext_header + EXT_HEADER_SIZE + EXT_SIGNATURE_SIZE * i;
    sum = orig_sum - (mc_header->sig + mc_header->pf + mc_header->cksum) + (ext_sig->sig + ext_sig->pf + ext_sig->cksum);
    if (sum) {
        pr_err ("aborting, bad checksum\n");
        return -EINVAL;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="254" endline="257">
{
    pr_err ("aborting, bad checksum\n");
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="268" endline="295">
{
    struct microcode_header_intel *mc_header = mc;
    struct extended_sigtable *ext_header;
    unsigned long total_size = get_totalsize (mc_header);
    int ext_sigcount, i;
    struct extended_signature *ext_sig;
    if (!update_match_revision (mc_header, rev))
        return 0;
    if (update_match_cpu (cpu_sig, mc_header->sig, mc_header->pf))
        return 1;
    if (total_size <= get_datasize (mc_header) + MC_HEADER_SIZE)
        return 0;
    ext_header = mc + get_datasize (mc_header) + MC_HEADER_SIZE;
    ext_sigcount = ext_header->count;
    ext_sig = (void *) ext_header + EXT_HEADER_SIZE;
    for (i = 0; i < ext_sigcount; i++) {
        if (update_match_cpu (cpu_sig, ext_sig->sig, ext_sig->pf))
            return 1;
        ext_sig++;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="289" endline="293">
{
    if (update_match_cpu (cpu_sig, ext_sig->sig, ext_sig->pf))
        return 1;
    ext_sig++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="298" endline="340">
{
    struct microcode_intel *mc_intel;
    struct ucode_cpu_info *uci;
    unsigned int val [2];
    int cpu_num;
    cpu_num = raw_smp_processor_id ();
    uci = ucode_cpu_info + cpu;
    mc_intel = uci->mc;
    BUG_ON (cpu_num != cpu);
    if (mc_intel == NULL)
        return 0;
    wrmsr (MSR_IA32_UCODE_WRITE, (unsigned long) mc_intel -> bits, (unsigned long) mc_intel -> bits >> 16 >> 16);
    wrmsr (MSR_IA32_UCODE_REV, 0, 0);
    sync_core ();
    rdmsr (MSR_IA32_UCODE_REV, val [0], val [1]);
    if (val[1] != mc_intel->hdr.rev) {
        pr_err ("CPU%d update to revision 0x%x failed\n", cpu_num, mc_intel -> hdr.rev);
        return -1;
    }
    pr_info ("CPU%d updated to revision 0x%x, date = %04x-%02x-%02x\n", cpu_num, val [1], mc_intel -> hdr.date & 0xffff, mc_intel -> hdr.date >> 24, (mc_intel -> hdr.date >> 16) & 0xff);
    uci->cpu_sig.rev = val[1];
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="326" endline="330">
{
    pr_err ("CPU%d update to revision 0x%x failed\n", cpu_num, mc_intel -> hdr.rev);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="344" endline="406">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
    u8 *ucode_ptr = data, *new_mc = NULL, *mc;
    int new_rev = uci->cpu_sig.rev;
    unsigned int leftover = size;
    enum ucode_state state = UCODE_OK;
    while (leftover) {
        struct microcode_header_intel mc_header;
        unsigned int mc_size;
        if (get_ucode_data (&mc_header, ucode_ptr, sizeof (mc_header)))
            break;
        mc_size = get_totalsize (&mc_header);
        if (!mc_size || mc_size > leftover) {
            pr_err ("error! Bad data in microcode data file\n");
            break;
        }
        mc = vmalloc (mc_size);
        if (!mc)
            break;
        if (get_ucode_data (mc, ucode_ptr, mc_size) || microcode_sanity_check (mc) < 0) {
            vfree (mc);
            break;
        }
        if (get_matching_microcode (&uci->cpu_sig, mc, new_rev)) {
            if (new_mc)
                vfree (new_mc);
            new_rev = mc_header.rev;
            new_mc = mc;
        }
        else
            vfree (mc);
        ucode_ptr += mc_size;
        leftover -= mc_size;
    }
    if (leftover) {
        if (new_mc)
            vfree (new_mc);
        state = UCODE_ERROR;
        goto out;
    }
    if (!new_mc) {
        state = UCODE_NFOUND;
        goto out;
    }
    if (uci->mc)
        vfree (uci->mc);
    uci->mc = (struct microcode_intel *) new_mc;
    pr_debug ("CPU%d found a matching microcode update with version 0x%x (current=0x%x)\n", cpu, new_rev, uci -> cpu_sig.rev);
out :
    return state;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="351" endline="384">
{
    struct microcode_header_intel mc_header;
    unsigned int mc_size;
    if (get_ucode_data (&mc_header, ucode_ptr, sizeof (mc_header)))
        break;
    mc_size = get_totalsize (&mc_header);
    if (!mc_size || mc_size > leftover) {
        pr_err ("error! Bad data in microcode data file\n");
        break;
    }
    mc = vmalloc (mc_size);
    if (!mc)
        break;
    if (get_ucode_data (mc, ucode_ptr, mc_size) || microcode_sanity_check (mc) < 0) {
        vfree (mc);
        break;
    }
    if (get_matching_microcode (&uci->cpu_sig, mc, new_rev)) {
        if (new_mc)
            vfree (new_mc);
        new_rev = mc_header.rev;
        new_mc = mc;
    }
    else
        vfree (mc);
    ucode_ptr += mc_size;
    leftover -= mc_size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="359" endline="362">
{
    pr_err ("error! Bad data in microcode data file\n");
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="369" endline="372">
{
    vfree (mc);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="374" endline="379">
{
    if (new_mc)
        vfree (new_mc);
    new_rev = mc_header.rev;
    new_mc = mc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="386" endline="391">
{
    if (new_mc)
        vfree (new_mc);
    state = UCODE_ERROR;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="393" endline="396">
{
    state = UCODE_NFOUND;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="409" endline="412">
{
    memcpy (to, from, n);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="415" endline="435">
{
    char name [30];
    struct cpuinfo_x86 *c = &cpu_data (cpu);
    const struct firmware *firmware;
    enum ucode_state ret;
    sprintf (name, "intel-ucode/%02x-%02x-%02x", c -> x86, c -> x86_model, c -> x86_mask);
    if (request_firmware (&firmware, name, device)) {
        pr_debug ("data file %s load failed\n", name);
        return UCODE_NFOUND;
    }
    ret = generic_load_microcode (cpu, (void *) firmware->data, firmware->size, &get_ucode_fw);
    release_firmware (firmware);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="424" endline="427">
{
    pr_debug ("data file %s load failed\n", name);
    return UCODE_NFOUND;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="438" endline="440">
{
    return copy_from_user (to, from, n);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="444" endline="446">
{
    return generic_load_microcode (cpu, (void *) buf, size, &get_ucode_user);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="449" endline="454">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
    vfree (uci -> mc);
    uci->mc = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_intel.c.ifdefed" startline="465" endline="467">
{
    return &microcode_intel_ops;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="23" endline="46">
{
    u32 htcfg;
    htcfg = read_pci_config (num, slot, func, 0x68);
    if (htcfg & (1 << 18)) {
        printk (KERN_INFO "Detected use of extended apic ids " "on hypertransport bus\n");
        if ((htcfg & (1 << 17)) == 0) {
            printk (KERN_INFO "Enabling hypertransport extended " "apic interrupt broadcast\n");
            printk (KERN_INFO "Note this is a bios bug, " "please contact your hw vendor\n");
            htcfg |= (1 << 17);
            write_pci_config (num, slot, func, 0x68, htcfg);
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="32" endline="43">
{
    printk (KERN_INFO "Detected use of extended apic ids " "on hypertransport bus\n");
    if ((htcfg & (1 << 17)) == 0) {
        printk (KERN_INFO "Enabling hypertransport extended " "apic interrupt broadcast\n");
        printk (KERN_INFO "Note this is a bios bug, " "please contact your hw vendor\n");
        htcfg |= (1 << 17);
        write_pci_config (num, slot, func, 0x68, htcfg);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="35" endline="42">
{
    printk (KERN_INFO "Enabling hypertransport extended " "apic interrupt broadcast\n");
    printk (KERN_INFO "Note this is a bios bug, " "please contact your hw vendor\n");
    htcfg |= (1 << 17);
    write_pci_config (num, slot, func, 0x68, htcfg);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="49" endline="59">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="72" endline="97">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="186" endline="187">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="190" endline="191">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="238" endline="274">
{
    u16 class;
    u16 vendor;
    u16 device;
    u8 type;
    int i;
    class = read_pci_config_16 (num, slot, func, PCI_CLASS_DEVICE);
    if (class == 0xffff)
        return -1;
    vendor = read_pci_config_16 (num, slot, func, PCI_VENDOR_ID);
    device = read_pci_config_16 (num, slot, func, PCI_DEVICE_ID);
    for (i = 0; early_qrk[i].f != NULL; i++) {
        if (((early_qrk[i].vendor == PCI_ANY_ID) || (early_qrk[i].vendor == vendor)) && ((early_qrk[i].device == PCI_ANY_ID) || (early_qrk[i].device == device)) && (!((early_qrk[i].class ^ class) & early_qrk[i].class_mask))) {
            if ((early_qrk[i].flags & QFLAG_DONE) != QFLAG_DONE)
                early_qrk[i].f (num, slot, func);
            early_qrk[i].flags |= QFLAG_APPLIED;
        }
    }
    type = read_pci_config_byte (num, slot, func, PCI_HEADER_TYPE);
    if (!(type & 0x80))
        return -1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="254" endline="266">
{
    if (((early_qrk[i].vendor == PCI_ANY_ID) || (early_qrk[i].vendor == vendor)) && ((early_qrk[i].device == PCI_ANY_ID) || (early_qrk[i].device == device)) && (!((early_qrk[i].class ^ class) & early_qrk[i].class_mask))) {
        if ((early_qrk[i].flags & QFLAG_DONE) != QFLAG_DONE)
            early_qrk[i].f (num, slot, func);
        early_qrk[i].flags |= QFLAG_APPLIED;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="260" endline="265">
{
    if ((early_qrk[i].flags & QFLAG_DONE) != QFLAG_DONE)
        early_qrk[i].f (num, slot, func);
    early_qrk[i].flags |= QFLAG_APPLIED;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="277" endline="291">
{
    int slot, func;
    if (!early_pci_allowed ())
        return;
    for (slot = 0; slot < 32; slot++)
        for (func = 0; func < 8; func++) {
            if (check_dev_quirk (0, slot, func))
                break;
        }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/early-quirks.c.ifdefed" startline="286" endline="290">
{
    if (check_dev_quirk (0, slot, func))
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/bootflag.c.ifdefed" startline="23" endline="33">
{
    int x = 0;
    int i;
    for (i = 0; i < 8; i++) {
        x ^= (v & 1);
        v >>= 1;
    }
    return x;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/bootflag.c.ifdefed" startline="27" endline="30">
{
    x ^= (v & 1);
    v >>= 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/bootflag.c.ifdefed" startline="36" endline="51">
{
    unsigned long flags;
    if (sbf_port != -1) {
        v &= ~SBF_PARITY;
        if (!parity (v))
            v |= SBF_PARITY;
        printk (KERN_INFO "Simple Boot Flag at 0x%x set to 0x%x\n", sbf_port, v);
        spin_lock_irqsave (& rtc_lock, flags);
        CMOS_WRITE (v, sbf_port);
        spin_unlock_irqrestore (& rtc_lock, flags);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/bootflag.c.ifdefed" startline="39" endline="50">
{
    v &= ~SBF_PARITY;
    if (!parity (v))
        v |= SBF_PARITY;
    printk (KERN_INFO "Simple Boot Flag at 0x%x set to 0x%x\n", sbf_port, v);
    spin_lock_irqsave (& rtc_lock, flags);
    CMOS_WRITE (v, sbf_port);
    spin_unlock_irqrestore (& rtc_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/bootflag.c.ifdefed" startline="54" endline="66">
{
    unsigned long flags;
    u8 v;
    if (sbf_port == -1)
        return 0;
    spin_lock_irqsave (& rtc_lock, flags);
    v = CMOS_READ (sbf_port);
    spin_unlock_irqrestore (& rtc_lock, flags);
    return v;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/bootflag.c.ifdefed" startline="69" endline="76">
{
    if (v & SBF_RESERVED)
        return 0;
    if (!parity (v))
        return 0;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/bootflag.c.ifdefed" startline="79" endline="100">
{
    u8 v;
    if (sbf_port == -1)
        return 0;
    v = sbf_read ();
    if (!sbf_value_valid (v)) {
        printk (KERN_WARNING "Simple Boot Flag value 0x%x read from " "CMOS RAM was invalid\n", v);
    }
    v &= ~SBF_RESERVED;
    v &= ~SBF_BOOTING;
    v &= ~SBF_DIAG;
    sbf_write (v);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/bootflag.c.ifdefed" startline="86" endline="89">
{
    printk (KERN_WARNING "Simple Boot Flag value 0x%x read from " "CMOS RAM was invalid\n", v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="60" endline="64">
{
    gart_resource.start = aper_base;
    gart_resource.end = aper_base + aper_size - 1;
    insert_resource (& iomem_resource, & gart_resource);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="70" endline="119">
{
    u32 aper_size;
    void *p;
    if (fallback_aper_order > 5)
        fallback_aper_order = 5;
    aper_size = (32 * 1024 * 1024) << fallback_aper_order;
    p = __alloc_bootmem_nopanic (aper_size, aper_size, 512ULL << 20);
    kmemleak_ignore (p);
    if (!p || __pa (p) + aper_size > 0xffffffff) {
        printk (KERN_ERR "Cannot allocate aperture memory hole (%p,%uK)\n", p, aper_size >> 10);
        if (p)
            free_bootmem (__pa (p), aper_size);
        return 0;
    }
    printk (KERN_INFO "Mapping aperture over %d KB of RAM @ %lx\n", aper_size >> 10, __pa (p));
    insert_aperture_resource ((u32) __pa (p), aper_size);
    register_nosave_region ((u32) __pa (p) >> PAGE_SHIFT, (u32) __pa (p + aper_size) >> PAGE_SHIFT);
    return (u32) __pa (p);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="104" endline="111">
{
    printk (KERN_ERR "Cannot allocate aperture memory hole (%p,%uK)\n", p, aper_size >> 10);
    if (p)
        free_bootmem (__pa (p), aper_size);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="124" endline="146">
{
    int bytes;
    u8 pos;
    if (!(read_pci_config_16 (bus, slot, func, PCI_STATUS) & PCI_STATUS_CAP_LIST))
        return 0;
    pos = read_pci_config_byte (bus, slot, func, PCI_CAPABILITY_LIST);
    for (bytes = 0; bytes < 48 && pos >= 0x40; bytes++) {
        u8 id;
        pos &= ~3;
        id = read_pci_config_byte (bus, slot, func, pos +PCI_CAP_LIST_ID);
        if (id == 0xff)
            break;
        if (id == cap)
            return pos;
        pos = read_pci_config_byte (bus, slot, func, pos +PCI_CAP_LIST_NEXT);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="133" endline="144">
{
    u8 id;
    pos &= ~3;
    id = read_pci_config_byte (bus, slot, func, pos +PCI_CAP_LIST_ID);
    if (id == 0xff)
        break;
    if (id == cap)
        return pos;
    pos = read_pci_config_byte (bus, slot, func, pos +PCI_CAP_LIST_NEXT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="150" endline="199">
{
    u32 apsize;
    u32 apsizereg;
    int nbits;
    u32 aper_low, aper_hi;
    u64 aper;
    u32 old_order;
    printk (KERN_INFO "AGP bridge at %02x:%02x:%02x\n", bus, slot, func);
    apsizereg = read_pci_config_16 (bus, slot, func, cap +0x14);
    if (apsizereg == 0xffffffff) {
        printk (KERN_ERR "APSIZE in AGP bridge unreadable\n");
        return 0;
    }
    old_order = *order;
    apsize = apsizereg & 0xfff;
    if (apsize & 0xff)
        apsize |= 0xf00;
    nbits = hweight16 (apsize);
    *order = 7 - nbits;
    if ((int) *order < 0)
        *order = 0;
    aper_low = read_pci_config (bus, slot, func, 0x10);
    aper_hi = read_pci_config (bus, slot, func, 0x14);
    aper = (aper_low & ~((1 << 22) - 1)) | ((u64) aper_hi << 32);
    printk (KERN_INFO "Aperture from AGP @ %Lx old size %u MB\n", aper, 32 << old_order);
    if (aper + (32ULL << (20 + *order)) > 0x100000000ULL) {
        printk (KERN_INFO "Aperture size %u MB (APSIZE %x) is not right, using settings from NB\n", 32 << * order, apsizereg);
        *order = old_order;
    }
    printk (KERN_INFO "Aperture from AGP @ %Lx size %u MB (APSIZE %x)\n", aper, 32 << * order, apsizereg);
    if (!aperture_valid (aper, (32 * 1024 * 1024) << *order, 32 << 20))
        return 0;
    return (u32) aper;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="160" endline="163">
{
    printk (KERN_ERR "APSIZE in AGP bridge unreadable\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="187" endline="191">
{
    printk (KERN_INFO "Aperture size %u MB (APSIZE %x) is not right, using settings from NB\n", 32 << * order, apsizereg);
    *order = old_order;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="215" endline="253">
{
    int bus, slot, func;
    for (bus = 0; bus < 256; bus++) {
        for (slot = 0; slot < 32; slot++) {
            for (func = 0; func < 8; func++) {
                u32 class, cap;
                u8 type;
                class = read_pci_config (bus, slot, func, PCI_CLASS_REVISION);
                if (class == 0xffffffff)
                    break;
                switch (class >> 16) {
                case PCI_CLASS_BRIDGE_HOST :
                case PCI_CLASS_BRIDGE_OTHER :
                    cap = find_cap (bus, slot, func, PCI_CAP_ID_AGP);
                    if (!cap)
                        break;
                    *valid_agp = 1;
                    return read_agp (bus, slot, func, cap, order);
                }
                type = read_pci_config_byte (bus, slot, func, PCI_HEADER_TYPE);
                if (!(type & 0x80))
                    break;
            }
        }
    }
    printk (KERN_INFO "No AGP bridge found\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="219" endline="249">
{
    for (slot = 0; slot < 32; slot++) {
        for (func = 0; func < 8; func++) {
            u32 class, cap;
            u8 type;
            class = read_pci_config (bus, slot, func, PCI_CLASS_REVISION);
            if (class == 0xffffffff)
                break;
            switch (class >> 16) {
            case PCI_CLASS_BRIDGE_HOST :
            case PCI_CLASS_BRIDGE_OTHER :
                cap = find_cap (bus, slot, func, PCI_CAP_ID_AGP);
                if (!cap)
                    break;
                *valid_agp = 1;
                return read_agp (bus, slot, func, cap, order);
            }
            type = read_pci_config_byte (bus, slot, func, PCI_HEADER_TYPE);
            if (!(type & 0x80))
                break;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="220" endline="248">
{
    for (func = 0; func < 8; func++) {
        u32 class, cap;
        u8 type;
        class = read_pci_config (bus, slot, func, PCI_CLASS_REVISION);
        if (class == 0xffffffff)
            break;
        switch (class >> 16) {
        case PCI_CLASS_BRIDGE_HOST :
        case PCI_CLASS_BRIDGE_OTHER :
            cap = find_cap (bus, slot, func, PCI_CAP_ID_AGP);
            if (!cap)
                break;
            *valid_agp = 1;
            return read_agp (bus, slot, func, cap, order);
        }
        type = read_pci_config_byte (bus, slot, func, PCI_HEADER_TYPE);
        if (!(type & 0x80))
            break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="221" endline="247">
{
    u32 class, cap;
    u8 type;
    class = read_pci_config (bus, slot, func, PCI_CLASS_REVISION);
    if (class == 0xffffffff)
        break;
    switch (class >> 16) {
    case PCI_CLASS_BRIDGE_HOST :
    case PCI_CLASS_BRIDGE_OTHER :
        cap = find_cap (bus, slot, func, PCI_CAP_ID_AGP);
        if (!cap)
            break;
        *valid_agp = 1;
        return read_agp (bus, slot, func, cap, order);
    }
    type = read_pci_config_byte (bus, slot, func, PCI_HEADER_TYPE);
    if (!(type & 0x80))
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="229" endline="240">
{
case PCI_CLASS_BRIDGE_HOST :
case PCI_CLASS_BRIDGE_OTHER :
    cap = find_cap (bus, slot, func, PCI_CAP_ID_AGP);
    if (!cap)
        break;
    *valid_agp = 1;
    return read_agp (bus, slot, func, cap, order);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="258" endline="268">
{
    if (!p)
        return -EINVAL;
    if (!strncmp (p, "off", 3))
        gart_fix_e820 = 0;
    else if (!strncmp (p, "on", 2))
        gart_fix_e820 = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="272" endline="370">
{
    u32 agp_aper_base = 0, agp_aper_order = 0;
    int i, fix, slot, valid_agp = 0;
    u32 ctl;
    u32 aper_size = 0, aper_order = 0, last_aper_order = 0;
    u64 aper_base = 0, last_aper_base = 0;
    int aper_enabled = 0, last_aper_enabled = 0, last_valid = 0;
    if (!early_pci_allowed ())
        return;
    agp_aper_base = search_agp_bridge (&agp_aper_order, &valid_agp);
    fix = 0;
    for (i = 0; i < ARRAY_SIZE (bus_dev_ranges); i++) {
        int bus;
        int dev_base, dev_limit;
        bus = bus_dev_ranges[i].bus;
        dev_base = bus_dev_ranges[i].dev_base;
        dev_limit = bus_dev_ranges[i].dev_limit;
        for (slot = dev_base; slot < dev_limit; slot++) {
            if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
                continue;
            ctl = read_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL);
            aper_enabled = ctl & AMD64_GARTEN;
            aper_order = (ctl >> 1) & 7;
            aper_size = (32 * 1024 * 1024) << aper_order;
            aper_base = read_pci_config (bus, slot, 3, AMD64_GARTAPERTUREBASE) & 0x7fff;
            aper_base <<= 25;
            if (last_valid) {
                if ((aper_order != last_aper_order) || (aper_base != last_aper_base) || (aper_enabled != last_aper_enabled)) {
                    fix = 1;
                    break;
                }
            }
            last_aper_order = aper_order;
            last_aper_base = aper_base;
            last_aper_enabled = aper_enabled;
            last_valid = 1;
        }
    }
    if (!fix && !aper_enabled)
        return;
    if (!aper_base || !aper_size || aper_base + aper_size > 0x100000000UL)
        fix = 1;
    if (gart_fix_e820 && !fix && aper_enabled) {
        if (e820_any_mapped (aper_base, aper_base +aper_size, E820_RAM)) {
            printk (KERN_INFO "update e820 for GART\n");
            e820_add_region (aper_base, aper_size, E820_RESERVED);
            update_e820 ();
        }
    }
    if (valid_agp)
        return;
    for (i = 0; i < ARRAY_SIZE (bus_dev_ranges); i++) {
        int bus;
        int dev_base, dev_limit;
        bus = bus_dev_ranges[i].bus;
        dev_base = bus_dev_ranges[i].dev_base;
        dev_limit = bus_dev_ranges[i].dev_limit;
        for (slot = dev_base; slot < dev_limit; slot++) {
            if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
                continue;
            ctl = read_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL);
            ctl &= ~AMD64_GARTEN;
            write_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL, ctl);
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="297" endline="330">
{
    int bus;
    int dev_base, dev_limit;
    bus = bus_dev_ranges[i].bus;
    dev_base = bus_dev_ranges[i].dev_base;
    dev_limit = bus_dev_ranges[i].dev_limit;
    for (slot = dev_base; slot < dev_limit; slot++) {
        if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
            continue;
        ctl = read_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL);
        aper_enabled = ctl & AMD64_GARTEN;
        aper_order = (ctl >> 1) & 7;
        aper_size = (32 * 1024 * 1024) << aper_order;
        aper_base = read_pci_config (bus, slot, 3, AMD64_GARTAPERTUREBASE) & 0x7fff;
        aper_base <<= 25;
        if (last_valid) {
            if ((aper_order != last_aper_order) || (aper_base != last_aper_base) || (aper_enabled != last_aper_enabled)) {
                fix = 1;
                break;
            }
        }
        last_aper_order = aper_order;
        last_aper_base = aper_base;
        last_aper_enabled = aper_enabled;
        last_valid = 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="305" endline="329">
{
    if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
        continue;
    ctl = read_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL);
    aper_enabled = ctl & AMD64_GARTEN;
    aper_order = (ctl >> 1) & 7;
    aper_size = (32 * 1024 * 1024) << aper_order;
    aper_base = read_pci_config (bus, slot, 3, AMD64_GARTAPERTUREBASE) & 0x7fff;
    aper_base <<= 25;
    if (last_valid) {
        if ((aper_order != last_aper_order) || (aper_base != last_aper_base) || (aper_enabled != last_aper_enabled)) {
            fix = 1;
            break;
        }
    }
    last_aper_order = aper_order;
    last_aper_base = aper_base;
    last_aper_enabled = aper_enabled;
    last_valid = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="316" endline="323">
{
    if ((aper_order != last_aper_order) || (aper_base != last_aper_base) || (aper_enabled != last_aper_enabled)) {
        fix = 1;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="319" endline="322">
{
    fix = 1;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="338" endline="346">
{
    if (e820_any_mapped (aper_base, aper_base +aper_size, E820_RAM)) {
        printk (KERN_INFO "update e820 for GART\n");
        e820_add_region (aper_base, aper_size, E820_RESERVED);
        update_e820 ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="340" endline="345">
{
    printk (KERN_INFO "update e820 for GART\n");
    e820_add_region (aper_base, aper_size, E820_RESERVED);
    update_e820 ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="352" endline="368">
{
    int bus;
    int dev_base, dev_limit;
    bus = bus_dev_ranges[i].bus;
    dev_base = bus_dev_ranges[i].dev_base;
    dev_limit = bus_dev_ranges[i].dev_limit;
    for (slot = dev_base; slot < dev_limit; slot++) {
        if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
            continue;
        ctl = read_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL);
        ctl &= ~AMD64_GARTEN;
        write_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL, ctl);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="360" endline="367">
{
    if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
        continue;
    ctl = read_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL);
    ctl &= ~AMD64_GARTEN;
    write_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL, ctl);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="375" endline="527">
{
    u32 agp_aper_base = 0, agp_aper_order = 0;
    u32 aper_size, aper_alloc = 0, aper_order = 0, last_aper_order = 0;
    u64 aper_base, last_aper_base = 0;
    int fix, slot, valid_agp = 0;
    int i, node;
    if (gart_iommu_aperture_disabled || !fix_aperture || !early_pci_allowed ())
        return;
    printk (KERN_INFO "Checking aperture...\n");
    if (!fallback_aper_force)
        agp_aper_base = search_agp_bridge (&agp_aper_order, &valid_agp);
    fix = 0;
    node = 0;
    for (i = 0; i < ARRAY_SIZE (bus_dev_ranges); i++) {
        int bus;
        int dev_base, dev_limit;
        u32 ctl;
        bus = bus_dev_ranges[i].bus;
        dev_base = bus_dev_ranges[i].dev_base;
        dev_limit = bus_dev_ranges[i].dev_limit;
        for (slot = dev_base; slot < dev_limit; slot++) {
            if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
                continue;
            iommu_detected = 1;
            gart_iommu_aperture = 1;
            x86_init.iommu.iommu_init = gart_iommu_init;
            ctl = read_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL);
            ctl &= ~GARTEN;
            write_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL, ctl);
            aper_order = (ctl >> 1) & 7;
            aper_size = (32 * 1024 * 1024) << aper_order;
            aper_base = read_pci_config (bus, slot, 3, AMD64_GARTAPERTUREBASE) & 0x7fff;
            aper_base <<= 25;
            printk (KERN_INFO "Node %d: aperture @ %Lx size %u MB\n", node, aper_base, aper_size >> 20);
            node++;
            if (!aperture_valid (aper_base, aper_size, 64 << 20)) {
                if (valid_agp && agp_aper_base && agp_aper_base == aper_base && agp_aper_order == aper_order) {
                    if (!no_iommu && max_pfn > MAX_DMA32_PFN && !printed_gart_size_msg) {
                        printk (KERN_ERR "you are using iommu with agp, but GART size is less than 64M\n");
                        printk (KERN_ERR "please increase GART size in your BIOS setup\n");
                        printk (KERN_ERR "if BIOS doesn't have that option, contact your HW vendor!\n");
                        printed_gart_size_msg = 1;
                    }
                }
                else {
                    fix = 1;
                    goto out;
                }
            }
            if ((last_aper_order && aper_order != last_aper_order) || (last_aper_base && aper_base != last_aper_base)) {
                fix = 1;
                goto out;
            }
            last_aper_order = aper_order;
            last_aper_base = aper_base;
        }
    }
out :
    if (!fix && !fallback_aper_force) {
        if (last_aper_base) {
            unsigned long n = (32 * 1024 * 1024) << last_aper_order;
            insert_aperture_resource ((u32) last_aper_base, n);
        }
        return;
    }
    if (!fallback_aper_force) {
        aper_alloc = agp_aper_base;
        aper_order = agp_aper_order;
    }
    if (aper_alloc) {
    }
    else if ((!no_iommu && max_pfn > MAX_DMA32_PFN) || force_iommu || valid_agp || fallback_aper_force) {
        printk (KERN_INFO "Your BIOS doesn't leave a aperture memory hole\n");
        printk (KERN_INFO "Please enable the IOMMU option in the BIOS setup\n");
        printk (KERN_INFO "This costs you %d MB of RAM\n", 32 << fallback_aper_order);
        aper_order = fallback_aper_order;
        aper_alloc = allocate_aperture ();
        if (!aper_alloc) {
            panic ("Not enough memory for aperture");
        }
    }
    else {
        return;
    }
    for (i = 0; i < ARRAY_SIZE (bus_dev_ranges); i++) {
        int bus;
        int dev_base, dev_limit;
        bus = bus_dev_ranges[i].bus;
        dev_base = bus_dev_ranges[i].dev_base;
        dev_limit = bus_dev_ranges[i].dev_limit;
        for (slot = dev_base; slot < dev_limit; slot++) {
            if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
                continue;
            write_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL, aper_order << 1);
            write_pci_config (bus, slot, 3, AMD64_GARTAPERTUREBASE, aper_alloc >> 25);
        }
    }
    set_up_gart_resume (aper_order, aper_alloc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="393" endline="458">
{
    int bus;
    int dev_base, dev_limit;
    u32 ctl;
    bus = bus_dev_ranges[i].bus;
    dev_base = bus_dev_ranges[i].dev_base;
    dev_limit = bus_dev_ranges[i].dev_limit;
    for (slot = dev_base; slot < dev_limit; slot++) {
        if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
            continue;
        iommu_detected = 1;
        gart_iommu_aperture = 1;
        x86_init.iommu.iommu_init = gart_iommu_init;
        ctl = read_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL);
        ctl &= ~GARTEN;
        write_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL, ctl);
        aper_order = (ctl >> 1) & 7;
        aper_size = (32 * 1024 * 1024) << aper_order;
        aper_base = read_pci_config (bus, slot, 3, AMD64_GARTAPERTUREBASE) & 0x7fff;
        aper_base <<= 25;
        printk (KERN_INFO "Node %d: aperture @ %Lx size %u MB\n", node, aper_base, aper_size >> 20);
        node++;
        if (!aperture_valid (aper_base, aper_size, 64 << 20)) {
            if (valid_agp && agp_aper_base && agp_aper_base == aper_base && agp_aper_order == aper_order) {
                if (!no_iommu && max_pfn > MAX_DMA32_PFN && !printed_gart_size_msg) {
                    printk (KERN_ERR "you are using iommu with agp, but GART size is less than 64M\n");
                    printk (KERN_ERR "please increase GART size in your BIOS setup\n");
                    printk (KERN_ERR "if BIOS doesn't have that option, contact your HW vendor!\n");
                    printed_gart_size_msg = 1;
                }
            }
            else {
                fix = 1;
                goto out;
            }
        }
        if ((last_aper_order && aper_order != last_aper_order) || (last_aper_base && aper_base != last_aper_base)) {
            fix = 1;
            goto out;
        }
        last_aper_order = aper_order;
        last_aper_base = aper_base;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="402" endline="457">
{
    if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
        continue;
    iommu_detected = 1;
    gart_iommu_aperture = 1;
    x86_init.iommu.iommu_init = gart_iommu_init;
    ctl = read_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL);
    ctl &= ~GARTEN;
    write_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL, ctl);
    aper_order = (ctl >> 1) & 7;
    aper_size = (32 * 1024 * 1024) << aper_order;
    aper_base = read_pci_config (bus, slot, 3, AMD64_GARTAPERTUREBASE) & 0x7fff;
    aper_base <<= 25;
    printk (KERN_INFO "Node %d: aperture @ %Lx size %u MB\n", node, aper_base, aper_size >> 20);
    node++;
    if (!aperture_valid (aper_base, aper_size, 64 << 20)) {
        if (valid_agp && agp_aper_base && agp_aper_base == aper_base && agp_aper_order == aper_order) {
            if (!no_iommu && max_pfn > MAX_DMA32_PFN && !printed_gart_size_msg) {
                printk (KERN_ERR "you are using iommu with agp, but GART size is less than 64M\n");
                printk (KERN_ERR "please increase GART size in your BIOS setup\n");
                printk (KERN_ERR "if BIOS doesn't have that option, contact your HW vendor!\n");
                printed_gart_size_msg = 1;
            }
        }
        else {
            fix = 1;
            goto out;
        }
    }
    if ((last_aper_order && aper_order != last_aper_order) || (last_aper_base && aper_base != last_aper_base)) {
        fix = 1;
        goto out;
    }
    last_aper_order = aper_order;
    last_aper_base = aper_base;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="431" endline="448">
{
    if (valid_agp && agp_aper_base && agp_aper_base == aper_base && agp_aper_order == aper_order) {
        if (!no_iommu && max_pfn > MAX_DMA32_PFN && !printed_gart_size_msg) {
            printk (KERN_ERR "you are using iommu with agp, but GART size is less than 64M\n");
            printk (KERN_ERR "please increase GART size in your BIOS setup\n");
            printk (KERN_ERR "if BIOS doesn't have that option, contact your HW vendor!\n");
            printed_gart_size_msg = 1;
        }
    }
    else {
        fix = 1;
        goto out;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="434" endline="444">
{
    if (!no_iommu && max_pfn > MAX_DMA32_PFN && !printed_gart_size_msg) {
        printk (KERN_ERR "you are using iommu with agp, but GART size is less than 64M\n");
        printk (KERN_ERR "please increase GART size in your BIOS setup\n");
        printk (KERN_ERR "if BIOS doesn't have that option, contact your HW vendor!\n");
        printed_gart_size_msg = 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="438" endline="443">
{
    printk (KERN_ERR "you are using iommu with agp, but GART size is less than 64M\n");
    printk (KERN_ERR "please increase GART size in your BIOS setup\n");
    printk (KERN_ERR "if BIOS doesn't have that option, contact your HW vendor!\n");
    printed_gart_size_msg = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="444" endline="447">
{
    fix = 1;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="451" endline="454">
{
    fix = 1;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="461" endline="468">
{
    if (last_aper_base) {
        unsigned long n = (32 * 1024 * 1024) << last_aper_order;
        insert_aperture_resource ((u32) last_aper_base, n);
    }
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="462" endline="466">
{
    unsigned long n = (32 * 1024 * 1024) << last_aper_order;
    insert_aperture_resource ((u32) last_aper_base, n);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="470" endline="473">
{
    aper_alloc = agp_aper_base;
    aper_order = agp_aper_order;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="475" endline="477">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="480" endline="502">
{
    printk (KERN_INFO "Your BIOS doesn't leave a aperture memory hole\n");
    printk (KERN_INFO "Please enable the IOMMU option in the BIOS setup\n");
    printk (KERN_INFO "This costs you %d MB of RAM\n", 32 << fallback_aper_order);
    aper_order = fallback_aper_order;
    aper_alloc = allocate_aperture ();
    if (!aper_alloc) {
        panic ("Not enough memory for aperture");
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="491" endline="501">
{
    panic ("Not enough memory for aperture");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="502" endline="504">
{
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="507" endline="524">
{
    int bus;
    int dev_base, dev_limit;
    bus = bus_dev_ranges[i].bus;
    dev_base = bus_dev_ranges[i].dev_base;
    dev_limit = bus_dev_ranges[i].dev_limit;
    for (slot = dev_base; slot < dev_limit; slot++) {
        if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
            continue;
        write_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL, aper_order << 1);
        write_pci_config (bus, slot, 3, AMD64_GARTAPERTUREBASE, aper_alloc >> 25);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/aperture_64.c.ifdefed" startline="514" endline="523">
{
    if (!early_is_k8_nb (read_pci_config (bus, slot, 3, 0x00)))
        continue;
    write_pci_config (bus, slot, 3, AMD64_GARTAPERTURECTL, aper_order << 1);
    write_pci_config (bus, slot, 3, AMD64_GARTAPERTUREBASE, aper_alloc >> 25);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="124" endline="129">
{
    struct cpu_info_ctx *ctx = arg;
    ctx->err = microcode_ops->collect_cpu_info (smp_processor_id (), ctx->cpu_sig);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="132" endline="141">
{
    struct cpu_info_ctx ctx = {
        .cpu_sig = cpu_sig,
        .err = 0
    };
    int ret;
    ret = smp_call_function_single (cpu, collect_cpu_info_local, &ctx, 1);
    if (!ret)
        ret = ctx.err;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="144" endline="155">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
    int ret;
    memset (uci, 0, sizeof (* uci));
    ret = collect_cpu_info_on_target (cpu, &uci->cpu_sig);
    if (!ret)
        uci->valid = 1;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="162" endline="166">
{
    struct apply_microcode_ctx *ctx = arg;
    ctx->err = microcode_ops->apply_microcode (smp_processor_id ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="169" endline="178">
{
    struct apply_microcode_ctx ctx = {
        .err = 0
    };
    int ret;
    ret = smp_call_function_single (cpu, apply_microcode_local, &ctx, 1);
    if (!ret)
        ret = ctx.err;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="272" endline="290">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
    int err = 0;
    mutex_lock (& microcode_mutex);
    if (uci->valid) {
        enum ucode_state ustate;
        ustate = microcode_ops->request_microcode_fw (cpu, &microcode_pdev->dev);
        if (ustate == UCODE_OK)
            apply_microcode_on_target (cpu);
        else if (ustate == UCODE_ERROR)
            err = -EINVAL;
    }
    mutex_unlock (& microcode_mutex);
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="277" endline="286">
{
    enum ucode_state ustate;
    ustate = microcode_ops->request_microcode_fw (cpu, &microcode_pdev->dev);
    if (ustate == UCODE_OK)
        apply_microcode_on_target (cpu);
    else if (ustate == UCODE_ERROR)
        err = -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="295" endline="316">
{
    unsigned long val;
    int cpu = dev->id;
    int ret = 0;
    char *end;
    val = simple_strtoul (buf, &end, 0);
    if (end == buf)
        return -EINVAL;
    if (val == 1) {
        get_online_cpus ();
        if (cpu_online (cpu))
            ret = reload_for_cpu (cpu);
        put_online_cpus ();
    }
    if (!ret)
        ret = size;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="305" endline="310">
{
    get_online_cpus ();
    if (cpu_online (cpu))
        ret = reload_for_cpu (cpu);
    put_online_cpus ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="320" endline="324">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + dev->id;
    return sprintf (buf, "0x%x\n", uci->cpu_sig.rev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="328" endline="332">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + dev->id;
    return sprintf (buf, "0x%x\n", uci->cpu_sig.pf);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="351" endline="356">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
    microcode_ops->microcode_fini_cpu (cpu);
    uci->valid = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="359" endline="369">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
    if (!uci->mc)
        return UCODE_NFOUND;
    pr_debug ("CPU%d updated upon resume\n", cpu);
    apply_microcode_on_target (cpu);
    return UCODE_OK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="372" endline="390">
{
    enum ucode_state ustate;
    if (collect_cpu_info (cpu))
        return UCODE_ERROR;
    if (system_state != SYSTEM_RUNNING)
        return UCODE_NFOUND;
    ustate = microcode_ops->request_microcode_fw (cpu, &microcode_pdev->dev);
    if (ustate == UCODE_OK) {
        pr_debug ("CPU%d updated upon init\n", cpu);
        apply_microcode_on_target (cpu);
    }
    return ustate;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="384" endline="387">
{
    pr_debug ("CPU%d updated upon init\n", cpu);
    apply_microcode_on_target (cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="393" endline="403">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
    enum ucode_state ustate;
    if (uci->valid)
        ustate = microcode_resume_cpu (cpu);
    else
        ustate = microcode_init_cpu (cpu);
    return ustate;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="406" endline="422">
{
    int err, cpu = sys_dev->id;
    if (!cpu_online (cpu))
        return 0;
    pr_debug ("CPU%d added\n", cpu);
    err = sysfs_create_group (&sys_dev->kobj, &mc_attr_group);
    if (err)
        return err;
    if (microcode_init_cpu (cpu) == UCODE_ERROR)
        err = -EINVAL;
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="425" endline="435">
{
    int cpu = sys_dev->id;
    if (!cpu_online (cpu))
        return 0;
    pr_debug ("CPU%d removed\n", cpu);
    microcode_fini_cpu (cpu);
    sysfs_remove_group (& sys_dev -> kobj, & mc_attr_group);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="438" endline="458">
{
    int cpu = dev->id;
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
    if (!cpu_online (cpu))
        return 0;
    WARN_ON (cpu != 0);
    if (uci->valid && uci->mc)
        microcode_ops->apply_microcode (cpu);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="468" endline="496">
{
    unsigned int cpu = (unsigned long) hcpu;
    struct sys_device *sys_dev;
    sys_dev = get_cpu_sysdev (cpu);
    switch (action) {
    case CPU_ONLINE :
    case CPU_ONLINE_FROZEN :
        microcode_update_cpu (cpu);
    case CPU_DOWN_FAILED :
    case CPU_DOWN_FAILED_FROZEN :
        pr_debug ("CPU%d added\n", cpu);
        if (sysfs_create_group (&sys_dev->kobj, &mc_attr_group))
            pr_err ("Failed to create group for CPU%d\n", cpu);
        break;
    case CPU_DOWN_PREPARE :
    case CPU_DOWN_PREPARE_FROZEN :
        sysfs_remove_group (&sys_dev->kobj, &mc_attr_group);
        pr_debug ("CPU%d removed\n", cpu);
        break;
    case CPU_DEAD :
    case CPU_UP_CANCELED_FROZEN :
        microcode_fini_cpu (cpu);
        break;
    }
    return NOTIFY_OK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="473" endline="494">
{
case CPU_ONLINE :
case CPU_ONLINE_FROZEN :
    microcode_update_cpu (cpu);
case CPU_DOWN_FAILED :
case CPU_DOWN_FAILED_FROZEN :
    pr_debug ("CPU%d added\n", cpu);
    if (sysfs_create_group (&sys_dev->kobj, &mc_attr_group))
        pr_err ("Failed to create group for CPU%d\n", cpu);
    break;
case CPU_DOWN_PREPARE :
case CPU_DOWN_PREPARE_FROZEN :
    sysfs_remove_group (&sys_dev->kobj, &mc_attr_group);
    pr_debug ("CPU%d removed\n", cpu);
    break;
case CPU_DEAD :
case CPU_UP_CANCELED_FROZEN :
    microcode_fini_cpu (cpu);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="503" endline="547">
{
    struct cpuinfo_x86 *c = &cpu_data (0);
    int error;
    if (c->x86_vendor == X86_VENDOR_INTEL)
        microcode_ops = init_intel_microcode ();
    else if (c->x86_vendor == X86_VENDOR_AMD)
        microcode_ops = init_amd_microcode ();
    if (!microcode_ops) {
        pr_err ("no support for this CPU vendor\n");
        return -ENODEV;
    }
    microcode_pdev = platform_device_register_simple ("microcode", -1, NULL, 0);
    if (IS_ERR (microcode_pdev)) {
        microcode_dev_exit ();
        return PTR_ERR (microcode_pdev);
    }
    get_online_cpus ();
    mutex_lock (& microcode_mutex);
    error = sysdev_driver_register (&cpu_sysdev_class, &mc_sysdev_driver);
    mutex_unlock (& microcode_mutex);
    put_online_cpus ();
    if (error) {
        platform_device_unregister (microcode_pdev);
        return error;
    }
    error = microcode_dev_init ();
    if (error)
        return error;
    register_hotcpu_notifier (& mc_cpu_notifier);
    pr_info ("Microcode Update Driver: v" MICROCODE_VERSION " <tigran@aivazian.fsnet.co.uk>, Peter Oruba\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="512" endline="515">
{
    pr_err ("no support for this CPU vendor\n");
    return -ENODEV;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="519" endline="522">
{
    microcode_dev_exit ();
    return PTR_ERR (microcode_pdev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="532" endline="535">
{
    platform_device_unregister (microcode_pdev);
    return error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_core.c.ifdefed" startline="551" endline="569">
{
    microcode_dev_exit ();
    unregister_hotcpu_notifier (& mc_cpu_notifier);
    get_online_cpus ();
    mutex_lock (& microcode_mutex);
    sysdev_driver_unregister (& cpu_sysdev_class, & mc_sysdev_driver);
    mutex_unlock (& microcode_mutex);
    put_online_cpus ();
    platform_device_unregister (microcode_pdev);
    microcode_ops = NULL;
    pr_info ("Microcode Update Driver: v" MICROCODE_VERSION " removed.\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/crash_dump_64.c.ifdefed" startline="31" endline="51">
{
    void *vaddr;
    if (!csize)
        return 0;
    vaddr = ioremap (pfn << PAGE_SHIFT, PAGE_SIZE);
    if (!vaddr)
        return -ENOMEM;
    if (userbuf) {
        if (copy_to_user (buf, vaddr +offset, csize)) {
            iounmap (vaddr);
            return -EFAULT;
        }
    }
    else
        memcpy (buf, vaddr +offset, csize);
    iounmap (vaddr);
    return csize;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/crash_dump_64.c.ifdefed" startline="41" endline="46">
{
    if (copy_to_user (buf, vaddr +offset, csize)) {
        iounmap (vaddr);
        return -EFAULT;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/crash_dump_64.c.ifdefed" startline="42" endline="45">
{
    iounmap (vaddr);
    return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="67" endline="74">
{
    unsigned long flags;
    write_seqlock_irqsave (& vsyscall_gtod_data.lock, flags);
    vsyscall_gtod_data.sys_tz = sys_tz;
    write_sequnlock_irqrestore (& vsyscall_gtod_data.lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="78" endline="93">
{
    unsigned long flags;
    write_seqlock_irqsave (& vsyscall_gtod_data.lock, flags);
    vsyscall_gtod_data.clock.vread = clock->vread;
    vsyscall_gtod_data.clock.cycle_last = clock->cycle_last;
    vsyscall_gtod_data.clock.mask = clock->mask;
    vsyscall_gtod_data.clock.mult = mult;
    vsyscall_gtod_data.clock.shift = clock->shift;
    vsyscall_gtod_data.wall_time_sec = wall_time->tv_sec;
    vsyscall_gtod_data.wall_time_nsec = wall_time->tv_nsec;
    vsyscall_gtod_data.wall_to_monotonic = wall_to_monotonic;
    vsyscall_gtod_data.wall_time_coarse = __current_kernel_time ();
    write_sequnlock_irqrestore (& vsyscall_gtod_data.lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="99" endline="101">
{
    *tz = __vsyscall_gtod_data.sys_tz;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="104" endline="111">
{
    int ret;
    asm volatile ("syscall"
        : "=a" (ret)
        : "0" (__NR_gettimeofday), "D" (tv), "S" (tz)
        : __syscall_clobber
    ) return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="114" endline="120">
{
    long secs;
    asm volatile ("syscall"
        : "=a" (secs)
        : "0" (__NR_time), "D" (t)
        : __syscall_clobber
    ) return secs;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="123" endline="157">
{
    cycle_t now, base, mask, cycle_delta;
    unsigned seq;
    unsigned long mult, shift, nsec;
    cycle_t (*vread) (void);
    do {
        seq = read_seqbegin (&__vsyscall_gtod_data.lock);
        vread = __vsyscall_gtod_data.clock.vread;
        if (unlikely (!__vsyscall_gtod_data.sysctl_enabled || !vread)) {
            gettimeofday (tv, NULL);
            return;
        }
        now = vread ();
        base = __vsyscall_gtod_data.clock.cycle_last;
        mask = __vsyscall_gtod_data.clock.mask;
        mult = __vsyscall_gtod_data.clock.mult;
        shift = __vsyscall_gtod_data.clock.shift;
        tv->tv_sec = __vsyscall_gtod_data.wall_time_sec;
        nsec = __vsyscall_gtod_data.wall_time_nsec;
    }
    while (read_seqretry (&__vsyscall_gtod_data.lock, seq));
    cycle_delta = (now - base) & mask;
    nsec += (cycle_delta * mult) >> shift;
    while (nsec >= NSEC_PER_SEC) {
        tv->tv_sec += 1;
        nsec -= NSEC_PER_SEC;
    }
    tv->tv_usec = nsec / NSEC_PER_USEC;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="128" endline="145">
{
    seq = read_seqbegin (&__vsyscall_gtod_data.lock);
    vread = __vsyscall_gtod_data.clock.vread;
    if (unlikely (!__vsyscall_gtod_data.sysctl_enabled || !vread)) {
        gettimeofday (tv, NULL);
        return;
    }
    now = vread ();
    base = __vsyscall_gtod_data.clock.cycle_last;
    mask = __vsyscall_gtod_data.clock.mask;
    mult = __vsyscall_gtod_data.clock.mult;
    shift = __vsyscall_gtod_data.clock.shift;
    tv->tv_sec = __vsyscall_gtod_data.wall_time_sec;
    nsec = __vsyscall_gtod_data.wall_time_nsec;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="132" endline="135">
{
    gettimeofday (tv, NULL);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="152" endline="155">
{
    tv->tv_sec += 1;
    nsec -= NSEC_PER_SEC;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="160" endline="166">
{
    if (tv)
        do_vgettimeofday (tv);
    if (tz)
        do_get_tz (tz);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="171" endline="182">
{
    struct timeval tv;
    time_t result;
    if (unlikely (!__vsyscall_gtod_data.sysctl_enabled))
        return time_syscall (t);
    vgettimeofday (& tv, NULL);
    result = tv.tv_sec;
    if (t)
        *t = result;
    return result;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="194" endline="224">
{
    unsigned int p;
    unsigned long j = 0;
    if (tcache && tcache->blob[0] == (j = __jiffies)) {
        p = tcache->blob[1];
    }
    else if (__vgetcpu_mode == VGETCPU_RDTSCP) {
        native_read_tscp (& p);
    }
    else {
        asm ("lsl %1,%0"
            : "=r" (p)
            : "r" (__PER_CPU_SEG)
        )}
    if (tcache) {
        tcache->blob[0] = j;
        tcache->blob[1] = p;
    }
    if (cpu)
        *cpu = p & 0xfff;
    if (node)
        *node = p >> 12;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="206" endline="208">
{
    p = tcache->blob[1];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="208" endline="211">
{
    native_read_tscp (& p);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="211" endline="214">
{
    asm ("lsl %1,%0"
        : "=r" (p)
        : "r" (__PER_CPU_SEG)
    )}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="215" endline="218">
{
    tcache->blob[0] = j;
    tcache->blob[1] = p;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="227" endline="229">
{
    return -ENOSYS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="250" endline="267">
{
    unsigned long d;
    unsigned long node = 0;
    if (cpu_has (&cpu_data (cpu), X86_FEATURE_RDTSCP))
        write_rdtscp_aux ((node << 12) | cpu);
    d = 0x0f40000000000ULL;
    d |= cpu;
    d |= (node & 0xf) << 12;
    d |= (node >> 4) << 48;
    write_gdt_entry (get_cpu_gdt_table (cpu), GDT_ENTRY_PER_CPU, & d, DESCTYPE_S);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="270" endline="273">
{
    vsyscall_set_cpu (raw_smp_processor_id ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="277" endline="282">
{
    long cpu = (long) arg;
    if (action == CPU_ONLINE || action == CPU_ONLINE_FROZEN)
        smp_call_function_single (cpu, cpu_vsyscall_init, NULL, 1);
    return NOTIFY_DONE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="285" endline="291">
{
    extern char __vsyscall_0;
    unsigned long physaddr_page0 = __pa_symbol (&__vsyscall_0);
    __set_fixmap (VSYSCALL_FIRST_PAGE, physaddr_page0, PAGE_KERNEL_VSYSCALL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsyscall_64.c.ifdefed" startline="294" endline="307">
{
    BUG_ON (((unsigned long) & vgettimeofday != VSYSCALL_ADDR (__NR_vgettimeofday)));
    BUG_ON ((unsigned long) & vtime != VSYSCALL_ADDR (__NR_vtime));
    BUG_ON ((VSYSCALL_ADDR (0) != __fix_to_virt (VSYSCALL_FIRST_PAGE)));
    BUG_ON ((unsigned long) & vgetcpu != VSYSCALL_ADDR (__NR_vgetcpu));
    on_each_cpu (cpu_vsyscall_init, NULL, 1);
    hotcpu_notifier (cpu_vsyscall_notifier, 30);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="39" endline="46">
{
    int sum = 0;
    while (len--)
        sum += *mp++;
    return sum & 0xFF;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="49" endline="51">
{
    return m->apicid;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="54" endline="72">
{
    int apicid;
    char *bootup_cpu = "";
    if (!(m->cpuflag & CPU_ENABLED)) {
        disabled_cpus++;
        return;
    }
    apicid = x86_init.mpparse.mpc_apic_id (m);
    if (m->cpuflag & CPU_BOOTPROCESSOR) {
        bootup_cpu = " (Bootup-CPU)";
        boot_cpu_physical_apicid = m->apicid;
    }
    printk (KERN_INFO "Processor #%d%s\n", m -> apicid, bootup_cpu);
    generic_processor_info (apicid, m -> apicver);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="58" endline="61">
{
    disabled_cpus++;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="65" endline="68">
{
    bootup_cpu = " (Bootup-CPU)";
    boot_cpu_physical_apicid = m->apicid;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="230" endline="230">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="231" endline="231">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="232" endline="232">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="237" endline="242">
{
    apic_printk (APIC_VERBOSE, "Lint: type %d, pol %d, trig %d, bus %02x," " IRQ %02x, APIC ID %x, APIC LINT %02x\n", m -> irqtype, m -> irqflag & 3, (m -> irqflag >> 2) & 3, m -> srcbusid, m -> srcbusirq, m -> destapic, m -> destapiclint);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="249" endline="282">
{
    if (memcmp (mpc->signature, MPC_SIGNATURE, 4)) {
        printk (KERN_ERR "MPTABLE: bad signature [%c%c%c%c]!\n", mpc -> signature [0], mpc -> signature [1], mpc -> signature [2], mpc -> signature [3]);
        return 0;
    }
    if (mpf_checksum ((unsigned char *) mpc, mpc->length)) {
        printk (KERN_ERR "MPTABLE: checksum error!\n");
        return 0;
    }
    if (mpc->spec != 0x01 && mpc->spec != 0x04) {
        printk (KERN_ERR "MPTABLE: bad table version (%d)!!\n", mpc -> spec);
        return 0;
    }
    if (!mpc->lapic) {
        printk (KERN_ERR "MPTABLE: null local APIC address!\n");
        return 0;
    }
    memcpy (oem, mpc -> oem, 8);
    oem[8] = 0;
    printk (KERN_INFO "MPTABLE: OEM ID: %s\n", oem);
    memcpy (str, mpc -> productid, 12);
    str[12] = 0;
    printk (KERN_INFO "MPTABLE: Product ID: %s\n", str);
    printk (KERN_INFO "MPTABLE: APIC at: 0x%X\n", mpc -> lapic);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="251" endline="256">
{
    printk (KERN_ERR "MPTABLE: bad signature [%c%c%c%c]!\n", mpc -> signature [0], mpc -> signature [1], mpc -> signature [2], mpc -> signature [3]);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="257" endline="260">
{
    printk (KERN_ERR "MPTABLE: checksum error!\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="261" endline="265">
{
    printk (KERN_ERR "MPTABLE: bad table version (%d)!!\n", mpc -> spec);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="266" endline="269">
{
    printk (KERN_ERR "MPTABLE: null local APIC address!\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="285" endline="288">
{
    *ptr += size;
    *count += size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="291" endline="296">
{
    printk (KERN_ERR "Your mptable is wrong, contact your HW vendor!\n" "type %x\n", * mpt);
    print_hex_dump (KERN_ERR, "  ", DUMP_PREFIX_ADDRESS, 16, 1, mpc, mpc -> length, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="298" endline="298">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="301" endline="365">
{
    char str [16];
    char oem [10];
    int count = sizeof (*mpc);
    unsigned char *mpt = ((unsigned char *) mpc) + count;
    if (!smp_check_mpc (mpc, oem, str))
        return 0;
    if (!acpi_lapic)
        mp_lapic_addr = mpc->lapic;
    if (early)
        return 1;
    if (mpc->oemptr)
        x86_init.mpparse.smp_read_mpc_oem (mpc);
    x86_init.mpparse.mpc_record (0);
    while (count < mpc->length) {
        switch (*mpt) {
        case MP_PROCESSOR :
            if (!acpi_lapic)
                MP_processor_info ((struct mpc_cpu *) mpt);
            skip_entry (& mpt, & count, sizeof (struct mpc_cpu));
            break;
        case MP_BUS :
            MP_bus_info ((struct mpc_bus *) mpt);
            skip_entry (& mpt, & count, sizeof (struct mpc_bus));
            break;
        case MP_IOAPIC :
            MP_ioapic_info ((struct mpc_ioapic *) mpt);
            skip_entry (& mpt, & count, sizeof (struct mpc_ioapic));
            break;
        case MP_INTSRC :
            MP_intsrc_info ((struct mpc_intsrc *) mpt);
            skip_entry (& mpt, & count, sizeof (struct mpc_intsrc));
            break;
        case MP_LINTSRC :
            MP_lintsrc_info ((struct mpc_lintsrc *) mpt);
            skip_entry (& mpt, & count, sizeof (struct mpc_lintsrc));
            break;
        default :
            smp_dump_mptable (mpc, mpt);
            count = mpc->length;
            break;
        }
        x86_init.mpparse.mpc_record (1);
    }
    if (!num_processors)
        printk (KERN_ERR "MPTABLE: no processors registered!\n");
    return num_processors;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="329" endline="360">
{
    switch (*mpt) {
    case MP_PROCESSOR :
        if (!acpi_lapic)
            MP_processor_info ((struct mpc_cpu *) mpt);
        skip_entry (& mpt, & count, sizeof (struct mpc_cpu));
        break;
    case MP_BUS :
        MP_bus_info ((struct mpc_bus *) mpt);
        skip_entry (& mpt, & count, sizeof (struct mpc_bus));
        break;
    case MP_IOAPIC :
        MP_ioapic_info ((struct mpc_ioapic *) mpt);
        skip_entry (& mpt, & count, sizeof (struct mpc_ioapic));
        break;
    case MP_INTSRC :
        MP_intsrc_info ((struct mpc_intsrc *) mpt);
        skip_entry (& mpt, & count, sizeof (struct mpc_intsrc));
        break;
    case MP_LINTSRC :
        MP_lintsrc_info ((struct mpc_lintsrc *) mpt);
        skip_entry (& mpt, & count, sizeof (struct mpc_lintsrc));
        break;
    default :
        smp_dump_mptable (mpc, mpt);
        count = mpc->length;
        break;
    }
    x86_init.mpparse.mpc_record (1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="330" endline="358">
{
case MP_PROCESSOR :
    if (!acpi_lapic)
        MP_processor_info ((struct mpc_cpu *) mpt);
    skip_entry (& mpt, & count, sizeof (struct mpc_cpu));
    break;
case MP_BUS :
    MP_bus_info ((struct mpc_bus *) mpt);
    skip_entry (& mpt, & count, sizeof (struct mpc_bus));
    break;
case MP_IOAPIC :
    MP_ioapic_info ((struct mpc_ioapic *) mpt);
    skip_entry (& mpt, & count, sizeof (struct mpc_ioapic));
    break;
case MP_INTSRC :
    MP_intsrc_info ((struct mpc_intsrc *) mpt);
    skip_entry (& mpt, & count, sizeof (struct mpc_intsrc));
    break;
case MP_LINTSRC :
    MP_lintsrc_info ((struct mpc_lintsrc *) mpt);
    skip_entry (& mpt, & count, sizeof (struct mpc_lintsrc));
    break;
default :
    smp_dump_mptable (mpc, mpt);
    count = mpc->length;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="493" endline="493">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="497" endline="537">
{
    struct mpc_cpu processor;
    struct mpc_lintsrc lintsrc;
    int linttypes [2] = {mp_ExtINT, mp_NMI};
    int i;
    mp_lapic_addr = APIC_DEFAULT_PHYS_BASE;
    processor.type = MP_PROCESSOR;
    processor.apicver = mpc_default_type > 4 ? 0x10 : 0x01;
    processor.cpuflag = CPU_ENABLED;
    processor.cpufeature = (boot_cpu_data.x86 << 8) | (boot_cpu_data.x86_model << 4) | boot_cpu_data.x86_mask;
    processor.featureflag = boot_cpu_data.x86_capability[0];
    processor.reserved[0] = 0;
    processor.reserved[1] = 0;
    for (i = 0; i < 2; i++) {
        processor.apicid = i;
        MP_processor_info (& processor);
    }
    construct_ioapic_table (mpc_default_type);
    lintsrc.type = MP_LINTSRC;
    lintsrc.irqflag = 0;
    lintsrc.srcbusid = 0;
    lintsrc.srcbusirq = 0;
    lintsrc.destapic = MP_APIC_ALL;
    for (i = 0; i < 2; i++) {
        lintsrc.irqtype = linttypes[i];
        lintsrc.destapiclint = i;
        MP_lintsrc_info (& lintsrc);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="520" endline="523">
{
    processor.apicid = i;
    MP_processor_info (& processor);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="532" endline="536">
{
    lintsrc.irqtype = linttypes[i];
    lintsrc.destapiclint = i;
    MP_lintsrc_info (& lintsrc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="542" endline="552">
{
    struct mpc_table *mpc;
    unsigned long size;
    mpc = early_ioremap (physptr, PAGE_SIZE);
    size = mpc->length;
    early_iounmap (mpc, PAGE_SIZE);
    apic_printk (APIC_VERBOSE, "  mpc: %lx-%lx\n", physptr, physptr + size);
    return size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="555" endline="601">
{
    struct mpc_table *mpc;
    unsigned long size;
    size = get_mpc_size (mpf->physptr);
    mpc = early_ioremap (mpf->physptr, size);
    if (!smp_read_mpc (mpc, early)) {
        printk (KERN_ERR "BIOS bug, MP table errors detected!...\n" "... disabling SMP support. (tell your hw vendor)\n");
        early_iounmap (mpc, size);
        return -1;
    }
    early_iounmap (mpc, size);
    if (early)
        return -1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="565" endline="573">
{
    printk (KERN_ERR "BIOS bug, MP table errors detected!...\n" "... disabling SMP support. (tell your hw vendor)\n");
    early_iounmap (mpc, size);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="607" endline="661">
{
    struct mpf_intel *mpf = mpf_found;
    if (!mpf)
        return;
    if (acpi_lapic && early)
        return;
    if (acpi_lapic && acpi_ioapic)
        return;
    printk (KERN_INFO "Intel MultiProcessor Specification v1.%d\n", mpf -> specification);
    if (mpf->feature1 != 0) {
        if (early) {
            mp_lapic_addr = APIC_DEFAULT_PHYS_BASE;
            return;
        }
        printk (KERN_INFO "Default MP configuration #%d\n", mpf -> feature1);
        construct_default_ISA_mptable (mpf -> feature1);
    }
    else if (mpf->physptr) {
        if (check_physptr (mpf, early))
            return;
    }
    else
        BUG ();
    if (!early)
        printk (KERN_INFO "Processors: %d\n", num_processors);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="637" endline="650">
{
    if (early) {
        mp_lapic_addr = APIC_DEFAULT_PHYS_BASE;
        return;
    }
    printk (KERN_INFO "Default MP configuration #%d\n", mpf -> feature1);
    construct_default_ISA_mptable (mpf -> feature1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="638" endline="644">
{
    mp_lapic_addr = APIC_DEFAULT_PHYS_BASE;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="650" endline="653">
{
    if (check_physptr (mpf, early))
        return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="664" endline="668">
{
    unsigned long size = get_mpc_size (mpf->physptr);
    reserve_early_overlap_ok (mpf -> physptr, mpf -> physptr + size, "MP-table mpc");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="671" endline="706">
{
    unsigned int *bp = phys_to_virt (base);
    struct mpf_intel *mpf;
    unsigned long mem;
    apic_printk (APIC_VERBOSE, "Scan SMP from %p for %ld bytes.\n", bp, length);
    BUILD_BUG_ON (sizeof (* mpf) != 16);
    while (length > 0) {
        mpf = (struct mpf_intel *) bp;
        if ((*bp == SMP_MAGIC_IDENT) && (mpf->length == 1) && !mpf_checksum ((unsigned char *) bp, 16) && ((mpf->specification == 1) || (mpf->specification == 4))) {
            mpf_found = mpf;
            printk (KERN_INFO "found SMP MP-table at [%p] %llx\n", mpf, (u64) virt_to_phys (mpf));
            mem = virt_to_phys (mpf);
            reserve_early_overlap_ok (mem, mem + sizeof (* mpf), "MP-table mpf");
            if (mpf->physptr)
                smp_reserve_memory (mpf);
            return 1;
        }
        bp += 4;
        length -= 16;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="680" endline="704">
{
    mpf = (struct mpf_intel *) bp;
    if ((*bp == SMP_MAGIC_IDENT) && (mpf->length == 1) && !mpf_checksum ((unsigned char *) bp, 16) && ((mpf->specification == 1) || (mpf->specification == 4))) {
        mpf_found = mpf;
        printk (KERN_INFO "found SMP MP-table at [%p] %llx\n", mpf, (u64) virt_to_phys (mpf));
        mem = virt_to_phys (mpf);
        reserve_early_overlap_ok (mem, mem + sizeof (* mpf), "MP-table mpf");
        if (mpf->physptr)
            smp_reserve_memory (mpf);
        return 1;
    }
    bp += 4;
    length -= 16;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="686" endline="701">
{
    mpf_found = mpf;
    printk (KERN_INFO "found SMP MP-table at [%p] %llx\n", mpf, (u64) virt_to_phys (mpf));
    mem = virt_to_phys (mpf);
    reserve_early_overlap_ok (mem, mem + sizeof (* mpf), "MP-table mpf");
    if (mpf->physptr)
        smp_reserve_memory (mpf);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="709" endline="744">
{
    unsigned int address;
    if (smp_scan_config (0x0, 0x400) || smp_scan_config (639 * 0x400, 0x400) || smp_scan_config (0xF0000, 0x10000))
        return;
    address = get_bios_ebda ();
    if (address)
        smp_scan_config (address, 0x400);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="817" endline="817">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="822" endline="831">
{
    int ret = 0;
    if (!mpc_new_phys || count <= mpc_new_length) {
        WARN (1, "update_mptable: No spare slots (length: %x)\n", count);
        return -1;
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="825" endline="828">
{
    WARN (1, "update_mptable: No spare slots (length: %x)\n", count);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="836" endline="904">
{
    int count = sizeof (*mpc);
    int nr_m_spare = 0;
    unsigned char *mpt = ((unsigned char *) mpc) + count;
    printk (KERN_INFO "mpc_length %x\n", mpc -> length);
    while (count < mpc->length) {
        switch (*mpt) {
        case MP_PROCESSOR :
            skip_entry (&mpt, &count, sizeof (struct mpc_cpu));
            break;
        case MP_BUS :
            skip_entry (&mpt, &count, sizeof (struct mpc_bus));
            break;
        case MP_IOAPIC :
            skip_entry (&mpt, &count, sizeof (struct mpc_ioapic));
            break;
        case MP_INTSRC :
            check_irq_src ((struct mpc_intsrc *) mpt, &nr_m_spare);
            skip_entry (& mpt, & count, sizeof (struct mpc_intsrc));
            break;
        case MP_LINTSRC :
            skip_entry (&mpt, &count, sizeof (struct mpc_lintsrc));
            break;
        default :
            smp_dump_mptable (mpc, mpt);
            goto out;
        }
    }
out :
    mpc->checksum = 0;
    mpc->checksum -= mpf_checksum ((unsigned char *) mpc, mpc->length);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="845" endline="868">
{
    switch (*mpt) {
    case MP_PROCESSOR :
        skip_entry (&mpt, &count, sizeof (struct mpc_cpu));
        break;
    case MP_BUS :
        skip_entry (&mpt, &count, sizeof (struct mpc_bus));
        break;
    case MP_IOAPIC :
        skip_entry (&mpt, &count, sizeof (struct mpc_ioapic));
        break;
    case MP_INTSRC :
        check_irq_src ((struct mpc_intsrc *) mpt, &nr_m_spare);
        skip_entry (& mpt, & count, sizeof (struct mpc_intsrc));
        break;
    case MP_LINTSRC :
        skip_entry (&mpt, &count, sizeof (struct mpc_lintsrc));
        break;
    default :
        smp_dump_mptable (mpc, mpt);
        goto out;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="846" endline="867">
{
case MP_PROCESSOR :
    skip_entry (&mpt, &count, sizeof (struct mpc_cpu));
    break;
case MP_BUS :
    skip_entry (&mpt, &count, sizeof (struct mpc_bus));
    break;
case MP_IOAPIC :
    skip_entry (&mpt, &count, sizeof (struct mpc_ioapic));
    break;
case MP_INTSRC :
    check_irq_src ((struct mpc_intsrc *) mpt, &nr_m_spare);
    skip_entry (& mpt, & count, sizeof (struct mpc_intsrc));
    break;
case MP_LINTSRC :
    skip_entry (&mpt, &count, sizeof (struct mpc_lintsrc));
    break;
default :
    smp_dump_mptable (mpc, mpt);
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="909" endline="915">
{
    enable_update_mptable = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="924" endline="934">
{
    enable_update_mptable = 1;
    alloc_mptable = 1;
    if (!p)
        return 0;
    mpc_new_length = memparse (p, &p);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="938" endline="943">
{
    if (enable_update_mptable && alloc_mptable) {
        u64 startt = 0;
        mpc_new_phys = early_reserve_e820 (startt, mpc_new_length, 4);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="939" endline="942">
{
    u64 startt = 0;
    mpc_new_phys = early_reserve_e820 (startt, mpc_new_length, 4);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="946" endline="1023">
{
    char str [16];
    char oem [10];
    struct mpf_intel *mpf;
    struct mpc_table *mpc, *mpc_new;
    if (!enable_update_mptable)
        return 0;
    mpf = mpf_found;
    if (!mpf)
        return 0;
    if (mpf->feature1 != 0)
        return 0;
    if (!mpf->physptr)
        return 0;
    mpc = phys_to_virt (mpf->physptr);
    if (!smp_check_mpc (mpc, oem, str))
        return 0;
    printk (KERN_INFO "mpf: %llx\n", (u64) virt_to_phys (mpf));
    printk (KERN_INFO "physptr: %x\n", mpf -> physptr);
    if (mpc_new_phys && mpc->length > mpc_new_length) {
        mpc_new_phys = 0;
        printk (KERN_INFO "mpc_new_length is %ld, please use alloc_mptable=8k\n", mpc_new_length);
    }
    if (!mpc_new_phys) {
        unsigned char old, new;
        mpc->checksum = 0;
        old = mpf_checksum ((unsigned char *) mpc, mpc->length);
        mpc->checksum = 0xff;
        new = mpf_checksum ((unsigned char *) mpc, mpc->length);
        if (old == new) {
            printk (KERN_INFO "mpc is readonly, please try alloc_mptable instead\n");
            return 0;
        }
        printk (KERN_INFO "use in-positon replacing\n");
    }
    else {
        mpf->physptr = mpc_new_phys;
        mpc_new = phys_to_virt (mpc_new_phys);
        memcpy (mpc_new, mpc, mpc -> length);
        mpc = mpc_new;
        if (mpc_new_phys - mpf->physptr) {
            struct mpf_intel *mpf_new;
            printk (KERN_INFO "mpf new: %x\n", 0x400 - 16);
            mpf_new = phys_to_virt (0x400 - 16);
            memcpy (mpf_new, mpf, 16);
            mpf = mpf_new;
            mpf->physptr = mpc_new_phys;
        }
        mpf->checksum = 0;
        mpf->checksum -= mpf_checksum ((unsigned char *) mpf, 16);
        printk (KERN_INFO "physptr new: %x\n", mpf -> physptr);
    }
    replace_intsrc_all (mpc, mpc_new_phys, mpc_new_length);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="976" endline="980">
{
    mpc_new_phys = 0;
    printk (KERN_INFO "mpc_new_length is %ld, please use alloc_mptable=8k\n", mpc_new_length);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="982" endline="994">
{
    unsigned char old, new;
    mpc->checksum = 0;
    old = mpf_checksum ((unsigned char *) mpc, mpc->length);
    mpc->checksum = 0xff;
    new = mpf_checksum ((unsigned char *) mpc, mpc->length);
    if (old == new) {
        printk (KERN_INFO "mpc is readonly, please try alloc_mptable instead\n");
        return 0;
    }
    printk (KERN_INFO "use in-positon replacing\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="989" endline="992">
{
    printk (KERN_INFO "mpc is readonly, please try alloc_mptable instead\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="994" endline="1012">
{
    mpf->physptr = mpc_new_phys;
    mpc_new = phys_to_virt (mpc_new_phys);
    memcpy (mpc_new, mpc, mpc -> length);
    mpc = mpc_new;
    if (mpc_new_phys - mpf->physptr) {
        struct mpf_intel *mpf_new;
        printk (KERN_INFO "mpf new: %x\n", 0x400 - 16);
        mpf_new = phys_to_virt (0x400 - 16);
        memcpy (mpf_new, mpf, 16);
        mpf = mpf_new;
        mpf->physptr = mpc_new_phys;
    }
    mpf->checksum = 0;
    mpf->checksum -= mpf_checksum ((unsigned char *) mpf, 16);
    printk (KERN_INFO "physptr new: %x\n", mpf -> physptr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/mpparse.c.ifdefed" startline="1000" endline="1008">
{
    struct mpf_intel *mpf_new;
    printk (KERN_INFO "mpf new: %x\n", 0x400 - 16);
    mpf_new = phys_to_virt (0x400 - 16);
    memcpy (mpf_new, mpf, 16);
    mpf = mpf_new;
    mpf->physptr = mpc_new_phys;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="106" endline="112">
{
    const struct pt_regs_offset *roff;
    for (roff = regoffset_table; roff->name != NULL; roff++)
        if (!strcmp (roff->name, name))
            return roff->offset;
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="122" endline="128">
{
    const struct pt_regs_offset *roff;
    for (roff = regoffset_table; roff->name != NULL; roff++)
        if (roff->offset == offset)
            return roff->name;
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="164" endline="166">
{
    return unlikely (value != 0 && (value & SEGMENT_RPL_MASK) != USER_RPL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="238" endline="241">
{
    BUILD_BUG_ON (offsetof (struct pt_regs, r15) != 0);
    return &regs->r15 + (offset / sizeof (regs->r15));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="244" endline="282">
{
    unsigned int seg;
    switch (offset) {
    case offsetof (struct user_regs_struct, fs) :
        if (task == current) {
            asm ("movl %%fs,%0"
                : "=r" (seg)
            ) return seg;
        }
        return task->thread.fsindex;
    case offsetof (struct user_regs_struct, gs) :
        if (task == current) {
            asm ("movl %%gs,%0"
                : "=r" (seg)
            ) return seg;
        }
        return task->thread.gsindex;
    case offsetof (struct user_regs_struct, ds) :
        if (task == current) {
            asm ("movl %%ds,%0"
                : "=r" (seg)
            ) return seg;
        }
        return task->thread.ds;
    case offsetof (struct user_regs_struct, es) :
        if (task == current) {
            asm ("movl %%es,%0"
                : "=r" (seg)
            ) return seg;
        }
        return task->thread.es;
    case offsetof (struct user_regs_struct, cs) :
    case offsetof (struct user_regs_struct, ss) :
        break;
    }
    return *pt_regs_access (task_pt_regs (task), offset);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="250" endline="280">
{
case offsetof (struct user_regs_struct, fs) :
    if (task == current) {
        asm ("movl %%fs,%0"
            : "=r" (seg)
        ) return seg;
    }
    return task->thread.fsindex;
case offsetof (struct user_regs_struct, gs) :
    if (task == current) {
        asm ("movl %%gs,%0"
            : "=r" (seg)
        ) return seg;
    }
    return task->thread.gsindex;
case offsetof (struct user_regs_struct, ds) :
    if (task == current) {
        asm ("movl %%ds,%0"
            : "=r" (seg)
        ) return seg;
    }
    return task->thread.ds;
case offsetof (struct user_regs_struct, es) :
    if (task == current) {
        asm ("movl %%es,%0"
            : "=r" (seg)
        ) return seg;
    }
    return task->thread.es;
case offsetof (struct user_regs_struct, cs) :
case offsetof (struct user_regs_struct, ss) :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="252" endline="256">
{
    asm ("movl %%fs,%0"
        : "=r" (seg)
    ) return seg;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="259" endline="262">
{
    asm ("movl %%gs,%0"
        : "=r" (seg)
    ) return seg;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="265" endline="268">
{
    asm ("movl %%ds,%0"
        : "=r" (seg)
    ) return seg;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="271" endline="274">
{
    asm ("movl %%es,%0"
        : "=r" (seg)
    ) return seg;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="286" endline="355">
{
    if (invalid_selector (value))
        return -EIO;
    switch (offset) {
    case offsetof (struct user_regs_struct, fs) :
        if ((value == FS_TLS_SEL && task->thread.fsindex == 0 && task->thread.fs != 0) || (value == 0 && task->thread.fsindex == FS_TLS_SEL && task->thread.fs == 0))
            break;
        task->thread.fsindex = value;
        if (task == current)
            loadsegment (fs, task->thread.fsindex);
        break;
    case offsetof (struct user_regs_struct, gs) :
        if ((value == GS_TLS_SEL && task->thread.gsindex == 0 && task->thread.gs != 0) || (value == 0 && task->thread.gsindex == GS_TLS_SEL && task->thread.gs == 0))
            break;
        task->thread.gsindex = value;
        if (task == current)
            load_gs_index (task->thread.gsindex);
        break;
    case offsetof (struct user_regs_struct, ds) :
        task->thread.ds = value;
        if (task == current)
            loadsegment (ds, task->thread.ds);
        break;
    case offsetof (struct user_regs_struct, es) :
        task->thread.es = value;
        if (task == current)
            loadsegment (es, task->thread.es);
        break;
    case offsetof (struct user_regs_struct, cs) :
        if (unlikely (value == 0))
            return -EIO;
        break;
    case offsetof (struct user_regs_struct, ss) :
        if (unlikely (value == 0))
            return -EIO;
        break;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="293" endline="352">
{
case offsetof (struct user_regs_struct, fs) :
    if ((value == FS_TLS_SEL && task->thread.fsindex == 0 && task->thread.fs != 0) || (value == 0 && task->thread.fsindex == FS_TLS_SEL && task->thread.fs == 0))
        break;
    task->thread.fsindex = value;
    if (task == current)
        loadsegment (fs, task->thread.fsindex);
    break;
case offsetof (struct user_regs_struct, gs) :
    if ((value == GS_TLS_SEL && task->thread.gsindex == 0 && task->thread.gs != 0) || (value == 0 && task->thread.gsindex == GS_TLS_SEL && task->thread.gs == 0))
        break;
    task->thread.gsindex = value;
    if (task == current)
        load_gs_index (task->thread.gsindex);
    break;
case offsetof (struct user_regs_struct, ds) :
    task->thread.ds = value;
    if (task == current)
        loadsegment (ds, task->thread.ds);
    break;
case offsetof (struct user_regs_struct, es) :
    task->thread.es = value;
    if (task == current)
        loadsegment (es, task->thread.es);
    break;
case offsetof (struct user_regs_struct, cs) :
    if (unlikely (value == 0))
        return -EIO;
    break;
case offsetof (struct user_regs_struct, ss) :
    if (unlikely (value == 0))
        return -EIO;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="360" endline="370">
{
    unsigned long retval = task_pt_regs (task)->flags;
    if (test_tsk_thread_flag (task, TIF_FORCED_TF))
        retval &= ~X86_EFLAGS_TF;
    return retval;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="373" endline="389">
{
    struct pt_regs *regs = task_pt_regs (task);
    if (value & X86_EFLAGS_TF)
        clear_tsk_thread_flag (task, TIF_FORCED_TF);
    else if (test_tsk_thread_flag (task, TIF_FORCED_TF))
        value |= X86_EFLAGS_TF;
    regs->flags = (regs->flags & ~FLAG_MASK) | (value & FLAG_MASK);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="393" endline="432">
{
    switch (offset) {
    case offsetof (struct user_regs_struct, cs) :
    case offsetof (struct user_regs_struct, ds) :
    case offsetof (struct user_regs_struct, es) :
    case offsetof (struct user_regs_struct, fs) :
    case offsetof (struct user_regs_struct, gs) :
    case offsetof (struct user_regs_struct, ss) :
        return set_segment_reg (child, offset, value);
    case offsetof (struct user_regs_struct, flags) :
        return set_flags (child, value);
    }
    *pt_regs_access (task_pt_regs (child), offset) = value;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="394" endline="428">
{
case offsetof (struct user_regs_struct, cs) :
case offsetof (struct user_regs_struct, ds) :
case offsetof (struct user_regs_struct, es) :
case offsetof (struct user_regs_struct, fs) :
case offsetof (struct user_regs_struct, gs) :
case offsetof (struct user_regs_struct, ss) :
    return set_segment_reg (child, offset, value);
case offsetof (struct user_regs_struct, flags) :
    return set_flags (child, value);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="435" endline="481">
{
    switch (offset) {
    case offsetof (struct user_regs_struct, cs) :
    case offsetof (struct user_regs_struct, ds) :
    case offsetof (struct user_regs_struct, es) :
    case offsetof (struct user_regs_struct, fs) :
    case offsetof (struct user_regs_struct, gs) :
    case offsetof (struct user_regs_struct, ss) :
        return get_segment_reg (task, offset);
    case offsetof (struct user_regs_struct, flags) :
        return get_flags (task);
    }
    return *pt_regs_access (task_pt_regs (task), offset);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="436" endline="478">
{
case offsetof (struct user_regs_struct, cs) :
case offsetof (struct user_regs_struct, ds) :
case offsetof (struct user_regs_struct, es) :
case offsetof (struct user_regs_struct, fs) :
case offsetof (struct user_regs_struct, gs) :
case offsetof (struct user_regs_struct, ss) :
    return get_segment_reg (task, offset);
case offsetof (struct user_regs_struct, flags) :
    return get_flags (task);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="487" endline="506">
{
    if (kbuf) {
        unsigned long *k = kbuf;
        while (count >= sizeof (*k)) {
            *k++ = getreg (target, pos);
            count -= sizeof (*k);
            pos += sizeof (*k);
        }
    }
    else {
        unsigned long __user *u = ubuf;
        while (count >= sizeof (*u)) {
            if (__put_user (getreg (target, pos), u++))
                return -EFAULT;
            count -= sizeof (*u);
            pos += sizeof (*u);
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="488" endline="495">
{
    unsigned long *k = kbuf;
    while (count >= sizeof (*k)) {
        *k++ = getreg (target, pos);
        count -= sizeof (*k);
        pos += sizeof (*k);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="490" endline="494">
{
    *k++ = getreg (target, pos);
    count -= sizeof (*k);
    pos += sizeof (*k);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="495" endline="503">
{
    unsigned long __user *u = ubuf;
    while (count >= sizeof (*u)) {
        if (__put_user (getreg (target, pos), u++))
            return -EFAULT;
        count -= sizeof (*u);
        pos += sizeof (*u);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="497" endline="502">
{
    if (__put_user (getreg (target, pos), u++))
        return -EFAULT;
    count -= sizeof (*u);
    pos += sizeof (*u);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="512" endline="534">
{
    int ret = 0;
    if (kbuf) {
        const unsigned long *k = kbuf;
        while (count >= sizeof (*k) && !ret) {
            ret = putreg (target, pos, *k++);
            count -= sizeof (*k);
            pos += sizeof (*k);
        }
    }
    else {
        const unsigned long __user *u = ubuf;
        while (count >= sizeof (*u) && !ret) {
            unsigned long word;
            ret = __get_user (word, u++);
            if (ret)
                break;
            ret = putreg (target, pos, word);
            count -= sizeof (*u);
            pos += sizeof (*u);
        }
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="514" endline="521">
{
    const unsigned long *k = kbuf;
    while (count >= sizeof (*k) && !ret) {
        ret = putreg (target, pos, *k++);
        count -= sizeof (*k);
        pos += sizeof (*k);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="516" endline="520">
{
    ret = putreg (target, pos, *k++);
    count -= sizeof (*k);
    pos += sizeof (*k);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="521" endline="532">
{
    const unsigned long __user *u = ubuf;
    while (count >= sizeof (*u) && !ret) {
        unsigned long word;
        ret = __get_user (word, u++);
        if (ret)
            break;
        ret = putreg (target, pos, word);
        count -= sizeof (*u);
        pos += sizeof (*u);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="523" endline="531">
{
    unsigned long word;
    ret = __get_user (word, u++);
    if (ret)
        break;
    ret = putreg (target, pos, word);
    count -= sizeof (*u);
    pos += sizeof (*u);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="539" endline="553">
{
    int i;
    struct thread_struct *thread = &(current->thread);
    for (i = 0; i < HBP_NUM; i++) {
        if (thread->ptrace_bps[i] == bp)
            break;
    }
    thread->debugreg6 |= (DR_TRAP0 << i);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="547" endline="550">
{
    if (thread->ptrace_bps[i] == bp)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="561" endline="574">
{
    int i;
    int dr7 = 0;
    struct arch_hw_breakpoint *info;
    for (i = 0; i < HBP_NUM; i++) {
        if (bp[i] && !bp[i]->attr.disabled) {
            info = counter_arch_bp (bp[i]);
            dr7 |= encode_dr7 (i, info->len, info->type);
        }
    }
    return dr7;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="566" endline="571">
{
    if (bp[i] && !bp[i]->attr.disabled) {
        info = counter_arch_bp (bp[i]);
        dr7 |= encode_dr7 (i, info->len, info->type);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="567" endline="570">
{
    info = counter_arch_bp (bp[i]);
    dr7 |= encode_dr7 (i, info->len, info->type);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="579" endline="602">
{
    int err;
    int gen_len, gen_type;
    struct perf_event_attr attr;
    if (!bp)
        return -EINVAL;
    err = arch_bp_generic_fields (len, type, &gen_len, &gen_type);
    if (err)
        return err;
    attr = bp->attr;
    attr.bp_len = gen_len;
    attr.bp_type = gen_type;
    attr.disabled = disabled;
    return modify_user_hw_breakpoint (bp, &attr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="608" endline="664">
{
    struct thread_struct *thread = &(tsk->thread);
    unsigned long old_dr7;
    int i, orig_ret = 0, rc = 0;
    int enabled, second_pass = 0;
    unsigned len, type;
    struct perf_event *bp;
    data &= ~DR_CONTROL_RESERVED;
    old_dr7 = ptrace_get_dr7 (thread->ptrace_bps);
restore :
    for (i = 0; i < HBP_NUM; i++) {
        enabled = decode_dr7 (data, i, &len, &type);
        bp = thread->ptrace_bps[i];
        if (!enabled) {
            if (bp) {
                if (!second_pass)
                    continue;
                rc = ptrace_modify_breakpoint (bp, len, type, tsk, 1);
                if (rc)
                    break;
            }
            continue;
        }
        rc = ptrace_modify_breakpoint (bp, len, type, tsk, 0);
        if (rc)
            break;
    }
    if (!second_pass) {
        second_pass = 1;
        if (rc < 0) {
            orig_ret = rc;
            data = old_dr7;
        }
        goto restore;
    }
    return ((orig_ret < 0) ? orig_ret : rc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="623" endline="650">
{
    enabled = decode_dr7 (data, i, &len, &type);
    bp = thread->ptrace_bps[i];
    if (!enabled) {
        if (bp) {
            if (!second_pass)
                continue;
            rc = ptrace_modify_breakpoint (bp, len, type, tsk, 1);
            if (rc)
                break;
        }
        continue;
    }
    rc = ptrace_modify_breakpoint (bp, len, type, tsk, 0);
    if (rc)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="627" endline="645">
{
    if (bp) {
        if (!second_pass)
            continue;
        rc = ptrace_modify_breakpoint (bp, len, type, tsk, 1);
        if (rc)
            break;
    }
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="628" endline="643">
{
    if (!second_pass)
        continue;
    rc = ptrace_modify_breakpoint (bp, len, type, tsk, 1);
    if (rc)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="655" endline="662">
{
    second_pass = 1;
    if (rc < 0) {
        orig_ret = rc;
        data = old_dr7;
    }
    goto restore;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="657" endline="660">
{
    orig_ret = rc;
    data = old_dr7;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="670" endline="686">
{
    struct thread_struct *thread = &(tsk->thread);
    unsigned long val = 0;
    if (n < HBP_NUM) {
        struct perf_event *bp;
        bp = thread->ptrace_bps[n];
        if (!bp)
            return 0;
        val = bp->hw.info.address;
    }
    else if (n == 6) {
        val = thread->debugreg6;
    }
    else if (n == 7) {
        val = thread->ptrace_dr7;
    }
    return val;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="674" endline="680">
{
    struct perf_event *bp;
    bp = thread->ptrace_bps[n];
    if (!bp)
        return 0;
    val = bp->hw.info.address;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="680" endline="682">
{
    val = thread->debugreg6;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="682" endline="684">
{
    val = thread->ptrace_dr7;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="690" endline="735">
{
    struct perf_event *bp;
    struct thread_struct *t = &tsk->thread;
    struct perf_event_attr attr;
    if (!t->ptrace_bps[nr]) {
        hw_breakpoint_init (& attr);
        attr.bp_addr = addr;
        attr.bp_len = HW_BREAKPOINT_LEN_1;
        attr.bp_type = HW_BREAKPOINT_W;
        attr.disabled = 1;
        bp = register_user_hw_breakpoint (&attr, ptrace_triggered, tsk);
        if (IS_ERR (bp))
            return PTR_ERR (bp);
        t->ptrace_bps[nr] = bp;
    }
    else {
        int err;
        bp = t->ptrace_bps[nr];
        attr = bp->attr;
        attr.bp_addr = addr;
        err = modify_user_hw_breakpoint (bp, &attr);
        if (err)
            return err;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="695" endline="721">
{
    hw_breakpoint_init (& attr);
    attr.bp_addr = addr;
    attr.bp_len = HW_BREAKPOINT_LEN_1;
    attr.bp_type = HW_BREAKPOINT_W;
    attr.disabled = 1;
    bp = register_user_hw_breakpoint (&attr, ptrace_triggered, tsk);
    if (IS_ERR (bp))
        return PTR_ERR (bp);
    t->ptrace_bps[nr] = bp;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="721" endline="731">
{
    int err;
    bp = t->ptrace_bps[nr];
    attr = bp->attr;
    attr.bp_addr = addr;
    err = modify_user_hw_breakpoint (bp, &attr);
    if (err)
        return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="741" endline="767">
{
    struct thread_struct *thread = &(tsk->thread);
    int rc = 0;
    if (n == 4 || n == 5)
        return -EIO;
    if (n == 6) {
        thread->debugreg6 = val;
        goto ret_path;
    }
    if (n < HBP_NUM) {
        rc = ptrace_set_breakpoint_addr (tsk, n, val);
        if (rc)
            return rc;
    }
    if (n == 7) {
        rc = ptrace_write_dr7 (tsk, val);
        if (!rc)
            thread->ptrace_dr7 = val;
    }
ret_path :
    return rc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="749" endline="752">
{
    thread->debugreg6 = val;
    goto ret_path;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="753" endline="757">
{
    rc = ptrace_set_breakpoint_addr (tsk, n, val);
    if (rc)
        return rc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="759" endline="763">
{
    rc = ptrace_write_dr7 (tsk, val);
    if (!rc)
        thread->ptrace_dr7 = val;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="775" endline="777">
{
    return target->thread.io_bitmap_max / regset->size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="783" endline="790">
{
    if (!target->thread.io_bitmap_ptr)
        return -ENXIO;
    return user_regset_copyout (&pos, &count, &kbuf, &ubuf, target->thread.io_bitmap_ptr, 0, IO_BITMAP_BYTES);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1134" endline="1139">
{
    user_disable_single_step (child);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1146" endline="1294">
{
    int ret;
    unsigned long __user *datap = (unsigned long __user *) data;
    switch (request) {
    case PTRACE_PEEKUSR :
        {
            unsigned long tmp;
            ret = -EIO;
            if ((addr & (sizeof (data) - 1)) || addr < 0 || addr >= sizeof (struct user))
                break;
            tmp = 0;
            if (addr < sizeof (struct user_regs_struct))
                tmp = getreg (child, addr);
            else if (addr >= offsetof (struct user, u_debugreg[0]) && addr <= offsetof (struct user, u_debugreg[7])) {
                addr -= offsetof (struct user, u_debugreg[0]);
                tmp = ptrace_get_debugreg (child, addr / sizeof (data));
            }
            ret = put_user (tmp, datap);
            break;
        }
    case PTRACE_POKEUSR :
        ret = -EIO;
        if ((addr & (sizeof (data) - 1)) || addr < 0 || addr >= sizeof (struct user))
            break;
        if (addr < sizeof (struct user_regs_struct))
            ret = putreg (child, addr, data);
        else if (addr >= offsetof (struct user, u_debugreg[0]) && addr <= offsetof (struct user, u_debugreg[7])) {
            addr -= offsetof (struct user, u_debugreg[0]);
            ret = ptrace_set_debugreg (child, addr / sizeof (data), data);
        }
        break;
    case PTRACE_GETREGS :
        return copy_regset_to_user (child, task_user_regset_view (current), REGSET_GENERAL, 0, sizeof (struct user_regs_struct), datap);
    case PTRACE_SETREGS :
        return copy_regset_from_user (child, task_user_regset_view (current), REGSET_GENERAL, 0, sizeof (struct user_regs_struct), datap);
    case PTRACE_GETFPREGS :
        return copy_regset_to_user (child, task_user_regset_view (current), REGSET_FP, 0, sizeof (struct user_i387_struct), datap);
    case PTRACE_SETFPREGS :
        return copy_regset_from_user (child, task_user_regset_view (current), REGSET_FP, 0, sizeof (struct user_i387_struct), datap);
    default :
        ret = ptrace_request (child, request, addr, data);
        break;
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1150" endline="1291">
{
case PTRACE_PEEKUSR :
    {
        unsigned long tmp;
        ret = -EIO;
        if ((addr & (sizeof (data) - 1)) || addr < 0 || addr >= sizeof (struct user))
            break;
        tmp = 0;
        if (addr < sizeof (struct user_regs_struct))
            tmp = getreg (child, addr);
        else if (addr >= offsetof (struct user, u_debugreg[0]) && addr <= offsetof (struct user, u_debugreg[7])) {
            addr -= offsetof (struct user, u_debugreg[0]);
            tmp = ptrace_get_debugreg (child, addr / sizeof (data));
        }
        ret = put_user (tmp, datap);
        break;
    }
case PTRACE_POKEUSR :
    ret = -EIO;
    if ((addr & (sizeof (data) - 1)) || addr < 0 || addr >= sizeof (struct user))
        break;
    if (addr < sizeof (struct user_regs_struct))
        ret = putreg (child, addr, data);
    else if (addr >= offsetof (struct user, u_debugreg[0]) && addr <= offsetof (struct user, u_debugreg[7])) {
        addr -= offsetof (struct user, u_debugreg[0]);
        ret = ptrace_set_debugreg (child, addr / sizeof (data), data);
    }
    break;
case PTRACE_GETREGS :
    return copy_regset_to_user (child, task_user_regset_view (current), REGSET_GENERAL, 0, sizeof (struct user_regs_struct), datap);
case PTRACE_SETREGS :
    return copy_regset_from_user (child, task_user_regset_view (current), REGSET_GENERAL, 0, sizeof (struct user_regs_struct), datap);
case PTRACE_GETFPREGS :
    return copy_regset_to_user (child, task_user_regset_view (current), REGSET_FP, 0, sizeof (struct user_i387_struct), datap);
case PTRACE_SETFPREGS :
    return copy_regset_from_user (child, task_user_regset_view (current), REGSET_FP, 0, sizeof (struct user_i387_struct), datap);
default :
    ret = ptrace_request (child, request, addr, data);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1152" endline="1170">
{
    unsigned long tmp;
    ret = -EIO;
    if ((addr & (sizeof (data) - 1)) || addr < 0 || addr >= sizeof (struct user))
        break;
    tmp = 0;
    if (addr < sizeof (struct user_regs_struct))
        tmp = getreg (child, addr);
    else if (addr >= offsetof (struct user, u_debugreg[0]) && addr <= offsetof (struct user, u_debugreg[7])) {
        addr -= offsetof (struct user, u_debugreg[0]);
        tmp = ptrace_get_debugreg (child, addr / sizeof (data));
    }
    ret = put_user (tmp, datap);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1164" endline="1167">
{
    addr -= offsetof (struct user, u_debugreg[0]);
    tmp = ptrace_get_debugreg (child, addr / sizeof (data));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1181" endline="1185">
{
    addr -= offsetof (struct user, u_debugreg[0]);
    ret = ptrace_set_debugreg (child, addr / sizeof (data), data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1666" endline="1674">
{
    xstate_fx_sw_bytes[USER_XSTATE_XCR0_WORD] = xstate_mask;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1677" endline="1687">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1693" endline="1701">
{
    tsk->thread.trap_no = 1;
    tsk->thread.error_code = error_code;
    memset (info, 0, sizeof (* info));
    info->si_signo = SIGTRAP;
    info->si_code = si_code;
    info->si_addr = user_mode_vm (regs) ? (void __user *) regs->ip : NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1706" endline="1708">
{
    fill_sigtrap_info (tsk, regs, 0, TRAP_BRKPT, info);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1712" endline="1718">
{
    struct siginfo info;
    fill_sigtrap_info (tsk, regs, error_code, si_code, & info);
    force_sig_info (SIGTRAP, & info, tsk);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1734" endline="1776">
{
    long ret = 0;
    if (test_thread_flag (TIF_SINGLESTEP))
        regs->flags |= X86_EFLAGS_TF;
    secure_computing (regs -> orig_ax);
    if (unlikely (test_thread_flag (TIF_SYSCALL_EMU)))
        ret = -1L;
    if ((ret || test_thread_flag (TIF_SYSCALL_TRACE)) && tracehook_report_syscall_entry (regs))
        ret = -1L;
    if (unlikely (test_thread_flag (TIF_SYSCALL_TRACEPOINT)))
        trace_sys_enter (regs, regs->orig_ax);
    if (unlikely (current->audit_context)) {
        if (IS_IA32)
            audit_syscall_entry (AUDIT_ARCH_I386, regs->orig_ax, regs->bx, regs->cx, regs->dx, regs->si);
    }
    return ret ? : regs->orig_ax;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1760" endline="1773">
{
    if (IS_IA32)
        audit_syscall_entry (AUDIT_ARCH_I386, regs->orig_ax, regs->bx, regs->cx, regs->dx, regs->si);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/ptrace.c.ifdefed" startline="1779" endline="1798">
{
    bool step;
    if (unlikely (current->audit_context))
        audit_syscall_exit (AUDITSC_RESULT (regs->ax), regs->ax);
    if (unlikely (test_thread_flag (TIF_SYSCALL_TRACEPOINT)))
        trace_sys_exit (regs, regs->ax);
    step = unlikely (test_thread_flag (TIF_SINGLESTEP)) && !test_thread_flag (TIF_SYSCALL_EMU);
    if (step || test_thread_flag (TIF_SYSCALL_TRACE))
        tracehook_report_syscall_exit (regs, step);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/trampoline.c.ifdefed" startline="18" endline="28">
{
    unsigned long mem;
    mem = find_e820_area (0, 1 << 20, TRAMPOLINE_SIZE, PAGE_SIZE);
    if (mem == -1L)
        panic ("Cannot allocate trampoline\n");
    trampoline_base = __va (mem);
    reserve_early (mem, mem + TRAMPOLINE_SIZE, "TRAMPOLINE");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/trampoline.c.ifdefed" startline="36" endline="39">
{
    memcpy (trampoline_base, trampoline_data, TRAMPOLINE_SIZE);
    return virt_to_phys (trampoline_base);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="40" endline="46">
{
    if (cpu_has_clflush)
        clflush (tceaddr);
    else
        wbinvd ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="50" endline="72">
{
    u64 *tp;
    u64 t;
    u64 rpn;
    t = (1 << TCE_READ_SHIFT);
    if (direction != DMA_TO_DEVICE)
        t |= (1 << TCE_WRITE_SHIFT);
    tp = ((u64 *) tbl->it_base) + index;
    while (npages--) {
        rpn = (virt_to_bus ((void *) uaddr)) >> PAGE_SHIFT;
        t &= ~TCE_RPN_MASK;
        t |= (rpn << TCE_RPN_SHIFT);
        *tp = cpu_to_be64 (t);
        flush_tce (tp);
        uaddr += PAGE_SIZE;
        tp++;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="61" endline="71">
{
    rpn = (virt_to_bus ((void *) uaddr)) >> PAGE_SHIFT;
    t &= ~TCE_RPN_MASK;
    t |= (rpn << TCE_RPN_SHIFT);
    *tp = cpu_to_be64 (t);
    flush_tce (tp);
    uaddr += PAGE_SIZE;
    tp++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="75" endline="85">
{
    u64 *tp;
    tp = ((u64 *) tbl->it_base) + index;
    while (npages--) {
        *tp = cpu_to_be64 (0);
        flush_tce (tp);
        tp++;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="80" endline="84">
{
    *tp = cpu_to_be64 (0);
    flush_tce (tp);
    tp++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="88" endline="95">
{
    return (1 << size) << 13;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="98" endline="132">
{
    unsigned int bitmapsz;
    unsigned long bmppages;
    int ret;
    tbl->it_busno = dev->bus->number;
    tbl->it_size = table_size_to_number_of_entries (specified_table_size);
    bitmapsz = tbl->it_size / BITS_PER_BYTE;
    bmppages = __get_free_pages (GFP_KERNEL, get_order (bitmapsz));
    if (!bmppages) {
        printk (KERN_ERR "Calgary: cannot allocate bitmap\n");
        ret = -ENOMEM;
        goto done;
    }
    tbl->it_map = (unsigned long *) bmppages;
    memset (tbl -> it_map, 0, bitmapsz);
    tbl->it_hint = 0;
    spin_lock_init (& tbl -> it_lock);
    return 0;
done :
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="114" endline="118">
{
    printk (KERN_ERR "Calgary: cannot allocate bitmap\n");
    ret = -ENOMEM;
    goto done;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="135" endline="166">
{
    struct iommu_table *tbl;
    int ret;
    if (pci_iommu (dev->bus)) {
        printk (KERN_ERR "Calgary: dev %p has sysdata->iommu %p\n", dev, pci_iommu (dev -> bus));
        BUG ();
    }
    tbl = kzalloc (sizeof (struct iommu_table), GFP_KERNEL);
    if (!tbl) {
        printk (KERN_ERR "Calgary: error allocating iommu_table\n");
        ret = -ENOMEM;
        goto done;
    }
    ret = tce_table_setparms (dev, tbl);
    if (ret)
        goto free_tbl;
    tbl->bbar = bbar;
    set_pci_iommu (dev -> bus, tbl);
    return 0;
free_tbl :
    kfree (tbl);
done :
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="139" endline="143">
{
    printk (KERN_ERR "Calgary: dev %p has sysdata->iommu %p\n", dev, pci_iommu (dev -> bus));
    BUG ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="146" endline="150">
{
    printk (KERN_ERR "Calgary: error allocating iommu_table\n");
    ret = -ENOMEM;
    goto done;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="169" endline="176">
{
    unsigned int size;
    size = table_size_to_number_of_entries (specified_table_size);
    size *= TCE_ENTRY_SIZE;
    return __alloc_bootmem_low (size, size, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tce_64.c.ifdefed" startline="179" endline="189">
{
    unsigned int size;
    if (!tbl)
        return;
    size = table_size_to_number_of_entries (specified_table_size);
    size *= TCE_ENTRY_SIZE;
    free_bootmem (__pa (tbl), size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-nommu.c.ifdefed" startline="17" endline="27">
{
    if (hwdev && !dma_capable (hwdev, bus, size)) {
        if (*hwdev->dma_mask >= DMA_BIT_MASK (32))
            printk (KERN_ERR "nommu_%s: overflow %Lx+%zu of device mask %Lx\n", name, (long long) bus, size, (long long) *hwdev->dma_mask);
        return 0;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-nommu.c.ifdefed" startline="18" endline="25">
{
    if (*hwdev->dma_mask >= DMA_BIT_MASK (32))
        printk (KERN_ERR "nommu_%s: overflow %Lx+%zu of device mask %Lx\n", name, (long long) bus, size, (long long) *hwdev->dma_mask);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-nommu.c.ifdefed" startline="33" endline="40">
{
    dma_addr_t bus = page_to_phys (page) + offset;
    WARN_ON (size == 0);
    if (!check_addr ("map_single", dev, bus, size))
        return DMA_ERROR_CODE;
    flush_write_buffers ();
    return bus;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-nommu.c.ifdefed" startline="60" endline="75">
{
    struct scatterlist *s;
    int i;
    WARN_ON (nents == 0 || sg [0].length == 0);

    for_each_sg (sg, s, nents, i) {
        BUG_ON (! sg_page (s));
        s->dma_address = sg_phys (s);
        if (!check_addr ("map_sg", hwdev, s->dma_address, s->length))
            return 0;
        s->dma_length = s->length;
    }

    flush_write_buffers ();
    return nents;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-nommu.c.ifdefed" startline="66" endline="72">
{
    BUG_ON (! sg_page (s));
    s->dma_address = sg_phys (s);
    if (!check_addr ("map_sg", hwdev, s->dma_address, s->length))
        return 0;
    s->dma_length = s->length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-nommu.c.ifdefed" startline="79" endline="81">
{
    free_pages ((unsigned long) vaddr, get_order (size));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-nommu.c.ifdefed" startline="86" endline="88">
{
    flush_write_buffers ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-nommu.c.ifdefed" startline="94" endline="96">
{
    flush_write_buffers ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="59" endline="66">
{
    if (!dev->dma_mask || !dma_supported (dev, mask))
        return -EIO;
    *dev->dma_mask = mask;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="122" endline="123">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="125" endline="126">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="131" endline="148">
{
    dma32_free_bootmem ();
    if (pci_swiotlb_detect ())
        goto out;
    gart_iommu_hole_init ();
    detect_calgary ();
    detect_intel_iommu ();
    amd_iommu_detect ();
out :
    pci_swiotlb_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="152" endline="179">
{
    unsigned long dma_mask;
    struct page *page;
    dma_addr_t addr;
    dma_mask = dma_alloc_coherent_mask (dev, flag);
    flag |= __GFP_ZERO;
again :
    page = alloc_pages_node (dev_to_node (dev), flag, get_order (size));
    if (!page)
        return NULL;
    addr = page_to_phys (page);
    if (addr + size > dma_mask) {
        __free_pages (page, get_order (size));
        if (dma_mask < DMA_BIT_MASK (32) && !(flag & GFP_DMA)) {
            flag = (flag & ~GFP_DMA32) | GFP_DMA;
            goto again;
        }
        return NULL;
    }
    *dma_addr = addr;
    return page_address (page);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="166" endline="175">
{
    __free_pages (page, get_order (size));
    if (dma_mask < DMA_BIT_MASK (32) && !(flag & GFP_DMA)) {
        flag = (flag & ~GFP_DMA32) | GFP_DMA;
        goto again;
    }
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="169" endline="172">
{
    flag = (flag & ~GFP_DMA32) | GFP_DMA;
    goto again;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="186" endline="246">
{
    iommu_merge = 1;
    if (!p)
        return -EINVAL;
    while (*p) {
        if (!strncmp (p, "off", 3))
            no_iommu = 1;
        if (!strncmp (p, "force", 5))
            force_iommu = 1;
        if (!strncmp (p, "noforce", 7)) {
            iommu_merge = 0;
            force_iommu = 0;
        }
        if (!strncmp (p, "biomerge", 8)) {
            iommu_merge = 1;
            force_iommu = 1;
        }
        if (!strncmp (p, "panic", 5))
            panic_on_overflow = 1;
        if (!strncmp (p, "nopanic", 7))
            panic_on_overflow = 0;
        if (!strncmp (p, "merge", 5)) {
            iommu_merge = 1;
            force_iommu = 1;
        }
        if (!strncmp (p, "nomerge", 7))
            iommu_merge = 0;
        if (!strncmp (p, "forcesac", 8))
            iommu_sac_force = 1;
        if (!strncmp (p, "allowdac", 8))
            forbid_dac = 0;
        if (!strncmp (p, "nodac", 5))
            forbid_dac = 1;
        if (!strncmp (p, "usedac", 6)) {
            forbid_dac = -1;
            return 1;
        }
        if (!strncmp (p, "pt", 2))
            iommu_pass_through = 1;
        gart_parse_options (p);
        p += strcspn (p, ",");
        if (*p == ',')
            ++p;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="192" endline="244">
{
    if (!strncmp (p, "off", 3))
        no_iommu = 1;
    if (!strncmp (p, "force", 5))
        force_iommu = 1;
    if (!strncmp (p, "noforce", 7)) {
        iommu_merge = 0;
        force_iommu = 0;
    }
    if (!strncmp (p, "biomerge", 8)) {
        iommu_merge = 1;
        force_iommu = 1;
    }
    if (!strncmp (p, "panic", 5))
        panic_on_overflow = 1;
    if (!strncmp (p, "nopanic", 7))
        panic_on_overflow = 0;
    if (!strncmp (p, "merge", 5)) {
        iommu_merge = 1;
        force_iommu = 1;
    }
    if (!strncmp (p, "nomerge", 7))
        iommu_merge = 0;
    if (!strncmp (p, "forcesac", 8))
        iommu_sac_force = 1;
    if (!strncmp (p, "allowdac", 8))
        forbid_dac = 0;
    if (!strncmp (p, "nodac", 5))
        forbid_dac = 1;
    if (!strncmp (p, "usedac", 6)) {
        forbid_dac = -1;
        return 1;
    }
    if (!strncmp (p, "pt", 2))
        iommu_pass_through = 1;
    gart_parse_options (p);
    p += strcspn (p, ",");
    if (*p == ',')
        ++p;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="198" endline="201">
{
    iommu_merge = 0;
    force_iommu = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="203" endline="206">
{
    iommu_merge = 1;
    force_iommu = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="211" endline="214">
{
    iommu_merge = 1;
    force_iommu = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="223" endline="226">
{
    forbid_dac = -1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="250" endline="287">
{
    struct dma_map_ops *ops = get_dma_ops (dev);
    if (ops->dma_supported)
        return ops->dma_supported (dev, mask);
    if (mask < DMA_BIT_MASK (24))
        return 0;
    if (iommu_sac_force && (mask >= DMA_BIT_MASK (40))) {
        dev_info (dev, "Force SAC with mask %Lx\n", mask);
        return 0;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="281" endline="284">
{
    dev_info (dev, "Force SAC with mask %Lx\n", mask);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="291" endline="307">
{
    dma_debug_init (PREALLOC_DMA_DEBUG_ENTRIES);
    x86_init.iommu.iommu_init ();
    if (swiotlb) {
        printk (KERN_INFO "PCI-DMA: " "Using software bounce buffering for IO (SWIOTLB)\n");
        swiotlb_print_info ();
    }
    else
        swiotlb_free ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-dma.c.ifdefed" startline="299" endline="303">
{
    printk (KERN_INFO "PCI-DMA: " "Using software bounce buffering for IO (SWIOTLB)\n");
    swiotlb_print_info ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/audit_64.c.ifdefed" startline="32" endline="38">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/audit_64.c.ifdefed" startline="41" endline="57">
{
    switch (syscall) {
    case __NR_open :
        return 2;
    case __NR_openat :
        return 3;
    case __NR_execve :
        return 5;
    default :
        return 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/audit_64.c.ifdefed" startline="47" endline="56">
{
case __NR_open :
    return 2;
case __NR_openat :
    return 3;
case __NR_execve :
    return 5;
default :
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/audit_64.c.ifdefed" startline="60" endline="79">
{
    audit_register_class (AUDIT_CLASS_WRITE, write_class);
    audit_register_class (AUDIT_CLASS_READ, read_class);
    audit_register_class (AUDIT_CLASS_DIR_WRITE, dir_class);
    audit_register_class (AUDIT_CLASS_CHATTR, chattr_class);
    audit_register_class (AUDIT_CLASS_SIGNAL, signal_class);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/addon_cpuid_features.c.ifdefed" startline="27" endline="56">
{
    u32 max_level;
    u32 regs [4];
    const struct cpuid_bit *cb;
    static const struct cpuid_bit __cpuinitconst cpuid_bits [] = {{X86_FEATURE_IDA, CR_EAX, 1, 0x00000006}, {X86_FEATURE_ARAT, CR_EAX, 2, 0x00000006}, {X86_FEATURE_NPT, CR_EDX, 0, 0x8000000a}, {X86_FEATURE_LBRV, CR_EDX, 1, 0x8000000a}, {X86_FEATURE_SVML, CR_EDX, 2, 0x8000000a}, {X86_FEATURE_NRIPS, CR_EDX, 3, 0x8000000a}, {0, 0, 0, 0}};
    for (cb = cpuid_bits; cb->feature; cb++) {
        max_level = cpuid_eax (cb->level & 0xffff0000);
        if (max_level < cb->level || max_level > (cb->level | 0xffff))
            continue;
        cpuid (cb -> level, & regs [CR_EAX], & regs [CR_EBX], & regs [CR_ECX], & regs [CR_EDX]);
        if (regs[cb->reg] & (1 << cb->bit))
            set_cpu_cap (c, cb->feature);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/addon_cpuid_features.c.ifdefed" startline="42" endline="55">
{
    max_level = cpuid_eax (cb->level & 0xffff0000);
    if (max_level < cb->level || max_level > (cb->level | 0xffff))
        continue;
    cpuid (cb -> level, & regs [CR_EAX], & regs [CR_EBX], & regs [CR_ECX], & regs [CR_EDX]);
    if (regs[cb->reg] & (1 << cb->bit))
        set_cpu_cap (c, cb->feature);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/addon_cpuid_features.c.ifdefed" startline="76" endline="145">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="295" endline="311">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="314" endline="320">
{
    int id = 0;
    return id;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="324" endline="356">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="359" endline="382">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="385" endline="415">
{
    early_init_amd_mc (c);
    if (c->x86_power & (1 << 8)) {
        set_cpu_cap (c, X86_FEATURE_CONSTANT_TSC);
        set_cpu_cap (c, X86_FEATURE_NONSTOP_TSC);
    }
    if (c->x86 == 5)
        if (c->x86_model == 13 || c->x86_model == 9 || (c->x86_model == 8 && c->x86_mask >= 8))
            set_cpu_cap (c, X86_FEATURE_K6_MTRR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="392" endline="395">
{
    set_cpu_cap (c, X86_FEATURE_CONSTANT_TSC);
    set_cpu_cap (c, X86_FEATURE_NONSTOP_TSC);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="418" endline="568">
{
    early_init_amd (c);
    clear_cpu_cap (c, 0 * 32 + 31);
    switch (c->x86) {
    case 4 :
        init_amd_k5 (c);
        break;
    case 5 :
        init_amd_k6 (c);
        break;
    case 6 :
        init_amd_k7 (c);
        break;
    }
    if (c->x86 < 6)
        clear_cpu_cap (c, X86_FEATURE_MCE);
    if (c->x86 >= 6)
        set_cpu_cap (c, X86_FEATURE_FXSAVE_LEAK);
    if (!c->x86_model_id[0]) {
        switch (c->x86) {
        case 0xf :
            strcpy (c->x86_model_id, "Hammer");
            break;
        }
    }
    cpu_detect_cache_sizes (c);
    if (c->extended_cpuid_level >= 0x80000008) {
        amd_detect_cmp (c);
        srat_detect_node (c);
    }
    if (c->extended_cpuid_level >= 0x80000006) {
        if ((c->x86 >= 0x0f) && (cpuid_edx (0x80000006) & 0xf000))
            num_cache_leaves = 4;
        else
            num_cache_leaves = 3;
    }
    if (c->x86 >= 0xf && c->x86 <= 0x11)
        set_cpu_cap (c, X86_FEATURE_K8);
    if (cpu_has_xmm2) {
        set_cpu_cap (c, X86_FEATURE_MFENCE_RDTSC);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="482" endline="492">
{
case 4 :
    init_amd_k5 (c);
    break;
case 5 :
    init_amd_k6 (c);
    break;
case 6 :
    init_amd_k7 (c);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="503" endline="511">
{
    switch (c->x86) {
    case 0xf :
        strcpy (c->x86_model_id, "Hammer");
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="504" endline="510">
{
case 0xf :
    strcpy (c->x86_model_id, "Hammer");
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="516" endline="519">
{
    amd_detect_cmp (c);
    srat_detect_node (c);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="525" endline="530">
{
    if ((c->x86 >= 0x0f) && (cpuid_edx (0x80000006) & 0xf000))
        num_cache_leaves = 4;
    else
        num_cache_leaves = 3;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/amd.c.ifdefed" startline="535" endline="538">
{
    set_cpu_cap (c, X86_FEATURE_MFENCE_RDTSC);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="231" endline="296">
{
    unsigned dummy;
    unsigned line_size, lines_per_tag, assoc, size_in_kb;
    union l1_cache l1i, l1d;
    union l2_cache l2;
    union l3_cache l3;
    union l1_cache *l1 = &l1d;
    eax->full = 0;
    ebx->full = 0;
    ecx->full = 0;
    cpuid (0x80000005, & dummy, & dummy, & l1d.val, & l1i.val);
    cpuid (0x80000006, & dummy, & dummy, & l2.val, & l3.val);
    switch (leaf) {
    case 1 :
        l1 = &l1i;
    case 0 :
        if (!l1->val)
            return;
        assoc = assocs[l1->assoc];
        line_size = l1->line_size;
        lines_per_tag = l1->lines_per_tag;
        size_in_kb = l1->size_in_kb;
        break;
    case 2 :
        if (!l2.val)
            return;
        assoc = assocs[l2.assoc];
        line_size = l2.line_size;
        lines_per_tag = l2.lines_per_tag;
        size_in_kb = current_cpu_data.x86_cache_size;
        break;
    case 3 :
        if (!l3.val)
            return;
        assoc = assocs[l3.assoc];
        line_size = l3.line_size;
        lines_per_tag = l3.lines_per_tag;
        size_in_kb = l3.size_encoded * 512;
        if (boot_cpu_has (X86_FEATURE_AMD_DCM)) {
            size_in_kb = size_in_kb >> 1;
            assoc = assoc >> 1;
        }
        break;
    default :
        return;
    }
    eax->split.is_self_initializing = 1;
    eax->split.type = types[leaf];
    eax->split.level = levels[leaf];
    eax->split.num_threads_sharing = 0;
    eax->split.num_cores_on_die = current_cpu_data.x86_max_cores - 1;
    if (assoc == 0xffff)
        eax->split.is_fully_associative = 1;
    ebx->split.coherency_line_size = line_size - 1;
    ebx->split.ways_of_associativity = assoc - 1;
    ebx->split.physical_line_partition = lines_per_tag - 1;
    ecx->split.number_of_sets = (size_in_kb * 1024) / line_size / (ebx->split.ways_of_associativity + 1) - 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="246" endline="280">
{
case 1 :
    l1 = &l1i;
case 0 :
    if (!l1->val)
        return;
    assoc = assocs[l1->assoc];
    line_size = l1->line_size;
    lines_per_tag = l1->lines_per_tag;
    size_in_kb = l1->size_in_kb;
    break;
case 2 :
    if (!l2.val)
        return;
    assoc = assocs[l2.assoc];
    line_size = l2.line_size;
    lines_per_tag = l2.lines_per_tag;
    size_in_kb = current_cpu_data.x86_cache_size;
    break;
case 3 :
    if (!l3.val)
        return;
    assoc = assocs[l3.assoc];
    line_size = l3.line_size;
    lines_per_tag = l3.lines_per_tag;
    size_in_kb = l3.size_encoded * 512;
    if (boot_cpu_has (X86_FEATURE_AMD_DCM)) {
        size_in_kb = size_in_kb >> 1;
        assoc = assoc >> 1;
    }
    break;
default :
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="273" endline="276">
{
    size_in_kb = size_in_kb >> 1;
    assoc = assoc >> 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="435" endline="436">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="442" endline="467">
{
    union _cpuid4_leaf_eax eax;
    union _cpuid4_leaf_ebx ebx;
    union _cpuid4_leaf_ecx ecx;
    unsigned edx;
    if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD) {
        amd_cpuid4 (index, & eax, & ebx, & ecx);
        if (boot_cpu_data.x86 >= 0x10)
            amd_check_l3_disable (index, this_leaf);
    }
    else {
        cpuid_count (4, index, & eax.full, & ebx.full, & ecx.full, & edx);
    }
    if (eax.split.type == CACHE_TYPE_NULL)
        return -EIO;
    this_leaf->eax = eax;
    this_leaf->ebx = ebx;
    this_leaf->ecx = ecx;
    this_leaf->size = (ecx.split.number_of_sets + 1) * (ebx.split.coherency_line_size + 1) * (ebx.split.physical_line_partition + 1) * (ebx.split.ways_of_associativity + 1);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="448" endline="452">
{
    amd_cpuid4 (index, & eax, & ebx, & ecx);
    if (boot_cpu_data.x86 >= 0x10)
        amd_check_l3_disable (index, this_leaf);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="452" endline="454">
{
    cpuid_count (4, index, & eax.full, & ebx.full, & ecx.full, & edx);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="470" endline="482">
{
    unsigned int eax, ebx, ecx, edx;
    union _cpuid4_leaf_eax cache_eax;
    int i = -1;
    do {
        ++i;
        cpuid_count (4, i, & eax, & ebx, & ecx, & edx);
        cache_eax.full = eax;
    }
    while (cache_eax.split.type != CACHE_TYPE_NULL);
    return i;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="475" endline="480">
{
    ++i;
    cpuid_count (4, i, & eax, & ebx, & ecx, & edx);
    cache_eax.full = eax;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="485" endline="627">
{
    unsigned int trace = 0, l1i = 0, l1d = 0, l2 = 0, l3 = 0;
    unsigned int new_l1d = 0, new_l1i = 0;
    unsigned int new_l2 = 0, new_l3 = 0, i;
    unsigned int l2_id = 0, l3_id = 0, num_threads_sharing, index_msb;
    if (c->cpuid_level > 3) {
        static int is_initialized;
        if (is_initialized == 0) {
            num_cache_leaves = find_num_cache_leaves ();
            is_initialized++;
        }
        for (i = 0; i < num_cache_leaves; i++) {
            struct _cpuid4_info_regs this_leaf;
            int retval;
            retval = cpuid4_cache_lookup_regs (i, &this_leaf);
            if (retval >= 0) {
                switch (this_leaf.eax.split.level) {
                case 1 :
                    if (this_leaf.eax.split.type == CACHE_TYPE_DATA)
                        new_l1d = this_leaf.size / 1024;
                    else if (this_leaf.eax.split.type == CACHE_TYPE_INST)
                        new_l1i = this_leaf.size / 1024;
                    break;
                case 2 :
                    new_l2 = this_leaf.size / 1024;
                    num_threads_sharing = 1 + this_leaf.eax.split.num_threads_sharing;
                    index_msb = get_count_order (num_threads_sharing);
                    l2_id = c->apicid >> index_msb;
                    break;
                case 3 :
                    new_l3 = this_leaf.size / 1024;
                    num_threads_sharing = 1 + this_leaf.eax.split.num_threads_sharing;
                    index_msb = get_count_order (num_threads_sharing);
                    l3_id = c->apicid >> index_msb;
                    break;
                default :
                    break;
                }
            }
        }
    }
    if ((num_cache_leaves == 0 || c->x86 == 15) && c->cpuid_level > 1) {
        int j, n;
        unsigned int regs [4];
        unsigned char *dp = (unsigned char *) regs;
        int only_trace = 0;
        if (num_cache_leaves != 0 && c->x86 == 15)
            only_trace = 1;
        n = cpuid_eax (2) & 0xFF;
        for (i = 0; i < n; i++) {
            cpuid (2, & regs [0], & regs [1], & regs [2], & regs [3]);
            for (j = 0; j < 3; j++)
                if (regs[j] & (1 << 31))
                    regs[j] = 0;
            for (j = 1; j < 16; j++) {
                unsigned char des = dp[j];
                unsigned char k = 0;
                while (cache_table[k].descriptor != 0) {
                    if (cache_table[k].descriptor == des) {
                        if (only_trace && cache_table[k].cache_type != LVL_TRACE)
                            break;
                        switch (cache_table[k].cache_type) {
                        case LVL_1_INST :
                            l1i += cache_table[k].size;
                            break;
                        case LVL_1_DATA :
                            l1d += cache_table[k].size;
                            break;
                        case LVL_2 :
                            l2 += cache_table[k].size;
                            break;
                        case LVL_3 :
                            l3 += cache_table[k].size;
                            break;
                        case LVL_TRACE :
                            trace += cache_table[k].size;
                            break;
                        }
                        break;
                    }
                    k++;
                }
            }
        }
    }
    if (new_l1d)
        l1d = new_l1d;
    if (new_l1i)
        l1i = new_l1i;
    if (new_l2) {
        l2 = new_l2;
    }
    if (new_l3) {
        l3 = new_l3;
    }
    c->x86_cache_size = l3 ? l3 : (l2 ? l2 : (l1i + l1d));
    return l2;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="495" endline="541">
{
    static int is_initialized;
    if (is_initialized == 0) {
        num_cache_leaves = find_num_cache_leaves ();
        is_initialized++;
    }
    for (i = 0; i < num_cache_leaves; i++) {
        struct _cpuid4_info_regs this_leaf;
        int retval;
        retval = cpuid4_cache_lookup_regs (i, &this_leaf);
        if (retval >= 0) {
            switch (this_leaf.eax.split.level) {
            case 1 :
                if (this_leaf.eax.split.type == CACHE_TYPE_DATA)
                    new_l1d = this_leaf.size / 1024;
                else if (this_leaf.eax.split.type == CACHE_TYPE_INST)
                    new_l1i = this_leaf.size / 1024;
                break;
            case 2 :
                new_l2 = this_leaf.size / 1024;
                num_threads_sharing = 1 + this_leaf.eax.split.num_threads_sharing;
                index_msb = get_count_order (num_threads_sharing);
                l2_id = c->apicid >> index_msb;
                break;
            case 3 :
                new_l3 = this_leaf.size / 1024;
                num_threads_sharing = 1 + this_leaf.eax.split.num_threads_sharing;
                index_msb = get_count_order (num_threads_sharing);
                l3_id = c->apicid >> index_msb;
                break;
            default :
                break;
            }
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="498" endline="502">
{
    num_cache_leaves = find_num_cache_leaves ();
    is_initialized++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="508" endline="540">
{
    struct _cpuid4_info_regs this_leaf;
    int retval;
    retval = cpuid4_cache_lookup_regs (i, &this_leaf);
    if (retval >= 0) {
        switch (this_leaf.eax.split.level) {
        case 1 :
            if (this_leaf.eax.split.type == CACHE_TYPE_DATA)
                new_l1d = this_leaf.size / 1024;
            else if (this_leaf.eax.split.type == CACHE_TYPE_INST)
                new_l1i = this_leaf.size / 1024;
            break;
        case 2 :
            new_l2 = this_leaf.size / 1024;
            num_threads_sharing = 1 + this_leaf.eax.split.num_threads_sharing;
            index_msb = get_count_order (num_threads_sharing);
            l2_id = c->apicid >> index_msb;
            break;
        case 3 :
            new_l3 = this_leaf.size / 1024;
            num_threads_sharing = 1 + this_leaf.eax.split.num_threads_sharing;
            index_msb = get_count_order (num_threads_sharing);
            l3_id = c->apicid >> index_msb;
            break;
        default :
            break;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="513" endline="539">
{
    switch (this_leaf.eax.split.level) {
    case 1 :
        if (this_leaf.eax.split.type == CACHE_TYPE_DATA)
            new_l1d = this_leaf.size / 1024;
        else if (this_leaf.eax.split.type == CACHE_TYPE_INST)
            new_l1i = this_leaf.size / 1024;
        break;
    case 2 :
        new_l2 = this_leaf.size / 1024;
        num_threads_sharing = 1 + this_leaf.eax.split.num_threads_sharing;
        index_msb = get_count_order (num_threads_sharing);
        l2_id = c->apicid >> index_msb;
        break;
    case 3 :
        new_l3 = this_leaf.size / 1024;
        num_threads_sharing = 1 + this_leaf.eax.split.num_threads_sharing;
        index_msb = get_count_order (num_threads_sharing);
        l3_id = c->apicid >> index_msb;
        break;
    default :
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="514" endline="538">
{
case 1 :
    if (this_leaf.eax.split.type == CACHE_TYPE_DATA)
        new_l1d = this_leaf.size / 1024;
    else if (this_leaf.eax.split.type == CACHE_TYPE_INST)
        new_l1i = this_leaf.size / 1024;
    break;
case 2 :
    new_l2 = this_leaf.size / 1024;
    num_threads_sharing = 1 + this_leaf.eax.split.num_threads_sharing;
    index_msb = get_count_order (num_threads_sharing);
    l2_id = c->apicid >> index_msb;
    break;
case 3 :
    new_l3 = this_leaf.size / 1024;
    num_threads_sharing = 1 + this_leaf.eax.split.num_threads_sharing;
    index_msb = get_count_order (num_threads_sharing);
    l3_id = c->apicid >> index_msb;
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="546" endline="602">
{
    int j, n;
    unsigned int regs [4];
    unsigned char *dp = (unsigned char *) regs;
    int only_trace = 0;
    if (num_cache_leaves != 0 && c->x86 == 15)
        only_trace = 1;
    n = cpuid_eax (2) & 0xFF;
    for (i = 0; i < n; i++) {
        cpuid (2, & regs [0], & regs [1], & regs [2], & regs [3]);
        for (j = 0; j < 3; j++)
            if (regs[j] & (1 << 31))
                regs[j] = 0;
        for (j = 1; j < 16; j++) {
            unsigned char des = dp[j];
            unsigned char k = 0;
            while (cache_table[k].descriptor != 0) {
                if (cache_table[k].descriptor == des) {
                    if (only_trace && cache_table[k].cache_type != LVL_TRACE)
                        break;
                    switch (cache_table[k].cache_type) {
                    case LVL_1_INST :
                        l1i += cache_table[k].size;
                        break;
                    case LVL_1_DATA :
                        l1d += cache_table[k].size;
                        break;
                    case LVL_2 :
                        l2 += cache_table[k].size;
                        break;
                    case LVL_3 :
                        l3 += cache_table[k].size;
                        break;
                    case LVL_TRACE :
                        trace += cache_table[k].size;
                        break;
                    }
                    break;
                }
                k++;
            }
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="559" endline="601">
{
    cpuid (2, & regs [0], & regs [1], & regs [2], & regs [3]);
    for (j = 0; j < 3; j++)
        if (regs[j] & (1 << 31))
            regs[j] = 0;
    for (j = 1; j < 16; j++) {
        unsigned char des = dp[j];
        unsigned char k = 0;
        while (cache_table[k].descriptor != 0) {
            if (cache_table[k].descriptor == des) {
                if (only_trace && cache_table[k].cache_type != LVL_TRACE)
                    break;
                switch (cache_table[k].cache_type) {
                case LVL_1_INST :
                    l1i += cache_table[k].size;
                    break;
                case LVL_1_DATA :
                    l1d += cache_table[k].size;
                    break;
                case LVL_2 :
                    l2 += cache_table[k].size;
                    break;
                case LVL_3 :
                    l3 += cache_table[k].size;
                    break;
                case LVL_TRACE :
                    trace += cache_table[k].size;
                    break;
                }
                break;
            }
            k++;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="568" endline="600">
{
    unsigned char des = dp[j];
    unsigned char k = 0;
    while (cache_table[k].descriptor != 0) {
        if (cache_table[k].descriptor == des) {
            if (only_trace && cache_table[k].cache_type != LVL_TRACE)
                break;
            switch (cache_table[k].cache_type) {
            case LVL_1_INST :
                l1i += cache_table[k].size;
                break;
            case LVL_1_DATA :
                l1d += cache_table[k].size;
                break;
            case LVL_2 :
                l2 += cache_table[k].size;
                break;
            case LVL_3 :
                l3 += cache_table[k].size;
                break;
            case LVL_TRACE :
                trace += cache_table[k].size;
                break;
            }
            break;
        }
        k++;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="573" endline="599">
{
    if (cache_table[k].descriptor == des) {
        if (only_trace && cache_table[k].cache_type != LVL_TRACE)
            break;
        switch (cache_table[k].cache_type) {
        case LVL_1_INST :
            l1i += cache_table[k].size;
            break;
        case LVL_1_DATA :
            l1d += cache_table[k].size;
            break;
        case LVL_2 :
            l2 += cache_table[k].size;
            break;
        case LVL_3 :
            l3 += cache_table[k].size;
            break;
        case LVL_TRACE :
            trace += cache_table[k].size;
            break;
        }
        break;
    }
    k++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="574" endline="596">
{
    if (only_trace && cache_table[k].cache_type != LVL_TRACE)
        break;
    switch (cache_table[k].cache_type) {
    case LVL_1_INST :
        l1i += cache_table[k].size;
        break;
    case LVL_1_DATA :
        l1d += cache_table[k].size;
        break;
    case LVL_2 :
        l2 += cache_table[k].size;
        break;
    case LVL_3 :
        l3 += cache_table[k].size;
        break;
    case LVL_TRACE :
        trace += cache_table[k].size;
        break;
    }
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="577" endline="593">
{
case LVL_1_INST :
    l1i += cache_table[k].size;
    break;
case LVL_1_DATA :
    l1d += cache_table[k].size;
    break;
case LVL_2 :
    l2 += cache_table[k].size;
    break;
case LVL_3 :
    l3 += cache_table[k].size;
    break;
case LVL_TRACE :
    trace += cache_table[k].size;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="610" endline="615">
{
    l2 = new_l2;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel_cacheinfo.c.ifdefed" startline="617" endline="622">
{
    l3 = new_l3;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="84" endline="88">
{
    struct cpuinfo_x86 *cpu = &cpu_data (cpuid);
    return cpu_has (cpu, X86_FEATURE_EST);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="91" endline="102">
{
    struct acpi_processor_performance *perf;
    int i;
    perf = data->acpi_data;
    for (i = 0; i < perf->state_count; i++) {
        if (value == perf->states[i].status)
            return data->freq_table[i].frequency;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="97" endline="100">
{
    if (value == perf->states[i].status)
        return data->freq_table[i].frequency;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="105" endline="117">
{
    int i;
    struct acpi_processor_performance *perf;
    msr &= INTEL_MSR_RANGE;
    perf = data->acpi_data;
    for (i = 0; data->freq_table[i].frequency != CPUFREQ_TABLE_END; i++) {
        if (msr == perf->states[data->freq_table[i].index].status)
            return data->freq_table[i].frequency;
    }
    return data->freq_table[0].frequency;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="112" endline="115">
{
    if (msr == perf->states[data->freq_table[i].index].status)
        return data->freq_table[i].frequency;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="120" endline="129">
{
    switch (data->cpu_feature) {
    case SYSTEM_INTEL_MSR_CAPABLE :
        return extract_msr (val, data);
    case SYSTEM_IO_CAPABLE :
        return extract_io (val, data);
    default :
        return 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="121" endline="128">
{
case SYSTEM_INTEL_MSR_CAPABLE :
    return extract_msr (val, data);
case SYSTEM_IO_CAPABLE :
    return extract_io (val, data);
default :
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="152" endline="168">
{
    struct drv_cmd *cmd = _cmd;
    u32 h;
    switch (cmd->type) {
    case SYSTEM_INTEL_MSR_CAPABLE :
        rdmsr (cmd->addr.msr.reg, cmd->val, h);
        break;
    case SYSTEM_IO_CAPABLE :
        acpi_os_read_port ((acpi_io_address) cmd->addr.io.port, &cmd->val, (u32) cmd->addr.io.bit_width);
        break;
    default :
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="156" endline="167">
{
case SYSTEM_INTEL_MSR_CAPABLE :
    rdmsr (cmd->addr.msr.reg, cmd->val, h);
    break;
case SYSTEM_IO_CAPABLE :
    acpi_os_read_port ((acpi_io_address) cmd->addr.io.port, &cmd->val, (u32) cmd->addr.io.bit_width);
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="172" endline="190">
{
    struct drv_cmd *cmd = _cmd;
    u32 lo, hi;
    switch (cmd->type) {
    case SYSTEM_INTEL_MSR_CAPABLE :
        rdmsr (cmd->addr.msr.reg, lo, hi);
        lo = (lo & ~INTEL_MSR_RANGE) | (cmd->val & INTEL_MSR_RANGE);
        wrmsr (cmd -> addr.msr.reg, lo, hi);
        break;
    case SYSTEM_IO_CAPABLE :
        acpi_os_write_port ((acpi_io_address) cmd->addr.io.port, cmd->val, (u32) cmd->addr.io.bit_width);
        break;
    default :
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="176" endline="189">
{
case SYSTEM_INTEL_MSR_CAPABLE :
    rdmsr (cmd->addr.msr.reg, lo, hi);
    lo = (lo & ~INTEL_MSR_RANGE) | (cmd->val & INTEL_MSR_RANGE);
    wrmsr (cmd -> addr.msr.reg, lo, hi);
    break;
case SYSTEM_IO_CAPABLE :
    acpi_os_write_port ((acpi_io_address) cmd->addr.io.port, cmd->val, (u32) cmd->addr.io.bit_width);
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="193" endline="199">
{
    int err;
    cmd->val = 0;
    err = smp_call_function_any (cmd->mask, do_drv_read, cmd, 1);
    WARN_ON_ONCE (err);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="202" endline="210">
{
    int this_cpu;
    this_cpu = get_cpu ();
    if (cpumask_test_cpu (this_cpu, cmd->mask))
        do_drv_write (cmd);
    smp_call_function_many (cmd -> mask, do_drv_write, cmd, 1);
    put_cpu ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="213" endline="241">
{
    struct acpi_processor_performance *perf;
    struct drv_cmd cmd;
    if (unlikely (cpumask_empty (mask)))
        return 0;
    switch (per_cpu (acfreq_data, cpumask_first (mask))->cpu_feature) {
    case SYSTEM_INTEL_MSR_CAPABLE :
        cmd.type = SYSTEM_INTEL_MSR_CAPABLE;
        cmd.addr.msr.reg = MSR_IA32_PERF_STATUS;
        break;
    case SYSTEM_IO_CAPABLE :
        cmd.type = SYSTEM_IO_CAPABLE;
        perf = per_cpu (acfreq_data, cpumask_first (mask))->acpi_data;
        cmd.addr.io.port = perf->control_register.address;
        cmd.addr.io.bit_width = perf->control_register.bit_width;
        break;
    default :
        return 0;
    }
    cmd.mask = mask;
    drv_read (& cmd);
    dprintk ("get_cur_val = %u\n", cmd.val);
    return cmd.val;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="220" endline="233">
{
case SYSTEM_INTEL_MSR_CAPABLE :
    cmd.type = SYSTEM_INTEL_MSR_CAPABLE;
    cmd.addr.msr.reg = MSR_IA32_PERF_STATUS;
    break;
case SYSTEM_IO_CAPABLE :
    cmd.type = SYSTEM_IO_CAPABLE;
    perf = per_cpu (acfreq_data, cpumask_first (mask))->acpi_data;
    cmd.addr.io.port = perf->control_register.address;
    cmd.addr.io.bit_width = perf->control_register.bit_width;
    break;
default :
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="245" endline="249">
{
    struct aperfmperf *am = _cur;
    get_aperfmperf (am);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="266" endline="280">
{
    struct aperfmperf perf;
    unsigned long ratio;
    unsigned int retval;
    if (smp_call_function_single (cpu, read_measured_perf_ctrs, &perf, 1))
        return 0;
    ratio = calc_aperfmperf_ratio (&per_cpu (acfreq_old_perf, cpu), &perf);
    per_cpu (acfreq_old_perf, cpu) = perf;
    retval = (policy->cpuinfo.max_freq * ratio) >> APERFMPERF_SHIFT;
    return retval;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="283" endline="308">
{
    struct acpi_cpufreq_data *data = per_cpu (acfreq_data, cpu);
    unsigned int freq;
    unsigned int cached_freq;
    dprintk ("get_cur_freq_on_cpu (%d)\n", cpu);
    if (unlikely (data == NULL || data->acpi_data == NULL || data->freq_table == NULL)) {
        return 0;
    }
    cached_freq = data->freq_table[data->acpi_data->state].frequency;
    freq = extract_freq (get_cur_val (cpumask_of (cpu)), data);
    if (freq != cached_freq) {
        data->resume = 1;
    }
    dprintk ("cur freq = %u\n", freq);
    return freq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="291" endline="293">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="297" endline="303">
{
    data->resume = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="312" endline="323">
{
    unsigned int cur_freq;
    unsigned int i;
    for (i = 0; i < 100; i++) {
        cur_freq = extract_freq (get_cur_val (mask), data);
        if (cur_freq == freq)
            return 1;
        udelay (10);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="316" endline="321">
{
    cur_freq = extract_freq (get_cur_val (mask), data);
    if (cur_freq == freq)
        return 1;
    udelay (10);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="327" endline="418">
{
    struct acpi_cpufreq_data *data = per_cpu (acfreq_data, policy->cpu);
    struct acpi_processor_performance *perf;
    struct cpufreq_freqs freqs;
    struct drv_cmd cmd;
    unsigned int next_state = 0;
    unsigned int next_perf_state = 0;
    unsigned int i;
    int result = 0;
    dprintk ("acpi_cpufreq_target %d (%d)\n", target_freq, policy -> cpu);
    if (unlikely (data == NULL || data->acpi_data == NULL || data->freq_table == NULL)) {
        return -ENODEV;
    }
    perf = data->acpi_data;
    result = cpufreq_frequency_table_target (policy, data->freq_table, target_freq, relation, &next_state);
    if (unlikely (result)) {
        result = -ENODEV;
        goto out;
    }
    next_perf_state = data->freq_table[next_state].index;
    if (perf->state == next_perf_state) {
        if (unlikely (data->resume)) {
            dprintk ("Called after resume, resetting to P%d\n", next_perf_state);
            data->resume = 0;
        }
        else {
            dprintk ("Already at target state (P%d)\n", next_perf_state);
            goto out;
        }
    }
    trace_power_frequency (POWER_PSTATE, data -> freq_table [next_state].frequency);
    switch (data->cpu_feature) {
    case SYSTEM_INTEL_MSR_CAPABLE :
        cmd.type = SYSTEM_INTEL_MSR_CAPABLE;
        cmd.addr.msr.reg = MSR_IA32_PERF_CTL;
        cmd.val = (u32) perf->states[next_perf_state].control;
        break;
    case SYSTEM_IO_CAPABLE :
        cmd.type = SYSTEM_IO_CAPABLE;
        cmd.addr.io.port = perf->control_register.address;
        cmd.addr.io.bit_width = perf->control_register.bit_width;
        cmd.val = (u32) perf->states[next_perf_state].control;
        break;
    default :
        result = -ENODEV;
        goto out;
    }
    if (policy->shared_type != CPUFREQ_SHARED_TYPE_ANY)
        cmd.mask = policy->cpus;
    else
        cmd.mask = cpumask_of (policy->cpu);
    freqs.old = perf->states[perf->state].core_frequency * 1000;
    freqs.new = data->freq_table[next_state].frequency;
    for_each_cpu (i, cmd.mask) {freqs
        .cpu = i cpufreq_notify_transition (&freqs, CPUFREQ_PRECHANGE)
    } drv_write (&cmd)
    if (acpi_pstate_strict) {
        if (!check_freqs (cmd.mask, freqs.new, data)) {
            dprintk ("acpi_cpufreq_target failed (%d)\n", policy -> cpu);
            result = -EAGAIN;
            goto out;
        }
    }
    for_each_cpu (i, cmd.mask) {freqs
        .cpu = i cpufreq_notify_transition (&freqs, CPUFREQ_POSTCHANGE)
    } perf->state
    = next_perf_state;
out :
    return result;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="340" endline="342">
{
    return -ENODEV;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="349" endline="352">
{
    result = -ENODEV;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="355" endline="365">
{
    if (unlikely (data->resume)) {
        dprintk ("Called after resume, resetting to P%d\n", next_perf_state);
        data->resume = 0;
    }
    else {
        dprintk ("Already at target state (P%d)\n", next_perf_state);
        goto out;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="356" endline="360">
{
    dprintk ("Called after resume, resetting to P%d\n", next_perf_state);
    data->resume = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="360" endline="364">
{
    dprintk ("Already at target state (P%d)\n", next_perf_state);
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="369" endline="384">
{
case SYSTEM_INTEL_MSR_CAPABLE :
    cmd.type = SYSTEM_INTEL_MSR_CAPABLE;
    cmd.addr.msr.reg = MSR_IA32_PERF_CTL;
    cmd.val = (u32) perf->states[next_perf_state].control;
    break;
case SYSTEM_IO_CAPABLE :
    cmd.type = SYSTEM_IO_CAPABLE;
    cmd.addr.io.port = perf->control_register.address;
    cmd.addr.io.bit_width = perf->control_register.bit_width;
    cmd.val = (u32) perf->states[next_perf_state].control;
    break;
default :
    result = -ENODEV;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="401" endline="408">
{
    if (!check_freqs (cmd.mask, freqs.new, data)) {
        dprintk ("acpi_cpufreq_target failed (%d)\n", policy -> cpu);
        result = -EAGAIN;
        goto out;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="402" endline="407">
{
    dprintk ("acpi_cpufreq_target failed (%d)\n", policy -> cpu);
    result = -EAGAIN;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="421" endline="427">
{
    struct acpi_cpufreq_data *data = per_cpu (acfreq_data, policy->cpu);
    dprintk ("acpi_cpufreq_verify\n");
    return cpufreq_frequency_table_verify (policy, data->freq_table);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="431" endline="455">
{
    struct acpi_processor_performance *perf = data->acpi_data;
    if (cpu_khz) {
        unsigned int i;
        unsigned long freq;
        unsigned long freqn = perf->states[0].core_frequency * 1000;
        for (i = 0; i < (perf->state_count - 1); i++) {
            freq = freqn;
            freqn = perf->states[i + 1].core_frequency * 1000;
            if ((2 * cpu_khz) > (freqn + freq)) {
                perf->state = i;
                return freq;
            }
        }
        perf->state = perf->state_count - 1;
        return freqn;
    }
    else {
        perf->state = 0;
        return perf->states[0].core_frequency * 1000;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="434" endline="450">
{
    unsigned int i;
    unsigned long freq;
    unsigned long freqn = perf->states[0].core_frequency * 1000;
    for (i = 0; i < (perf->state_count - 1); i++) {
        freq = freqn;
        freqn = perf->states[i + 1].core_frequency * 1000;
        if ((2 * cpu_khz) > (freqn + freq)) {
            perf->state = i;
            return freq;
        }
    }
    perf->state = perf->state_count - 1;
    return freqn;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="440" endline="447">
{
    freq = freqn;
    freqn = perf->states[i + 1].core_frequency * 1000;
    if ((2 * cpu_khz) > (freqn + freq)) {
        perf->state = i;
        return freq;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="443" endline="446">
{
    perf->state = i;
    return freq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="450" endline="454">
{
    perf->state = 0;
    return perf->states[0].core_frequency * 1000;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="458" endline="466">
{
    unsigned int i;
    for_each_possible_cpu (i)
    free_cpumask_var (per_cpu_ptr (acpi_perf_data, i) -> shared_cpu_map);
    free_percpu (acpi_perf_data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="477" endline="500">
{
    unsigned int i;
    dprintk ("acpi_cpufreq_early_init\n");
    acpi_perf_data = alloc_percpu (struct acpi_processor_performance);
    if (!acpi_perf_data) {
        dprintk ("Memory allocation error for acpi_perf_data.\n");
        return -ENOMEM;
    }

    for_each_possible_cpu (i) {
        if (!zalloc_cpumask_var_node (&per_cpu_ptr (acpi_perf_data, i)->shared_cpu_map, GFP_KERNEL, cpu_to_node (i))) {
            free_acpi_perf_data ();
            return -ENOMEM;
        }
    }

    acpi_processor_preregister_performance (acpi_perf_data);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="482" endline="485">
{
    dprintk ("Memory allocation error for acpi_perf_data.\n");
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="486" endline="495">
{
    if (!zalloc_cpumask_var_node (&per_cpu_ptr (acpi_perf_data, i)->shared_cpu_map, GFP_KERNEL, cpu_to_node (i))) {
        free_acpi_perf_data ();
        return -ENOMEM;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="489" endline="494">
{
    free_acpi_perf_data ();
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="553" endline="734">
{
    unsigned int i;
    unsigned int valid_states = 0;
    unsigned int cpu = policy->cpu;
    struct acpi_cpufreq_data *data;
    unsigned int result = 0;
    struct cpuinfo_x86 *c = &cpu_data (policy->cpu);
    struct acpi_processor_performance *perf;
    dprintk ("acpi_cpufreq_cpu_init\n");
    data = kzalloc (sizeof (struct acpi_cpufreq_data), GFP_KERNEL);
    if (!data)
        return -ENOMEM;
    data->acpi_data = per_cpu_ptr (acpi_perf_data, cpu);
    per_cpu (acfreq_data, cpu) = data;
    if (cpu_has (c, X86_FEATURE_CONSTANT_TSC))
        acpi_cpufreq_driver.flags |= CPUFREQ_CONST_LOOPS;
    result = acpi_processor_register_performance (data->acpi_data, cpu);
    if (result)
        goto err_free;
    perf = data->acpi_data;
    policy->shared_type = perf->shared_type;
    if (policy->shared_type == CPUFREQ_SHARED_TYPE_ALL || policy->shared_type == CPUFREQ_SHARED_TYPE_ANY) {
        cpumask_copy (policy -> cpus, perf -> shared_cpu_map);
    }
    cpumask_copy (policy -> related_cpus, perf -> shared_cpu_map);
    if (perf->state_count <= 1) {
        dprintk ("No P-States\n");
        result = -ENODEV;
        goto err_unreg;
    }
    if (perf->control_register.space_id != perf->status_register.space_id) {
        result = -ENODEV;
        goto err_unreg;
    }
    switch (perf->control_register.space_id) {
    case ACPI_ADR_SPACE_SYSTEM_IO :
        dprintk ("SYSTEM IO addr space\n");
        data->cpu_feature = SYSTEM_IO_CAPABLE;
        break;
    case ACPI_ADR_SPACE_FIXED_HARDWARE :
        dprintk ("HARDWARE addr space\n");
        if (!check_est_cpu (cpu)) {
            result = -ENODEV;
            goto err_unreg;
        }
        data->cpu_feature = SYSTEM_INTEL_MSR_CAPABLE;
        break;
    default :
        dprintk ("Unknown addr space %d\n", (u32) (perf->control_register.space_id));
        result = -ENODEV;
        goto err_unreg;
    }
    data->freq_table = kmalloc (sizeof (struct cpufreq_frequency_table) * (perf->state_count + 1), GFP_KERNEL);
    if (!data->freq_table) {
        result = -ENOMEM;
        goto err_unreg;
    }
    policy->cpuinfo.transition_latency = 0;
    for (i = 0; i < perf->state_count; i++) {
        if ((perf->states[i].transition_latency * 1000) > policy->cpuinfo.transition_latency)
            policy->cpuinfo.transition_latency = perf->states[i].transition_latency * 1000;
    }
    if (perf->control_register.space_id == ACPI_ADR_SPACE_FIXED_HARDWARE && policy->cpuinfo.transition_latency > 20 * 1000) {
        policy->cpuinfo.transition_latency = 20 * 1000;
        printk_once (KERN_INFO "P-state transition latency capped at 20 uS\n");
    }
    for (i = 0; i < perf->state_count; i++) {
        if (i > 0 && perf->states[i].core_frequency >= data->freq_table[valid_states - 1].frequency / 1000)
            continue;
        data->freq_table[valid_states].index = i;
        data->freq_table[valid_states].frequency = perf->states[i].core_frequency * 1000;
        valid_states++;
    }
    data->freq_table[valid_states].frequency = CPUFREQ_TABLE_END;
    perf->state = 0;
    result = cpufreq_frequency_table_cpuinfo (policy, data->freq_table);
    if (result)
        goto err_freqfree;
    if (perf->states[0].core_frequency * 1000 != policy->cpuinfo.max_freq)
        printk (KERN_WARNING FW_WARN "P-state 0 is not max freq\n");
    switch (perf->control_register.space_id) {
    case ACPI_ADR_SPACE_SYSTEM_IO :
        policy->cur = acpi_cpufreq_guess_freq (data, policy->cpu);
        break;
    case ACPI_ADR_SPACE_FIXED_HARDWARE :
        acpi_cpufreq_driver.get = get_cur_freq_on_cpu;
        policy->cur = get_cur_freq_on_cpu (cpu);
        break;
    default :
        break;
    }
    acpi_processor_notify_smm (THIS_MODULE);
    if (cpu_has (c, X86_FEATURE_APERFMPERF))
        acpi_cpufreq_driver.getavg = get_measured_perf;
    dprintk ("CPU%u - ACPI performance management activated.\n", cpu);
    for (i = 0; i < perf->state_count; i++)
        dprintk ("     %cP%d: %d MHz, %d mW, %d uS\n", (i == perf->state ? '*' : ' '), i, (u32) perf->states[i].core_frequency, (u32) perf->states[i].power, (u32) perf->states[i].transition_latency);
    cpufreq_frequency_table_get_attr (data -> freq_table, policy -> cpu);
    data->resume = 1;
    return result;
err_freqfree :
    kfree (data->freq_table);
err_unreg :
    acpi_processor_unregister_performance (perf, cpu);
err_free :
    kfree (data);
    per_cpu (acfreq_data, cpu) = NULL;
    return result;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="597" endline="599">
{
    cpumask_copy (policy -> cpus, perf -> shared_cpu_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="611" endline="615">
{
    dprintk ("No P-States\n");
    result = -ENODEV;
    goto err_unreg;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="617" endline="620">
{
    result = -ENODEV;
    goto err_unreg;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="622" endline="640">
{
case ACPI_ADR_SPACE_SYSTEM_IO :
    dprintk ("SYSTEM IO addr space\n");
    data->cpu_feature = SYSTEM_IO_CAPABLE;
    break;
case ACPI_ADR_SPACE_FIXED_HARDWARE :
    dprintk ("HARDWARE addr space\n");
    if (!check_est_cpu (cpu)) {
        result = -ENODEV;
        goto err_unreg;
    }
    data->cpu_feature = SYSTEM_INTEL_MSR_CAPABLE;
    break;
default :
    dprintk ("Unknown addr space %d\n", (u32) (perf->control_register.space_id));
    result = -ENODEV;
    goto err_unreg;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="629" endline="632">
{
    result = -ENODEV;
    goto err_unreg;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="644" endline="647">
{
    result = -ENOMEM;
    goto err_unreg;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="651" endline="656">
{
    if ((perf->states[i].transition_latency * 1000) > policy->cpuinfo.transition_latency)
        policy->cpuinfo.transition_latency = perf->states[i].transition_latency * 1000;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="660" endline="664">
{
    policy->cpuinfo.transition_latency = 20 * 1000;
    printk_once (KERN_INFO "P-state transition latency capped at 20 uS\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="667" endline="676">
{
    if (i > 0 && perf->states[i].core_frequency >= data->freq_table[valid_states - 1].frequency / 1000)
        continue;
    data->freq_table[valid_states].index = i;
    data->freq_table[valid_states].frequency = perf->states[i].core_frequency * 1000;
    valid_states++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="687" endline="698">
{
case ACPI_ADR_SPACE_SYSTEM_IO :
    policy->cur = acpi_cpufreq_guess_freq (data, policy->cpu);
    break;
case ACPI_ADR_SPACE_FIXED_HARDWARE :
    acpi_cpufreq_driver.get = get_cur_freq_on_cpu;
    policy->cur = get_cur_freq_on_cpu (cpu);
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="737" endline="751">
{
    struct acpi_cpufreq_data *data = per_cpu (acfreq_data, policy->cpu);
    dprintk ("acpi_cpufreq_cpu_exit\n");
    if (data) {
        cpufreq_frequency_table_put_attr (policy -> cpu);
        per_cpu (acfreq_data, policy->cpu) = NULL;
        acpi_processor_unregister_performance (data -> acpi_data, policy -> cpu);
        kfree (data);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="742" endline="748">
{
    cpufreq_frequency_table_put_attr (policy -> cpu);
    per_cpu (acfreq_data, policy->cpu) = NULL;
    acpi_processor_unregister_performance (data -> acpi_data, policy -> cpu);
    kfree (data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="754" endline="762">
{
    struct acpi_cpufreq_data *data = per_cpu (acfreq_data, policy->cpu);
    dprintk ("acpi_cpufreq_resume\n");
    data->resume = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="782" endline="799">
{
    int ret;
    if (acpi_disabled)
        return 0;
    dprintk ("acpi_cpufreq_init\n");
    ret = acpi_cpufreq_early_init ();
    if (ret)
        return ret;
    ret = cpufreq_register_driver (&acpi_cpufreq_driver);
    if (ret)
        free_acpi_perf_data ();
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/cpufreq/acpi-cpufreq.c.ifdefed" startline="802" endline="808">
{
    dprintk ("acpi_cpufreq_exit\n");
    cpufreq_unregister_driver (& acpi_cpufreq_driver);
    free_percpu (acpi_perf_data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/bugs_64.c.ifdefed" startline="15" endline="33">
{
    identify_boot_cpu ();
    alternative_instructions ();
    if (!direct_gbpages)
        set_memory_4k ((unsigned long) __va (0), 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="67" endline="84">
{
    switch (boot_cpu_data.x86_vendor) {
    case X86_VENDOR_AMD :
        return msr - MSR_K7_PERFCTR0;
    case X86_VENDOR_INTEL :
        if (cpu_has (&boot_cpu_data, X86_FEATURE_ARCH_PERFMON))
            return msr - MSR_ARCH_PERFMON_PERFCTR0;
        switch (boot_cpu_data.x86) {
        case 6 :
            return msr - MSR_P6_PERFCTR0;
        case 15 :
            return msr - MSR_P4_BPU_PERFCTR0;
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="69" endline="82">
{
case X86_VENDOR_AMD :
    return msr - MSR_K7_PERFCTR0;
case X86_VENDOR_INTEL :
    if (cpu_has (&boot_cpu_data, X86_FEATURE_ARCH_PERFMON))
        return msr - MSR_ARCH_PERFMON_PERFCTR0;
    switch (boot_cpu_data.x86) {
    case 6 :
        return msr - MSR_P6_PERFCTR0;
    case 15 :
        return msr - MSR_P4_BPU_PERFCTR0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="76" endline="81">
{
case 6 :
    return msr - MSR_P6_PERFCTR0;
case 15 :
    return msr - MSR_P4_BPU_PERFCTR0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="91" endline="109">
{
    switch (boot_cpu_data.x86_vendor) {
    case X86_VENDOR_AMD :
        return msr - MSR_K7_EVNTSEL0;
    case X86_VENDOR_INTEL :
        if (cpu_has (&boot_cpu_data, X86_FEATURE_ARCH_PERFMON))
            return msr - MSR_ARCH_PERFMON_EVENTSEL0;
        switch (boot_cpu_data.x86) {
        case 6 :
            return msr - MSR_P6_EVNTSEL0;
        case 15 :
            return msr - MSR_P4_BSU_ESCR0;
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="93" endline="106">
{
case X86_VENDOR_AMD :
    return msr - MSR_K7_EVNTSEL0;
case X86_VENDOR_INTEL :
    if (cpu_has (&boot_cpu_data, X86_FEATURE_ARCH_PERFMON))
        return msr - MSR_ARCH_PERFMON_EVENTSEL0;
    switch (boot_cpu_data.x86) {
    case 6 :
        return msr - MSR_P6_EVNTSEL0;
    case 15 :
        return msr - MSR_P4_BSU_ESCR0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="100" endline="105">
{
case 6 :
    return msr - MSR_P6_EVNTSEL0;
case 15 :
    return msr - MSR_P4_BSU_ESCR0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="113" endline="117">
{
    BUG_ON (counter > NMI_MAX_COUNTER_BITS);
    return !test_bit (counter, perfctr_nmi_owner);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="121" endline="132">
{
    unsigned int counter;
    counter = nmi_perfctr_msr_to_bit (msr);
    if (counter > NMI_MAX_COUNTER_BITS)
        return 1;
    if (!test_and_set_bit (counter, perfctr_nmi_owner))
        return 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="136" endline="145">
{
    unsigned int counter;
    counter = nmi_perfctr_msr_to_bit (msr);
    if (counter > NMI_MAX_COUNTER_BITS)
        return;
    clear_bit (counter, perfctr_nmi_owner);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="149" endline="160">
{
    unsigned int counter;
    counter = nmi_evntsel_msr_to_bit (msr);
    if (counter > NMI_MAX_COUNTER_BITS)
        return 1;
    if (!test_and_set_bit (counter, evntsel_nmi_owner))
        return 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="164" endline="173">
{
    unsigned int counter;
    counter = nmi_evntsel_msr_to_bit (msr);
    if (counter > NMI_MAX_COUNTER_BITS)
        return;
    clear_bit (counter, evntsel_nmi_owner);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="177" endline="189">
{
    BUG_ON (nmi_watchdog != NMI_LOCAL_APIC);
    if (atomic_read (&nmi_active) <= 0)
        return;
    on_each_cpu (stop_apic_nmi_watchdog, NULL, 1);
    if (wd_ops)
        wd_ops->unreserve ();
    BUG_ON (atomic_read (& nmi_active) != 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="192" endline="209">
{
    BUG_ON (nmi_watchdog != NMI_LOCAL_APIC);
    if (atomic_read (&nmi_active) != 0)
        return;
    if (!wd_ops)
        return;
    if (!wd_ops->reserve ()) {
        printk (KERN_ERR "NMI watchdog: cannot reserve perfctrs\n");
        return;
    }
    on_each_cpu (setup_apic_nmi_watchdog, NULL, 1);
    touch_nmi_watchdog ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="202" endline="205">
{
    printk (KERN_ERR "NMI watchdog: cannot reserve perfctrs\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="216" endline="235">
{
    u64 counter_val;
    unsigned int retval = hz;
    counter_val = (u64) cpu_khz * 1000;
    do_div (counter_val, retval);
    if (counter_val > 0x7fffffffULL) {
        u64 count = (u64) cpu_khz * 1000;
        do_div (count, 0x7fffffffUL);
        retval = count + 1;
    }
    return retval;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="229" endline="233">
{
    u64 count = (u64) cpu_khz * 1000;
    do_div (count, 0x7fffffffUL);
    retval = count + 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="239" endline="246">
{
    u64 count = (u64) cpu_khz * 1000;
    do_div (count, nmi_hz);
    if (descr)
        pr_debug ("setting %s to -0x%08Lx\n", descr, count);
    wrmsrl (perfctr_msr, 0 - count);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="250" endline="257">
{
    u64 count = (u64) cpu_khz * 1000;
    do_div (count, nmi_hz);
    if (descr)
        pr_debug ("setting %s to -0x%08Lx\n", descr, count);
    wrmsr (perfctr_msr, (u32) (- count), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="271" endline="303">
{
    unsigned int perfctr_msr, evntsel_msr;
    unsigned int evntsel;
    struct nmi_watchdog_ctlblk *wd = &__get_cpu_var (nmi_watchdog_ctlblk);
    perfctr_msr = wd_ops->perfctr;
    evntsel_msr = wd_ops->evntsel;
    wrmsrl (perfctr_msr, 0UL);
    evntsel = K7_EVNTSEL_INT | K7_EVNTSEL_OS | K7_EVNTSEL_USR | K7_NMI_EVENT;
    wrmsr (evntsel_msr, evntsel, 0);
    write_watchdog_counter (perfctr_msr, "K7_PERFCTR0", nmi_hz);
    wd->perfctr_msr = perfctr_msr;
    wd->evntsel_msr = evntsel_msr;
    wd->cccr_msr = 0;
    cpu_nmi_set_wd_enabled ();
    apic_write (APIC_LVTPC, APIC_DM_NMI);
    evntsel |= K7_EVNTSEL_ENABLE;
    wrmsr (evntsel_msr, evntsel, 0);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="306" endline="310">
{
    struct nmi_watchdog_ctlblk *wd = &__get_cpu_var (nmi_watchdog_ctlblk);
    wrmsr (wd -> evntsel_msr, 0, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="313" endline="322">
{
    if (!reserve_perfctr_nmi (wd_ops->perfctr))
        return 0;
    if (!reserve_evntsel_nmi (wd_ops->evntsel)) {
        release_perfctr_nmi (wd_ops -> perfctr);
        return 0;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="317" endline="320">
{
    release_perfctr_nmi (wd_ops -> perfctr);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="325" endline="328">
{
    release_evntsel_nmi (wd_ops -> evntsel);
    release_perfctr_nmi (wd_ops -> perfctr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="332" endline="335">
{
    write_watchdog_counter (wd -> perfctr_msr, NULL, nmi_hz);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="359" endline="394">
{
    unsigned int perfctr_msr, evntsel_msr;
    unsigned int evntsel;
    struct nmi_watchdog_ctlblk *wd = &__get_cpu_var (nmi_watchdog_ctlblk);
    perfctr_msr = wd_ops->perfctr;
    evntsel_msr = wd_ops->evntsel;
    if (wrmsr_safe (perfctr_msr, 0, 0) < 0)
        return 0;
    evntsel = P6_EVNTSEL_INT | P6_EVNTSEL_OS | P6_EVNTSEL_USR | P6_NMI_EVENT;
    wrmsr (evntsel_msr, evntsel, 0);
    nmi_hz = adjust_for_32bit_ctr (nmi_hz);
    write_watchdog_counter32 (perfctr_msr, "P6_PERFCTR0", nmi_hz);
    wd->perfctr_msr = perfctr_msr;
    wd->evntsel_msr = evntsel_msr;
    wd->cccr_msr = 0;
    cpu_nmi_set_wd_enabled ();
    apic_write (APIC_LVTPC, APIC_DM_NMI);
    evntsel |= P6_EVNTSEL0_ENABLE;
    wrmsr (evntsel_msr, evntsel, 0);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="397" endline="408">
{
    apic_write (APIC_LVTPC, APIC_DM_NMI);
    write_watchdog_counter32 (wd -> perfctr_msr, NULL, nmi_hz);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="466" endline="559">
{
    unsigned int perfctr_msr, evntsel_msr, cccr_msr;
    unsigned int evntsel, cccr_val;
    unsigned int misc_enable, dummy;
    unsigned int ht_num;
    struct nmi_watchdog_ctlblk *wd = &__get_cpu_var (nmi_watchdog_ctlblk);
    rdmsr (MSR_IA32_MISC_ENABLE, misc_enable, dummy);
    if (!(misc_enable & MSR_P4_MISC_ENABLE_PERF_AVAIL))
        return 0;
    ht_num = 0;
    if (!ht_num) {
        perfctr_msr = MSR_P4_IQ_PERFCTR0;
        evntsel_msr = MSR_P4_CRU_ESCR0;
        cccr_msr = MSR_P4_IQ_CCCR0;
        cccr_val = P4_CCCR_OVF_PMI0 | P4_CCCR_ESCR_SELECT (4);
        if (reset_devices) {
            unsigned int low, high;
            int i;
            for (i = 0; i < P4_CONTROLS; i++) {
                rdmsr (p4_controls [i], low, high);
                low &= ~(P4_CCCR_ENABLE | P4_CCCR_OVF);
                wrmsr (p4_controls [i], low, high);
            }
        }
    }
    else {
        perfctr_msr = MSR_P4_IQ_PERFCTR1;
        evntsel_msr = MSR_P4_CRU_ESCR0;
        cccr_msr = MSR_P4_IQ_CCCR1;
        if (boot_cpu_data.x86_model == 4 && boot_cpu_data.x86_mask == 4)
            cccr_val = P4_CCCR_OVF_PMI0;
        else
            cccr_val = P4_CCCR_OVF_PMI1;
        cccr_val |= P4_CCCR_ESCR_SELECT (4);
    }
    evntsel = P4_ESCR_EVENT_SELECT (0x3F) | P4_ESCR_OS | P4_ESCR_USR;
    cccr_val |= P4_CCCR_THRESHOLD (15) | P4_CCCR_COMPLEMENT | P4_CCCR_COMPARE | P4_CCCR_REQUIRED;
    wrmsr (evntsel_msr, evntsel, 0);
    wrmsr (cccr_msr, cccr_val, 0);
    write_watchdog_counter (perfctr_msr, "P4_IQ_COUNTER0", nmi_hz);
    wd->perfctr_msr = perfctr_msr;
    wd->evntsel_msr = evntsel_msr;
    wd->cccr_msr = cccr_msr;
    cpu_nmi_set_wd_enabled ();
    apic_write (APIC_LVTPC, APIC_DM_NMI);
    cccr_val |= P4_CCCR_ENABLE;
    wrmsr (cccr_msr, cccr_val, 0);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="495" endline="521">
{
    perfctr_msr = MSR_P4_IQ_PERFCTR0;
    evntsel_msr = MSR_P4_CRU_ESCR0;
    cccr_msr = MSR_P4_IQ_CCCR0;
    cccr_val = P4_CCCR_OVF_PMI0 | P4_CCCR_ESCR_SELECT (4);
    if (reset_devices) {
        unsigned int low, high;
        int i;
        for (i = 0; i < P4_CONTROLS; i++) {
            rdmsr (p4_controls [i], low, high);
            low &= ~(P4_CCCR_ENABLE | P4_CCCR_OVF);
            wrmsr (p4_controls [i], low, high);
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="511" endline="520">
{
    unsigned int low, high;
    int i;
    for (i = 0; i < P4_CONTROLS; i++) {
        rdmsr (p4_controls [i], low, high);
        low &= ~(P4_CCCR_ENABLE | P4_CCCR_OVF);
        wrmsr (p4_controls [i], low, high);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="515" endline="519">
{
    rdmsr (p4_controls [i], low, high);
    low &= ~(P4_CCCR_ENABLE | P4_CCCR_OVF);
    wrmsr (p4_controls [i], low, high);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="521" endline="533">
{
    perfctr_msr = MSR_P4_IQ_PERFCTR1;
    evntsel_msr = MSR_P4_CRU_ESCR0;
    cccr_msr = MSR_P4_IQ_CCCR1;
    if (boot_cpu_data.x86_model == 4 && boot_cpu_data.x86_mask == 4)
        cccr_val = P4_CCCR_OVF_PMI0;
    else
        cccr_val = P4_CCCR_OVF_PMI1;
    cccr_val |= P4_CCCR_ESCR_SELECT (4);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="562" endline="566">
{
    struct nmi_watchdog_ctlblk *wd = &__get_cpu_var (nmi_watchdog_ctlblk);
    wrmsr (wd -> cccr_msr, 0, 0);
    wrmsr (wd -> evntsel_msr, 0, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="569" endline="588">
{
    if (!reserve_perfctr_nmi (MSR_P4_IQ_PERFCTR0))
        return 0;
    if (!reserve_evntsel_nmi (MSR_P4_CRU_ESCR0))
        goto fail2;
    return 1;
fail2 :
    release_perfctr_nmi (MSR_P4_IQ_PERFCTR0);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="591" endline="598">
{
    release_evntsel_nmi (MSR_P4_CRU_ESCR0);
    release_perfctr_nmi (MSR_P4_IQ_PERFCTR0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="601" endline="616">
{
    unsigned dummy;
    rdmsrl (wd -> cccr_msr, dummy);
    dummy &= ~P4_CCCR_OVF;
    wrmsrl (wd -> cccr_msr, dummy);
    apic_write (APIC_LVTPC, APIC_DM_NMI);
    write_watchdog_counter (wd -> perfctr_msr, NULL, nmi_hz);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="640" endline="687">
{
    unsigned int ebx;
    union cpuid10_eax eax;
    unsigned int unused;
    unsigned int perfctr_msr, evntsel_msr;
    unsigned int evntsel;
    struct nmi_watchdog_ctlblk *wd = &__get_cpu_var (nmi_watchdog_ctlblk);
    cpuid (10, & (eax.full), & ebx, & unused, & unused);
    if ((eax.split.mask_length < (ARCH_PERFMON_UNHALTED_CORE_CYCLES_INDEX + 1)) || (ebx & ARCH_PERFMON_UNHALTED_CORE_CYCLES_PRESENT))
        return 0;
    perfctr_msr = wd_ops->perfctr;
    evntsel_msr = wd_ops->evntsel;
    wrmsrl (perfctr_msr, 0UL);
    evntsel = ARCH_PERFMON_EVENTSEL_INT | ARCH_PERFMON_EVENTSEL_OS | ARCH_PERFMON_EVENTSEL_USR | ARCH_PERFMON_NMI_EVENT_SEL | ARCH_PERFMON_NMI_EVENT_UMASK;
    wrmsr (evntsel_msr, evntsel, 0);
    nmi_hz = adjust_for_32bit_ctr (nmi_hz);
    write_watchdog_counter32 (perfctr_msr, "INTEL_ARCH_PERFCTR0", nmi_hz);
    wd->perfctr_msr = perfctr_msr;
    wd->evntsel_msr = evntsel_msr;
    wd->cccr_msr = 0;
    cpu_nmi_set_wd_enabled ();
    apic_write (APIC_LVTPC, APIC_DM_NMI);
    evntsel |= ARCH_PERFMON_EVENTSEL_ENABLE;
    wrmsr (evntsel_msr, evntsel, 0);
    intel_arch_wd_ops.checkbit = 1ULL << (eax.split.bit_width - 1);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="700" endline="740">
{
    switch (boot_cpu_data.x86_vendor) {
    case X86_VENDOR_AMD :
        if (boot_cpu_data.x86 != 6 && boot_cpu_data.x86 != 15 && boot_cpu_data.x86 != 16 && boot_cpu_data.x86 != 17)
            return;
        wd_ops = &k7_wd_ops;
        break;
    case X86_VENDOR_INTEL :
        if ((boot_cpu_data.x86 == 6 && boot_cpu_data.x86_model == 14) || ((boot_cpu_data.x86 == 6 && boot_cpu_data.x86_model == 15 && boot_cpu_data.x86_mask == 4))) {
            intel_arch_wd_ops.perfctr = MSR_ARCH_PERFMON_PERFCTR0;
            intel_arch_wd_ops.evntsel = MSR_ARCH_PERFMON_EVENTSEL0;
        }
        if (cpu_has (&boot_cpu_data, X86_FEATURE_ARCH_PERFMON)) {
            wd_ops = &intel_arch_wd_ops;
            break;
        }
        switch (boot_cpu_data.x86) {
        case 6 :
            if (boot_cpu_data.x86_model > 13)
                return;
            wd_ops = &p6_wd_ops;
            break;
        case 15 :
            wd_ops = &p4_wd_ops;
            break;
        default :
            return;
        }
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="701" endline="739">
{
case X86_VENDOR_AMD :
    if (boot_cpu_data.x86 != 6 && boot_cpu_data.x86 != 15 && boot_cpu_data.x86 != 16 && boot_cpu_data.x86 != 17)
        return;
    wd_ops = &k7_wd_ops;
    break;
case X86_VENDOR_INTEL :
    if ((boot_cpu_data.x86 == 6 && boot_cpu_data.x86_model == 14) || ((boot_cpu_data.x86 == 6 && boot_cpu_data.x86_model == 15 && boot_cpu_data.x86_mask == 4))) {
        intel_arch_wd_ops.perfctr = MSR_ARCH_PERFMON_PERFCTR0;
        intel_arch_wd_ops.evntsel = MSR_ARCH_PERFMON_EVENTSEL0;
    }
    if (cpu_has (&boot_cpu_data, X86_FEATURE_ARCH_PERFMON)) {
        wd_ops = &intel_arch_wd_ops;
        break;
    }
    switch (boot_cpu_data.x86) {
    case 6 :
        if (boot_cpu_data.x86_model > 13)
            return;
        wd_ops = &p6_wd_ops;
        break;
    case 15 :
        wd_ops = &p4_wd_ops;
        break;
    default :
        return;
    }
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="717" endline="720">
{
    intel_arch_wd_ops.perfctr = MSR_ARCH_PERFMON_PERFCTR0;
    intel_arch_wd_ops.evntsel = MSR_ARCH_PERFMON_EVENTSEL0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="721" endline="724">
{
    wd_ops = &intel_arch_wd_ops;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="725" endline="737">
{
case 6 :
    if (boot_cpu_data.x86_model > 13)
        return;
    wd_ops = &p6_wd_ops;
    break;
case 15 :
    wd_ops = &p4_wd_ops;
    break;
default :
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="745" endline="767">
{
    if (!wd_ops) {
        probe_nmi_watchdog ();
        if (!wd_ops) {
            printk (KERN_INFO "NMI watchdog: CPU not supported\n");
            return -1;
        }
        if (!wd_ops->reserve ()) {
            printk (KERN_ERR "NMI watchdog: cannot reserve perfctrs\n");
            return -1;
        }
    }
    if (!(wd_ops->setup (nmi_hz))) {
        printk (KERN_ERR "Cannot setup NMI watchdog on CPU %d\n", raw_smp_processor_id ());
        return -1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="746" endline="758">
{
    probe_nmi_watchdog ();
    if (!wd_ops) {
        printk (KERN_INFO "NMI watchdog: CPU not supported\n");
        return -1;
    }
    if (!wd_ops->reserve ()) {
        printk (KERN_ERR "NMI watchdog: cannot reserve perfctrs\n");
        return -1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="748" endline="751">
{
    printk (KERN_INFO "NMI watchdog: CPU not supported\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="753" endline="757">
{
    printk (KERN_ERR "NMI watchdog: cannot reserve perfctrs\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="760" endline="764">
{
    printk (KERN_ERR "Cannot setup NMI watchdog on CPU %d\n", raw_smp_processor_id ());
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="770" endline="773">
{
    if (wd_ops)
        wd_ops->stop ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="776" endline="782">
{
    struct nmi_watchdog_ctlblk *wd = &__get_cpu_var (nmi_watchdog_ctlblk);
    if (wd->perfctr_msr == MSR_P6_PERFCTR0 || wd->perfctr_msr == MSR_ARCH_PERFMON_PERFCTR1)
        hz = adjust_for_32bit_ctr (hz);
    return hz;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perfctr-watchdog.c.ifdefed" startline="785" endline="795">
{
    struct nmi_watchdog_ctlblk *wd = &__get_cpu_var (nmi_watchdog_ctlblk);
    u64 ctr;
    rdmsrl (wd -> perfctr_msr, ctr);
    if (ctr & wd_ops->checkbit)
        return 0;
    wd_ops->rearm (wd, nmi_hz);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="32" endline="133">
{
    if (c->x86 > 6 || (c->x86 == 6 && c->x86_model >= 0xd)) {
        u64 misc_enable;
        rdmsrl (MSR_IA32_MISC_ENABLE, misc_enable);
        if (misc_enable & MSR_IA32_MISC_ENABLE_LIMIT_CPUID) {
            misc_enable &= ~MSR_IA32_MISC_ENABLE_LIMIT_CPUID;
            wrmsrl (MSR_IA32_MISC_ENABLE, misc_enable);
            c->cpuid_level = cpuid_eax (0);
        }
    }
    if ((c->x86 == 0xf && c->x86_model >= 0x03) || (c->x86 == 0x6 && c->x86_model >= 0x0e))
        set_cpu_cap (c, X86_FEATURE_CONSTANT_TSC);
    if (c->x86 == 6 && c->x86_model == 0x1c && c->x86_mask <= 2) {
        u32 ucode, junk;
        wrmsr (MSR_IA32_UCODE_REV, 0, 0);
        sync_core ();
        rdmsr (MSR_IA32_UCODE_REV, junk, ucode);
        if (ucode < 0x20e) {
            printk (KERN_WARNING "Atom PSE erratum detected, BIOS microcode update recommended\n");
            clear_cpu_cap (c, X86_FEATURE_PSE);
        }
    }
    if (c->x86 == 15 && c->x86_cache_alignment == 64)
        c->x86_cache_alignment = 128;
    if (c->x86 == 0xF && c->x86_model == 0x3 && (c->x86_mask == 0x3 || c->x86_mask == 0x4))
        c->x86_phys_bits = 36;
    if (c->x86_power & (1 << 8)) {
        set_cpu_cap (c, X86_FEATURE_CONSTANT_TSC);
        set_cpu_cap (c, X86_FEATURE_NONSTOP_TSC);
        if (!check_tsc_unstable ())
            sched_clock_stable = 1;
    }
    if (c->x86 == 6 && c->x86_model < 15)
        clear_cpu_cap (c, X86_FEATURE_PAT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="34" endline="44">
{
    u64 misc_enable;
    rdmsrl (MSR_IA32_MISC_ENABLE, misc_enable);
    if (misc_enable & MSR_IA32_MISC_ENABLE_LIMIT_CPUID) {
        misc_enable &= ~MSR_IA32_MISC_ENABLE_LIMIT_CPUID;
        wrmsrl (MSR_IA32_MISC_ENABLE, misc_enable);
        c->cpuid_level = cpuid_eax (0);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="39" endline="43">
{
    misc_enable &= ~MSR_IA32_MISC_ENABLE_LIMIT_CPUID;
    wrmsrl (MSR_IA32_MISC_ENABLE, misc_enable);
    c->cpuid_level = cpuid_eax (0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="58" endline="69">
{
    u32 ucode, junk;
    wrmsr (MSR_IA32_UCODE_REV, 0, 0);
    sync_core ();
    rdmsr (MSR_IA32_UCODE_REV, junk, ucode);
    if (ucode < 0x20e) {
        printk (KERN_WARNING "Atom PSE erratum detected, BIOS microcode update recommended\n");
        clear_cpu_cap (c, X86_FEATURE_PSE);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="65" endline="68">
{
    printk (KERN_WARNING "Atom PSE erratum detected, BIOS microcode update recommended\n");
    clear_cpu_cap (c, X86_FEATURE_PSE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="91" endline="96">
{
    set_cpu_cap (c, X86_FEATURE_CONSTANT_TSC);
    set_cpu_cap (c, X86_FEATURE_NONSTOP_TSC);
    if (!check_tsc_unstable ())
        sched_clock_stable = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="273" endline="274">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="278" endline="295">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="301" endline="313">
{
    unsigned int eax, ebx, ecx, edx;
    if (c->cpuid_level < 4)
        return 1;
    cpuid_count (4, 0, & eax, & ebx, & ecx, & edx);
    if (eax & 0x1f)
        return (eax >> 26) + 1;
    else
        return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="316" endline="351">
{
    u32 vmx_msr_low, vmx_msr_high, msr_ctl, msr_ctl2;
    clear_cpu_cap (c, X86_FEATURE_TPR_SHADOW);
    clear_cpu_cap (c, X86_FEATURE_VNMI);
    clear_cpu_cap (c, X86_FEATURE_FLEXPRIORITY);
    clear_cpu_cap (c, X86_FEATURE_EPT);
    clear_cpu_cap (c, X86_FEATURE_VPID);
    rdmsr (MSR_IA32_VMX_PROCBASED_CTLS, vmx_msr_low, vmx_msr_high);
    msr_ctl = vmx_msr_high | vmx_msr_low;
    if (msr_ctl & X86_VMX_FEATURE_PROC_CTLS_TPR_SHADOW)
        set_cpu_cap (c, X86_FEATURE_TPR_SHADOW);
    if (msr_ctl & X86_VMX_FEATURE_PROC_CTLS_VNMI)
        set_cpu_cap (c, X86_FEATURE_VNMI);
    if (msr_ctl & X86_VMX_FEATURE_PROC_CTLS_2ND_CTLS) {
        rdmsr (MSR_IA32_VMX_PROCBASED_CTLS2, vmx_msr_low, vmx_msr_high);
        msr_ctl2 = vmx_msr_high | vmx_msr_low;
        if ((msr_ctl2 & X86_VMX_FEATURE_PROC_CTLS2_VIRT_APIC) && (msr_ctl & X86_VMX_FEATURE_PROC_CTLS_TPR_SHADOW))
            set_cpu_cap (c, X86_FEATURE_FLEXPRIORITY);
        if (msr_ctl2 & X86_VMX_FEATURE_PROC_CTLS2_EPT)
            set_cpu_cap (c, X86_FEATURE_EPT);
        if (msr_ctl2 & X86_VMX_FEATURE_PROC_CTLS2_VPID)
            set_cpu_cap (c, X86_FEATURE_VPID);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="339" endline="350">
{
    rdmsr (MSR_IA32_VMX_PROCBASED_CTLS2, vmx_msr_low, vmx_msr_high);
    msr_ctl2 = vmx_msr_high | vmx_msr_low;
    if ((msr_ctl2 & X86_VMX_FEATURE_PROC_CTLS2_VIRT_APIC) && (msr_ctl & X86_VMX_FEATURE_PROC_CTLS_TPR_SHADOW))
        set_cpu_cap (c, X86_FEATURE_FLEXPRIORITY);
    if (msr_ctl2 & X86_VMX_FEATURE_PROC_CTLS2_EPT)
        set_cpu_cap (c, X86_FEATURE_EPT);
    if (msr_ctl2 & X86_VMX_FEATURE_PROC_CTLS2_VPID)
        set_cpu_cap (c, X86_FEATURE_VPID);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="354" endline="460">
{
    unsigned int l2 = 0;
    early_init_intel (c);
    intel_workarounds (c);
    detect_extended_topology (c);
    l2 = init_intel_cacheinfo (c);
    if (c->cpuid_level > 9) {
        unsigned eax = cpuid_eax (10);
        if ((eax & 0xff) && (((eax >> 8) & 0xff) > 1))
            set_cpu_cap (c, X86_FEATURE_ARCH_PERFMON);
    }
    if (c->cpuid_level > 6) {
        unsigned ecx = cpuid_ecx (6);
        if (ecx & 0x01)
            set_cpu_cap (c, X86_FEATURE_APERFMPERF);
    }
    if (cpu_has_xmm2)
        set_cpu_cap (c, X86_FEATURE_LFENCE_RDTSC);
    if (cpu_has_ds) {
        unsigned int l1;
        rdmsr (MSR_IA32_MISC_ENABLE, l1, l2);
        if (!(l1 & (1 << 11)))
            set_cpu_cap (c, X86_FEATURE_BTS);
        if (!(l1 & (1 << 12)))
            set_cpu_cap (c, X86_FEATURE_PEBS);
        ds_init_intel (c);
    }
    if (c->x86 == 6 && c->x86_model == 29 && cpu_has_clflush)
        set_cpu_cap (c, X86_FEATURE_CLFLUSH_MONITOR);
    if (c->x86 == 6) {
        char *p = NULL;
        switch (c->x86_model) {
        case 5 :
            if (c->x86_mask == 0) {
                if (l2 == 0)
                    p = "Celeron (Covington)";
                else if (l2 == 256)
                    p = "Mobile Pentium II (Dixon)";
            }
            break;
        case 6 :
            if (l2 == 128)
                p = "Celeron (Mendocino)";
            else if (c->x86_mask == 0 || c->x86_mask == 5)
                p = "Celeron-A";
            break;
        case 8 :
            if (l2 == 128)
                p = "Celeron (Coppermine)";
            break;
        }
        if (p)
            strcpy (c->x86_model_id, p);
    }
    if (c->x86 == 15)
        set_cpu_cap (c, X86_FEATURE_P4);
    if (c->x86 == 6)
        set_cpu_cap (c, X86_FEATURE_P3);
    if (!cpu_has (c, X86_FEATURE_XTOPOLOGY)) {
        c->x86_max_cores = intel_num_cpu_cores (c);
    }
    srat_detect_node (c);
    if (cpu_has (c, X86_FEATURE_VMX))
        detect_vmx_virtcap (c);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="369" endline="374">
{
    unsigned eax = cpuid_eax (10);
    if ((eax & 0xff) && (((eax >> 8) & 0xff) > 1))
        set_cpu_cap (c, X86_FEATURE_ARCH_PERFMON);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="376" endline="380">
{
    unsigned ecx = cpuid_ecx (6);
    if (ecx & 0x01)
        set_cpu_cap (c, X86_FEATURE_APERFMPERF);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="384" endline="392">
{
    unsigned int l1;
    rdmsr (MSR_IA32_MISC_ENABLE, l1, l2);
    if (!(l1 & (1 << 11)))
        set_cpu_cap (c, X86_FEATURE_BTS);
    if (!(l1 & (1 << 12)))
        set_cpu_cap (c, X86_FEATURE_PEBS);
    ds_init_intel (c);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="408" endline="436">
{
    char *p = NULL;
    switch (c->x86_model) {
    case 5 :
        if (c->x86_mask == 0) {
            if (l2 == 0)
                p = "Celeron (Covington)";
            else if (l2 == 256)
                p = "Mobile Pentium II (Dixon)";
        }
        break;
    case 6 :
        if (l2 == 128)
            p = "Celeron (Mendocino)";
        else if (c->x86_mask == 0 || c->x86_mask == 5)
            p = "Celeron-A";
        break;
    case 8 :
        if (l2 == 128)
            p = "Celeron (Coppermine)";
        break;
    }
    if (p)
        strcpy (c->x86_model_id, p);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="411" endline="432">
{
case 5 :
    if (c->x86_mask == 0) {
        if (l2 == 0)
            p = "Celeron (Covington)";
        else if (l2 == 256)
            p = "Mobile Pentium II (Dixon)";
    }
    break;
case 6 :
    if (l2 == 128)
        p = "Celeron (Mendocino)";
    else if (c->x86_mask == 0 || c->x86_mask == 5)
        p = "Celeron-A";
    break;
case 8 :
    if (l2 == 128)
        p = "Celeron (Coppermine)";
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="413" endline="418">
{
    if (l2 == 0)
        p = "Celeron (Covington)";
    else if (l2 == 256)
        p = "Mobile Pentium II (Dixon)";
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/intel.c.ifdefed" startline="444" endline="453">
{
    c->x86_max_cores = intel_num_cpu_cores (c);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="199" endline="239">
{
    struct hw_perf_event *hwc = &event->hw;
    int shift = 64 - x86_pmu.event_bits;
    u64 prev_raw_count, new_raw_count;
    int idx = hwc->idx;
    s64 delta;
    if (idx == X86_PMC_IDX_FIXED_BTS)
        return 0;
again :
    prev_raw_count = atomic64_read (&hwc->prev_count);
    rdmsrl (hwc -> event_base + idx, new_raw_count);
    if (atomic64_cmpxchg (&hwc->prev_count, prev_raw_count, new_raw_count) != prev_raw_count)
        goto again;
    delta = (new_raw_count << shift) - (prev_raw_count << shift);
    delta >>= shift;
    atomic64_add (delta, & event -> count);
    atomic64_sub (delta, & hwc -> period_left);
    return new_raw_count;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="245" endline="281">
{
    return true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="284" endline="296">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="299" endline="301">
{
    return x86_pmu.enable_bts != NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="304" endline="313">
{
    struct debug_store *ds = per_cpu (cpu_hw_events, cpu).ds;
    if (!ds)
        return;
    wrmsr_on_cpu (cpu, MSR_IA32_DS_AREA, (u32) ((u64) (unsigned long) ds), (u32) ((u64) (unsigned long) ds >> 32));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="316" endline="321">
{
    if (!per_cpu (cpu_hw_events, cpu).ds)
        return;
    wrmsr_on_cpu (cpu, MSR_IA32_DS_AREA, 0, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="324" endline="348">
{
    int cpu;
    if (!bts_available ())
        return;
    get_online_cpus ();
    for_each_online_cpu (cpu)
    fini_debug_store_on_cpu (cpu);

    for_each_possible_cpu (cpu) {
        struct debug_store *ds = per_cpu (cpu_hw_events, cpu).ds;
        if (!ds)
            continue;
        per_cpu (cpu_hw_events, cpu).ds = NULL;
        kfree ((void *) (unsigned long) ds -> bts_buffer_base);
        kfree (ds);
    }

    put_online_cpus ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="335" endline="345">
{
    struct debug_store *ds = per_cpu (cpu_hw_events, cpu).ds;
    if (!ds)
        continue;
    per_cpu (cpu_hw_events, cpu).ds = NULL;
    kfree ((void *) (unsigned long) ds -> bts_buffer_base);
    kfree (ds);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="351" endline="395">
{
    int cpu, err = 0;
    if (!bts_available ())
        return 0;
    get_online_cpus ();

    for_each_possible_cpu (cpu) {
        struct debug_store *ds;
        void *buffer;
        err = -ENOMEM;
        buffer = kzalloc (BTS_BUFFER_SIZE, GFP_KERNEL);
        if (unlikely (!buffer))
            break;
        ds = kzalloc (sizeof (*ds), GFP_KERNEL);
        if (unlikely (!ds)) {
            kfree (buffer);
            break;
        }
        ds->bts_buffer_base = (u64) (unsigned long) buffer;
        ds->bts_index = ds->bts_buffer_base;
        ds->bts_absolute_maximum = ds->bts_buffer_base + BTS_BUFFER_SIZE;
        ds->bts_interrupt_threshold = ds->bts_absolute_maximum - BTS_OVFL_TH;
        per_cpu (cpu_hw_events, cpu).ds = ds;
        err = 0;
    }

    if (err)
        release_bts_hardware ();
    else {
        for_each_online_cpu (cpu)
        init_debug_store_on_cpu (cpu);
    }
    put_online_cpus ();
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="359" endline="383">
{
    struct debug_store *ds;
    void *buffer;
    err = -ENOMEM;
    buffer = kzalloc (BTS_BUFFER_SIZE, GFP_KERNEL);
    if (unlikely (!buffer))
        break;
    ds = kzalloc (sizeof (*ds), GFP_KERNEL);
    if (unlikely (!ds)) {
        kfree (buffer);
        break;
    }
    ds->bts_buffer_base = (u64) (unsigned long) buffer;
    ds->bts_index = ds->bts_buffer_base;
    ds->bts_absolute_maximum = ds->bts_buffer_base + BTS_BUFFER_SIZE;
    ds->bts_interrupt_threshold = ds->bts_absolute_maximum - BTS_OVFL_TH;
    per_cpu (cpu_hw_events, cpu).ds = ds;
    err = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="369" endline="372">
{
    kfree (buffer);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="387" endline="390">
{
    for_each_online_cpu (cpu)
    init_debug_store_on_cpu (cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="398" endline="404">
{
    if (atomic_dec_and_mutex_lock (&active_events, &pmc_reserve_mutex)) {
        release_pmc_hardware ();
        release_bts_hardware ();
        mutex_unlock (& pmc_reserve_mutex);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="399" endline="403">
{
    release_pmc_hardware ();
    release_bts_hardware ();
    mutex_unlock (& pmc_reserve_mutex);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="407" endline="409">
{
    return x86_pmu.handle_irq != NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="413" endline="442">
{
    unsigned int cache_type, cache_op, cache_result;
    u64 config, val;
    config = attr->config;
    cache_type = (config >> 0) & 0xff;
    if (cache_type >= PERF_COUNT_HW_CACHE_MAX)
        return -EINVAL;
    cache_op = (config >> 8) & 0xff;
    if (cache_op >= PERF_COUNT_HW_CACHE_OP_MAX)
        return -EINVAL;
    cache_result = (config >> 16) & 0xff;
    if (cache_result >= PERF_COUNT_HW_CACHE_RESULT_MAX)
        return -EINVAL;
    val = hw_cache_event_ids[cache_type][cache_op][cache_result];
    if (val == 0)
        return -ENOENT;
    if (val == -1)
        return -EINVAL;
    hwc->config |= val;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="448" endline="553">
{
    struct perf_event_attr *attr = &event->attr;
    struct hw_perf_event *hwc = &event->hw;
    u64 config;
    int err;
    if (!x86_pmu_initialized ())
        return -ENODEV;
    err = 0;
    if (!atomic_inc_not_zero (&active_events)) {
        mutex_lock (& pmc_reserve_mutex);
        if (atomic_read (&active_events) == 0) {
            if (!reserve_pmc_hardware ())
                err = -EBUSY;
            else
                err = reserve_bts_hardware ();
        }
        if (!err)
            atomic_inc (&active_events);
        mutex_unlock (& pmc_reserve_mutex);
    }
    if (err)
        return err;
    event->destroy = hw_perf_event_destroy;
    hwc->config = ARCH_PERFMON_EVENTSEL_INT;
    hwc->idx = -1;
    hwc->last_cpu = -1;
    hwc->last_tag = ~0ULL;
    if (!attr->exclude_user)
        hwc->config |= ARCH_PERFMON_EVENTSEL_USR;
    if (!attr->exclude_kernel)
        hwc->config |= ARCH_PERFMON_EVENTSEL_OS;
    if (!hwc->sample_period) {
        hwc->sample_period = x86_pmu.max_period;
        hwc->last_period = hwc->sample_period;
        atomic64_set (& hwc -> period_left, hwc -> sample_period);
    }
    else {
        if (!x86_pmu.apic)
            return -EOPNOTSUPP;
    }
    if (attr->type == PERF_TYPE_RAW) {
        hwc->config |= x86_pmu.raw_event (attr->config);
        if ((hwc->config & ARCH_PERFMON_EVENTSEL_ANY) && perf_paranoid_cpu () && !capable (CAP_SYS_ADMIN))
            return -EACCES;
        return 0;
    }
    if (attr->type == PERF_TYPE_HW_CACHE)
        return set_ext_hw_attr (hwc, attr);
    if (attr->config >= x86_pmu.max_events)
        return -EINVAL;
    config = x86_pmu.event_map (attr->config);
    if (config == 0)
        return -ENOENT;
    if (config == -1LL)
        return -EINVAL;
    if ((attr->config == PERF_COUNT_HW_BRANCH_INSTRUCTIONS) && (hwc->sample_period == 1)) {
        if (!bts_available ())
            return -EOPNOTSUPP;
        if (hwc->config & ARCH_PERFMON_EVENTSEL_OS)
            return -EOPNOTSUPP;
    }
    hwc->config |= config;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="458" endline="469">
{
    mutex_lock (& pmc_reserve_mutex);
    if (atomic_read (&active_events) == 0) {
        if (!reserve_pmc_hardware ())
            err = -EBUSY;
        else
            err = reserve_bts_hardware ();
    }
    if (!err)
        atomic_inc (&active_events);
    mutex_unlock (& pmc_reserve_mutex);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="460" endline="465">
{
    if (!reserve_pmc_hardware ())
        err = -EBUSY;
    else
        err = reserve_bts_hardware ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="493" endline="497">
{
    hwc->sample_period = x86_pmu.max_period;
    hwc->last_period = hwc->sample_period;
    atomic64_set (& hwc -> period_left, hwc -> sample_period);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="497" endline="506">
{
    if (!x86_pmu.apic)
        return -EOPNOTSUPP;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="511" endline="517">
{
    hwc->config |= x86_pmu.raw_event (attr->config);
    if ((hwc->config & ARCH_PERFMON_EVENTSEL_ANY) && perf_paranoid_cpu () && !capable (CAP_SYS_ADMIN))
        return -EACCES;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="540" endline="548">
{
    if (!bts_available ())
        return -EOPNOTSUPP;
    if (hwc->config & ARCH_PERFMON_EVENTSEL_OS)
        return -EOPNOTSUPP;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="556" endline="571">
{
    struct cpu_hw_events *cpuc = &__get_cpu_var (cpu_hw_events);
    int idx;
    for (idx = 0; idx < x86_pmu.num_events; idx++) {
        u64 val;
        if (!test_bit (idx, cpuc->active_mask))
            continue;
        rdmsrl (x86_pmu.eventsel + idx, val);
        if (!(val & ARCH_PERFMON_EVENTSEL_ENABLE))
            continue;
        val &= ~ARCH_PERFMON_EVENTSEL_ENABLE;
        wrmsrl (x86_pmu.eventsel + idx, val);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="560" endline="570">
{
    u64 val;
    if (!test_bit (idx, cpuc->active_mask))
        continue;
    rdmsrl (x86_pmu.eventsel + idx, val);
    if (!(val & ARCH_PERFMON_EVENTSEL_ENABLE))
        continue;
    val &= ~ARCH_PERFMON_EVENTSEL_ENABLE;
    wrmsrl (x86_pmu.eventsel + idx, val);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="574" endline="588">
{
    struct cpu_hw_events *cpuc = &__get_cpu_var (cpu_hw_events);
    if (!x86_pmu_initialized ())
        return;
    if (!cpuc->enabled)
        return;
    cpuc->n_added = 0;
    cpuc->enabled = 0;
    barrier ();
    x86_pmu.disable_all ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="591" endline="606">
{
    struct cpu_hw_events *cpuc = &__get_cpu_var (cpu_hw_events);
    int idx;
    for (idx = 0; idx < x86_pmu.num_events; idx++) {
        struct perf_event *event = cpuc->events[idx];
        u64 val;
        if (!test_bit (idx, cpuc->active_mask))
            continue;
        val = event->hw.config;
        val |= ARCH_PERFMON_EVENTSEL_ENABLE;
        wrmsrl (x86_pmu.eventsel + idx, val);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="595" endline="605">
{
    struct perf_event *event = cpuc->events[idx];
    u64 val;
    if (!test_bit (idx, cpuc->active_mask))
        continue;
    val = event->hw.config;
    val |= ARCH_PERFMON_EVENTSEL_ENABLE;
    wrmsrl (x86_pmu.eventsel + idx, val);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="611" endline="613">
{
    return event->pmu == &pmu;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="616" endline="716">
{
    struct event_constraint *c, *constraints [X86_PMC_IDX_MAX];
    unsigned long used_mask [BITS_TO_LONGS (X86_PMC_IDX_MAX)];
    int i, j, w, wmax, num = 0;
    struct hw_perf_event *hwc;
    bitmap_zero (used_mask, X86_PMC_IDX_MAX);
    for (i = 0; i < n; i++) {
        c = x86_pmu.get_event_constraints (cpuc, cpuc->event_list[i]);
        constraints[i] = c;
    }
    for (i = 0; i < n; i++) {
        hwc = &cpuc->event_list[i]->hw;
        c = constraints[i];
        if (hwc->idx == -1)
            break;
        if (!test_bit (hwc->idx, c->idxmsk))
            break;
        if (test_bit (hwc->idx, used_mask))
            break;
        __set_bit (hwc -> idx, used_mask);
        if (assign)
            assign[i] = hwc->idx;
    }
    if (i == n)
        goto done;
    bitmap_zero (used_mask, X86_PMC_IDX_MAX);
    wmax = x86_pmu.num_events;
    if (x86_pmu.num_events_fixed)
        wmax++;
    for (w = 1, num = n; num && w <= wmax; w++) {
        for (i = 0; num && i < n; i++) {
            c = constraints[i];
            hwc = &cpuc->event_list[i]->hw;
            if (c->weight != w)
                continue;
            for_each_set_bit (j, c -> idxmsk, X86_PMC_IDX_MAX)
            {
                if (!test_bit (j, used_mask))
                    break;
            }
            if (j == X86_PMC_IDX_MAX)
                break;
            __set_bit (j, used_mask);
            if (assign)
                assign[i] = j;
            num--;
        }
    }
done :
    if (!assign || num) {
        for (i = 0; i < n; i++) {
            if (x86_pmu.put_event_constraints)
                x86_pmu.put_event_constraints (cpuc, cpuc->event_list[i]);
        }
    }
    return num ? -ENOSPC : 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="624" endline="627">
{
    c = x86_pmu.get_event_constraints (cpuc, cpuc->event_list[i]);
    constraints[i] = c;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="632" endline="651">
{
    hwc = &cpuc->event_list[i]->hw;
    c = constraints[i];
    if (hwc->idx == -1)
        break;
    if (!test_bit (hwc->idx, c->idxmsk))
        break;
    if (test_bit (hwc->idx, used_mask))
        break;
    __set_bit (hwc -> idx, used_mask);
    if (assign)
        assign[i] = hwc->idx;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="680" endline="703">
{
    for (i = 0; num && i < n; i++) {
        c = constraints[i];
        hwc = &cpuc->event_list[i]->hw;
        if (c->weight != w)
            continue;
        for_each_set_bit (j, c -> idxmsk, X86_PMC_IDX_MAX)
        {
            if (!test_bit (j, used_mask))
                break;
        }
        if (j == X86_PMC_IDX_MAX)
            break;
        __set_bit (j, used_mask);
        if (assign)
            assign[i] = j;
        num--;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="682" endline="702">
{
    c = constraints[i];
    hwc = &cpuc->event_list[i]->hw;
    if (c->weight != w)
        continue;
    for_each_set_bit (j, c -> idxmsk, X86_PMC_IDX_MAX)
    {
        if (!test_bit (j, used_mask))
            break;
    }
    if (j == X86_PMC_IDX_MAX)
        break;
    __set_bit (j, used_mask);
    if (assign)
        assign[i] = j;
    num--;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="689" endline="692">
{
    if (!test_bit (j, used_mask))
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="709" endline="714">
{
    for (i = 0; i < n; i++) {
        if (x86_pmu.put_event_constraints)
            x86_pmu.put_event_constraints (cpuc, cpuc->event_list[i]);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="710" endline="713">
{
    if (x86_pmu.put_event_constraints)
        x86_pmu.put_event_constraints (cpuc, cpuc->event_list[i]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="723" endline="753">
{
    struct perf_event *event;
    int n, max_count;
    max_count = x86_pmu.num_events + x86_pmu.num_events_fixed;
    n = cpuc->n_events;
    if (is_x86_event (leader)) {
        if (n >= max_count)
            return -ENOSPC;
        cpuc->event_list[n] = leader;
        n++;
    }
    if (!dogrp)
        return n;
    list_for_each_entry (event, &leader->sibling_list, group_entry) {
        if (!is_x86_event (event) || event->state <= PERF_EVENT_STATE_OFF)
            continue;
        if (n >= max_count)
            return -ENOSPC;
        cpuc->event_list[n] = event;
        n++;
    }
    return n;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="732" endline="737">
{
    if (n >= max_count)
        return -ENOSPC;
    cpuc->event_list[n] = leader;
    n++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="741" endline="751">
{
    if (!is_x86_event (event) || event->state <= PERF_EVENT_STATE_OFF)
        continue;
    if (n >= max_count)
        return -ENOSPC;
    cpuc->event_list[n] = event;
    n++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="757" endline="779">
{
    struct hw_perf_event *hwc = &event->hw;
    hwc->idx = cpuc->assign[i];
    hwc->last_cpu = smp_processor_id ();
    hwc->last_tag = ++cpuc->tags[i];
    if (hwc->idx == X86_PMC_IDX_FIXED_BTS) {
        hwc->config_base = 0;
        hwc->event_base = 0;
    }
    else if (hwc->idx >= X86_PMC_IDX_FIXED) {
        hwc->config_base = MSR_ARCH_PERFMON_FIXED_CTR_CTRL;
        hwc->event_base = MSR_ARCH_PERFMON_FIXED_CTR0 - X86_PMC_IDX_FIXED;
    }
    else {
        hwc->config_base = x86_pmu.eventsel;
        hwc->event_base = x86_pmu.perfctr;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="764" endline="767">
{
    hwc->config_base = 0;
    hwc->event_base = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="767" endline="775">
{
    hwc->config_base = MSR_ARCH_PERFMON_FIXED_CTR_CTRL;
    hwc->event_base = MSR_ARCH_PERFMON_FIXED_CTR0 - X86_PMC_IDX_FIXED;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="775" endline="778">
{
    hwc->config_base = x86_pmu.eventsel;
    hwc->event_base = x86_pmu.perfctr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="784" endline="788">
{
    return hwc->idx == cpuc->assign[i] && hwc->last_cpu == smp_processor_id () && hwc->last_tag == cpuc->tags[i];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="794" endline="851">
{
    struct cpu_hw_events *cpuc = &__get_cpu_var (cpu_hw_events);
    struct perf_event *event;
    struct hw_perf_event *hwc;
    int i;
    if (!x86_pmu_initialized ())
        return;
    if (cpuc->enabled)
        return;
    if (cpuc->n_added) {
        int n_running = cpuc->n_events - cpuc->n_added;
        for (i = 0; i < n_running; i++) {
            event = cpuc->event_list[i];
            hwc = &event->hw;
            if (hwc->idx == -1 || match_prev_assignment (hwc, cpuc, i))
                continue;
            x86_pmu_stop (event);
        }
        for (i = 0; i < cpuc->n_events; i++) {
            event = cpuc->event_list[i];
            hwc = &event->hw;
            if (!match_prev_assignment (hwc, cpuc, i))
                x86_assign_hw_event (event, cpuc, i);
            else if (i < n_running)
                continue;
            x86_pmu_start (event);
        }
        cpuc->n_added = 0;
        perf_events_lapic_init ();
    }
    cpuc->enabled = 1;
    barrier ();
    x86_pmu.enable_all ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="806" endline="845">
{
    int n_running = cpuc->n_events - cpuc->n_added;
    for (i = 0; i < n_running; i++) {
        event = cpuc->event_list[i];
        hwc = &event->hw;
        if (hwc->idx == -1 || match_prev_assignment (hwc, cpuc, i))
            continue;
        x86_pmu_stop (event);
    }
    for (i = 0; i < cpuc->n_events; i++) {
        event = cpuc->event_list[i];
        hwc = &event->hw;
        if (!match_prev_assignment (hwc, cpuc, i))
            x86_assign_hw_event (event, cpuc, i);
        else if (i < n_running)
            continue;
        x86_pmu_start (event);
    }
    cpuc->n_added = 0;
    perf_events_lapic_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="815" endline="830">
{
    event = cpuc->event_list[i];
    hwc = &event->hw;
    if (hwc->idx == -1 || match_prev_assignment (hwc, cpuc, i))
        continue;
    x86_pmu_stop (event);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="832" endline="842">
{
    event = cpuc->event_list[i];
    hwc = &event->hw;
    if (!match_prev_assignment (hwc, cpuc, i))
        x86_assign_hw_event (event, cpuc, i);
    else if (i < n_running)
        continue;
    x86_pmu_start (event);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="854" endline="857">
{
    (void) checking_wrmsrl (hwc->config_base + hwc->idx, hwc->config | ARCH_PERFMON_EVENTSEL_ENABLE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="860" endline="863">
{
    struct hw_perf_event *hwc = &event->hw;
    (void) checking_wrmsrl (hwc->config_base + hwc->idx, hwc->config);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="873" endline="921">
{
    struct hw_perf_event *hwc = &event->hw;
    s64 left = atomic64_read (&hwc->period_left);
    s64 period = hwc->sample_period;
    int err, ret = 0, idx = hwc->idx;
    if (idx == X86_PMC_IDX_FIXED_BTS)
        return 0;
    if (unlikely (left <= -period)) {
        left = period;
        atomic64_set (& hwc -> period_left, left);
        hwc->last_period = period;
        ret = 1;
    }
    if (unlikely (left <= 0)) {
        left += period;
        atomic64_set (& hwc -> period_left, left);
        hwc->last_period = period;
        ret = 1;
    }
    if (unlikely (left < 2))
        left = 2;
    if (left > x86_pmu.max_period)
        left = x86_pmu.max_period;
    per_cpu (pmc_prev_left[idx], smp_processor_id ()) = left;
    atomic64_set (& hwc -> prev_count, (u64) - left);
    err = checking_wrmsrl (hwc->event_base + idx, (u64) (-left) & x86_pmu.event_mask);
    perf_event_update_userpage (event);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="885" endline="890">
{
    left = period;
    atomic64_set (& hwc -> period_left, left);
    hwc->last_period = period;
    ret = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="892" endline="897">
{
    left += period;
    atomic64_set (& hwc -> period_left, left);
    hwc->last_period = period;
    ret = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="924" endline="928">
{
    struct cpu_hw_events *cpuc = &__get_cpu_var (cpu_hw_events);
    if (cpuc->enabled)
        __x86_pmu_enable_event (&event->hw);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="940" endline="966">
{
    struct cpu_hw_events *cpuc = &__get_cpu_var (cpu_hw_events);
    struct hw_perf_event *hwc;
    int assign [X86_PMC_IDX_MAX];
    int n, n0, ret;
    hwc = &event->hw;
    n0 = cpuc->n_events;
    n = collect_events (cpuc, event, false);
    if (n < 0)
        return n;
    ret = x86_schedule_events (cpuc, n, assign);
    if (ret)
        return ret;
    memcpy (cpuc -> assign, assign, n * sizeof (int));
    cpuc->n_events = n;
    cpuc->n_added += n - n0;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="969" endline="983">
{
    struct cpu_hw_events *cpuc = &__get_cpu_var (cpu_hw_events);
    int idx = event->hw.idx;
    if (idx == -1)
        return -EAGAIN;
    x86_perf_event_set_period (event);
    cpuc->events[idx] = event;
    __set_bit (idx, cpuc -> active_mask);
    x86_pmu.enable (event);
    perf_event_update_userpage (event);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="986" endline="989">
{
    int ret = x86_pmu_start (event);
    WARN_ON_ONCE (ret);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="992" endline="1040">
{
    u64 ctrl, status, overflow, pmc_ctrl, pmc_count, prev_left, fixed;
    struct cpu_hw_events *cpuc;
    unsigned long flags;
    int cpu, idx;
    if (!x86_pmu.num_events)
        return;
    local_irq_save (flags);
    cpu = smp_processor_id ();
    cpuc = &per_cpu (cpu_hw_events, cpu);
    if (x86_pmu.version >= 2) {
        rdmsrl (MSR_CORE_PERF_GLOBAL_CTRL, ctrl);
        rdmsrl (MSR_CORE_PERF_GLOBAL_STATUS, status);
        rdmsrl (MSR_CORE_PERF_GLOBAL_OVF_CTRL, overflow);
        rdmsrl (MSR_ARCH_PERFMON_FIXED_CTR_CTRL, fixed);
        pr_info ("\n");
        pr_info ("CPU#%d: ctrl:       %016llx\n", cpu, ctrl);
        pr_info ("CPU#%d: status:     %016llx\n", cpu, status);
        pr_info ("CPU#%d: overflow:   %016llx\n", cpu, overflow);
        pr_info ("CPU#%d: fixed:      %016llx\n", cpu, fixed);
    }
    pr_info ("CPU#%d: active:       %016llx\n", cpu, * (u64 *) cpuc -> active_mask);
    for (idx = 0; idx < x86_pmu.num_events; idx++) {
        rdmsrl (x86_pmu.eventsel + idx, pmc_ctrl);
        rdmsrl (x86_pmu.perfctr + idx, pmc_count);
        prev_left = per_cpu (pmc_prev_left[idx], cpu);
        pr_info ("CPU#%d:   gen-PMC%d ctrl:  %016llx\n", cpu, idx, pmc_ctrl);
        pr_info ("CPU#%d:   gen-PMC%d count: %016llx\n", cpu, idx, pmc_count);
        pr_info ("CPU#%d:   gen-PMC%d left:  %016llx\n", cpu, idx, prev_left);
    }
    for (idx = 0; idx < x86_pmu.num_events_fixed; idx++) {
        rdmsrl (MSR_ARCH_PERFMON_FIXED_CTR0 + idx, pmc_count);
        pr_info ("CPU#%d: fixed-PMC%d count: %016llx\n", cpu, idx, pmc_count);
    }
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1006" endline="1017">
{
    rdmsrl (MSR_CORE_PERF_GLOBAL_CTRL, ctrl);
    rdmsrl (MSR_CORE_PERF_GLOBAL_STATUS, status);
    rdmsrl (MSR_CORE_PERF_GLOBAL_OVF_CTRL, overflow);
    rdmsrl (MSR_ARCH_PERFMON_FIXED_CTR_CTRL, fixed);
    pr_info ("\n");
    pr_info ("CPU#%d: ctrl:       %016llx\n", cpu, ctrl);
    pr_info ("CPU#%d: status:     %016llx\n", cpu, status);
    pr_info ("CPU#%d: overflow:   %016llx\n", cpu, overflow);
    pr_info ("CPU#%d: fixed:      %016llx\n", cpu, fixed);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1020" endline="1032">
{
    rdmsrl (x86_pmu.eventsel + idx, pmc_ctrl);
    rdmsrl (x86_pmu.perfctr + idx, pmc_count);
    prev_left = per_cpu (pmc_prev_left[idx], cpu);
    pr_info ("CPU#%d:   gen-PMC%d ctrl:  %016llx\n", cpu, idx, pmc_ctrl);
    pr_info ("CPU#%d:   gen-PMC%d count: %016llx\n", cpu, idx, pmc_count);
    pr_info ("CPU#%d:   gen-PMC%d left:  %016llx\n", cpu, idx, prev_left);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1033" endline="1038">
{
    rdmsrl (MSR_ARCH_PERFMON_FIXED_CTR0 + idx, pmc_count);
    pr_info ("CPU#%d: fixed-PMC%d count: %016llx\n", cpu, idx, pmc_count);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1043" endline="1060">
{
    struct cpu_hw_events *cpuc = &__get_cpu_var (cpu_hw_events);
    struct hw_perf_event *hwc = &event->hw;
    int idx = hwc->idx;
    if (!__test_and_clear_bit (idx, cpuc->active_mask))
        return;
    x86_pmu.disable (event);
    x86_perf_event_update (event);
    cpuc->events[idx] = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1063" endline="1083">
{
    struct cpu_hw_events *cpuc = &__get_cpu_var (cpu_hw_events);
    int i;
    x86_pmu_stop (event);
    for (i = 0; i < cpuc->n_events; i++) {
        if (event == cpuc->event_list[i]) {
            if (x86_pmu.put_event_constraints)
                x86_pmu.put_event_constraints (cpuc, event);
            while (++i < cpuc->n_events)
                cpuc->event_list[i - 1] = cpuc->event_list[i];
            --cpuc->n_events;
            break;
        }
    }
    perf_event_update_userpage (event);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1069" endline="1081">
{
    if (event == cpuc->event_list[i]) {
        if (x86_pmu.put_event_constraints)
            x86_pmu.put_event_constraints (cpuc, event);
        while (++i < cpuc->n_events)
            cpuc->event_list[i - 1] = cpuc->event_list[i];
        --cpuc->n_events;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1070" endline="1080">
{
    if (x86_pmu.put_event_constraints)
        x86_pmu.put_event_constraints (cpuc, event);
    while (++i < cpuc->n_events)
        cpuc->event_list[i - 1] = cpuc->event_list[i];
    --cpuc->n_events;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1086" endline="1126">
{
    struct perf_sample_data data;
    struct cpu_hw_events *cpuc;
    struct perf_event *event;
    struct hw_perf_event *hwc;
    int idx, handled = 0;
    u64 val;
    perf_sample_data_init (& data, 0);
    cpuc = &__get_cpu_var (cpu_hw_events);
    for (idx = 0; idx < x86_pmu.num_events; idx++) {
        if (!test_bit (idx, cpuc->active_mask))
            continue;
        event = cpuc->events[idx];
        hwc = &event->hw;
        val = x86_perf_event_update (event);
        if (val & (1ULL << (x86_pmu.event_bits - 1)))
            continue;
        handled = 1;
        data.period = event->hw.last_period;
        if (!x86_perf_event_set_period (event))
            continue;
        if (perf_event_overflow (event, 1, &data, regs))
            x86_pmu_stop (event);
    }
    if (handled)
        inc_irq_stat (apic_perf_irqs);
    return handled;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1098" endline="1120">
{
    if (!test_bit (idx, cpuc->active_mask))
        continue;
    event = cpuc->events[idx];
    hwc = &event->hw;
    val = x86_perf_event_update (event);
    if (val & (1ULL << (x86_pmu.event_bits - 1)))
        continue;
    handled = 1;
    data.period = event->hw.last_period;
    if (!x86_perf_event_set_period (event))
        continue;
    if (perf_event_overflow (event, 1, &data, regs))
        x86_pmu_stop (event);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1129" endline="1135">
{
    irq_enter ();
    ack_APIC_irq ();
    inc_irq_stat (apic_pending_irqs);
    perf_event_do_pending ();
    irq_exit ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1138" endline="1145">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1148" endline="1158">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1163" endline="1194">
{
    struct die_args *args = __args;
    struct pt_regs *regs;
    if (!atomic_read (&active_events))
        return NOTIFY_DONE;
    switch (cmd) {
    case DIE_NMI :
    case DIE_NMI_IPI :
        break;
    default :
        return NOTIFY_DONE;
    }
    regs = args->regs;
    x86_pmu.handle_irq (regs);
    return NOTIFY_STOP;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1170" endline="1177">
{
case DIE_NMI :
case DIE_NMI_IPI :
    break;
default :
    return NOTIFY_DONE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1207" endline="1218">
{
    struct event_constraint *c;
    if (x86_pmu.event_constraints) {
        for_each_event_constraint (c, x86_pmu.event_constraints)
        {
            if ((event->hw.config & c->cmask) == c->code)
                return c;
        }
    }
    return &unconstrained;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1210" endline="1215">
{
    for_each_event_constraint (c, x86_pmu.event_constraints)
    {
        if ((event->hw.config & c->cmask) == c->code)
            return c;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1211" endline="1214">
{
    if ((event->hw.config & c->cmask) == c->code)
        return c;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1222" endline="1239">
{
    int ret = 0;
    event->state = PERF_EVENT_STATE_ACTIVE;
    event->oncpu = smp_processor_id ();
    event->tstamp_running += event->ctx->time - event->tstamp_stopped;
    if (!is_x86_event (event))
        ret = event->pmu->enable (event);
    if (!ret && !is_software_event (event))
        cpuctx->active_oncpu++;
    if (!ret && event->attr.exclusive)
        cpuctx->exclusive = 1;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1243" endline="1257">
{
    event->state = PERF_EVENT_STATE_INACTIVE;
    event->oncpu = -1;
    if (!is_x86_event (event))
        event->pmu->disable (event);
    event->tstamp_running -= event->ctx->time - event->tstamp_stopped;
    if (!is_software_event (event))
        cpuctx->active_oncpu--;
    if (event->attr.exclusive || !cpuctx->active_oncpu)
        cpuctx->exclusive = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1271" endline="1328">
{
    struct cpu_hw_events *cpuc = &__get_cpu_var (cpu_hw_events);
    struct perf_event *sub;
    int assign [X86_PMC_IDX_MAX];
    int n0, n1, ret;
    n0 = collect_events (cpuc, leader, true);
    if (n0 < 0)
        return n0;
    ret = x86_schedule_events (cpuc, n0, assign);
    if (ret)
        return ret;
    ret = x86_event_sched_in (leader, cpuctx);
    if (ret)
        return ret;
    n1 = 1;
    list_for_each_entry (sub, &leader->sibling_list, group_entry) {
        if (sub->state > PERF_EVENT_STATE_OFF) {
            ret = x86_event_sched_in (sub, cpuctx);
            if (ret)
                goto undo;
            ++n1;
        }
    }
    memcpy (cpuc -> assign, assign, n0 * sizeof (int));
    cpuc->n_events = n0;
    cpuc->n_added += n1;
    ctx->nr_active += n1;
    return 1;
undo :
    x86_event_sched_out (leader, cpuctx);
    n0 = 1;
    list_for_each_entry (sub, &leader->sibling_list, group_entry) {
        if (sub->state == PERF_EVENT_STATE_ACTIVE) {
            x86_event_sched_out (sub, cpuctx);
            if (++n0 == n1)
                break;
        }
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1291" endline="1298">
{
    if (sub->state > PERF_EVENT_STATE_OFF) {
        ret = x86_event_sched_in (sub, cpuctx);
        if (ret)
            goto undo;
        ++n1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1292" endline="1297">
{
    ret = x86_event_sched_in (sub, cpuctx);
    if (ret)
        goto undo;
    ++n1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1320" endline="1326">
{
    if (sub->state == PERF_EVENT_STATE_ACTIVE) {
        x86_event_sched_out (sub, cpuctx);
        if (++n0 == n1)
            break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1321" endline="1325">
{
    x86_event_sched_out (sub, cpuctx);
    if (++n0 == n1)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1336" endline="1367">
{
    unsigned int cpu = (long) hcpu;
    int ret = NOTIFY_OK;
    switch (action & ~CPU_TASKS_FROZEN) {
    case CPU_UP_PREPARE :
        if (x86_pmu.cpu_prepare)
            ret = x86_pmu.cpu_prepare (cpu);
        break;
    case CPU_STARTING :
        if (x86_pmu.cpu_starting)
            x86_pmu.cpu_starting (cpu);
        break;
    case CPU_DYING :
        if (x86_pmu.cpu_dying)
            x86_pmu.cpu_dying (cpu);
        break;
    case CPU_UP_CANCELED :
    case CPU_DEAD :
        if (x86_pmu.cpu_dead)
            x86_pmu.cpu_dead (cpu);
        break;
    default :
        break;
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1340" endline="1364">
{
case CPU_UP_PREPARE :
    if (x86_pmu.cpu_prepare)
        ret = x86_pmu.cpu_prepare (cpu);
    break;
case CPU_STARTING :
    if (x86_pmu.cpu_starting)
        x86_pmu.cpu_starting (cpu);
    break;
case CPU_DYING :
    if (x86_pmu.cpu_dying)
        x86_pmu.cpu_dying (cpu);
    break;
case CPU_UP_CANCELED :
case CPU_DEAD :
    if (x86_pmu.cpu_dead)
        x86_pmu.cpu_dead (cpu);
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1370" endline="1377">
{
    if (cpu_has_apic)
        return;
    x86_pmu.apic = 0;
    pr_info ("no APIC, boot with the \"lapic\" boot parameter to force-enable it.\n");
    pr_info ("no hardware sampling interrupt available.\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1380" endline="1449">
{
    struct event_constraint *c;
    int err;
    pr_info ("Performance Events: ");
    switch (boot_cpu_data.x86_vendor) {
    case X86_VENDOR_INTEL :
        err = intel_pmu_init ();
        break;
    case X86_VENDOR_AMD :
        err = amd_pmu_init ();
        break;
    default :
        return;
    }
    if (err != 0) {
        pr_cont ("no PMU driver, software events only.\n");
        return;
    }
    pmu_check_apic ();
    pr_cont ("%s PMU driver.\n", x86_pmu.name);
    if (x86_pmu.num_events > X86_PMC_MAX_GENERIC) {
        WARN (1, KERN_ERR "hw perf events %d > max(%d), clipping!", x86_pmu.num_events, X86_PMC_MAX_GENERIC);
        x86_pmu.num_events = X86_PMC_MAX_GENERIC;
    }
    perf_event_mask = (1 << x86_pmu.num_events) - 1;
    perf_max_events = x86_pmu.num_events;
    if (x86_pmu.num_events_fixed > X86_PMC_MAX_FIXED) {
        WARN (1, KERN_ERR "hw perf events fixed %d > max(%d), clipping!", x86_pmu.num_events_fixed, X86_PMC_MAX_FIXED);
        x86_pmu.num_events_fixed = X86_PMC_MAX_FIXED;
    }
    perf_event_mask |= ((1LL << x86_pmu.num_events_fixed) - 1) << X86_PMC_IDX_FIXED;
    x86_pmu.intel_ctrl = perf_event_mask;
    perf_events_lapic_init ();
    register_die_notifier (& perf_event_nmi_notifier);
    unconstrained = (struct event_constraint) __EVENT_CONSTRAINT (0, (1ULL << x86_pmu.num_events) - 1, 0, x86_pmu.num_events);
    if (x86_pmu.event_constraints) {
        for_each_event_constraint (c, x86_pmu.event_constraints)
        {
            if (c->cmask != INTEL_ARCH_FIXED_MASK)
                continue;
            c->idxmsk64 |= (1ULL << x86_pmu.num_events) - 1;
            c->weight += x86_pmu.num_events;
        }
    }
    pr_info ("... version:                %d\n", x86_pmu.version);
    pr_info ("... bit width:              %d\n", x86_pmu.event_bits);
    pr_info ("... generic registers:      %d\n", x86_pmu.num_events);
    pr_info ("... value mask:             %016Lx\n", x86_pmu.event_mask);
    pr_info ("... max period:             %016Lx\n", x86_pmu.max_period);
    pr_info ("... fixed-purpose events:   %d\n", x86_pmu.num_events_fixed);
    pr_info ("... event mask:             %016Lx\n", perf_event_mask);
    perf_cpu_notifier (x86_pmu_notifier);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1386" endline="1395">
{
case X86_VENDOR_INTEL :
    err = intel_pmu_init ();
    break;
case X86_VENDOR_AMD :
    err = amd_pmu_init ();
    break;
default :
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1396" endline="1399">
{
    pr_cont ("no PMU driver, software events only.\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1405" endline="1409">
{
    WARN (1, KERN_ERR "hw perf events %d > max(%d), clipping!", x86_pmu.num_events, X86_PMC_MAX_GENERIC);
    x86_pmu.num_events = X86_PMC_MAX_GENERIC;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1413" endline="1417">
{
    WARN (1, KERN_ERR "hw perf events fixed %d > max(%d), clipping!", x86_pmu.num_events_fixed, X86_PMC_MAX_FIXED);
    x86_pmu.num_events_fixed = X86_PMC_MAX_FIXED;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1430" endline="1438">
{
    for_each_event_constraint (c, x86_pmu.event_constraints)
    {
        if (c->cmask != INTEL_ARCH_FIXED_MASK)
            continue;
        c->idxmsk64 |= (1ULL << x86_pmu.num_events) - 1;
        c->weight += x86_pmu.num_events;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1431" endline="1437">
{
    if (c->cmask != INTEL_ARCH_FIXED_MASK)
        continue;
    c->idxmsk64 |= (1ULL << x86_pmu.num_events) - 1;
    c->weight += x86_pmu.num_events;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1452" endline="1454">
{
    x86_perf_event_update (event);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1477" endline="1511">
{
    struct perf_event *leader = event->group_leader;
    struct cpu_hw_events *fake_cpuc;
    int ret, n;
    ret = -ENOMEM;
    fake_cpuc = kmalloc (sizeof (*fake_cpuc), GFP_KERNEL | __GFP_ZERO);
    if (!fake_cpuc)
        goto out;
    ret = -ENOSPC;
    n = collect_events (fake_cpuc, leader, true);
    if (n < 0)
        goto out_free;
    fake_cpuc->n_events = n;
    n = collect_events (fake_cpuc, event, false);
    if (n < 0)
        goto out_free;
    fake_cpuc->n_events = n;
    ret = x86_schedule_events (fake_cpuc, n, NULL);
out_free :
    kfree (fake_cpuc);
out :
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1514" endline="1540">
{
    const struct pmu *tmp;
    int err;
    err = __hw_perf_event_init (event);
    if (!err) {
        tmp = event->pmu;
        event->pmu = &pmu;
        if (event->group_leader != event)
            err = validate_group (event);
        event->pmu = tmp;
    }
    if (err) {
        if (event->destroy)
            event->destroy (event);
        return ERR_PTR (err);
    }
    return &pmu;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1519" endline="1532">
{
    tmp = event->pmu;
    event->pmu = &pmu;
    if (event->group_leader != event)
        err = validate_group (event);
    event->pmu = tmp;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1533" endline="1537">
{
    if (event->destroy)
        event->destroy (event);
    return ERR_PTR (err);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1548" endline="1551">
{
    if (entry->nr < PERF_MAX_STACK_DEPTH)
        entry->ip[entry->nr++] = ip;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1559" endline="1561">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1564" endline="1566">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1569" endline="1571">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1574" endline="1579">
{
    struct perf_callchain_entry *entry = data;
    if (reliable)
        callchain_store (entry, addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1593" endline="1598">
{
    callchain_store (entry, PERF_CONTEXT_KERNEL);
    callchain_store (entry, regs -> ip);
    dump_trace (NULL, regs, NULL, regs -> bp, & backtrace_ops, entry);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1605" endline="1633">
{
    unsigned long offset, addr = (unsigned long) from;
    int type = in_nmi () ? KM_NMI : KM_IRQ0;
    unsigned long size, len = 0;
    struct page *page;
    void *map;
    int ret;
    do {
        ret = __get_user_pages_fast (addr, 1, 0, &page);
        if (!ret)
            break;
        offset = addr & (PAGE_SIZE - 1);
        size = min (PAGE_SIZE -offset, n -len);
        map = kmap_atomic (page, type);
        memcpy (to, map + offset, size);
        kunmap_atomic (map, type);
        put_page (page);
        len += size;
        to += size;
        addr += size;
    }
    while (len < n);
    return len;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1613" endline="1630">
{
    ret = __get_user_pages_fast (addr, 1, 0, &page);
    if (!ret)
        break;
    offset = addr & (PAGE_SIZE - 1);
    size = min (PAGE_SIZE -offset, n -len);
    map = kmap_atomic (page, type);
    memcpy (to, map + offset, size);
    kunmap_atomic (map, type);
    put_page (page);
    len += size;
    to += size;
    addr += size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1667" endline="1669">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1674" endline="1704">
{
    struct stack_frame frame;
    const void __user *fp;
    if (!user_mode (regs))
        regs = task_pt_regs (current);
    fp = (void __user *) regs->bp;
    callchain_store (entry, PERF_CONTEXT_USER);
    callchain_store (entry, regs -> ip);
    if (perf_callchain_user32 (regs, entry))
        return;
    while (entry->nr < PERF_MAX_STACK_DEPTH) {
        unsigned long bytes;
        frame.next_frame = NULL;
        frame.return_address = 0;
        bytes = copy_from_user_nmi (&frame, fp, sizeof (frame));
        if (bytes != sizeof (frame))
            break;
        if ((unsigned long) fp < regs->sp)
            break;
        callchain_store (entry, frame.return_address);
        fp = frame.next_frame;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1689" endline="1703">
{
    unsigned long bytes;
    frame.next_frame = NULL;
    frame.return_address = 0;
    bytes = copy_from_user_nmi (&frame, fp, sizeof (frame));
    if (bytes != sizeof (frame))
        break;
    if ((unsigned long) fp < regs->sp)
        break;
    callchain_store (entry, frame.return_address);
    fp = frame.next_frame;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1708" endline="1724">
{
    int is_user;
    if (!regs)
        return;
    is_user = user_mode (regs);
    if (is_user && current->state != TASK_RUNNING)
        return;
    if (!is_user)
        perf_callchain_kernel (regs, entry);
    if (current->mm)
        perf_callchain_user (regs, entry);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1727" endline="1740">
{
    struct perf_callchain_entry *entry;
    if (in_nmi ())
        entry = &__get_cpu_var (pmc_nmi_entry);
    else
        entry = &__get_cpu_var (pmc_irq_entry);
    entry->nr = 0;
    perf_do_callchain (regs, entry);
    return entry;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/perf_event.c.ifdefed" startline="1743" endline="1752">
{
    regs->ip = ip;
    regs->bp = rewind_frame_pointer (skip +1);
    regs->cs = __KERNEL_CS;
    local_save_flags (regs -> flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="69" endline="135">
{
    unsigned long base, size;
    mtrr_type type;
    int i;
    for (i = 0; i < num_var_ranges; i++) {
        type = range_state[i].type;
        if (type != MTRR_TYPE_WRBACK)
            continue;
        base = range_state[i].base_pfn;
        size = range_state[i].size_pfn;
        nr_range = add_range_with_merge (range, RANGE_NUM, nr_range, base, base +size);
    }
    if (debug_print) {
        printk (KERN_DEBUG "After WB checking\n");
        for (i = 0; i < nr_range; i++)
            printk (KERN_DEBUG "MTRR MAP PFN: %016llx - %016llx\n", range[i].start, range[i].end);
    }
    for (i = 0; i < num_var_ranges; i++) {
        type = range_state[i].type;
        if (type != MTRR_TYPE_UNCACHABLE && type != MTRR_TYPE_WRPROT)
            continue;
        size = range_state[i].size_pfn;
        if (!size)
            continue;
        base = range_state[i].base_pfn;
        if (base < (1 << (20 - PAGE_SHIFT)) && mtrr_state.have_fixed && (mtrr_state.enabled & 1)) {
            printk (BIOS_BUG_MSG, i);
            if (base + size <= (1 << (20 - PAGE_SHIFT)))
                continue;
            size -= (1 << (20 - PAGE_SHIFT)) - base;
            base = 1 << (20 - PAGE_SHIFT);
        }
        subtract_range (range, RANGE_NUM, base, base + size);
    }
    if (extra_remove_size)
        subtract_range (range, RANGE_NUM, extra_remove_base, extra_remove_base +extra_remove_size);
    if (debug_print) {
        printk (KERN_DEBUG "After UC checking\n");
        for (i = 0; i < RANGE_NUM; i++) {
            if (!range[i].end)
                continue;
            printk (KERN_DEBUG "MTRR MAP PFN: %016llx - %016llx\n", range [i].start, range [i].end);
        }
    }
    nr_range = clean_sort_range (range, RANGE_NUM);
    if (debug_print) {
        printk (KERN_DEBUG "After sorting\n");
        for (i = 0; i < nr_range; i++)
            printk (KERN_DEBUG "MTRR MAP PFN: %016llx - %016llx\n", range[i].start, range[i].end);
    }
    return nr_range;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="74" endline="82">
{
    type = range_state[i].type;
    if (type != MTRR_TYPE_WRBACK)
        continue;
    base = range_state[i].base_pfn;
    size = range_state[i].size_pfn;
    nr_range = add_range_with_merge (range, RANGE_NUM, nr_range, base, base +size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="83" endline="88">
{
    printk (KERN_DEBUG "After WB checking\n");
    for (i = 0; i < nr_range; i++)
        printk (KERN_DEBUG "MTRR MAP PFN: %016llx - %016llx\n", range[i].start, range[i].end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="91" endline="110">
{
    type = range_state[i].type;
    if (type != MTRR_TYPE_UNCACHABLE && type != MTRR_TYPE_WRPROT)
        continue;
    size = range_state[i].size_pfn;
    if (!size)
        continue;
    base = range_state[i].base_pfn;
    if (base < (1 << (20 - PAGE_SHIFT)) && mtrr_state.have_fixed && (mtrr_state.enabled & 1)) {
        printk (BIOS_BUG_MSG, i);
        if (base + size <= (1 << (20 - PAGE_SHIFT)))
            continue;
        size -= (1 << (20 - PAGE_SHIFT)) - base;
        base = 1 << (20 - PAGE_SHIFT);
    }
    subtract_range (range, RANGE_NUM, base, base + size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="101" endline="108">
{
    printk (BIOS_BUG_MSG, i);
    if (base + size <= (1 << (20 - PAGE_SHIFT)))
        continue;
    size -= (1 << (20 - PAGE_SHIFT)) - base;
    base = 1 << (20 - PAGE_SHIFT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="115" endline="123">
{
    printk (KERN_DEBUG "After UC checking\n");
    for (i = 0; i < RANGE_NUM; i++) {
        if (!range[i].end)
            continue;
        printk (KERN_DEBUG "MTRR MAP PFN: %016llx - %016llx\n", range [i].start, range [i].end);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="117" endline="122">
{
    if (!range[i].end)
        continue;
    printk (KERN_DEBUG "MTRR MAP PFN: %016llx - %016llx\n", range [i].start, range [i].end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="127" endline="132">
{
    printk (KERN_DEBUG "After sorting\n");
    for (i = 0; i < nr_range; i++)
        printk (KERN_DEBUG "MTRR MAP PFN: %016llx - %016llx\n", range[i].start, range[i].end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="801" endline="803">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="809" endline="812">
{
    disable_mtrr_trim = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="825" endline="843">
{
    u32 l, h;
    if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD)
        return 0;
    if (boot_cpu_data.x86 < 0xf || boot_cpu_data.x86 > 0x11)
        return 0;
    if (rdmsr_safe (MSR_K8_SYSCFG, &l, &h) < 0)
        return 0;
    if ((l & (Tom2Enabled | Tom2ForceMemTypeWB)) == (Tom2Enabled | Tom2ForceMemTypeWB))
        return 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="847" endline="858">
{
    u64 trim_start, trim_size;
    trim_start = start_pfn;
    trim_start <<= PAGE_SHIFT;
    trim_size = limit_pfn;
    trim_size <<= PAGE_SHIFT;
    trim_size -= trim_start;
    return e820_update_range (trim_start, trim_size, E820_RAM, E820_RESERVED);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="872" endline="980">
{
    unsigned long i, base, size, highest_pfn = 0, def, dummy;
    mtrr_type type;
    u64 total_trim_size;
    int num [MTRR_NUM_TYPES + 1];
    if (!is_cpu (INTEL) || disable_mtrr_trim)
        return 0;
    rdmsr (MSR_MTRRdefType, def, dummy);
    def &= 0xff;
    if (def != MTRR_TYPE_UNCACHABLE)
        return 0;
    memset (range_state, 0, sizeof (range_state));
    for (i = 0; i < num_var_ranges; i++) {
        mtrr_if->get (i, &base, &size, &type);
        range_state[i].base_pfn = base;
        range_state[i].size_pfn = size;
        range_state[i].type = type;
    }
    for (i = 0; i < num_var_ranges; i++) {
        type = range_state[i].type;
        if (type != MTRR_TYPE_WRBACK)
            continue;
        base = range_state[i].base_pfn;
        size = range_state[i].size_pfn;
        if (highest_pfn < base + size)
            highest_pfn = base + size;
    }
    if (!highest_pfn) {
        printk (KERN_INFO "CPU MTRRs all blank - virtualized system.\n");
        return 0;
    }
    memset (num, 0, sizeof (num));
    for (i = 0; i < num_var_ranges; i++) {
        type = range_state[i].type;
        if (type >= MTRR_NUM_TYPES)
            continue;
        size = range_state[i].size_pfn;
        if (!size)
            type = MTRR_NUM_TYPES;
        num[type]++;
    }
    if (!num[MTRR_TYPE_WRBACK])
        return 0;
    if (num[MTRR_TYPE_WRBACK] + num[MTRR_TYPE_UNCACHABLE] != num_var_ranges - num[MTRR_NUM_TYPES])
        return 0;
    memset (range, 0, sizeof (range));
    nr_range = 0;
    if (mtrr_tom2) {
        range[nr_range].start = (1ULL << (32 - PAGE_SHIFT));
        range[nr_range].end = mtrr_tom2 >> PAGE_SHIFT;
        if (highest_pfn < range[nr_range].end)
            highest_pfn = range[nr_range].end;
        nr_range++;
    }
    nr_range = x86_get_mtrr_mem_range (range, nr_range, 0, 0);
    total_trim_size = 0;
    if (range[0].start)
        total_trim_size += real_trim_memory (0, range[0].start);
    for (i = 0; i < nr_range - 1; i++) {
        if (range[i].end < range[i + 1].start)
            total_trim_size += real_trim_memory (range[i].end, range[i + 1].start);
    }
    i = nr_range - 1;
    if (range[i].end < end_pfn)
        total_trim_size += real_trim_memory (range[i].end, end_pfn);
    if (total_trim_size) {
        pr_warning ("WARNING: BIOS bug: CPU MTRRs don't cover all of memory, losing %lluMB of RAM.\n", total_trim_size >> 20);
        if (!changed_by_mtrr_cleanup)
            WARN_ON (1);
        pr_info ("update e820 for mtrr\n");
        update_e820 ();
        return 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="893" endline="898">
{
    mtrr_if->get (i, &base, &size, &type);
    range_state[i].base_pfn = base;
    range_state[i].size_pfn = size;
    range_state[i].type = type;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="901" endline="909">
{
    type = range_state[i].type;
    if (type != MTRR_TYPE_WRBACK)
        continue;
    base = range_state[i].base_pfn;
    size = range_state[i].size_pfn;
    if (highest_pfn < base + size)
        highest_pfn = base + size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="912" endline="915">
{
    printk (KERN_INFO "CPU MTRRs all blank - virtualized system.\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="919" endline="927">
{
    type = range_state[i].type;
    if (type >= MTRR_NUM_TYPES)
        continue;
    size = range_state[i].size_pfn;
    if (!size)
        type = MTRR_NUM_TYPES;
    num[type]++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="940" endline="946">
{
    range[nr_range].start = (1ULL << (32 - PAGE_SHIFT));
    range[nr_range].end = mtrr_tom2 >> PAGE_SHIFT;
    if (highest_pfn < range[nr_range].end)
        highest_pfn = range[nr_range].end;
    nr_range++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="955" endline="959">
{
    if (range[i].end < range[i + 1].start)
        total_trim_size += real_trim_memory (range[i].end, range[i + 1].start);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/cleanup.c.ifdefed" startline="967" endline="977">
{
    pr_warning ("WARNING: BIOS bug: CPU MTRRs don't cover all of memory, losing %lluMB of RAM.\n", total_trim_size >> 20);
    if (!changed_by_mtrr_cleanup)
        WARN_ON (1);
    pr_info ("update e820 for mtrr\n");
    update_e820 ();
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/if.c.ifdefed" startline="31" endline="33">
{
    return (x <= 6) ? mtrr_strings[x] : "?";
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="50" endline="65">
{
    u32 lo, hi;
    if (!((boot_cpu_data.x86_vendor == X86_VENDOR_AMD) && (boot_cpu_data.x86 >= 0x0f)))
        return;
    rdmsr (MSR_K8_SYSCFG, lo, hi);
    if (lo & K8_MTRRFIXRANGE_DRAM_MODIFY) {
        printk (KERN_ERR FW_WARN "MTRR: CPU %u: SYSCFG[MtrrFixDramModEn]" " not cleared by BIOS, clearing this bit\n", smp_processor_id ());
        lo &= ~K8_MTRRFIXRANGE_DRAM_MODIFY;
        mtrr_wrmsr (MSR_K8_SYSCFG, lo, hi);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="58" endline="64">
{
    printk (KERN_ERR FW_WARN "MTRR: CPU %u: SYSCFG[MtrrFixDramModEn]" " not cleared by BIOS, clearing this bit\n", smp_processor_id ());
    lo &= ~K8_MTRRFIXRANGE_DRAM_MODIFY;
    mtrr_wrmsr (MSR_K8_SYSCFG, lo, hi);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="74" endline="167">
{
    int i;
    u64 base, mask;
    u8 prev_match, curr_match;
    if (!mtrr_state_set)
        return 0xFF;
    if (!mtrr_state.enabled)
        return 0xFF;
    end--;
    if (mtrr_state.have_fixed && (start < 0x100000)) {
        int idx;
        if (start < 0x80000) {
            idx = 0;
            idx += (start >> 16);
            return mtrr_state.fixed_ranges[idx];
        }
        else if (start < 0xC0000) {
            idx = 1 * 8;
            idx += ((start - 0x80000) >> 14);
            return mtrr_state.fixed_ranges[idx];
        }
        else if (start < 0x1000000) {
            idx = 3 * 8;
            idx += ((start - 0xC0000) >> 12);
            return mtrr_state.fixed_ranges[idx];
        }
    }
    if (!(mtrr_state.enabled & 2))
        return mtrr_state.def_type;
    prev_match = 0xFF;
    for (i = 0; i < num_var_ranges; ++i) {
        unsigned short start_state, end_state;
        if (!(mtrr_state.var_ranges[i].mask_lo & (1 << 11)))
            continue;
        base = (((u64) mtrr_state.var_ranges[i].base_hi) << 32) + (mtrr_state.var_ranges[i].base_lo & PAGE_MASK);
        mask = (((u64) mtrr_state.var_ranges[i].mask_hi) << 32) + (mtrr_state.var_ranges[i].mask_lo & PAGE_MASK);
        start_state = ((start & mask) == (base & mask));
        end_state = ((end & mask) == (base & mask));
        if (start_state != end_state)
            return 0xFE;
        if ((start & mask) != (base & mask))
            continue;
        curr_match = mtrr_state.var_ranges[i].base_lo & 0xff;
        if (prev_match == 0xFF) {
            prev_match = curr_match;
            continue;
        }
        if (prev_match == MTRR_TYPE_UNCACHABLE || curr_match == MTRR_TYPE_UNCACHABLE) {
            return MTRR_TYPE_UNCACHABLE;
        }
        if ((prev_match == MTRR_TYPE_WRBACK && curr_match == MTRR_TYPE_WRTHROUGH) || (prev_match == MTRR_TYPE_WRTHROUGH && curr_match == MTRR_TYPE_WRBACK)) {
            prev_match = MTRR_TYPE_WRTHROUGH;
            curr_match = MTRR_TYPE_WRTHROUGH;
        }
        if (prev_match != curr_match)
            return MTRR_TYPE_UNCACHABLE;
    }
    if (mtrr_tom2) {
        if (start >= (1ULL << 32) && (end < mtrr_tom2))
            return MTRR_TYPE_WRBACK;
    }
    if (prev_match != 0xFF)
        return prev_match;
    return mtrr_state.def_type;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="89" endline="105">
{
    int idx;
    if (start < 0x80000) {
        idx = 0;
        idx += (start >> 16);
        return mtrr_state.fixed_ranges[idx];
    }
    else if (start < 0xC0000) {
        idx = 1 * 8;
        idx += ((start - 0x80000) >> 14);
        return mtrr_state.fixed_ranges[idx];
    }
    else if (start < 0x1000000) {
        idx = 3 * 8;
        idx += ((start - 0xC0000) >> 12);
        return mtrr_state.fixed_ranges[idx];
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="92" endline="96">
{
    idx = 0;
    idx += (start >> 16);
    return mtrr_state.fixed_ranges[idx];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="96" endline="100">
{
    idx = 1 * 8;
    idx += ((start - 0x80000) >> 14);
    return mtrr_state.fixed_ranges[idx];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="100" endline="104">
{
    idx = 3 * 8;
    idx += ((start - 0xC0000) >> 12);
    return mtrr_state.fixed_ranges[idx];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="116" endline="156">
{
    unsigned short start_state, end_state;
    if (!(mtrr_state.var_ranges[i].mask_lo & (1 << 11)))
        continue;
    base = (((u64) mtrr_state.var_ranges[i].base_hi) << 32) + (mtrr_state.var_ranges[i].base_lo & PAGE_MASK);
    mask = (((u64) mtrr_state.var_ranges[i].mask_hi) << 32) + (mtrr_state.var_ranges[i].mask_lo & PAGE_MASK);
    start_state = ((start & mask) == (base & mask));
    end_state = ((end & mask) == (base & mask));
    if (start_state != end_state)
        return 0xFE;
    if ((start & mask) != (base & mask))
        continue;
    curr_match = mtrr_state.var_ranges[i].base_lo & 0xff;
    if (prev_match == 0xFF) {
        prev_match = curr_match;
        continue;
    }
    if (prev_match == MTRR_TYPE_UNCACHABLE || curr_match == MTRR_TYPE_UNCACHABLE) {
        return MTRR_TYPE_UNCACHABLE;
    }
    if ((prev_match == MTRR_TYPE_WRBACK && curr_match == MTRR_TYPE_WRTHROUGH) || (prev_match == MTRR_TYPE_WRTHROUGH && curr_match == MTRR_TYPE_WRBACK)) {
        prev_match = MTRR_TYPE_WRTHROUGH;
        curr_match = MTRR_TYPE_WRTHROUGH;
    }
    if (prev_match != curr_match)
        return MTRR_TYPE_UNCACHABLE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="136" endline="139">
{
    prev_match = curr_match;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="142" endline="144">
{
    return MTRR_TYPE_UNCACHABLE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="149" endline="152">
{
    prev_match = MTRR_TYPE_WRTHROUGH;
    curr_match = MTRR_TYPE_WRTHROUGH;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="158" endline="161">
{
    if (start >= (1ULL << 32) && (end < mtrr_tom2))
        return MTRR_TYPE_WRBACK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="172" endline="175">
{
    rdmsr (MTRRphysBase_MSR (index), vr -> base_lo, vr -> base_hi);
    rdmsr (MTRRphysMask_MSR (index), vr -> mask_lo, vr -> mask_hi);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="180" endline="189">
{
    struct mtrr_var_range *vr;
    vr = mtrr_state.var_ranges;
    vr[index].base_lo = base_lo;
    vr[index].base_hi = base_hi;
    vr[index].mask_lo = mask_lo;
    vr[index].mask_hi = mask_hi;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="192" endline="204">
{
    unsigned int *p = (unsigned int *) frs;
    int i;
    k8_check_syscfg_dram_mod_en ();
    rdmsr (MSR_MTRRfix64K_00000, p [0], p [1]);
    for (i = 0; i < 2; i++)
        rdmsr (MSR_MTRRfix16K_80000 +i, p[2 + i * 2], p[3 + i * 2]);
    for (i = 0; i < 8; i++)
        rdmsr (MSR_MTRRfix4K_C0000 +i, p[6 + i * 2], p[7 + i * 2]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="207" endline="210">
{
    if (cpu_has_mtrr)
        get_fixed_ranges (mtrr_state.fixed_ranges);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="217" endline="225">
{
    if (!last_fixed_end)
        return;
    pr_debug ("  %05X-%05X %s\n", last_fixed_start, last_fixed_end - 1, mtrr_attrib_to_str (last_fixed_type));
    last_fixed_end = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="229" endline="233">
{
    last_fixed_start = base;
    last_fixed_end = end;
    last_fixed_type = type;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="237" endline="253">
{
    unsigned i;
    for (i = 0; i < 8; ++i, ++types, base += step) {
        if (last_fixed_end == 0) {
            update_fixed_last (base, base + step, * types);
            continue;
        }
        if (last_fixed_end == base && last_fixed_type == *types) {
            last_fixed_end = base + step;
            continue;
        }
        print_fixed_last ();
        update_fixed_last (base, base + step, * types);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="240" endline="252">
{
    if (last_fixed_end == 0) {
        update_fixed_last (base, base + step, * types);
        continue;
    }
    if (last_fixed_end == base && last_fixed_type == *types) {
        last_fixed_end = base + step;
        continue;
    }
    print_fixed_last ();
    update_fixed_last (base, base + step, * types);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="241" endline="244">
{
    update_fixed_last (base, base + step, * types);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="245" endline="248">
{
    last_fixed_end = base + step;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="259" endline="303">
{
    unsigned int i;
    int high_width;
    pr_debug ("MTRR default type: %s\n", mtrr_attrib_to_str (mtrr_state.def_type));
    if (mtrr_state.have_fixed) {
        pr_debug ("MTRR fixed ranges %sabled:\n", mtrr_state.enabled & 1 ? "en" : "dis");
        print_fixed (0x00000, 0x10000, mtrr_state.fixed_ranges + 0);
        for (i = 0; i < 2; ++i)
            print_fixed (0x80000 + i * 0x20000, 0x04000, mtrr_state.fixed_ranges + (i + 1) * 8);
        for (i = 0; i < 8; ++i)
            print_fixed (0xC0000 + i * 0x08000, 0x01000, mtrr_state.fixed_ranges + (i + 3) * 8);
        print_fixed_last ();
    }
    pr_debug ("MTRR variable ranges %sabled:\n", mtrr_state.enabled & 2 ? "en" : "dis");
    if (size_or_mask & 0xffffffffUL)
        high_width = ffs (size_or_mask &0xffffffffUL) - 1;
    else
        high_width = ffs (size_or_mask >> 32) + 32 - 1;
    high_width = (high_width - (32 - PAGE_SHIFT) + 3) / 4;
    for (i = 0; i < num_var_ranges; ++i) {
        if (mtrr_state.var_ranges[i].mask_lo & (1 << 11))
            pr_debug ("  %u base %0*X%05X000 mask %0*X%05X000 %s\n", i, high_width, mtrr_state.var_ranges[i].base_hi, mtrr_state.var_ranges[i].base_lo >> 12, high_width, mtrr_state.var_ranges[i].mask_hi, mtrr_state.var_ranges[i].mask_lo >> 12, mtrr_attrib_to_str (mtrr_state.var_ranges[i].base_lo & 0xff));
        else
            pr_debug ("  %u disabled\n", i);
    }
    if (mtrr_tom2)
        pr_debug ("TOM2: %016llx aka %lldM\n", mtrr_tom2, mtrr_tom2 >> 20);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="265" endline="278">
{
    pr_debug ("MTRR fixed ranges %sabled:\n", mtrr_state.enabled & 1 ? "en" : "dis");
    print_fixed (0x00000, 0x10000, mtrr_state.fixed_ranges + 0);
    for (i = 0; i < 2; ++i)
        print_fixed (0x80000 + i * 0x20000, 0x04000, mtrr_state.fixed_ranges + (i + 1) * 8);
    for (i = 0; i < 8; ++i)
        print_fixed (0xC0000 + i * 0x08000, 0x01000, mtrr_state.fixed_ranges + (i + 3) * 8);
    print_fixed_last ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="287" endline="300">
{
    if (mtrr_state.var_ranges[i].mask_lo & (1 << 11))
        pr_debug ("  %u base %0*X%05X000 mask %0*X%05X000 %s\n", i, high_width, mtrr_state.var_ranges[i].base_hi, mtrr_state.var_ranges[i].base_lo >> 12, high_width, mtrr_state.var_ranges[i].mask_hi, mtrr_state.var_ranges[i].mask_lo >> 12, mtrr_attrib_to_str (mtrr_state.var_ranges[i].base_lo & 0xff));
    else
        pr_debug ("  %u disabled\n", i);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="307" endline="350">
{
    struct mtrr_var_range *vrs;
    unsigned long flags;
    unsigned lo, dummy;
    unsigned int i;
    vrs = mtrr_state.var_ranges;
    rdmsr (MSR_MTRRcap, lo, dummy);
    mtrr_state.have_fixed = (lo >> 8) & 1;
    for (i = 0; i < num_var_ranges; i++)
        get_mtrr_var_range (i, &vrs[i]);
    if (mtrr_state.have_fixed)
        get_fixed_ranges (mtrr_state.fixed_ranges);
    rdmsr (MSR_MTRRdefType, lo, dummy);
    mtrr_state.def_type = (lo & 0xff);
    mtrr_state.enabled = (lo & 0xc00) >> 10;
    if (amd_special_default_mtrr ()) {
        unsigned low, high;
        rdmsr (MSR_K8_TOP_MEM2, low, high);
        mtrr_tom2 = high;
        mtrr_tom2 <<= 32;
        mtrr_tom2 |= low;
        mtrr_tom2 &= 0xffffff800000ULL;
    }
    print_mtrr_state ();
    mtrr_state_set = 1;
    local_irq_save (flags);
    prepare_set ();
    pat_init ();
    post_set ();
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="327" endline="336">
{
    unsigned low, high;
    rdmsr (MSR_K8_TOP_MEM2, low, high);
    mtrr_tom2 = high;
    mtrr_tom2 <<= 32;
    mtrr_tom2 |= low;
    mtrr_tom2 &= 0xffffff800000ULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="354" endline="368">
{
    unsigned long mask = smp_changes_mask;
    if (!mask)
        return;
    if (mask & MTRR_CHANGE_MASK_FIXED)
        pr_warning ("mtrr: your CPUs had inconsistent fixed MTRR settings\n");
    if (mask & MTRR_CHANGE_MASK_VARIABLE)
        pr_warning ("mtrr: your CPUs had inconsistent variable MTRR settings\n");
    if (mask & MTRR_CHANGE_MASK_DEFTYPE)
        pr_warning ("mtrr: your CPUs had inconsistent MTRRdefType settings\n");
    printk (KERN_INFO "mtrr: probably your BIOS does not setup all CPUs.\n");
    printk (KERN_INFO "mtrr: corrected configuration.\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="376" endline="382">
{
    if (wrmsr_safe (msr, a, b) < 0) {
        printk (KERN_ERR "MTRR: CPU %u: Writing MSR %x to %x:%x failed\n", smp_processor_id (), msr, a, b);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="377" endline="381">
{
    printk (KERN_ERR "MTRR: CPU %u: Writing MSR %x to %x:%x failed\n", smp_processor_id (), msr, a, b);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="392" endline="401">
{
    unsigned lo, hi;
    rdmsr (msr, lo, hi);
    if (lo != msrwords[0] || hi != msrwords[1]) {
        mtrr_wrmsr (msr, msrwords [0], msrwords [1]);
        *changed = true;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="397" endline="400">
{
    mtrr_wrmsr (msr, msrwords [0], msrwords [1]);
    *changed = true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="413" endline="429">
{
    unsigned long lbase, lsize;
    mtrr_type ltype;
    int i, max;
    max = num_var_ranges;
    if (replace_reg >= 0 && replace_reg < max)
        return replace_reg;
    for (i = 0; i < max; ++i) {
        mtrr_if->get (i, &lbase, &lsize, &ltype);
        if (lsize == 0)
            return i;
    }
    return -ENOSPC;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="422" endline="426">
{
    mtrr_if->get (i, &lbase, &lsize, &ltype);
    if (lsize == 0)
        return i;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="433" endline="481">
{
    unsigned int mask_lo, mask_hi, base_lo, base_hi;
    unsigned int tmp, hi;
    int cpu;
    cpu = get_cpu ();
    rdmsr (MTRRphysMask_MSR (reg), mask_lo, mask_hi);
    if ((mask_lo & 0x800) == 0) {
        *base = 0;
        *size = 0;
        *type = 0;
        goto out_put_cpu;
    }
    rdmsr (MTRRphysBase_MSR (reg), base_lo, base_hi);
    tmp = mask_hi << (32 - PAGE_SHIFT) | mask_lo >> PAGE_SHIFT;
    mask_lo = size_or_mask | tmp;
    hi = fls (tmp);
    if (hi > 0) {
        tmp |= ~((1 << (hi - 1)) - 1);
        if (tmp != mask_lo) {
            printk (KERN_WARNING "mtrr: your BIOS has configured an incorrect mask, fixing it.\n");
            mask_lo = tmp;
        }
    }
    *size = -mask_lo;
    *base = base_hi << (32 - PAGE_SHIFT) | base_lo >> PAGE_SHIFT;
    *type = base_lo & 0xff;
out_put_cpu :
    put_cpu ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="446" endline="452">
{
    *base = 0;
    *size = 0;
    *type = 0;
    goto out_put_cpu;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="462" endline="469">
{
    tmp |= ~((1 << (hi - 1)) - 1);
    if (tmp != mask_lo) {
        printk (KERN_WARNING "mtrr: your BIOS has configured an incorrect mask, fixing it.\n");
        mask_lo = tmp;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="465" endline="468">
{
    printk (KERN_WARNING "mtrr: your BIOS has configured an incorrect mask, fixing it.\n");
    mask_lo = tmp;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="489" endline="503">
{
    unsigned long long *saved = (unsigned long long *) frs;
    bool changed = false;
    int block = -1, range;
    k8_check_syscfg_dram_mod_en ();
    while (fixed_range_blocks[++block].ranges) {
        for (range = 0; range < fixed_range_blocks[block].ranges; range++)
            set_fixed_range (fixed_range_blocks[block].base_msr + range, &changed, (unsigned int *) saved++);
    }
    return changed;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="496" endline="500">
{
    for (range = 0; range < fixed_range_blocks[block].ranges; range++)
        set_fixed_range (fixed_range_blocks[block].base_msr + range, &changed, (unsigned int *) saved++);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="510" endline="532">
{
    unsigned int lo, hi;
    bool changed = false;
    rdmsr (MTRRphysBase_MSR (index), lo, hi);
    if ((vr->base_lo & 0xfffff0ffUL) != (lo & 0xfffff0ffUL) || (vr->base_hi & (size_and_mask >> (32 - PAGE_SHIFT))) != (hi & (size_and_mask >> (32 - PAGE_SHIFT)))) {
        mtrr_wrmsr (MTRRphysBase_MSR (index), vr -> base_lo, vr -> base_hi);
        changed = true;
    }
    rdmsr (MTRRphysMask_MSR (index), lo, hi);
    if ((vr->mask_lo & 0xfffff800UL) != (lo & 0xfffff800UL) || (vr->mask_hi & (size_and_mask >> (32 - PAGE_SHIFT))) != (hi & (size_and_mask >> (32 - PAGE_SHIFT)))) {
        mtrr_wrmsr (MTRRphysMask_MSR (index), vr -> mask_lo, vr -> mask_hi);
        changed = true;
    }
    return changed;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="517" endline="521">
{
    mtrr_wrmsr (MTRRphysBase_MSR (index), vr -> base_lo, vr -> base_hi);
    changed = true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="527" endline="530">
{
    mtrr_wrmsr (MTRRphysMask_MSR (index), vr -> mask_lo, vr -> mask_hi);
    changed = true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="543" endline="568">
{
    unsigned long change_mask = 0;
    unsigned int i;
    for (i = 0; i < num_var_ranges; i++) {
        if (set_mtrr_var_ranges (i, &mtrr_state.var_ranges[i]))
            change_mask |= MTRR_CHANGE_MASK_VARIABLE;
    }
    if (mtrr_state.have_fixed && set_fixed_ranges (mtrr_state.fixed_ranges))
        change_mask |= MTRR_CHANGE_MASK_FIXED;
    if ((deftype_lo & 0xff) != mtrr_state.def_type || ((deftype_lo & 0xc00) >> 10) != mtrr_state.enabled) {
        deftype_lo = (deftype_lo & ~0xcff) | mtrr_state.def_type | (mtrr_state.enabled << 10);
        change_mask |= MTRR_CHANGE_MASK_DEFTYPE;
    }
    return change_mask;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="547" endline="550">
{
    if (set_mtrr_var_ranges (i, &mtrr_state.var_ranges[i]))
        change_mask |= MTRR_CHANGE_MASK_VARIABLE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="560" endline="565">
{
    deftype_lo = (deftype_lo & ~0xcff) | mtrr_state.def_type | (mtrr_state.enabled << 10);
    change_mask |= MTRR_CHANGE_MASK_DEFTYPE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="582" endline="613">
{
    unsigned long cr0;
    raw_spin_lock (& set_atomicity_lock);
    cr0 = read_cr0 () | X86_CR0_CD;
    write_cr0 (cr0);
    wbinvd ();
    if (cpu_has_pge) {
        cr4 = read_cr4 ();
        write_cr4 (cr4 & ~ X86_CR4_PGE);
    }
    __flush_tlb ();
    rdmsr (MSR_MTRRdefType, deftype_lo, deftype_hi);
    mtrr_wrmsr (MSR_MTRRdefType, deftype_lo & ~ 0xcff, deftype_hi);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="600" endline="603">
{
    cr4 = read_cr4 ();
    write_cr4 (cr4 & ~ X86_CR4_PGE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="616" endline="630">
{
    __flush_tlb ();
    mtrr_wrmsr (MSR_MTRRdefType, deftype_lo, deftype_hi);
    write_cr0 (read_cr0 () & 0xbfffffff);
    if (cpu_has_pge)
        write_cr4 (cr4);
    raw_spin_unlock (& set_atomicity_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="633" endline="656">
{
    unsigned long mask, count;
    unsigned long flags;
    local_irq_save (flags);
    prepare_set ();
    mask = set_mtrr_state ();
    pat_init ();
    post_set ();
    local_irq_restore (flags);
    for (count = 0; count < sizeof mask * 8; ++count) {
        if (mask & 0x01)
            set_bit (count, &smp_changes_mask);
        mask >>= 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="650" endline="654">
{
    if (mask & 0x01)
        set_bit (count, &smp_changes_mask);
    mask >>= 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="670" endline="698">
{
    unsigned long flags;
    struct mtrr_var_range *vr;
    vr = &mtrr_state.var_ranges[reg];
    local_irq_save (flags);
    prepare_set ();
    if (size == 0) {
        mtrr_wrmsr (MTRRphysMask_MSR (reg), 0, 0);
        memset (vr, 0, sizeof (struct mtrr_var_range));
    }
    else {
        vr->base_lo = base << PAGE_SHIFT | type;
        vr->base_hi = (base & size_and_mask) >> (32 - PAGE_SHIFT);
        vr->mask_lo = -size << PAGE_SHIFT | 0x800;
        vr->mask_hi = (-size & size_and_mask) >> (32 - PAGE_SHIFT);
        mtrr_wrmsr (MTRRphysBase_MSR (reg), vr -> base_lo, vr -> base_hi);
        mtrr_wrmsr (MTRRphysMask_MSR (reg), vr -> mask_lo, vr -> mask_hi);
    }
    post_set ();
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="679" endline="686">
{
    mtrr_wrmsr (MTRRphysMask_MSR (reg), 0, 0);
    memset (vr, 0, sizeof (struct mtrr_var_range));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="686" endline="694">
{
    vr->base_lo = base << PAGE_SHIFT | type;
    vr->base_hi = (base & size_and_mask) >> (32 - PAGE_SHIFT);
    vr->mask_lo = -size << PAGE_SHIFT | 0x800;
    vr->mask_hi = (-size & size_and_mask) >> (32 - PAGE_SHIFT);
    mtrr_wrmsr (MTRRphysBase_MSR (reg), vr -> base_lo, vr -> base_hi);
    mtrr_wrmsr (MTRRphysMask_MSR (reg), vr -> mask_lo, vr -> mask_hi);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="702" endline="737">
{
    unsigned long lbase, last;
    if (is_cpu (INTEL) && boot_cpu_data.x86 == 6 && boot_cpu_data.x86_model == 1 && boot_cpu_data.x86_mask <= 7) {
        if (base & ((1 << (22 - PAGE_SHIFT)) - 1)) {
            pr_warning ("mtrr: base(0x%lx000) is not 4 MiB aligned\n", base);
            return -EINVAL;
        }
        if (!(base + size < 0x70000 || base > 0x7003F) && (type == MTRR_TYPE_WRCOMB || type == MTRR_TYPE_WRBACK)) {
            pr_warning ("mtrr: writable mtrr between 0x70000000 and 0x7003FFFF may hang the CPU.\n");
            return -EINVAL;
        }
    }
    last = base + size - 1;
    for (lbase = base; !(lbase & 1) && (last & 1); lbase = lbase >> 1, last = last >> 1)
        ;
    if (lbase != last) {
        pr_warning ("mtrr: base(0x%lx000) is not aligned on a size(0x%lx000) boundary\n", base, size);
        return -EINVAL;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="711" endline="722">
{
    if (base & ((1 << (22 - PAGE_SHIFT)) - 1)) {
        pr_warning ("mtrr: base(0x%lx000) is not 4 MiB aligned\n", base);
        return -EINVAL;
    }
    if (!(base + size < 0x70000 || base > 0x7003F) && (type == MTRR_TYPE_WRCOMB || type == MTRR_TYPE_WRBACK)) {
        pr_warning ("mtrr: writable mtrr between 0x70000000 and 0x7003FFFF may hang the CPU.\n");
        return -EINVAL;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="712" endline="715">
{
    pr_warning ("mtrr: base(0x%lx000) is not 4 MiB aligned\n", base);
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="718" endline="721">
{
    pr_warning ("mtrr: writable mtrr between 0x70000000 and 0x7003FFFF may hang the CPU.\n");
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="732" endline="735">
{
    pr_warning ("mtrr: base(0x%lx000) is not aligned on a size(0x%lx000) boundary\n", base, size);
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="740" endline="744">
{
    unsigned long config, dummy;
    rdmsr (MSR_MTRRcap, config, dummy);
    return config & (1 << 10);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/generic.c.ifdefed" startline="747" endline="749">
{
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="71" endline="74">
{
    if (ops->vendor && ops->vendor < X86_VENDOR_NUM)
        mtrr_ops[ops->vendor] = ops;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="78" endline="111">
{
    struct pci_dev *dev;
    u8 rev;
    dev = pci_get_class (PCI_CLASS_BRIDGE_HOST << 8, NULL);
    if (dev != NULL) {
        if (dev->vendor == PCI_VENDOR_ID_SERVERWORKS && dev->device == PCI_DEVICE_ID_SERVERWORKS_LE) {
            pci_read_config_byte (dev, PCI_CLASS_REVISION, & rev);
            if (rev <= 5) {
                pr_info ("mtrr: Serverworks LE rev < 6 detected. Write-combining disabled.\n");
                pci_dev_put (dev);
                return 0;
            }
        }
        if (dev->vendor == PCI_VENDOR_ID_INTEL && dev->device == PCI_DEVICE_ID_INTEL_82451NX) {
            pr_info ("mtrr: Intel 450NX MMC detected. Write-combining disabled.\n");
            pci_dev_put (dev);
            return 0;
        }
        pci_dev_put (dev);
    }
    return mtrr_if->have_wrcomb ? mtrr_if->have_wrcomb () : 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="83" endline="109">
{
    if (dev->vendor == PCI_VENDOR_ID_SERVERWORKS && dev->device == PCI_DEVICE_ID_SERVERWORKS_LE) {
        pci_read_config_byte (dev, PCI_CLASS_REVISION, & rev);
        if (rev <= 5) {
            pr_info ("mtrr: Serverworks LE rev < 6 detected. Write-combining disabled.\n");
            pci_dev_put (dev);
            return 0;
        }
    }
    if (dev->vendor == PCI_VENDOR_ID_INTEL && dev->device == PCI_DEVICE_ID_INTEL_82451NX) {
        pr_info ("mtrr: Intel 450NX MMC detected. Write-combining disabled.\n");
        pci_dev_put (dev);
        return 0;
    }
    pci_dev_put (dev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="90" endline="97">
{
    pci_read_config_byte (dev, PCI_CLASS_REVISION, & rev);
    if (rev <= 5) {
        pr_info ("mtrr: Serverworks LE rev < 6 detected. Write-combining disabled.\n");
        pci_dev_put (dev);
        return 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="92" endline="96">
{
    pr_info ("mtrr: Serverworks LE rev < 6 detected. Write-combining disabled.\n");
    pci_dev_put (dev);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="103" endline="107">
{
    pr_info ("mtrr: Intel 450NX MMC detected. Write-combining disabled.\n");
    pci_dev_put (dev);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="115" endline="126">
{
    unsigned long config = 0, dummy;
    if (use_intel ())
        rdmsr (MSR_MTRRcap, config, dummy);
    else if (is_cpu (AMD))
        config = 2;
    else if (is_cpu (CYRIX) || is_cpu (CENTAUR))
        config = 8;
    num_var_ranges = config & 0xff;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="129" endline="135">
{
    int i, max;
    max = num_var_ranges;
    for (i = 0; i < max; i++)
        mtrr_usage_table[i] = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="153" endline="182">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="185" endline="190">
{
    return type1 == MTRR_TYPE_UNCACHABLE || type2 == MTRR_TYPE_UNCACHABLE || (type1 == MTRR_TYPE_WRTHROUGH && type2 == MTRR_TYPE_WRBACK) || (type1 == MTRR_TYPE_WRBACK && type2 == MTRR_TYPE_WRTHROUGH);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="234" endline="292">
{
    struct set_mtrr_data data;
    unsigned long flags;
    data.smp_reg = reg;
    data.smp_base = base;
    data.smp_size = size;
    data.smp_type = type;
    atomic_set (& data.count, num_booting_cpus () - 1);
    smp_wmb ();
    atomic_set (& data.gate, 0);
    if (smp_call_function (ipi_handler, &data, 0) != 0)
        panic ("mtrr: timed out waiting for other CPUs\n");
    local_irq_save (flags);
    while (atomic_read (&data.count))
        cpu_relax ();
    atomic_set (& data.count, num_booting_cpus () - 1);
    smp_wmb ();
    atomic_set (& data.gate, 1);
    if (reg != ~0U)
        mtrr_if->set (reg, base, size, type);
    else if (!mtrr_aps_delayed_init)
        mtrr_if->set_all ();
    while (atomic_read (&data.count))
        cpu_relax ();
    atomic_set (& data.count, num_booting_cpus () - 1);
    smp_wmb ();
    atomic_set (& data.gate, 0);
    while (atomic_read (&data.count))
        cpu_relax ();
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="331" endline="433">
{
    unsigned long lbase, lsize;
    int i, replace, error;
    mtrr_type ltype;
    if (!mtrr_if)
        return -ENXIO;
    error = mtrr_if->validate_add_page (base, size, type);
    if (error)
        return error;
    if (type >= MTRR_NUM_TYPES) {
        pr_warning ("mtrr: type: %u invalid\n", type);
        return -EINVAL;
    }
    if ((type == MTRR_TYPE_WRCOMB) && !have_wrcomb ()) {
        pr_warning ("mtrr: your processor doesn't support write-combining\n");
        return -ENOSYS;
    }
    if (!size) {
        pr_warning ("mtrr: zero sized request\n");
        return -EINVAL;
    }
    if (base & size_or_mask || size & size_or_mask) {
        pr_warning ("mtrr: base or size exceeds the MTRR width\n");
        return -EINVAL;
    }
    error = -EINVAL;
    replace = -1;
    get_online_cpus ();
    mutex_lock (& mtrr_mutex);
    for (i = 0; i < num_var_ranges; ++i) {
        mtrr_if->get (i, &lbase, &lsize, &ltype);
        if (!lsize || base > lbase + lsize - 1 || base + size - 1 < lbase)
            continue;
        if (base < lbase || base + size - 1 > lbase + lsize - 1) {
            if (base <= lbase && base + size - 1 >= lbase + lsize - 1) {
                if (type == ltype) {
                    replace = replace == -1 ? i : -2;
                    continue;
                }
                else if (types_compatible (type, ltype))
                    continue;
            }
            pr_warning ("mtrr: 0x%lx000,0x%lx000 overlaps existing" " 0x%lx000,0x%lx000\n", base, size, lbase, lsize);
            goto out;
        }
        if (ltype != type) {
            if (types_compatible (type, ltype))
                continue;
            pr_warning ("mtrr: type mismatch for %lx000,%lx000 old: %s new: %s\n", base, size, mtrr_attrib_to_str (ltype), mtrr_attrib_to_str (type));
            goto out;
        }
        if (increment)
            ++mtrr_usage_table[i];
        error = i;
        goto out;
    }
    i = mtrr_if->get_free_region (base, size, replace);
    if (i >= 0) {
        set_mtrr (i, base, size, type);
        if (likely (replace < 0)) {
            mtrr_usage_table[i] = 1;
        }
        else {
            mtrr_usage_table[i] = mtrr_usage_table[replace];
            if (increment)
                mtrr_usage_table[i]++;
            if (unlikely (replace != i)) {
                set_mtrr (replace, 0, 0, 0);
                mtrr_usage_table[replace] = 0;
            }
        }
    }
    else {
        pr_info ("mtrr: no more MTRRs available\n");
    }
    error = i;
out :
    mutex_unlock (&mtrr_mutex);
    put_online_cpus ();
    return error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="343" endline="346">
{
    pr_warning ("mtrr: type: %u invalid\n", type);
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="349" endline="352">
{
    pr_warning ("mtrr: your processor doesn't support write-combining\n");
    return -ENOSYS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="354" endline="357">
{
    pr_warning ("mtrr: zero sized request\n");
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="359" endline="362">
{
    pr_warning ("mtrr: base or size exceeds the MTRR width\n");
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="372" endline="409">
{
    mtrr_if->get (i, &lbase, &lsize, &ltype);
    if (!lsize || base > lbase + lsize - 1 || base + size - 1 < lbase)
        continue;
    if (base < lbase || base + size - 1 > lbase + lsize - 1) {
        if (base <= lbase && base + size - 1 >= lbase + lsize - 1) {
            if (type == ltype) {
                replace = replace == -1 ? i : -2;
                continue;
            }
            else if (types_compatible (type, ltype))
                continue;
        }
        pr_warning ("mtrr: 0x%lx000,0x%lx000 overlaps existing" " 0x%lx000,0x%lx000\n", base, size, lbase, lsize);
        goto out;
    }
    if (ltype != type) {
        if (types_compatible (type, ltype))
            continue;
        pr_warning ("mtrr: type mismatch for %lx000,%lx000 old: %s new: %s\n", base, size, mtrr_attrib_to_str (ltype), mtrr_attrib_to_str (type));
        goto out;
    }
    if (increment)
        ++mtrr_usage_table[i];
    error = i;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="381" endline="395">
{
    if (base <= lbase && base + size - 1 >= lbase + lsize - 1) {
        if (type == ltype) {
            replace = replace == -1 ? i : -2;
            continue;
        }
        else if (types_compatible (type, ltype))
            continue;
    }
    pr_warning ("mtrr: 0x%lx000,0x%lx000 overlaps existing" " 0x%lx000,0x%lx000\n", base, size, lbase, lsize);
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="383" endline="390">
{
    if (type == ltype) {
        replace = replace == -1 ? i : -2;
        continue;
    }
    else if (types_compatible (type, ltype))
        continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="385" endline="388">
{
    replace = replace == -1 ? i : -2;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="397" endline="404">
{
    if (types_compatible (type, ltype))
        continue;
    pr_warning ("mtrr: type mismatch for %lx000,%lx000 old: %s new: %s\n", base, size, mtrr_attrib_to_str (ltype), mtrr_attrib_to_str (type));
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="412" endline="425">
{
    set_mtrr (i, base, size, type);
    if (likely (replace < 0)) {
        mtrr_usage_table[i] = 1;
    }
    else {
        mtrr_usage_table[i] = mtrr_usage_table[replace];
        if (increment)
            mtrr_usage_table[i]++;
        if (unlikely (replace != i)) {
            set_mtrr (replace, 0, 0, 0);
            mtrr_usage_table[replace] = 0;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="414" endline="416">
{
    mtrr_usage_table[i] = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="416" endline="424">
{
    mtrr_usage_table[i] = mtrr_usage_table[replace];
    if (increment)
        mtrr_usage_table[i]++;
    if (unlikely (replace != i)) {
        set_mtrr (replace, 0, 0, 0);
        mtrr_usage_table[replace] = 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="420" endline="423">
{
    set_mtrr (replace, 0, 0, 0);
    mtrr_usage_table[replace] = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="425" endline="427">
{
    pr_info ("mtrr: no more MTRRs available\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="436" endline="444">
{
    if ((base & (PAGE_SIZE - 1)) || (size & (PAGE_SIZE - 1))) {
        pr_warning ("mtrr: size and base must be multiples of 4 kiB\n");
        pr_debug ("mtrr: size: 0x%lx  base: 0x%lx\n", size, base);
        dump_stack ();
        return -1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="437" endline="442">
{
    pr_warning ("mtrr: size and base must be multiples of 4 kiB\n");
    pr_debug ("mtrr: size: 0x%lx  base: 0x%lx\n", size, base);
    dump_stack ();
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="483" endline="488">
{
    if (mtrr_check (base, size))
        return -EINVAL;
    return mtrr_add_page (base >> PAGE_SHIFT, size >> PAGE_SHIFT, type, increment);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="506" endline="554">
{
    int i, max;
    mtrr_type ltype;
    unsigned long lbase, lsize;
    int error = -EINVAL;
    if (!mtrr_if)
        return -ENXIO;
    max = num_var_ranges;
    get_online_cpus ();
    mutex_lock (& mtrr_mutex);
    if (reg < 0) {
        for (i = 0; i < max; ++i) {
            mtrr_if->get (i, &lbase, &lsize, &ltype);
            if (lbase == base && lsize == size) {
                reg = i;
                break;
            }
        }
        if (reg < 0) {
            pr_debug ("mtrr: no MTRR for %lx000,%lx000 found\n", base, size);
            goto out;
        }
    }
    if (reg >= max) {
        pr_warning ("mtrr: register: %d too big\n", reg);
        goto out;
    }
    mtrr_if->get (reg, &lbase, &lsize, &ltype);
    if (lsize < 1) {
        pr_warning ("mtrr: MTRR %d not used\n", reg);
        goto out;
    }
    if (mtrr_usage_table[reg] < 1) {
        pr_warning ("mtrr: reg: %d has count=0\n", reg);
        goto out;
    }
    if (--mtrr_usage_table[reg] < 1)
        set_mtrr (reg, 0, 0, 0);
    error = reg;
out :
    mutex_unlock (&mtrr_mutex);
    put_online_cpus ();
    return error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="519" endline="533">
{
    for (i = 0; i < max; ++i) {
        mtrr_if->get (i, &lbase, &lsize, &ltype);
        if (lbase == base && lsize == size) {
            reg = i;
            break;
        }
    }
    if (reg < 0) {
        pr_debug ("mtrr: no MTRR for %lx000,%lx000 found\n", base, size);
        goto out;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="521" endline="527">
{
    mtrr_if->get (i, &lbase, &lsize, &ltype);
    if (lbase == base && lsize == size) {
        reg = i;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="523" endline="526">
{
    reg = i;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="528" endline="532">
{
    pr_debug ("mtrr: no MTRR for %lx000,%lx000 found\n", base, size);
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="534" endline="537">
{
    pr_warning ("mtrr: register: %d too big\n", reg);
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="539" endline="542">
{
    pr_warning ("mtrr: MTRR %d not used\n", reg);
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="543" endline="546">
{
    pr_warning ("mtrr: reg: %d has count=0\n", reg);
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="571" endline="575">
{
    if (mtrr_check (base, size))
        return -EINVAL;
    return mtrr_del_page (reg, base >> PAGE_SHIFT, size >> PAGE_SHIFT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="584" endline="590">
{
    amd_init_mtrr ();
    cyrix_init_mtrr ();
    centaur_init_mtrr ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="604" endline="613">
{
    int i;
    for (i = 0; i < num_var_ranges; i++) {
        mtrr_if->get (i, &mtrr_value[i].lbase, &mtrr_value[i].lsize, &mtrr_value[i].ltype);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="607" endline="611">
{
    mtrr_if->get (i, &mtrr_value[i].lbase, &mtrr_value[i].lsize, &mtrr_value[i].ltype);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="616" endline="627">
{
    int i;
    for (i = 0; i < num_var_ranges; i++) {
        if (mtrr_value[i].lsize) {
            set_mtrr (i, mtrr_value [i].lbase, mtrr_value [i].lsize, mtrr_value [i].ltype);
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="619" endline="625">
{
    if (mtrr_value[i].lsize) {
        set_mtrr (i, mtrr_value [i].lbase, mtrr_value [i].lsize, mtrr_value [i].ltype);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="620" endline="624">
{
    set_mtrr (i, mtrr_value [i].lbase, mtrr_value [i].lsize, mtrr_value [i].ltype);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="646" endline="727">
{
    u32 phys_addr;
    init_ifs ();
    phys_addr = 32;
    if (cpu_has_mtrr) {
        mtrr_if = &generic_mtrr_ops;
        size_or_mask = 0xff000000;
        size_and_mask = 0x00f00000;
        phys_addr = 36;
        if (cpuid_eax (0x80000000) >= 0x80000008) {
            phys_addr = cpuid_eax (0x80000008) & 0xff;
            if (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL && boot_cpu_data.x86 == 0xF && boot_cpu_data.x86_model == 0x3 && (boot_cpu_data.x86_mask == 0x3 || boot_cpu_data.x86_mask == 0x4))
                phys_addr = 36;
            size_or_mask = ~((1ULL << (phys_addr - PAGE_SHIFT)) - 1);
            size_and_mask = ~size_or_mask & 0xfffff00000ULL;
        }
        else if (boot_cpu_data.x86_vendor == X86_VENDOR_CENTAUR && boot_cpu_data.x86 == 6) {
            size_or_mask = 0xfff00000;
            size_and_mask = 0;
            phys_addr = 32;
        }
    }
    else {
        switch (boot_cpu_data.x86_vendor) {
        case X86_VENDOR_AMD :
            if (cpu_has_k6_mtrr) {
                mtrr_if = mtrr_ops[X86_VENDOR_AMD];
                size_or_mask = 0xfff00000;
                size_and_mask = 0;
            }
            break;
        case X86_VENDOR_CENTAUR :
            if (cpu_has_centaur_mcr) {
                mtrr_if = mtrr_ops[X86_VENDOR_CENTAUR];
                size_or_mask = 0xfff00000;
                size_and_mask = 0;
            }
            break;
        case X86_VENDOR_CYRIX :
            if (cpu_has_cyrix_arr) {
                mtrr_if = mtrr_ops[X86_VENDOR_CYRIX];
                size_or_mask = 0xfff00000;
                size_and_mask = 0;
            }
            break;
        default :
            break;
        }
    }
    if (mtrr_if) {
        set_num_var_ranges ();
        init_table ();
        if (use_intel ()) {
            get_mtrr_state ();
            if (mtrr_cleanup (phys_addr)) {
                changed_by_mtrr_cleanup = 1;
                mtrr_if->set_all ();
            }
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="653" endline="686">
{
    mtrr_if = &generic_mtrr_ops;
    size_or_mask = 0xff000000;
    size_and_mask = 0x00f00000;
    phys_addr = 36;
    if (cpuid_eax (0x80000000) >= 0x80000008) {
        phys_addr = cpuid_eax (0x80000008) & 0xff;
        if (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL && boot_cpu_data.x86 == 0xF && boot_cpu_data.x86_model == 0x3 && (boot_cpu_data.x86_mask == 0x3 || boot_cpu_data.x86_mask == 0x4))
            phys_addr = 36;
        size_or_mask = ~((1ULL << (phys_addr - PAGE_SHIFT)) - 1);
        size_and_mask = ~size_or_mask & 0xfffff00000ULL;
    }
    else if (boot_cpu_data.x86_vendor == X86_VENDOR_CENTAUR && boot_cpu_data.x86 == 6) {
        size_or_mask = 0xfff00000;
        size_and_mask = 0;
        phys_addr = 32;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="664" endline="676">
{
    phys_addr = cpuid_eax (0x80000008) & 0xff;
    if (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL && boot_cpu_data.x86 == 0xF && boot_cpu_data.x86_model == 0x3 && (boot_cpu_data.x86_mask == 0x3 || boot_cpu_data.x86_mask == 0x4))
        phys_addr = 36;
    size_or_mask = ~((1ULL << (phys_addr - PAGE_SHIFT)) - 1);
    size_and_mask = ~size_or_mask & 0xfffff00000ULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="677" endline="685">
{
    size_or_mask = 0xfff00000;
    size_and_mask = 0;
    phys_addr = 32;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="686" endline="713">
{
    switch (boot_cpu_data.x86_vendor) {
    case X86_VENDOR_AMD :
        if (cpu_has_k6_mtrr) {
            mtrr_if = mtrr_ops[X86_VENDOR_AMD];
            size_or_mask = 0xfff00000;
            size_and_mask = 0;
        }
        break;
    case X86_VENDOR_CENTAUR :
        if (cpu_has_centaur_mcr) {
            mtrr_if = mtrr_ops[X86_VENDOR_CENTAUR];
            size_or_mask = 0xfff00000;
            size_and_mask = 0;
        }
        break;
    case X86_VENDOR_CYRIX :
        if (cpu_has_cyrix_arr) {
            mtrr_if = mtrr_ops[X86_VENDOR_CYRIX];
            size_or_mask = 0xfff00000;
            size_and_mask = 0;
        }
        break;
    default :
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="687" endline="712">
{
case X86_VENDOR_AMD :
    if (cpu_has_k6_mtrr) {
        mtrr_if = mtrr_ops[X86_VENDOR_AMD];
        size_or_mask = 0xfff00000;
        size_and_mask = 0;
    }
    break;
case X86_VENDOR_CENTAUR :
    if (cpu_has_centaur_mcr) {
        mtrr_if = mtrr_ops[X86_VENDOR_CENTAUR];
        size_or_mask = 0xfff00000;
        size_and_mask = 0;
    }
    break;
case X86_VENDOR_CYRIX :
    if (cpu_has_cyrix_arr) {
        mtrr_if = mtrr_ops[X86_VENDOR_CYRIX];
        size_or_mask = 0xfff00000;
        size_and_mask = 0;
    }
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="689" endline="694">
{
    mtrr_if = mtrr_ops[X86_VENDOR_AMD];
    size_or_mask = 0xfff00000;
    size_and_mask = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="697" endline="701">
{
    mtrr_if = mtrr_ops[X86_VENDOR_CENTAUR];
    size_or_mask = 0xfff00000;
    size_and_mask = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="704" endline="708">
{
    mtrr_if = mtrr_ops[X86_VENDOR_CYRIX];
    size_or_mask = 0xfff00000;
    size_and_mask = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="715" endline="726">
{
    set_num_var_ranges ();
    init_table ();
    if (use_intel ()) {
        get_mtrr_state ();
        if (mtrr_cleanup (phys_addr)) {
            changed_by_mtrr_cleanup = 1;
            mtrr_if->set_all ();
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="718" endline="725">
{
    get_mtrr_state ();
    if (mtrr_cleanup (phys_addr)) {
        changed_by_mtrr_cleanup = 1;
        mtrr_if->set_all ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="721" endline="724">
{
    changed_by_mtrr_cleanup = 1;
    mtrr_if->set_all ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="730" endline="747">
{
    if (!use_intel () || mtrr_aps_delayed_init)
        return;
    set_mtrr (~ 0U, 0, 0, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="753" endline="755">
{
    smp_call_function_single (0, mtrr_save_fixed_ranges, NULL, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="758" endline="763">
{
    if (!use_intel ())
        return;
    mtrr_aps_delayed_init = true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="769" endline="775">
{
    if (!use_intel ())
        return;
    set_mtrr (~ 0U, 0, 0, 0);
    mtrr_aps_delayed_init = false;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="778" endline="783">
{
    if (!use_intel ())
        return;
    mtrr_if->set_all ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="786" endline="807">
{
    if (!mtrr_if)
        return 0;
    if (use_intel ()) {
        if (!changed_by_mtrr_cleanup)
            mtrr_state_warn ();
        return 0;
    }
    sysdev_driver_register (& cpu_sysdev_class, & mtrr_sysdev_driver);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mtrr/main.c.ifdefed" startline="790" endline="794">
{
    if (!changed_by_mtrr_cleanup)
        mtrr_state_warn ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="54" endline="59">
{
    alloc_bootmem_cpumask_var (& cpu_initialized_mask);
    alloc_bootmem_cpumask_var (& cpu_callin_mask);
    alloc_bootmem_cpumask_var (& cpu_callout_mask);
    alloc_bootmem_cpumask_var (& cpu_sibling_setup_mask);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="62" endline="76">
{
    if (c->cpuid_level == -1) {
        if (c->x86 == 4)
            strcpy (c->x86_model_id, "486");
        else if (c->x86 == 3)
            strcpy (c->x86_model_id, "386");
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="68" endline="74">
{
    if (c->x86 == 4)
        strcpy (c->x86_model_id, "486");
    else if (c->x86 == 3)
        strcpy (c->x86_model_id, "386");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="141" endline="144">
{
    setup_clear_cpu_cap (X86_FEATURE_XSAVE);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="236" endline="238">
{
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="241" endline="243">
{
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="245" endline="246">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="268" endline="295">
{
    const struct cpuid_dependent_feature *df;
    for (df = cpuid_dependent_features; df->feature; df++) {
        if (!cpu_has (c, df->feature))
            continue;
        if (!((s32) df->level < 0 ? (u32) df->level > (u32) c->extended_cpuid_level : (s32) df->level > (s32) c->cpuid_level))
            continue;
        clear_cpu_cap (c, df -> feature);
        if (!warn)
            continue;
        printk (KERN_WARNING "CPU: CPU feature %s disabled, no CPUID level 0x%x\n", x86_cap_flags [df -> feature], df -> level);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="271" endline="294">
{
    if (!cpu_has (c, df->feature))
        continue;
    if (!((s32) df->level < 0 ? (u32) df->level > (u32) c->extended_cpuid_level : (s32) df->level > (s32) c->cpuid_level))
        continue;
    clear_cpu_cap (c, df -> feature);
    if (!warn)
        continue;
    printk (KERN_WARNING "CPU: CPU feature %s disabled, no CPUID level 0x%x\n", x86_cap_flags [df -> feature], df -> level);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="306" endline="323">
{
    const struct cpu_model_info *info;
    if (c->x86_model >= 16)
        return NULL;
    if (!this_cpu)
        return NULL;
    info = this_cpu->c_models;
    while (info && info->family) {
        if (info->family == c->x86)
            return info->model_names[c->x86_model];
        info++;
    }
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="317" endline="321">
{
    if (info->family == c->x86)
        return info->model_names[c->x86_model];
    info++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="329" endline="337">
{
    loadsegment (gs, 0);
    wrmsrl (MSR_GS_BASE, (unsigned long) per_cpu (irq_stack_union.gs_base, cpu));
    load_stack_canary_segment ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="344" endline="353">
{
    struct desc_ptr gdt_descr;
    gdt_descr.address = (long) get_cpu_gdt_table (cpu);
    gdt_descr.size = GDT_SIZE - 1;
    load_gdt (& gdt_descr);
    load_percpu_segment (cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="358" endline="384">
{
    unsigned int *v;
    char *p, *q;
    if (c->extended_cpuid_level < 0x80000004)
        return;
    v = (unsigned int *) c->x86_model_id;
    cpuid (0x80000002, & v [0], & v [1], & v [2], & v [3]);
    cpuid (0x80000003, & v [4], & v [5], & v [6], & v [7]);
    cpuid (0x80000004, & v [8], & v [9], & v [10], & v [11]);
    c->x86_model_id[48] = 0;
    p = q = &c->x86_model_id[0];
    while (*p == ' ')
        p++;
    if (p != q) {
        while (*p)
            *q++ = *p++;
        while (q <= &c->x86_model_id[48])
            *q++ = '\0';
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="378" endline="383">
{
    while (*p)
        *q++ = *p++;
    while (q <= &c->x86_model_id[48])
        *q++ = '\0';
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="387" endline="423">
{
    unsigned int n, dummy, ebx, ecx, edx, l2size;
    n = c->extended_cpuid_level;
    if (n >= 0x80000005) {
        cpuid (0x80000005, & dummy, & ebx, & ecx, & edx);
        c->x86_cache_size = (ecx >> 24) + (edx >> 24);
    }
    if (n < 0x80000006)
        return;
    cpuid (0x80000006, & dummy, & ebx, & ecx, & edx);
    l2size = ecx >> 16;
    if (this_cpu->c_size_cache)
        l2size = this_cpu->c_size_cache (c, l2size);
    if (cachesize_override != -1)
        l2size = cachesize_override;
    if (l2size == 0)
        return;
    c->x86_cache_size = l2size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="392" endline="399">
{
    cpuid (0x80000005, & dummy, & ebx, & ecx, & edx);
    c->x86_cache_size = (ecx >> 24) + (edx >> 24);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="426" endline="481">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="484" endline="508">
{
    char *v = c->x86_vendor_id;
    int i;
    for (i = 0; i < X86_VENDOR_NUM; i++) {
        if (!cpu_devs[i])
            break;
        if (!strcmp (v, cpu_devs[i]->c_ident[0]) || (cpu_devs[i]->c_ident[1] && !strcmp (v, cpu_devs[i]->c_ident[1]))) {
            this_cpu = cpu_devs[i];
            c->x86_vendor = this_cpu->c_x86_vendor;
            return;
        }
    }
    printk_once (KERN_ERR "CPU: vendor_id '%s' unknown, using generic init.\n" \ "CPU: Your system may be unstable.\n", v);
    c->x86_vendor = X86_VENDOR_UNKNOWN;
    this_cpu = &default_cpu;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="488" endline="500">
{
    if (!cpu_devs[i])
        break;
    if (!strcmp (v, cpu_devs[i]->c_ident[0]) || (cpu_devs[i]->c_ident[1] && !strcmp (v, cpu_devs[i]->c_ident[1]))) {
        this_cpu = cpu_devs[i];
        c->x86_vendor = this_cpu->c_x86_vendor;
        return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="494" endline="499">
{
    this_cpu = cpu_devs[i];
    c->x86_vendor = this_cpu->c_x86_vendor;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="511" endline="538">
{
    cpuid (0x00000000, (unsigned int *) & c -> cpuid_level, (unsigned int *) & c -> x86_vendor_id [0], (unsigned int *) & c -> x86_vendor_id [8], (unsigned int *) & c -> x86_vendor_id [4]);
    c->x86 = 4;
    if (c->cpuid_level >= 0x00000001) {
        u32 junk, tfms, cap0, misc;
        cpuid (0x00000001, & tfms, & misc, & junk, & cap0);
        c->x86 = (tfms >> 8) & 0xf;
        c->x86_model = (tfms >> 4) & 0xf;
        c->x86_mask = tfms & 0xf;
        if (c->x86 == 0xf)
            c->x86 += (tfms >> 20) & 0xff;
        if (c->x86 >= 0x6)
            c->x86_model += ((tfms >> 16) & 0xf) << 4;
        if (cap0 & (1 << 19)) {
            c->x86_clflush_size = ((misc >> 8) & 0xff) * 8;
            c->x86_cache_alignment = c->x86_clflush_size;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="520" endline="537">
{
    u32 junk, tfms, cap0, misc;
    cpuid (0x00000001, & tfms, & misc, & junk, & cap0);
    c->x86 = (tfms >> 8) & 0xf;
    c->x86_model = (tfms >> 4) & 0xf;
    c->x86_mask = tfms & 0xf;
    if (c->x86 == 0xf)
        c->x86 += (tfms >> 20) & 0xff;
    if (c->x86 >= 0x6)
        c->x86_model += ((tfms >> 16) & 0xf) << 4;
    if (cap0 & (1 << 19)) {
        c->x86_clflush_size = ((misc >> 8) & 0xff) * 8;
        c->x86_cache_alignment = c->x86_clflush_size;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="533" endline="536">
{
    c->x86_clflush_size = ((misc >> 8) & 0xff) * 8;
    c->x86_cache_alignment = c->x86_clflush_size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="541" endline="579">
{
    u32 tfms, xlvl;
    u32 ebx;
    if (c->cpuid_level >= 0x00000001) {
        u32 capability, excap;
        cpuid (0x00000001, & tfms, & ebx, & excap, & capability);
        c->x86_capability[0] = capability;
        c->x86_capability[4] = excap;
    }
    xlvl = cpuid_eax (0x80000000);
    c->extended_cpuid_level = xlvl;
    if ((xlvl & 0xffff0000) == 0x80000000) {
        if (xlvl >= 0x80000001) {
            c->x86_capability[1] = cpuid_edx (0x80000001);
            c->x86_capability[6] = cpuid_ecx (0x80000001);
        }
    }
    if (c->extended_cpuid_level >= 0x80000008) {
        u32 eax = cpuid_eax (0x80000008);
        c->x86_virt_bits = (eax >> 8) & 0xff;
        c->x86_phys_bits = eax & 0xff;
    }
    if (c->extended_cpuid_level >= 0x80000007)
        c->x86_power = cpuid_edx (0x80000007);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="546" endline="552">
{
    u32 capability, excap;
    cpuid (0x00000001, & tfms, & ebx, & excap, & capability);
    c->x86_capability[0] = capability;
    c->x86_capability[4] = excap;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="558" endline="563">
{
    if (xlvl >= 0x80000001) {
        c->x86_capability[1] = cpuid_edx (0x80000001);
        c->x86_capability[6] = cpuid_ecx (0x80000001);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="559" endline="562">
{
    c->x86_capability[1] = cpuid_edx (0x80000001);
    c->x86_capability[6] = cpuid_ecx (0x80000001);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="565" endline="570">
{
    u32 eax = cpuid_eax (0x80000008);
    c->x86_virt_bits = (eax >> 8) & 0xff;
    c->x86_phys_bits = eax & 0xff;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="582" endline="605">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="617" endline="652">
{
    c->x86_clflush_size = 32;
    c->x86_phys_bits = 32;
    c->x86_virt_bits = 32;
    c->x86_cache_alignment = c->x86_clflush_size;
    memset (& c -> x86_capability, 0, sizeof c -> x86_capability);
    c->extended_cpuid_level = 0;
    if (!have_cpuid_p ())
        identify_cpu_without_cpuid (c);
    if (!have_cpuid_p ())
        return;
    cpu_detect (c);
    get_cpu_vendor (c);
    get_cpu_cap (c);
    if (this_cpu->c_early_init)
        this_cpu->c_early_init (c);
    filter_cpuid_features (c, false);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="655" endline="685">
{
    const struct cpu_dev * const *cdev;
    int count = 0;
    for (cdev = __x86_cpu_dev_start; cdev < __x86_cpu_dev_end; cdev++) {
        const struct cpu_dev *cpudev = *cdev;
        if (count >= X86_VENDOR_NUM)
            break;
        cpu_devs[count] = cpudev;
        count++;
    }
    early_identify_cpu (& boot_cpu_data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="663" endline="683">
{
    const struct cpu_dev *cpudev = *cdev;
    if (count >= X86_VENDOR_NUM)
        break;
    cpu_devs[count] = cpudev;
    count++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="696" endline="698">
{
    clear_cpu_cap (c, X86_FEATURE_NOPL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="701" endline="736">
{
    c->extended_cpuid_level = 0;
    if (!have_cpuid_p ())
        identify_cpu_without_cpuid (c);
    if (!have_cpuid_p ())
        return;
    cpu_detect (c);
    get_cpu_vendor (c);
    get_cpu_cap (c);
    if (c->cpuid_level >= 0x00000001) {
        c->initial_apicid = (cpuid_ebx (1) >> 24) & 0xFF;
    }
    get_model_name (c);
    init_scattered_cpuid_features (c);
    detect_nopl (c);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="717" endline="730">
{
    c->initial_apicid = (cpuid_ebx (1) >> 24) & 0xFF;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="742" endline="852">
{
    int i;
    c->loops_per_jiffy = loops_per_jiffy;
    c->x86_cache_size = -1;
    c->x86_vendor = X86_VENDOR_UNKNOWN;
    c->x86_model = c->x86_mask = 0;
    c->x86_vendor_id[0] = '\0';
    c->x86_model_id[0] = '\0';
    c->x86_max_cores = 1;
    c->x86_coreid_bits = 0;
    c->cpuid_level = -1;
    c->x86_clflush_size = 32;
    c->x86_phys_bits = 32;
    c->x86_virt_bits = 32;
    c->x86_cache_alignment = c->x86_clflush_size;
    memset (& c -> x86_capability, 0, sizeof c -> x86_capability);
    generic_identify (c);
    if (this_cpu->c_identify)
        this_cpu->c_identify (c);
    for (i = 0; i < NCAPINTS; i++) {
        c->x86_capability[i] &= ~cpu_caps_cleared[i];
        c->x86_capability[i] |= cpu_caps_set[i];
    }
    if (this_cpu->c_init)
        this_cpu->c_init (c);
    squash_the_stupid_serial_number (c);
    filter_cpuid_features (c, true);
    if (!c->x86_model_id[0]) {
        const char *p;
        p = table_lookup_model (c);
        if (p)
            strcpy (c->x86_model_id, p);
        else
            sprintf (c->x86_model_id, "%02x/%02x", c->x86, c->x86_model);
    }
    init_hypervisor (c);
    for (i = 0; i < NCAPINTS; i++) {
        c->x86_capability[i] &= ~cpu_caps_cleared[i];
        c->x86_capability[i] |= cpu_caps_set[i];
    }
    if (c != &boot_cpu_data) {
        for (i = 0; i < NCAPINTS; i++)
            boot_cpu_data.x86_capability[i] &= c->x86_capability[i];
    }
    mcheck_cpu_init (c);
    select_idle_routine (c);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="772" endline="775">
{
    c->x86_capability[i] &= ~cpu_caps_cleared[i];
    c->x86_capability[i] |= cpu_caps_set[i];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="806" endline="815">
{
    const char *p;
    p = table_lookup_model (c);
    if (p)
        strcpy (c->x86_model_id, p);
    else
        sprintf (c->x86_model_id, "%02x/%02x", c->x86, c->x86_model);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="827" endline="830">
{
    c->x86_capability[i] &= ~cpu_caps_cleared[i];
    c->x86_capability[i] |= cpu_caps_set[i];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="838" endline="842">
{
    for (i = 0; i < NCAPINTS; i++)
        boot_cpu_data.x86_capability[i] &= c->x86_capability[i];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="865" endline="875">
{
    identify_cpu (& boot_cpu_data);
    init_c1e_mask ();
    vgetcpu_set_mode ();
    init_hw_perf_events ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="878" endline="885">
{
    BUG_ON (c == & boot_cpu_data);
    identify_cpu (c);
    mtrr_ap_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="900" endline="916">
{
    unsigned index_min, index_max;
    unsigned index;
    u64 val;
    int i;
    for (i = 0; i < ARRAY_SIZE (msr_range_array); i++) {
        index_min = msr_range_array[i].min;
        index_max = msr_range_array[i].max;
        for (index = index_min; index < index_max; index++) {
            if (rdmsrl_amd_safe (index, &val))
                continue;
            printk (KERN_INFO " MSR%08x: %016llx\n", index, val);
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="906" endline="915">
{
    index_min = msr_range_array[i].min;
    index_max = msr_range_array[i].max;
    for (index = index_min; index < index_max; index++) {
        if (rdmsrl_amd_safe (index, &val))
            continue;
        printk (KERN_INFO " MSR%08x: %016llx\n", index, val);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="910" endline="914">
{
    if (rdmsrl_amd_safe (index, &val))
        continue;
    printk (KERN_INFO " MSR%08x: %016llx\n", index, val);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="921" endline="929">
{
    int num;
    get_option (& arg, & num);
    if (num > 0)
        show_msr = num;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="933" endline="936">
{
    setup_clear_cpu_cap (X86_FEATURE_CLFLSH);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="940" endline="970">
{
    const char *vendor = NULL;
    if (c->x86_vendor < X86_VENDOR_NUM) {
        vendor = this_cpu->c_vendor;
    }
    else {
        if (c->cpuid_level >= 0)
            vendor = c->x86_vendor_id;
    }
    if (vendor && !strstr (c->x86_model_id, vendor))
        printk (KERN_CONT "%s ", vendor);
    if (c->x86_model_id[0])
        printk (KERN_CONT "%s", c->x86_model_id);
    else
        printk (KERN_CONT "%d86", c->x86);
    if (c->x86_mask || c->cpuid_level >= 0)
        printk (KERN_CONT " stepping %02x\n", c->x86_mask);
    else
        printk (KERN_CONT "\n");
    if (show_msr)
        print_cpu_msr ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="943" endline="945">
{
    vendor = this_cpu->c_vendor;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="945" endline="948">
{
    if (c->cpuid_level >= 0)
        vendor = c->x86_vendor_id;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="973" endline="982">
{
    int bit;
    if (get_option (&arg, &bit) && bit < NCAPINTS * 32)
        setup_clear_cpu_cap (bit);
    else
        return 0;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="1062" endline="1068">
{
    memset (regs, 0, sizeof (struct pt_regs));
    regs->fs = __KERNEL_PERCPU;
    regs->gs = __KERNEL_STACK_CANARY;
    return regs;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="1075" endline="1085">
{
    int i;
    for (i = 0; i < 8; i++) {
        if ((i == 4) || (i == 5))
            continue;
        set_debugreg (0, i);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="1078" endline="1084">
{
    if ((i == 4) || (i == 5))
        continue;
    set_debugreg (0, i);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="1201" endline="1260">
{
    int cpu = smp_processor_id ();
    struct task_struct *curr = current;
    struct tss_struct *t = &per_cpu (init_tss, cpu);
    struct thread_struct *thread = &curr->thread;
    if (cpumask_test_and_set_cpu (cpu, cpu_initialized_mask)) {
        printk (KERN_WARNING "CPU#%d already initialized!\n", cpu);
        for (;;)
            local_irq_enable ();
    }
    printk (KERN_INFO "Initializing CPU#%d\n", cpu);
    if (cpu_has_vme || cpu_has_tsc || cpu_has_de)
        clear_in_cr4 (X86_CR4_VME | X86_CR4_PVI | X86_CR4_TSD | X86_CR4_DE);
    load_idt (& idt_descr);
    switch_to_new_gdt (cpu);
    atomic_inc (& init_mm.mm_count);
    curr->active_mm = &init_mm;
    BUG_ON (curr -> mm);
    enter_lazy_tlb (& init_mm, curr);
    load_sp0 (t, thread);
    set_tss_desc (cpu, t);
    load_TR_desc ();
    load_LDT (& init_mm.context);
    t->x86_tss.io_bitmap_base = offsetof (struct tss_struct, io_bitmap);
    clear_all_debug_regs ();
    if (cpu_has_xsave)
        current_thread_info ()->status = TS_XSAVE;
    else
        current_thread_info ()->status = 0;
    clear_used_math ();
    mxcsr_feature_mask_init ();
    if (smp_processor_id () == boot_cpu_id)
        init_thread_xstate ();
    xsave_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/common.c.ifdefed" startline="1207" endline="1211">
{
    printk (KERN_WARNING "CPU#%d already initialized!\n", cpu);
    for (;;)
        local_irq_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/vmware.c.ifdefed" startline="46" endline="50">
{
    uint32_t eax, ebx, ecx, edx;
    VMWARE_PORT (GETVERSION, eax, ebx, ecx, edx);
    return eax != (uint32_t) -1 && ebx == VMWARE_HYPERVISOR_MAGIC;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/vmware.c.ifdefed" startline="53" endline="66">
{
    uint64_t tsc_hz;
    uint32_t eax, ebx, ecx, edx;
    VMWARE_PORT (GETHZ, eax, ebx, ecx, edx);
    tsc_hz = eax | (((uint64_t) ebx) << 32);
    do_div (tsc_hz, 1000);
    BUG_ON (tsc_hz >> 32);
    printk (KERN_INFO "TSC freq read from hypervisor : %lu.%03lu MHz\n", (unsigned long) tsc_hz / 1000, (unsigned long) tsc_hz % 1000);
    return tsc_hz;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/vmware.c.ifdefed" startline="69" endline="79">
{
    uint32_t eax, ebx, ecx, edx;
    VMWARE_PORT (GETHZ, eax, ebx, ecx, edx);
    if (ebx != UINT_MAX)
        x86_platform.calibrate_tsc = vmware_get_tsc_khz;
    else
        printk (KERN_WARNING "Failed to get TSC freq from the hypervisor\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/vmware.c.ifdefed" startline="87" endline="104">
{
    if (cpu_has_hypervisor) {
        unsigned int eax, ebx, ecx, edx;
        char hyper_vendor_id [13];
        cpuid (CPUID_VMWARE_INFO_LEAF, & eax, & ebx, & ecx, & edx);
        memcpy (hyper_vendor_id + 0, & ebx, 4);
        memcpy (hyper_vendor_id + 4, & ecx, 4);
        memcpy (hyper_vendor_id + 8, & edx, 4);
        hyper_vendor_id[12] = '\0';
        if (!strcmp (hyper_vendor_id, "VMwareVMware"))
            return 1;
    }
    else if (dmi_available && dmi_name_in_serial ("VMware") && __vmware_platform ())
        return 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/vmware.c.ifdefed" startline="88" endline="99">
{
    unsigned int eax, ebx, ecx, edx;
    char hyper_vendor_id [13];
    cpuid (CPUID_VMWARE_INFO_LEAF, & eax, & ebx, & ecx, & edx);
    memcpy (hyper_vendor_id + 0, & ebx, 4);
    memcpy (hyper_vendor_id + 4, & ecx, 4);
    memcpy (hyper_vendor_id + 8, & edx, 4);
    hyper_vendor_id[12] = '\0';
    if (!strcmp (hyper_vendor_id, "VMwareVMware"))
        return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/vmware.c.ifdefed" startline="120" endline="123">
{
    set_cpu_cap (c, X86_FEATURE_CONSTANT_TSC);
    set_cpu_cap (c, X86_FEATURE_TSC_RELIABLE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/centaur.c.ifdefed" startline="251" endline="298">
{
    u32 lo, hi;
    if (cpuid_eax (0xC0000000) >= 0xC0000001) {
        u32 tmp = cpuid_edx (0xC0000001);
        if ((tmp & (ACE_PRESENT | ACE_ENABLED)) == ACE_PRESENT) {
            rdmsr (MSR_VIA_FCR, lo, hi);
            lo |= ACE_FCR;
            wrmsr (MSR_VIA_FCR, lo, hi);
            printk (KERN_INFO "CPU: Enabled ACE h/w crypto\n");
        }
        if ((tmp & (RNG_PRESENT | RNG_ENABLED)) == RNG_PRESENT) {
            rdmsr (MSR_VIA_RNG, lo, hi);
            lo |= RNG_ENABLE;
            wrmsr (MSR_VIA_RNG, lo, hi);
            printk (KERN_INFO "CPU: Enabled h/w RNG\n");
        }
        c->x86_capability[5] = cpuid_edx (0xC0000001);
    }
    if (c->x86 == 0x6 && c->x86_model >= 0xf) {
        c->x86_cache_alignment = c->x86_clflush_size * 2;
        set_cpu_cap (c, X86_FEATURE_REP_GOOD);
    }
    cpu_detect_cache_sizes (c);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/centaur.c.ifdefed" startline="255" endline="278">
{
    u32 tmp = cpuid_edx (0xC0000001);
    if ((tmp & (ACE_PRESENT | ACE_ENABLED)) == ACE_PRESENT) {
        rdmsr (MSR_VIA_FCR, lo, hi);
        lo |= ACE_FCR;
        wrmsr (MSR_VIA_FCR, lo, hi);
        printk (KERN_INFO "CPU: Enabled ACE h/w crypto\n");
    }
    if ((tmp & (RNG_PRESENT | RNG_ENABLED)) == RNG_PRESENT) {
        rdmsr (MSR_VIA_RNG, lo, hi);
        lo |= RNG_ENABLE;
        wrmsr (MSR_VIA_RNG, lo, hi);
        printk (KERN_INFO "CPU: Enabled h/w RNG\n");
    }
    c->x86_capability[5] = cpuid_edx (0xC0000001);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/centaur.c.ifdefed" startline="259" endline="264">
{
    rdmsr (MSR_VIA_FCR, lo, hi);
    lo |= ACE_FCR;
    wrmsr (MSR_VIA_FCR, lo, hi);
    printk (KERN_INFO "CPU: Enabled ACE h/w crypto\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/centaur.c.ifdefed" startline="267" endline="272">
{
    rdmsr (MSR_VIA_RNG, lo, hi);
    lo |= RNG_ENABLE;
    wrmsr (MSR_VIA_RNG, lo, hi);
    printk (KERN_INFO "CPU: Enabled h/w RNG\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/centaur.c.ifdefed" startline="292" endline="295">
{
    c->x86_cache_alignment = c->x86_clflush_size * 2;
    set_cpu_cap (c, X86_FEATURE_REP_GOOD);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/centaur.c.ifdefed" startline="322" endline="338">
{
    switch (c->x86) {
    case 6 :
        if (c->x86_model >= 0xf)
            set_cpu_cap (c, X86_FEATURE_CONSTANT_TSC);
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/centaur.c.ifdefed" startline="323" endline="334">
{
case 6 :
    if (c->x86_model >= 0xf)
        set_cpu_cap (c, X86_FEATURE_CONSTANT_TSC);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/centaur.c.ifdefed" startline="341" endline="469">
{
    early_init_centaur (c);
    switch (c->x86) {
    case 6 :
        init_c3 (c);
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/centaur.c.ifdefed" startline="356" endline="465">
{
case 6 :
    init_c3 (c);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/centaur.c.ifdefed" startline="473" endline="489">
{
    return size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="108" endline="113">
{
    pr_emerg ("No human readable MCE decoding support on this CPU type.\n");
    pr_emerg ("Run the message through 'mcelog --ascii' to decode.\n");
    return NOTIFY_STOP;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="129" endline="142">
{
    memset (m, 0, sizeof (struct mce));
    m->cpu = m->extcpu = smp_processor_id ();
    rdtscll (m -> tsc);
    m->time = get_seconds ();
    m->cpuvendor = boot_cpu_data.x86_vendor;
    m->cpuid = cpuid_eax (1);
    m->apicid = cpu_data (m->extcpu).initial_apicid;
    rdmsrl (MSR_IA32_MCG_CAP, m -> mcgcap);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="160" endline="200">
{
    unsigned next, entry;
    trace_mce_record (mce);
    mce->finished = 0;
    wmb ();
    for (;;) {
        entry = rcu_dereference_check_mce (mcelog.next);
        for (;;) {
            if (entry >= MCE_LOG_LEN) {
                set_bit (MCE_OVERFLOW, (unsigned long *) & mcelog.flags);
                return;
            }
            if (mcelog.entry[entry].finished) {
                entry++;
                continue;
            }
            break;
        }
        smp_rmb ();
        next = entry + 1;
        if (cmpxchg (&mcelog.next, entry, next) == entry)
            break;
    }
    memcpy (mcelog.entry + entry, mce, sizeof (struct mce));
    wmb ();
    mcelog.entry[entry].finished = 1;
    wmb ();
    mce->finished = 1;
    set_bit (0, & mce_need_notify);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="168" endline="192">
{
    entry = rcu_dereference_check_mce (mcelog.next);
    for (;;) {
        if (entry >= MCE_LOG_LEN) {
            set_bit (MCE_OVERFLOW, (unsigned long *) & mcelog.flags);
            return;
        }
        if (mcelog.entry[entry].finished) {
            entry++;
            continue;
        }
        break;
    }
    smp_rmb ();
    next = entry + 1;
    if (cmpxchg (&mcelog.next, entry, next) == entry)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="170" endline="187">
{
    if (entry >= MCE_LOG_LEN) {
        set_bit (MCE_OVERFLOW, (unsigned long *) & mcelog.flags);
        return;
    }
    if (mcelog.entry[entry].finished) {
        entry++;
        continue;
    }
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="176" endline="180">
{
    set_bit (MCE_OVERFLOW, (unsigned long *) & mcelog.flags);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="182" endline="185">
{
    entry++;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="203" endline="232">
{
    pr_emerg ("CPU %d: Machine Check Exception: %16Lx Bank %d: %016Lx\n", m -> extcpu, m -> mcgstatus, m -> bank, m -> status);
    if (m->ip) {
        pr_emerg ("RIP%s %02x:<%016Lx> ", ! (m -> mcgstatus & MCG_STATUS_EIPV) ? " !INEXACT!" : "", m -> cs, m -> ip);
        if (m->cs == __KERNEL_CS)
            print_symbol ("{%s}", m->ip);
        pr_cont ("\n");
    }
    pr_emerg ("TSC %llx ", m -> tsc);
    if (m->addr)
        pr_cont ("ADDR %llx ", m->addr);
    if (m->misc)
        pr_cont ("MISC %llx ", m->misc);
    pr_cont ("\n");
    pr_emerg ("PROCESSOR %u:%x TIME %llu SOCKET %u APIC %x\n", m -> cpuvendor, m -> cpuid, m -> time, m -> socketid, m -> apicid);
    atomic_notifier_call_chain (& x86_mce_decoder_chain, 0, m);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="207" endline="215">
{
    pr_emerg ("RIP%s %02x:<%016Lx> ", ! (m -> mcgstatus & MCG_STATUS_EIPV) ? " !INEXACT!" : "", m -> cs, m -> ip);
    if (m->cs == __KERNEL_CS)
        print_symbol ("{%s}", m->ip);
    pr_cont ("\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="235" endline="237">
{
    pr_emerg ("\nHARDWARE ERROR\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="240" endline="242">
{
    pr_emerg ("This is not a software problem!\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="253" endline="263">
{
    long timeout = PANIC_TIMEOUT * USEC_PER_SEC;
    preempt_disable ();
    local_irq_enable ();
    while (timeout-- > 0)
        udelay (1);
    if (panic_timeout == 0)
        panic_timeout = mce_panic_timeout;
    panic ("Panicing machine check CPU died");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="266" endline="316">
{
    int i;
    if (!fake_panic) {
        if (atomic_inc_return (&mce_paniced) > 1)
            wait_for_panic ();
        barrier ();
        bust_spinlocks (1);
        console_verbose ();
    }
    else {
        if (atomic_inc_return (&mce_fake_paniced) > 1)
            return;
    }
    print_mce_head ();
    for (i = 0; i < MCE_LOG_LEN; i++) {
        struct mce *m = &mcelog.entry[i];
        if (!(m->status & MCI_STATUS_VAL))
            continue;
        if (!(m->status & MCI_STATUS_UC))
            print_mce (m);
    }
    for (i = 0; i < MCE_LOG_LEN; i++) {
        struct mce *m = &mcelog.entry[i];
        if (!(m->status & MCI_STATUS_VAL))
            continue;
        if (!(m->status & MCI_STATUS_UC))
            continue;
        if (!final || memcmp (m, final, sizeof (struct mce)))
            print_mce (m);
    }
    if (final)
        print_mce (final);
    if (cpu_missing)
        printk (KERN_EMERG "Some CPUs didn't answer in synchronization\n");
    print_mce_tail ();
    if (exp)
        printk (KERN_EMERG "Machine check: %s\n", exp);
    if (!fake_panic) {
        if (panic_timeout == 0)
            panic_timeout = mce_panic_timeout;
        panic (msg);
    }
    else
        printk (KERN_EMERG "Fake kernel panic: %s\n", msg);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="269" endline="279">
{
    if (atomic_inc_return (&mce_paniced) > 1)
        wait_for_panic ();
    barrier ();
    bust_spinlocks (1);
    console_verbose ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="279" endline="283">
{
    if (atomic_inc_return (&mce_fake_paniced) > 1)
        return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="286" endline="292">
{
    struct mce *m = &mcelog.entry[i];
    if (!(m->status & MCI_STATUS_VAL))
        continue;
    if (!(m->status & MCI_STATUS_UC))
        print_mce (m);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="294" endline="302">
{
    struct mce *m = &mcelog.entry[i];
    if (!(m->status & MCI_STATUS_VAL))
        continue;
    if (!(m->status & MCI_STATUS_UC))
        continue;
    if (!final || memcmp (m, final, sizeof (struct mce)))
        print_mce (m);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="310" endline="314">
{
    if (panic_timeout == 0)
        panic_timeout = mce_panic_timeout;
    panic (msg);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="321" endline="335">
{
    unsigned bank = __get_cpu_var (injectm.bank);
    if (msr == rip_msr)
        return offsetof (struct mce, ip);
    if (msr == MSR_IA32_MCx_STATUS (bank))
        return offsetof (struct mce, status);
    if (msr == MSR_IA32_MCx_ADDR (bank))
        return offsetof (struct mce, addr);
    if (msr == MSR_IA32_MCx_MISC (bank))
        return offsetof (struct mce, misc);
    if (msr == MSR_IA32_MCG_STATUS)
        return offsetof (struct mce, mcgstatus);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="339" endline="361">
{
    u64 v;
    if (__get_cpu_var (injectm).finished) {
        int offset = msr_to_offset (msr);
        if (offset < 0)
            return 0;
        return *(u64*) ((char *) &__get_cpu_var (injectm) + offset);
    }
    if (rdmsrl_safe (msr, &v)) {
        WARN_ONCE (1, "mce: Unable to read msr %d!\n", msr);
        v = 0;
    }
    return v;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="342" endline="348">
{
    int offset = msr_to_offset (msr);
    if (offset < 0)
        return 0;
    return *(u64*) ((char *) &__get_cpu_var (injectm) + offset);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="350" endline="358">
{
    WARN_ONCE (1, "mce: Unable to read msr %d!\n", msr);
    v = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="364" endline="373">
{
    if (__get_cpu_var (injectm).finished) {
        int offset = msr_to_offset (msr);
        if (offset >= 0)
            *(u64*) ((char *) &__get_cpu_var (injectm) + offset) = v;
        return;
    }
    wrmsrl (msr, v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="365" endline="371">
{
    int offset = msr_to_offset (msr);
    if (offset >= 0)
        *(u64*) ((char *) &__get_cpu_var (injectm) + offset) = v;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="391" endline="395">
{
    struct mce_ring *r = &__get_cpu_var (mce_ring);
    return r->start == r->end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="398" endline="413">
{
    struct mce_ring *r;
    int ret = 0;
    *pfn = 0;
    get_cpu ();
    r = &__get_cpu_var (mce_ring);
    if (r->start == r->end)
        goto out;
    *pfn = r->ring[r->start];
    r->start = (r->start + 1) % MCE_RING_SIZE;
    ret = 1;
out :
    put_cpu ();
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="417" endline="428">
{
    struct mce_ring *r = &__get_cpu_var (mce_ring);
    unsigned next;
    next = (r->end + 1) % MCE_RING_SIZE;
    if (next == r->start)
        return -1;
    r->ring[r->end] = pfn;
    wmb ();
    r->end = next;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="431" endline="435">
{
    if (mce_disabled)
        return 0;
    return cpu_has (c, X86_FEATURE_MCE) && cpu_has (c, X86_FEATURE_MCA);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="438" endline="444">
{
    if (!mce_ring_empty ()) {
        struct work_struct *work = &__get_cpu_var (mce_work);
        if (!work_pending (work))
            schedule_work (work);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="439" endline="443">
{
    struct work_struct *work = &__get_cpu_var (mce_work);
    if (!work_pending (work))
        schedule_work (work);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="451" endline="462">
{
    if (regs && (m->mcgstatus & (MCG_STATUS_RIPV | MCG_STATUS_EIPV))) {
        m->ip = regs->ip;
        m->cs = regs->cs;
    }
    else {
        m->ip = 0;
        m->cs = 0;
    }
    if (rip_msr)
        m->ip = mce_rdmsrl (rip_msr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="453" endline="456">
{
    m->ip = regs->ip;
    m->cs = regs->cs;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="456" endline="459">
{
    m->ip = 0;
    m->cs = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="482" endline="518">
{
    if (regs->flags & (X86_VM_MASK | X86_EFLAGS_IF)) {
        mce_notify_irq ();
        mce_schedule_work ();
        return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="483" endline="493">
{
    mce_notify_irq ();
    mce_schedule_work ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="538" endline="599">
{
    struct mce m;
    int i;
    __get_cpu_var (mce_poll_count)++;
    mce_setup (& m);
    m.mcgstatus = mce_rdmsrl (MSR_IA32_MCG_STATUS);
    for (i = 0; i < banks; i++) {
        if (!mce_banks[i].ctl || !test_bit (i, *b))
            continue;
        m.misc = 0;
        m.addr = 0;
        m.bank = i;
        m.tsc = 0;
        barrier ();
        m.status = mce_rdmsrl (MSR_IA32_MCx_STATUS (i));
        if (!(m.status & MCI_STATUS_VAL))
            continue;
        if (!(flags & MCP_UC) && (m.status & (mce_ser ? MCI_STATUS_S : MCI_STATUS_UC)))
            continue;
        if (m.status & MCI_STATUS_MISCV)
            m.misc = mce_rdmsrl (MSR_IA32_MCx_MISC (i));
        if (m.status & MCI_STATUS_ADDRV)
            m.addr = mce_rdmsrl (MSR_IA32_MCx_ADDR (i));
        if (!(flags & MCP_TIMESTAMP))
            m.tsc = 0;
        if (!(flags & MCP_DONTLOG) && !mce_dont_log_ce) {
            mce_log (& m);
            add_taint (TAINT_MACHINE_CHECK);
        }
        mce_wrmsrl (MSR_IA32_MCx_STATUS (i), 0);
    }
    sync_core ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="547" endline="591">
{
    if (!mce_banks[i].ctl || !test_bit (i, *b))
        continue;
    m.misc = 0;
    m.addr = 0;
    m.bank = i;
    m.tsc = 0;
    barrier ();
    m.status = mce_rdmsrl (MSR_IA32_MCx_STATUS (i));
    if (!(m.status & MCI_STATUS_VAL))
        continue;
    if (!(flags & MCP_UC) && (m.status & (mce_ser ? MCI_STATUS_S : MCI_STATUS_UC)))
        continue;
    if (m.status & MCI_STATUS_MISCV)
        m.misc = mce_rdmsrl (MSR_IA32_MCx_MISC (i));
    if (m.status & MCI_STATUS_ADDRV)
        m.addr = mce_rdmsrl (MSR_IA32_MCx_ADDR (i));
    if (!(flags & MCP_TIMESTAMP))
        m.tsc = 0;
    if (!(flags & MCP_DONTLOG) && !mce_dont_log_ce) {
        mce_log (& m);
        add_taint (TAINT_MACHINE_CHECK);
    }
    mce_wrmsrl (MSR_IA32_MCx_STATUS (i), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="582" endline="585">
{
    mce_log (& m);
    add_taint (TAINT_MACHINE_CHECK);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="607" endline="616">
{
    int i;
    for (i = 0; i < banks; i++) {
        m->status = mce_rdmsrl (MSR_IA32_MCx_STATUS (i));
        if (mce_severity (m, tolerant, msg) >= MCE_PANIC_SEVERITY)
            return 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="610" endline="614">
{
    m->status = mce_rdmsrl (MSR_IA32_MCx_STATUS (i));
    if (mce_severity (m, tolerant, msg) >= MCE_PANIC_SEVERITY)
        return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="633" endline="657">
{
    rmb ();
    if (atomic_read (&mce_paniced))
        wait_for_panic ();
    if (!monarch_timeout)
        goto out;
    if ((s64) *t < SPINUNIT) {
        if (tolerant < 1)
            mce_panic ("Timeout synchronizing machine check over CPUs", NULL, NULL);
        cpu_missing = 1;
        return 1;
    }
    *t -= SPINUNIT;
out :
    touch_nmi_watchdog ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="645" endline="652">
{
    if (tolerant < 1)
        mce_panic ("Timeout synchronizing machine check over CPUs", NULL, NULL);
    cpu_missing = 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="684" endline="733">
{
    int cpu;
    struct mce *m = NULL;
    int global_worst = 0;
    char *msg = NULL;
    char *nmsg = NULL;

    for_each_possible_cpu (cpu) {
        int severity = mce_severity (&per_cpu (mces_seen, cpu), tolerant, &nmsg);
        if (severity > global_worst) {
            msg = nmsg;
            global_worst = severity;
            m = &per_cpu (mces_seen, cpu);
        }
    }

    if (m && global_worst >= MCE_PANIC_SEVERITY && tolerant < 3)
        mce_panic ("Fatal Machine check", m, msg);
    if (global_worst <= MCE_KEEP_SEVERITY && tolerant < 3)
        mce_panic ("Machine check from unknown source", NULL, NULL);
    for_each_possible_cpu (cpu)
    memset (& per_cpu (mces_seen, cpu), 0, sizeof (struct mce));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="696" endline="704">
{
    int severity = mce_severity (&per_cpu (mces_seen, cpu), tolerant, &nmsg);
    if (severity > global_worst) {
        msg = nmsg;
        global_worst = severity;
        m = &per_cpu (mces_seen, cpu);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="699" endline="703">
{
    msg = nmsg;
    global_worst = severity;
    m = &per_cpu (mces_seen, cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="745" endline="803">
{
    int order;
    int cpus = num_online_cpus ();
    u64 timeout = (u64) monarch_timeout * NSEC_PER_USEC;
    if (!timeout)
        return -1;
    atomic_add (* no_way_out, & global_nwo);
    smp_wmb ();
    order = atomic_inc_return (&mce_callin);
    while (atomic_read (&mce_callin) != cpus) {
        if (mce_timed_out (&timeout)) {
            atomic_set (& global_nwo, 0);
            return -1;
        }
        ndelay (SPINUNIT);
    }
    smp_rmb ();
    if (order == 1) {
        atomic_set (& mce_executing, 1);
    }
    else {
        while (atomic_read (&mce_executing) < order) {
            if (mce_timed_out (&timeout)) {
                atomic_set (& global_nwo, 0);
                return -1;
            }
            ndelay (SPINUNIT);
        }
    }
    *no_way_out = atomic_read (&global_nwo);
    return order;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="763" endline="769">
{
    if (mce_timed_out (&timeout)) {
        atomic_set (& global_nwo, 0);
        return -1;
    }
    ndelay (SPINUNIT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="764" endline="767">
{
    atomic_set (& global_nwo, 0);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="776" endline="781">
{
    atomic_set (& mce_executing, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="781" endline="795">
{
    while (atomic_read (&mce_executing) < order) {
        if (mce_timed_out (&timeout)) {
            atomic_set (& global_nwo, 0);
            return -1;
        }
        ndelay (SPINUNIT);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="788" endline="794">
{
    if (mce_timed_out (&timeout)) {
        atomic_set (& global_nwo, 0);
        return -1;
    }
    ndelay (SPINUNIT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="789" endline="792">
{
    atomic_set (& global_nwo, 0);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="810" endline="870">
{
    int ret = -1;
    u64 timeout = (u64) monarch_timeout * NSEC_PER_USEC;
    if (!timeout)
        goto reset;
    if (order < 0)
        goto reset;
    atomic_inc (& mce_executing);
    if (order == 1) {
        int cpus = num_online_cpus ();
        while (atomic_read (&mce_executing) <= cpus) {
            if (mce_timed_out (&timeout))
                goto reset;
            ndelay (SPINUNIT);
        }
        mce_reign ();
        barrier ();
        ret = 0;
    }
    else {
        while (atomic_read (&mce_executing) != 0) {
            if (mce_timed_out (&timeout))
                goto reset;
            ndelay (SPINUNIT);
        }
        return 0;
    }
reset :
    atomic_set (&global_nwo, 0);
    atomic_set (& mce_callin, 0);
    barrier ();
    atomic_set (& mce_executing, 0);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="824" endline="841">
{
    int cpus = num_online_cpus ();
    while (atomic_read (&mce_executing) <= cpus) {
        if (mce_timed_out (&timeout))
            goto reset;
        ndelay (SPINUNIT);
    }
    mce_reign ();
    barrier ();
    ret = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="832" endline="836">
{
    if (mce_timed_out (&timeout))
        goto reset;
    ndelay (SPINUNIT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="841" endline="855">
{
    while (atomic_read (&mce_executing) != 0) {
        if (mce_timed_out (&timeout))
            goto reset;
        ndelay (SPINUNIT);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="845" endline="849">
{
    if (mce_timed_out (&timeout))
        goto reset;
    ndelay (SPINUNIT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="879" endline="887">
{
    if (!(m->status & MCI_STATUS_MISCV) || !(m->status & MCI_STATUS_ADDRV))
        return 0;
    if ((m->misc & 0x3f) > PAGE_SHIFT)
        return 0;
    if (((m->misc >> 6) & 7) != MCM_ADDR_PHYS)
        return 0;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="890" endline="897">
{
    int i;
    for (i = 0; i < banks; i++) {
        if (test_bit (i, toclear))
            mce_wrmsrl (MSR_IA32_MCx_STATUS (i), 0);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="893" endline="896">
{
    if (test_bit (i, toclear))
        mce_wrmsrl (MSR_IA32_MCx_STATUS (i), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="912" endline="1079">
{
    struct mce m, *final;
    int i;
    int worst = 0;
    int severity;
    int order;
    int no_way_out = 0;
    int kill_it = 0;
    DECLARE_BITMAP (toclear, MAX_NR_BANKS);
    char *msg = "Unknown";
    atomic_inc (& mce_entry);
    __get_cpu_var (mce_exception_count)++;
    if (notify_die (DIE_NMI, "machine check", regs, error_code, 18, SIGKILL) == NOTIFY_STOP)
        goto out;
    if (!banks)
        goto out;
    mce_setup (& m);
    m.mcgstatus = mce_rdmsrl (MSR_IA32_MCG_STATUS);
    final = &__get_cpu_var (mces_seen);
    *final = m;
    no_way_out = mce_no_way_out (&m, &msg);
    barrier ();
    if (!(m.mcgstatus & MCG_STATUS_RIPV))
        kill_it = 1;
    order = mce_start (&no_way_out);
    for (i = 0; i < banks; i++) {
        __clear_bit (i, toclear);
        if (!mce_banks[i].ctl)
            continue;
        m.misc = 0;
        m.addr = 0;
        m.bank = i;
        m.status = mce_rdmsrl (MSR_IA32_MCx_STATUS (i));
        if ((m.status & MCI_STATUS_VAL) == 0)
            continue;
        if (!(m.status & (mce_ser ? MCI_STATUS_S : MCI_STATUS_UC)) && !no_way_out)
            continue;
        add_taint (TAINT_MACHINE_CHECK);
        severity = mce_severity (&m, tolerant, NULL);
        if (severity == MCE_KEEP_SEVERITY && !no_way_out)
            continue;
        __set_bit (i, toclear);
        if (severity == MCE_NO_SEVERITY) {
            continue;
        }
        if (severity == MCE_AR_SEVERITY)
            kill_it = 1;
        if (m.status & MCI_STATUS_MISCV)
            m.misc = mce_rdmsrl (MSR_IA32_MCx_MISC (i));
        if (m.status & MCI_STATUS_ADDRV)
            m.addr = mce_rdmsrl (MSR_IA32_MCx_ADDR (i));
        if (severity == MCE_AO_SEVERITY && mce_usable_address (&m))
            mce_ring_add (m.addr >> PAGE_SHIFT);
        mce_get_rip (& m, regs);
        mce_log (& m);
        if (severity > worst) {
            *final = m;
            worst = severity;
        }
    }
    if (!no_way_out)
        mce_clear_state (toclear);
    if (mce_end (order) < 0)
        no_way_out = worst >= MCE_PANIC_SEVERITY;
    if (no_way_out && tolerant < 3)
        mce_panic ("Fatal machine check on current CPU", final, msg);
    if (kill_it && tolerant < 3)
        force_sig (SIGBUS, current);
    set_thread_flag (TIF_MCE_NOTIFY);
    if (worst > 0)
        mce_report_event (regs);
    mce_wrmsrl (MSR_IA32_MCG_STATUS, 0);
out :
    atomic_dec (&mce_entry);
    sync_core ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="967" endline="1038">
{
    __clear_bit (i, toclear);
    if (!mce_banks[i].ctl)
        continue;
    m.misc = 0;
    m.addr = 0;
    m.bank = i;
    m.status = mce_rdmsrl (MSR_IA32_MCx_STATUS (i));
    if ((m.status & MCI_STATUS_VAL) == 0)
        continue;
    if (!(m.status & (mce_ser ? MCI_STATUS_S : MCI_STATUS_UC)) && !no_way_out)
        continue;
    add_taint (TAINT_MACHINE_CHECK);
    severity = mce_severity (&m, tolerant, NULL);
    if (severity == MCE_KEEP_SEVERITY && !no_way_out)
        continue;
    __set_bit (i, toclear);
    if (severity == MCE_NO_SEVERITY) {
        continue;
    }
    if (severity == MCE_AR_SEVERITY)
        kill_it = 1;
    if (m.status & MCI_STATUS_MISCV)
        m.misc = mce_rdmsrl (MSR_IA32_MCx_MISC (i));
    if (m.status & MCI_STATUS_ADDRV)
        m.addr = mce_rdmsrl (MSR_IA32_MCx_ADDR (i));
    if (severity == MCE_AO_SEVERITY && mce_usable_address (&m))
        mce_ring_add (m.addr >> PAGE_SHIFT);
    mce_get_rip (& m, regs);
    mce_log (& m);
    if (severity > worst) {
        *final = m;
        worst = severity;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1002" endline="1008">
{
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1034" endline="1037">
{
    *final = m;
    worst = severity;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1084" endline="1086">
{
    printk (KERN_ERR "Action optional memory failure at %lx ignored\n", pfn);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1100" endline="1105">
{
    unsigned long pfn;
    mce_notify_irq ();
    while (mce_ring_get (&pfn))
        memory_failure (pfn, MCE_VECTOR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1108" endline="1110">
{
    mce_notify_process ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1148" endline="1171">
{
    struct timer_list *t = &per_cpu (mce_timer, data);
    int *n;
    WARN_ON (smp_processor_id () != data);
    if (mce_available (&current_cpu_data)) {
        machine_check_poll (MCP_TIMESTAMP, & __get_cpu_var (mce_poll_banks));
    }
    n = &__get_cpu_var (mce_next_interval);
    if (mce_notify_irq ())
        *n = max (*n / 2, HZ / 100);
    else
        *n = min (*n * 2, (int) round_jiffies_relative (check_interval *HZ));
    t->expires = jiffies + *n;
    add_timer_on (t, smp_processor_id ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1154" endline="1157">
{
    machine_check_poll (MCP_TIMESTAMP, & __get_cpu_var (mce_poll_banks));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1174" endline="1176">
{
    call_usermodehelper (mce_helper, mce_helper_argv, NULL, UMH_NO_WAIT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1186" endline="1209">
{
    static DEFINE_RATELIMIT_STATE (ratelimit, 60 * HZ, 2);
    clear_thread_flag (TIF_MCE_NOTIFY);
    if (test_and_clear_bit (0, &mce_need_notify)) {
        wake_up_interruptible (& mce_wait);
        if (mce_helper[0] && !work_pending (&mce_trigger_work))
            schedule_work (&mce_trigger_work);
        if (__ratelimit (&ratelimit))
            printk (KERN_INFO "Machine check events logged\n");
        return 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1192" endline="1207">
{
    wake_up_interruptible (& mce_wait);
    if (mce_helper[0] && !work_pending (&mce_trigger_work))
        schedule_work (&mce_trigger_work);
    if (__ratelimit (&ratelimit))
        printk (KERN_INFO "Machine check events logged\n");
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1213" endline="1226">
{
    int i;
    mce_banks = kzalloc (banks * sizeof (struct mce_bank), GFP_KERNEL);
    if (!mce_banks)
        return -ENOMEM;
    for (i = 0; i < banks; i++) {
        struct mce_bank *b = &mce_banks[i];
        b->ctl = -1ULL;
        b->init = 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1219" endline="1224">
{
    struct mce_bank *b = &mce_banks[i];
    b->ctl = -1ULL;
    b->init = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1232" endline="1267">
{
    unsigned b;
    u64 cap;
    rdmsrl (MSR_IA32_MCG_CAP, cap);
    b = cap & MCG_BANKCNT_MASK;
    if (!banks)
        printk (KERN_INFO "mce: CPU supports %d MCE banks\n", b);
    if (b > MAX_NR_BANKS) {
        printk (KERN_WARNING "MCE: Using only %u machine check banks out of %u\n", MAX_NR_BANKS, b);
        b = MAX_NR_BANKS;
    }
    WARN_ON (banks != 0 && b != banks);
    banks = b;
    if (!mce_banks) {
        int err = __mcheck_cpu_mce_banks_init ();
        if (err)
            return err;
    }
    if ((cap & MCG_EXT_P) && MCG_EXT_CNT (cap) >= 9)
        rip_msr = MSR_IA32_MCG_EIP;
    if (cap & MCG_SER_P)
        mce_ser = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1242" endline="1247">
{
    printk (KERN_WARNING "MCE: Using only %u machine check banks out of %u\n", MAX_NR_BANKS, b);
    b = MAX_NR_BANKS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1252" endline="1257">
{
    int err = __mcheck_cpu_mce_banks_init ();
    if (err)
        return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1270" endline="1295">
{
    mce_banks_t all_banks;
    u64 cap;
    int i;
    bitmap_fill (all_banks, MAX_NR_BANKS);
    machine_check_poll (MCP_UC | (! mce_bootlog ? MCP_DONTLOG : 0), & all_banks);
    set_in_cr4 (X86_CR4_MCE);
    rdmsrl (MSR_IA32_MCG_CAP, cap);
    if (cap & MCG_CTL_P)
        wrmsr (MSR_IA32_MCG_CTL, 0xffffffff, 0xffffffff);
    for (i = 0; i < banks; i++) {
        struct mce_bank *b = &mce_banks[i];
        if (!b->init)
            continue;
        wrmsrl (MSR_IA32_MCx_CTL (i), b -> ctl);
        wrmsrl (MSR_IA32_MCx_STATUS (i), 0);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1287" endline="1294">
{
    struct mce_bank *b = &mce_banks[i];
    if (!b->init)
        continue;
    wrmsrl (MSR_IA32_MCx_CTL (i), b -> ctl);
    wrmsrl (MSR_IA32_MCx_STATUS (i), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1299" endline="1364">
{
    if (c->x86_vendor == X86_VENDOR_UNKNOWN) {
        pr_info ("MCE: unknown CPU type - not enabling MCE support.\n");
        return -EOPNOTSUPP;
    }
    if (c->x86_vendor == X86_VENDOR_AMD) {
        if (c->x86 == 15 && banks > 4) {
            clear_bit (10, (unsigned long *) & mce_banks [4].ctl);
        }
        if (c->x86 <= 17 && mce_bootlog < 0) {
            mce_bootlog = 0;
        }
        if (c->x86 == 6 && banks > 0)
            mce_banks[0].ctl = 0;
    }
    if (c->x86_vendor == X86_VENDOR_INTEL) {
        if (c->x86 == 6 && c->x86_model < 0x1A && banks > 0)
            mce_banks[0].init = 0;
        if ((c->x86 > 6 || (c->x86 == 6 && c->x86_model >= 0xe)) && monarch_timeout < 0)
            monarch_timeout = USEC_PER_SEC;
        if (c->x86 == 6 && c->x86_model <= 13 && mce_bootlog < 0)
            mce_bootlog = 0;
    }
    if (monarch_timeout < 0)
        monarch_timeout = 0;
    if (mce_bootlog != 0)
        mce_panic_timeout = 30;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1300" endline="1303">
{
    pr_info ("MCE: unknown CPU type - not enabling MCE support.\n");
    return -EOPNOTSUPP;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1306" endline="1328">
{
    if (c->x86 == 15 && banks > 4) {
        clear_bit (10, (unsigned long *) & mce_banks [4].ctl);
    }
    if (c->x86 <= 17 && mce_bootlog < 0) {
        mce_bootlog = 0;
    }
    if (c->x86 == 6 && banks > 0)
        mce_banks[0].ctl = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1307" endline="1314">
{
    clear_bit (10, (unsigned long *) & mce_banks [4].ctl);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1315" endline="1321">
{
    mce_bootlog = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1330" endline="1357">
{
    if (c->x86 == 6 && c->x86_model < 0x1A && banks > 0)
        mce_banks[0].init = 0;
    if ((c->x86 > 6 || (c->x86 == 6 && c->x86_model >= 0xe)) && monarch_timeout < 0)
        monarch_timeout = USEC_PER_SEC;
    if (c->x86 == 6 && c->x86_model <= 13 && mce_bootlog < 0)
        mce_bootlog = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1367" endline="1378">
{
    if (c->x86 != 5)
        return;
    switch (c->x86_vendor) {
    case X86_VENDOR_INTEL :
        intel_p5_mcheck_init (c);
        break;
    case X86_VENDOR_CENTAUR :
        winchip_mcheck_init (c);
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1370" endline="1377">
{
case X86_VENDOR_INTEL :
    intel_p5_mcheck_init (c);
    break;
case X86_VENDOR_CENTAUR :
    winchip_mcheck_init (c);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1381" endline="1392">
{
    switch (c->x86_vendor) {
    case X86_VENDOR_INTEL :
        mce_intel_feature_init (c);
        break;
    case X86_VENDOR_AMD :
        mce_amd_feature_init (c);
        break;
    default :
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1382" endline="1391">
{
case X86_VENDOR_INTEL :
    mce_intel_feature_init (c);
    break;
case X86_VENDOR_AMD :
    mce_amd_feature_init (c);
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1395" endline="1409">
{
    struct timer_list *t = &__get_cpu_var (mce_timer);
    int *n = &__get_cpu_var (mce_next_interval);
    setup_timer (t, mce_start_timer, smp_processor_id ());
    if (mce_ignore_ce)
        return;
    *n = check_interval * HZ;
    if (!*n)
        return;
    t->expires = round_jiffies (jiffies +*n);
    add_timer_on (t, smp_processor_id ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1413" endline="1416">
{
    printk (KERN_ERR "CPU#%d: Unexpected int18 (Machine Check).\n", smp_processor_id ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1427" endline="1448">
{
    if (mce_disabled)
        return;
    __mcheck_cpu_ancient_init (c);
    if (!mce_available (c))
        return;
    if (__mcheck_cpu_cap_init () < 0 || __mcheck_cpu_apply_quirks (c) < 0) {
        mce_disabled = 1;
        return;
    }
    machine_check_vector = do_machine_check;
    __mcheck_cpu_init_generic ();
    __mcheck_cpu_init_vendor (c);
    __mcheck_cpu_init_timer ();
    INIT_WORK (& __get_cpu_var (mce_work), mce_process_work);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1436" endline="1439">
{
    mce_disabled = 1;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1459" endline="1475">
{
    spin_lock (& mce_state_lock);
    if (open_exclu || (open_count && (file->f_flags & O_EXCL))) {
        spin_unlock (& mce_state_lock);
        return -EBUSY;
    }
    if (file->f_flags & O_EXCL)
        open_exclu = 1;
    open_count++;
    spin_unlock (& mce_state_lock);
    return nonseekable_open (inode, file);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1462" endline="1466">
{
    spin_unlock (& mce_state_lock);
    return -EBUSY;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1478" endline="1487">
{
    spin_lock (& mce_state_lock);
    open_count--;
    open_exclu = 0;
    spin_unlock (& mce_state_lock);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1490" endline="1494">
{
    unsigned long *cpu_tsc = (unsigned long *) data;
    rdtscll (cpu_tsc [smp_processor_id ()]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1498" endline="1569">
{
    char __user *buf = ubuf;
    unsigned long *cpu_tsc;
    unsigned prev, next;
    int i, err;
    cpu_tsc = kmalloc (nr_cpu_ids * sizeof (long), GFP_KERNEL);
    if (!cpu_tsc)
        return -ENOMEM;
    mutex_lock (& mce_read_mutex);
    next = rcu_dereference_check_mce (mcelog.next);
    if (*off != 0 || usize < MCE_LOG_LEN * sizeof (struct mce)) {
        mutex_unlock (& mce_read_mutex);
        kfree (cpu_tsc);
        return -EINVAL;
    }
    err = 0;
    prev = 0;
    do {
        for (i = prev; i < next; i++) {
            unsigned long start = jiffies;
            while (!mcelog.entry[i].finished) {
                if (time_after_eq (jiffies, start +2)) {
                    memset (mcelog.entry + i, 0, sizeof (struct mce));
                    goto timeout;
                }
                cpu_relax ();
            }
            smp_rmb ();
            err |= copy_to_user (buf, mcelog.entry + i, sizeof (struct mce));
            buf += sizeof (struct mce);
        timeout :
            ;
        }
        memset (mcelog.entry + prev, 0, (next - prev) * sizeof (struct mce));
        prev = next;
        next = cmpxchg (&mcelog.next, prev, 0);
    }
    while (next != prev);
    synchronize_sched ();
    on_each_cpu (collect_tscs, cpu_tsc, 1);
    for (i = next; i < MCE_LOG_LEN; i++) {
        if (mcelog.entry[i].finished && mcelog.entry[i].tsc < cpu_tsc[mcelog.entry[i].cpu]) {
            err |= copy_to_user (buf, mcelog.entry + i, sizeof (struct mce));
            smp_rmb ();
            buf += sizeof (struct mce);
            memset (& mcelog.entry [i], 0, sizeof (struct mce));
        }
    }
    mutex_unlock (& mce_read_mutex);
    kfree (cpu_tsc);
    return err ? -EFAULT : buf - ubuf;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1512" endline="1517">
{
    mutex_unlock (& mce_read_mutex);
    kfree (cpu_tsc);
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1521" endline="1545">
{
    for (i = prev; i < next; i++) {
        unsigned long start = jiffies;
        while (!mcelog.entry[i].finished) {
            if (time_after_eq (jiffies, start +2)) {
                memset (mcelog.entry + i, 0, sizeof (struct mce));
                goto timeout;
            }
            cpu_relax ();
        }
        smp_rmb ();
        err |= copy_to_user (buf, mcelog.entry + i, sizeof (struct mce));
        buf += sizeof (struct mce);
    timeout :
        ;
    }
    memset (mcelog.entry + prev, 0, (next - prev) * sizeof (struct mce));
    prev = next;
    next = cmpxchg (&mcelog.next, prev, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1522" endline="1539">
{
    unsigned long start = jiffies;
    while (!mcelog.entry[i].finished) {
        if (time_after_eq (jiffies, start +2)) {
            memset (mcelog.entry + i, 0, sizeof (struct mce));
            goto timeout;
        }
        cpu_relax ();
    }
    smp_rmb ();
    err |= copy_to_user (buf, mcelog.entry + i, sizeof (struct mce));
    buf += sizeof (struct mce);
timeout :
    ;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1525" endline="1532">
{
    if (time_after_eq (jiffies, start +2)) {
        memset (mcelog.entry + i, 0, sizeof (struct mce));
        goto timeout;
    }
    cpu_relax ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1526" endline="1530">
{
    memset (mcelog.entry + i, 0, sizeof (struct mce));
    goto timeout;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1555" endline="1564">
{
    if (mcelog.entry[i].finished && mcelog.entry[i].tsc < cpu_tsc[mcelog.entry[i].cpu]) {
        err |= copy_to_user (buf, mcelog.entry + i, sizeof (struct mce));
        smp_rmb ();
        buf += sizeof (struct mce);
        memset (& mcelog.entry [i], 0, sizeof (struct mce));
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1557" endline="1563">
{
    err |= copy_to_user (buf, mcelog.entry + i, sizeof (struct mce));
    smp_rmb ();
    buf += sizeof (struct mce);
    memset (& mcelog.entry [i], 0, sizeof (struct mce));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1572" endline="1577">
{
    poll_wait (file, & mce_wait, wait);
    if (rcu_dereference_check_mce (mcelog.next))
        return POLLIN | POLLRDNORM;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1580" endline="1603">
{
    int __user *p = (int __user *) arg;
    if (!capable (CAP_SYS_ADMIN))
        return -EPERM;
    switch (cmd) {
    case MCE_GET_RECORD_LEN :
        return put_user (sizeof (struct mce), p);
    case MCE_GET_LOG_LEN :
        return put_user (MCE_LOG_LEN, p);
    case MCE_GETCLEAR_FLAGS :
        {
            unsigned flags;
            do {
                flags = mcelog.flags;
            }
            while (cmpxchg (&mcelog.flags, flags, 0) != flags);
            return put_user (flags, p);
        }
    default :
        return -ENOTTY;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1586" endline="1602">
{
case MCE_GET_RECORD_LEN :
    return put_user (sizeof (struct mce), p);
case MCE_GET_LOG_LEN :
    return put_user (MCE_LOG_LEN, p);
case MCE_GETCLEAR_FLAGS :
    {
        unsigned flags;
        do {
            flags = mcelog.flags;
        }
        while (cmpxchg (&mcelog.flags, flags, 0) != flags);
        return put_user (flags, p);
    }
default :
    return -ENOTTY;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1591" endline="1599">
{
    unsigned flags;
    do {
        flags = mcelog.flags;
    }
    while (cmpxchg (&mcelog.flags, flags, 0) != flags);
    return put_user (flags, p);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1594" endline="1596">
{
    flags = mcelog.flags;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1633" endline="1662">
{
    if (*str == 0) {
        enable_p5_mce ();
        return 1;
    }
    if (*str == '=')
        str++;
    if (!strcmp (str, "off"))
        mce_disabled = 1;
    else if (!strcmp (str, "no_cmci"))
        mce_cmci_disabled = 1;
    else if (!strcmp (str, "dont_log_ce"))
        mce_dont_log_ce = 1;
    else if (!strcmp (str, "ignore_ce"))
        mce_ignore_ce = 1;
    else if (!strcmp (str, "bootlog") || !strcmp (str, "nobootlog"))
        mce_bootlog = (str[0] == 'b');
    else if (isdigit (str[0])) {
        get_option (& str, & tolerant);
        if (*str == ',') {
            ++str;
            get_option (& str, & monarch_timeout);
        }
    }
    else {
        printk (KERN_INFO "mce argument %s ignored. Please use /sys\n", str);
        return 0;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1634" endline="1637">
{
    enable_p5_mce ();
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1650" endline="1656">
{
    get_option (& str, & tolerant);
    if (*str == ',') {
        ++str;
        get_option (& str, & monarch_timeout);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1652" endline="1655">
{
    ++str;
    get_option (& str, & monarch_timeout);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1656" endline="1660">
{
    printk (KERN_INFO "mce argument %s ignored. Please use /sys\n", str);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1666" endline="1672">
{
    atomic_notifier_chain_register (& x86_mce_decoder_chain, & mce_dec_nb);
    mcheck_intel_therm_init ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1683" endline="1693">
{
    int i;
    for (i = 0; i < banks; i++) {
        struct mce_bank *b = &mce_banks[i];
        if (b->init)
            wrmsrl (MSR_IA32_MCx_CTL (i), 0);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1686" endline="1691">
{
    struct mce_bank *b = &mce_banks[i];
    if (b->init)
        wrmsrl (MSR_IA32_MCx_CTL (i), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1696" endline="1698">
{
    return mce_disable_error_reporting ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1701" endline="1703">
{
    return mce_disable_error_reporting ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1711" endline="1716">
{
    __mcheck_cpu_init_generic ();
    __mcheck_cpu_init_vendor (& current_cpu_data);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1719" endline="1725">
{
    del_timer_sync (& __get_cpu_var (mce_timer));
    if (!mce_available (&current_cpu_data))
        return;
    __mcheck_cpu_init_generic ();
    __mcheck_cpu_init_timer ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1729" endline="1731">
{
    on_each_cpu (mce_cpu_restart, NULL, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1735" endline="1741">
{
    if (!mce_available (&current_cpu_data))
        return;
    if (all)
        del_timer_sync (&__get_cpu_var (mce_timer));
    cmci_clear ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1744" endline="1751">
{
    if (!mce_available (&current_cpu_data))
        return;
    cmci_reenable ();
    cmci_recheck ();
    if (all)
        __mcheck_cpu_init_timer ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1766" endline="1768">
{
    return container_of (attr, struct mce_bank, attr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1772" endline="1774">
{
    return sprintf (buf, "%llx\n", attr_to_bank (attr)->ctl);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1778" endline="1788">
{
    u64 new;
    if (strict_strtoull (buf, 0, &new) < 0)
        return -EINVAL;
    attr_to_bank (attr)->ctl = new;
    mce_restart ();
    return size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1792" endline="1796">
{
    strcpy (buf, mce_helper);
    strcat (buf, "\n");
    return strlen (mce_helper) + 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1800" endline="1811">
{
    char *p;
    strncpy (mce_helper, buf, sizeof (mce_helper));
    mce_helper[sizeof (mce_helper) - 1] = 0;
    p = strchr (mce_helper, '\n');
    if (p)
        *p = 0;
    return strlen (mce_helper) + !!p;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1816" endline="1834">
{
    u64 new;
    if (strict_strtoull (buf, 0, &new) < 0)
        return -EINVAL;
    if (mce_ignore_ce ^ !!new) {
        if (new) {
            on_each_cpu (mce_disable_ce, (void *) 1, 1);
            mce_ignore_ce = 1;
        }
        else {
            mce_ignore_ce = 0;
            on_each_cpu (mce_enable_ce, (void *) 1, 1);
        }
    }
    return size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1822" endline="1832">
{
    if (new) {
        on_each_cpu (mce_disable_ce, (void *) 1, 1);
        mce_ignore_ce = 1;
    }
    else {
        mce_ignore_ce = 0;
        on_each_cpu (mce_enable_ce, (void *) 1, 1);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1823" endline="1827">
{
    on_each_cpu (mce_disable_ce, (void *) 1, 1);
    mce_ignore_ce = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1827" endline="1831">
{
    mce_ignore_ce = 0;
    on_each_cpu (mce_enable_ce, (void *) 1, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1839" endline="1857">
{
    u64 new;
    if (strict_strtoull (buf, 0, &new) < 0)
        return -EINVAL;
    if (mce_cmci_disabled ^ !!new) {
        if (new) {
            on_each_cpu (mce_disable_ce, NULL, 1);
            mce_cmci_disabled = 1;
        }
        else {
            mce_cmci_disabled = 0;
            on_each_cpu (mce_enable_ce, NULL, 1);
        }
    }
    return size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1845" endline="1855">
{
    if (new) {
        on_each_cpu (mce_disable_ce, NULL, 1);
        mce_cmci_disabled = 1;
    }
    else {
        mce_cmci_disabled = 0;
        on_each_cpu (mce_enable_ce, NULL, 1);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1846" endline="1850">
{
    on_each_cpu (mce_disable_ce, NULL, 1);
    mce_cmci_disabled = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1850" endline="1854">
{
    mce_cmci_disabled = 0;
    on_each_cpu (mce_enable_ce, NULL, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1862" endline="1866">
{
    ssize_t ret = sysdev_store_int (s, attr, buf, size);
    mce_restart ();
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1904" endline="1943">
{
    int err;
    int i, j;
    if (!mce_available (&boot_cpu_data))
        return -EIO;
    memset (& per_cpu (mce_dev, cpu).kobj, 0, sizeof (struct kobject));
    per_cpu (mce_dev, cpu).id = cpu;
    per_cpu (mce_dev, cpu).cls = &mce_sysclass;
    err = sysdev_register (&per_cpu (mce_dev, cpu));
    if (err)
        return err;
    for (i = 0; mce_attrs[i]; i++) {
        err = sysdev_create_file (&per_cpu (mce_dev, cpu), mce_attrs[i]);
        if (err)
            goto error;
    }
    for (j = 0; j < banks; j++) {
        err = sysdev_create_file (&per_cpu (mce_dev, cpu), &mce_banks[j].attr);
        if (err)
            goto error2;
    }
    cpumask_set_cpu (cpu, mce_dev_initialized);
    return 0;
error2 :
    while (--j >= 0)
        sysdev_remove_file (&per_cpu (mce_dev, cpu), &mce_banks[j].attr);
error :
    while (--i >= 0)
        sysdev_remove_file (&per_cpu (mce_dev, cpu), mce_attrs[i]);
    sysdev_unregister (& per_cpu (mce_dev, cpu));
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1919" endline="1923">
{
    err = sysdev_create_file (&per_cpu (mce_dev, cpu), mce_attrs[i]);
    if (err)
        goto error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1924" endline="1929">
{
    err = sysdev_create_file (&per_cpu (mce_dev, cpu), &mce_banks[j].attr);
    if (err)
        goto error2;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1946" endline="1960">
{
    int i;
    if (!cpumask_test_cpu (cpu, mce_dev_initialized))
        return;
    for (i = 0; mce_attrs[i]; i++)
        sysdev_remove_file (&per_cpu (mce_dev, cpu), mce_attrs[i]);
    for (i = 0; i < banks; i++)
        sysdev_remove_file (&per_cpu (mce_dev, cpu), &mce_banks[i].attr);
    sysdev_unregister (& per_cpu (mce_dev, cpu));
    cpumask_clear_cpu (cpu, mce_dev_initialized);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1964" endline="1979">
{
    unsigned long action = *(unsignedlong*) h;
    int i;
    if (!mce_available (&current_cpu_data))
        return;
    if (!(action & CPU_TASKS_FROZEN))
        cmci_clear ();
    for (i = 0; i < banks; i++) {
        struct mce_bank *b = &mce_banks[i];
        if (b->init)
            wrmsrl (MSR_IA32_MCx_CTL (i), 0);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1973" endline="1978">
{
    struct mce_bank *b = &mce_banks[i];
    if (b->init)
        wrmsrl (MSR_IA32_MCx_CTL (i), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1982" endline="1997">
{
    unsigned long action = *(unsignedlong*) h;
    int i;
    if (!mce_available (&current_cpu_data))
        return;
    if (!(action & CPU_TASKS_FROZEN))
        cmci_reenable ();
    for (i = 0; i < banks; i++) {
        struct mce_bank *b = &mce_banks[i];
        if (b->init)
            wrmsrl (MSR_IA32_MCx_CTL (i), b->ctl);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="1991" endline="1996">
{
    struct mce_bank *b = &mce_banks[i];
    if (b->init)
        wrmsrl (MSR_IA32_MCx_CTL (i), b->ctl);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="2002" endline="2039">
{
    unsigned int cpu = (unsigned long) hcpu;
    struct timer_list *t = &per_cpu (mce_timer, cpu);
    switch (action) {
    case CPU_ONLINE :
    case CPU_ONLINE_FROZEN :
        mce_create_device (cpu);
        if (threshold_cpu_callback)
            threshold_cpu_callback (action, cpu);
        break;
    case CPU_DEAD :
    case CPU_DEAD_FROZEN :
        if (threshold_cpu_callback)
            threshold_cpu_callback (action, cpu);
        mce_remove_device (cpu);
        break;
    case CPU_DOWN_PREPARE :
    case CPU_DOWN_PREPARE_FROZEN :
        del_timer_sync (t);
        smp_call_function_single (cpu, mce_disable_cpu, & action, 1);
        break;
    case CPU_DOWN_FAILED :
    case CPU_DOWN_FAILED_FROZEN :
        if (!mce_ignore_ce && check_interval) {
            t->expires = round_jiffies (jiffies +__get_cpu_var (mce_next_interval));
            add_timer_on (t, cpu);
        }
        smp_call_function_single (cpu, mce_reenable_cpu, & action, 1);
        break;
    case CPU_POST_DEAD :
        cmci_rediscover (cpu);
        break;
    }
    return NOTIFY_OK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="2006" endline="2037">
{
case CPU_ONLINE :
case CPU_ONLINE_FROZEN :
    mce_create_device (cpu);
    if (threshold_cpu_callback)
        threshold_cpu_callback (action, cpu);
    break;
case CPU_DEAD :
case CPU_DEAD_FROZEN :
    if (threshold_cpu_callback)
        threshold_cpu_callback (action, cpu);
    mce_remove_device (cpu);
    break;
case CPU_DOWN_PREPARE :
case CPU_DOWN_PREPARE_FROZEN :
    del_timer_sync (t);
    smp_call_function_single (cpu, mce_disable_cpu, & action, 1);
    break;
case CPU_DOWN_FAILED :
case CPU_DOWN_FAILED_FROZEN :
    if (!mce_ignore_ce && check_interval) {
        t->expires = round_jiffies (jiffies +__get_cpu_var (mce_next_interval));
        add_timer_on (t, cpu);
    }
    smp_call_function_single (cpu, mce_reenable_cpu, & action, 1);
    break;
case CPU_POST_DEAD :
    cmci_rediscover (cpu);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="2026" endline="2030">
{
    t->expires = round_jiffies (jiffies +__get_cpu_var (mce_next_interval));
    add_timer_on (t, cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="2046" endline="2061">
{
    int i;
    for (i = 0; i < banks; i++) {
        struct mce_bank *b = &mce_banks[i];
        struct sysdev_attribute *a = &b->attr;
        sysfs_attr_init (& a -> attr);
        a->attr.name = b->attrname;
        snprintf (b -> attrname, ATTR_LEN, "bank%d", i);
        a->attr.mode = 0644;
        a->show = show_bank;
        a->store = set_bank;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="2049" endline="2060">
{
    struct mce_bank *b = &mce_banks[i];
    struct sysdev_attribute *a = &b->attr;
    sysfs_attr_init (& a -> attr);
    a->attr.name = b->attrname;
    snprintf (b -> attrname, ATTR_LEN, "bank%d", i);
    a->attr.mode = 0644;
    a->show = show_bank;
    a->store = set_bank;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="2064" endline="2089">
{
    int err;
    int i = 0;
    if (!mce_available (&boot_cpu_data))
        return -EIO;
    zalloc_cpumask_var (& mce_dev_initialized, GFP_KERNEL);
    mce_init_banks ();
    err = sysdev_class_register (&mce_sysclass);
    if (err)
        return err;

    for_each_online_cpu (i) {
        err = mce_create_device (i);
        if (err)
            return err;
    }

    register_hotcpu_notifier (& mce_cpu_notifier);
    misc_register (& mce_log_device);
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="2079" endline="2083">
{
    err = mce_create_device (i);
    if (err)
        return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce.c.ifdefed" startline="2097" endline="2100">
{
    mce_disabled = 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="98" endline="125">
{
    struct thresh_restart *tr = _tr;
    u32 mci_misc_hi, mci_misc_lo;
    rdmsr (tr -> b -> address, mci_misc_lo, mci_misc_hi);
    if (tr->b->threshold_limit < (mci_misc_hi & THRESHOLD_MAX))
        tr->reset = 1;
    if (tr->reset) {
        mci_misc_hi = (mci_misc_hi & ~(MASK_ERR_COUNT_HI | MASK_OVERFLOW_HI)) | (THRESHOLD_MAX - tr->b->threshold_limit);
    }
    else if (tr->old_limit) {
        int new_count = (mci_misc_hi & THRESHOLD_MAX) + (tr->old_limit - tr->b->threshold_limit);
        mci_misc_hi = (mci_misc_hi & ~MASK_ERR_COUNT_HI) | (new_count & THRESHOLD_MAX);
    }
    tr->b->interrupt_enable ? (mci_misc_hi = (mci_misc_hi & ~MASK_INT_TYPE_HI) | INT_TYPE_APIC) : (mci_misc_hi &= ~MASK_INT_TYPE_HI);
    mci_misc_hi |= MASK_COUNT_EN_HI;
    wrmsr (tr -> b -> address, mci_misc_lo, mci_misc_hi);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="107" endline="111">
{
    mci_misc_hi = (mci_misc_hi & ~(MASK_ERR_COUNT_HI | MASK_OVERFLOW_HI)) | (THRESHOLD_MAX - tr->b->threshold_limit);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="111" endline="117">
{
    int new_count = (mci_misc_hi & THRESHOLD_MAX) + (tr->old_limit - tr->b->threshold_limit);
    mci_misc_hi = (mci_misc_hi & ~MASK_ERR_COUNT_HI) | (new_count & THRESHOLD_MAX);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="129" endline="184">
{
    unsigned int cpu = smp_processor_id ();
    u32 low = 0, high = 0, address = 0;
    unsigned int bank, block;
    struct thresh_restart tr;
    u8 lvt_off;
    for (bank = 0; bank < NR_BANKS; ++bank) {
        for (block = 0; block < NR_BLOCKS; ++block) {
            if (block == 0)
                address = MSR_IA32_MC0_MISC + bank * 4;
            else if (block == 1) {
                address = (low & MASK_BLKPTR_LO) >> 21;
                if (!address)
                    break;
                address += MCG_XBLK_ADDR;
            }
            else
                ++address;
            if (rdmsr_safe (address, &low, &high))
                break;
            if (!(high & MASK_VALID_HI)) {
                if (block)
                    continue;
                else
                    break;
            }
            if (!(high & MASK_CNTP_HI) || (high & MASK_LOCKED_HI))
                continue;
            if (!block)
                per_cpu (bank_map, cpu) |= (1 << bank);
            lvt_off = setup_APIC_eilvt_mce (THRESHOLD_APIC_VECTOR, APIC_EILVT_MSG_FIX, 0);
            high &= ~MASK_LVTOFF_HI;
            high |= lvt_off << 20;
            wrmsr (address, low, high);
            threshold_defaults.address = address;
            tr.b = &threshold_defaults;
            tr.reset = 0;
            tr.old_limit = 0;
            threshold_restart_bank (& tr);
            mce_threshold_vector = amd_threshold_interrupt;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="136" endline="183">
{
    for (block = 0; block < NR_BLOCKS; ++block) {
        if (block == 0)
            address = MSR_IA32_MC0_MISC + bank * 4;
        else if (block == 1) {
            address = (low & MASK_BLKPTR_LO) >> 21;
            if (!address)
                break;
            address += MCG_XBLK_ADDR;
        }
        else
            ++address;
        if (rdmsr_safe (address, &low, &high))
            break;
        if (!(high & MASK_VALID_HI)) {
            if (block)
                continue;
            else
                break;
        }
        if (!(high & MASK_CNTP_HI) || (high & MASK_LOCKED_HI))
            continue;
        if (!block)
            per_cpu (bank_map, cpu) |= (1 << bank);
        lvt_off = setup_APIC_eilvt_mce (THRESHOLD_APIC_VECTOR, APIC_EILVT_MSG_FIX, 0);
        high &= ~MASK_LVTOFF_HI;
        high |= lvt_off << 20;
        wrmsr (address, low, high);
        threshold_defaults.address = address;
        tr.b = &threshold_defaults;
        tr.reset = 0;
        tr.old_limit = 0;
        threshold_restart_bank (& tr);
        mce_threshold_vector = amd_threshold_interrupt;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="137" endline="182">
{
    if (block == 0)
        address = MSR_IA32_MC0_MISC + bank * 4;
    else if (block == 1) {
        address = (low & MASK_BLKPTR_LO) >> 21;
        if (!address)
            break;
        address += MCG_XBLK_ADDR;
    }
    else
        ++address;
    if (rdmsr_safe (address, &low, &high))
        break;
    if (!(high & MASK_VALID_HI)) {
        if (block)
            continue;
        else
            break;
    }
    if (!(high & MASK_CNTP_HI) || (high & MASK_LOCKED_HI))
        continue;
    if (!block)
        per_cpu (bank_map, cpu) |= (1 << bank);
    lvt_off = setup_APIC_eilvt_mce (THRESHOLD_APIC_VECTOR, APIC_EILVT_MSG_FIX, 0);
    high &= ~MASK_LVTOFF_HI;
    high |= lvt_off << 20;
    wrmsr (address, low, high);
    threshold_defaults.address = address;
    tr.b = &threshold_defaults;
    tr.reset = 0;
    tr.old_limit = 0;
    threshold_restart_bank (& tr);
    mce_threshold_vector = amd_threshold_interrupt;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="140" endline="145">
{
    address = (low & MASK_BLKPTR_LO) >> 21;
    if (!address)
        break;
    address += MCG_XBLK_ADDR;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="151" endline="156">
{
    if (block)
        continue;
    else
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="196" endline="252">
{
    u32 low = 0, high = 0, address = 0;
    unsigned int bank, block;
    struct mce m;
    mce_setup (& m);
    for (bank = 0; bank < NR_BANKS; ++bank) {
        if (!(per_cpu (bank_map, m.cpu) & (1 << bank)))
            continue;
        for (block = 0; block < NR_BLOCKS; ++block) {
            if (block == 0) {
                address = MSR_IA32_MC0_MISC + bank * 4;
            }
            else if (block == 1) {
                address = (low & MASK_BLKPTR_LO) >> 21;
                if (!address)
                    break;
                address += MCG_XBLK_ADDR;
            }
            else {
                ++address;
            }
            if (rdmsr_safe (address, &low, &high))
                break;
            if (!(high & MASK_VALID_HI)) {
                if (block)
                    continue;
                else
                    break;
            }
            if (!(high & MASK_CNTP_HI) || (high & MASK_LOCKED_HI))
                continue;
            machine_check_poll (MCP_TIMESTAMP, & __get_cpu_var (mce_poll_banks));
            if (high & MASK_OVERFLOW_HI) {
                rdmsrl (address, m.misc);
                rdmsrl (MSR_IA32_MC0_STATUS + bank * 4, m.status);
                m.bank = K8_MCE_THRESHOLD_BASE + bank * NR_BLOCKS + block;
                mce_log (& m);
                return;
            }
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="204" endline="251">
{
    if (!(per_cpu (bank_map, m.cpu) & (1 << bank)))
        continue;
    for (block = 0; block < NR_BLOCKS; ++block) {
        if (block == 0) {
            address = MSR_IA32_MC0_MISC + bank * 4;
        }
        else if (block == 1) {
            address = (low & MASK_BLKPTR_LO) >> 21;
            if (!address)
                break;
            address += MCG_XBLK_ADDR;
        }
        else {
            ++address;
        }
        if (rdmsr_safe (address, &low, &high))
            break;
        if (!(high & MASK_VALID_HI)) {
            if (block)
                continue;
            else
                break;
        }
        if (!(high & MASK_CNTP_HI) || (high & MASK_LOCKED_HI))
            continue;
        machine_check_poll (MCP_TIMESTAMP, & __get_cpu_var (mce_poll_banks));
        if (high & MASK_OVERFLOW_HI) {
            rdmsrl (address, m.misc);
            rdmsrl (MSR_IA32_MC0_STATUS + bank * 4, m.status);
            m.bank = K8_MCE_THRESHOLD_BASE + bank * NR_BLOCKS + block;
            mce_log (& m);
            return;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="207" endline="250">
{
    if (block == 0) {
        address = MSR_IA32_MC0_MISC + bank * 4;
    }
    else if (block == 1) {
        address = (low & MASK_BLKPTR_LO) >> 21;
        if (!address)
            break;
        address += MCG_XBLK_ADDR;
    }
    else {
        ++address;
    }
    if (rdmsr_safe (address, &low, &high))
        break;
    if (!(high & MASK_VALID_HI)) {
        if (block)
            continue;
        else
            break;
    }
    if (!(high & MASK_CNTP_HI) || (high & MASK_LOCKED_HI))
        continue;
    machine_check_poll (MCP_TIMESTAMP, & __get_cpu_var (mce_poll_banks));
    if (high & MASK_OVERFLOW_HI) {
        rdmsrl (address, m.misc);
        rdmsrl (MSR_IA32_MC0_STATUS + bank * 4, m.status);
        m.bank = K8_MCE_THRESHOLD_BASE + bank * NR_BLOCKS + block;
        mce_log (& m);
        return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="208" endline="210">
{
    address = MSR_IA32_MC0_MISC + bank * 4;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="210" endline="215">
{
    address = (low & MASK_BLKPTR_LO) >> 21;
    if (!address)
        break;
    address += MCG_XBLK_ADDR;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="215" endline="217">
{
    ++address;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="222" endline="227">
{
    if (block)
        continue;
    else
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="240" endline="249">
{
    rdmsrl (address, m.misc);
    rdmsrl (MSR_IA32_MC0_STATUS + bank * 4, m.status);
    m.bank = K8_MCE_THRESHOLD_BASE + bank * NR_BLOCKS + block;
    mce_log (& m);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="274" endline="290">
{
    struct thresh_restart tr;
    unsigned long new;
    if (strict_strtoul (buf, 0, &new) < 0)
        return -EINVAL;
    b->interrupt_enable = !!new;
    tr.b = b;
    tr.reset = 0;
    tr.old_limit = 0;
    smp_call_function_single (b -> cpu, threshold_restart_bank, & tr, 1);
    return size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="294" endline="314">
{
    struct thresh_restart tr;
    unsigned long new;
    if (strict_strtoul (buf, 0, &new) < 0)
        return -EINVAL;
    if (new > THRESHOLD_MAX)
        new = THRESHOLD_MAX;
    if (new < 1)
        new = 1;
    tr.old_limit = b->threshold_limit;
    b->threshold_limit = new;
    tr.b = b;
    tr.reset = 0;
    smp_call_function_single (b -> cpu, threshold_restart_bank, & tr, 1);
    return size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="322" endline="329">
{
    struct threshold_block_cross_cpu *tbcc = _tbcc;
    struct threshold_block *b = tbcc->tb;
    u32 low, high;
    rdmsr (b -> address, low, high);
    tbcc->retval = (high & 0xFFF) - (THRESHOLD_MAX - b->threshold_limit);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="332" endline="337">
{
    struct threshold_block_cross_cpu tbcc = {
        .tb = b,
    };
    smp_call_function_single (b -> cpu, local_error_count_handler, & tbcc, 1);
    return sprintf (buf, "%lx\n", tbcc.retval);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="341" endline="346">
{
    struct thresh_restart tr = {
        .b = b,
        .reset = 1,
        .old_limit = 0
    };
    smp_call_function_single (b -> cpu, threshold_restart_bank, & tr, 1);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="370" endline="378">
{
    struct threshold_block *b = to_block (kobj);
    struct threshold_attr *a = to_attr (attr);
    ssize_t ret;
    ret = a->show ? a->show (b, buf) : -EIO;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="382" endline="390">
{
    struct threshold_block *b = to_block (kobj);
    struct threshold_attr *a = to_attr (attr);
    ssize_t ret;
    ret = a->store ? a->store (b, buf, count) : -EIO;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="406" endline="478">
{
    struct threshold_block *b = NULL;
    u32 low, high;
    int err;
    if ((bank >= NR_BANKS) || (block >= NR_BLOCKS))
        return 0;
    if (rdmsr_safe_on_cpu (cpu, address, &low, &high))
        return 0;
    if (!(high & MASK_VALID_HI)) {
        if (block)
            goto recurse;
        else
            return 0;
    }
    if (!(high & MASK_CNTP_HI) || (high & MASK_LOCKED_HI))
        goto recurse;
    b = kzalloc (sizeof (struct threshold_block), GFP_KERNEL);
    if (!b)
        return -ENOMEM;
    b->block = block;
    b->bank = bank;
    b->cpu = cpu;
    b->address = address;
    b->interrupt_enable = 0;
    b->threshold_limit = THRESHOLD_MAX;
    INIT_LIST_HEAD (& b -> miscj);
    if (per_cpu (threshold_banks, cpu)[bank]->blocks) {
        list_add (& b -> miscj, & per_cpu (threshold_banks, cpu) [bank] -> blocks -> miscj);
    }
    else {
        per_cpu (threshold_banks, cpu)[bank]->blocks = b;
    }
    err = kobject_init_and_add (&b->kobj, &threshold_ktype, per_cpu (threshold_banks, cpu)[bank]->kobj, "misc%i", block);
    if (err)
        goto out_free;
recurse :
    if (!block) {
        address = (low & MASK_BLKPTR_LO) >> 21;
        if (!address)
            return 0;
        address += MCG_XBLK_ADDR;
    }
    else {
        ++address;
    }
    err = allocate_threshold_blocks (cpu, bank, ++block, address);
    if (err)
        goto out_free;
    if (b)
        kobject_uevent (&b->kobj, KOBJ_ADD);
    return err;
out_free :
    if (b) {
        kobject_put (& b -> kobj);
        kfree (b);
    }
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="417" endline="422">
{
    if (block)
        goto recurse;
    else
        return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="441" endline="444">
{
    list_add (& b -> miscj, & per_cpu (threshold_banks, cpu) [bank] -> blocks -> miscj);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="444" endline="446">
{
    per_cpu (threshold_banks, cpu)[bank]->blocks = b;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="454" endline="459">
{
    address = (low & MASK_BLKPTR_LO) >> 21;
    if (!address)
        return 0;
    address += MCG_XBLK_ADDR;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="459" endline="461">
{
    ++address;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="473" endline="476">
{
    kobject_put (& b -> kobj);
    kfree (b);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="482" endline="485">
{
    return allocate_threshold_blocks (cpu, bank, 0, MSR_IA32_MC0_MISC +bank * 4);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="489" endline="575">
{
    int i, err = 0;
    struct threshold_bank *b = NULL;
    char name [32];
    sprintf (name, "threshold_bank%i", bank);
    b = kzalloc (sizeof (struct threshold_bank), GFP_KERNEL);
    if (!b) {
        err = -ENOMEM;
        goto out;
    }
    if (!alloc_cpumask_var (&b->cpus, GFP_KERNEL)) {
        kfree (b);
        err = -ENOMEM;
        goto out;
    }
    b->kobj = kobject_create_and_add (name, &per_cpu (mce_dev, cpu).kobj);
    if (!b->kobj)
        goto out_free;
    cpumask_setall (b -> cpus);
    per_cpu (threshold_banks, cpu)[bank] = b;
    err = local_allocate_threshold_blocks (cpu, bank);
    if (err)
        goto out_free;
    for_each_cpu (i, b -> cpus)
    {
        if (i == cpu)
            continue;
        err = sysfs_create_link (&per_cpu (mce_dev, i).kobj, b->kobj, name);
        if (err)
            goto out;
        per_cpu (threshold_banks, i)[bank] = b;
    }
    goto out;
out_free :
    per_cpu (threshold_banks, cpu)[bank] = NULL;
    free_cpumask_var (b -> cpus);
    kfree (b);
out :
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="529" endline="532">
{
    err = -ENOMEM;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="533" endline="537">
{
    kfree (b);
    err = -ENOMEM;
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="555" endline="565">
{
    if (i == cpu)
        continue;
    err = sysfs_create_link (&per_cpu (mce_dev, i).kobj, b->kobj, name);
    if (err)
        goto out;
    per_cpu (threshold_banks, i)[bank] = b;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="579" endline="592">
{
    unsigned int bank;
    int err = 0;
    for (bank = 0; bank < NR_BANKS; ++bank) {
        if (!(per_cpu (bank_map, cpu) & (1 << bank)))
            continue;
        err = threshold_create_bank (cpu, bank);
        if (err)
            goto out;
    }
out :
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="583" endline="589">
{
    if (!(per_cpu (bank_map, cpu) & (1 << bank)))
        continue;
    err = threshold_create_bank (cpu, bank);
    if (err)
        goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="602" endline="618">
{
    struct threshold_block *pos = NULL;
    struct threshold_block *tmp = NULL;
    struct threshold_bank *head = per_cpu (threshold_banks, cpu)[bank];
    if (!head)
        return;
    list_for_each_entry_safe (pos, tmp, &head->blocks->miscj, miscj) {
        kobject_put (& pos -> kobj);
        list_del (& pos -> miscj);
        kfree (pos);
    }
    kfree (per_cpu (threshold_banks, cpu) [bank] -> blocks);
    per_cpu (threshold_banks, cpu)[bank]->blocks = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="610" endline="614">
{
    kobject_put (& pos -> kobj);
    list_del (& pos -> miscj);
    kfree (pos);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="621" endline="661">
{
    struct threshold_bank *b;
    char name [32];
    int i = 0;
    b = per_cpu (threshold_banks, cpu)[bank];
    if (!b)
        return;
    if (!b->blocks)
        goto free_out;
    sprintf (name, "threshold_bank%i", bank);
    for_each_cpu (i, b -> cpus)
    {
        if (i == cpu)
            continue;
        sysfs_remove_link (& per_cpu (mce_dev, i).kobj, name);
        per_cpu (threshold_banks, i)[bank] = NULL;
    }
    deallocate_threshold_block (cpu, bank);
free_out :
    kobject_del (b->kobj);
    kobject_put (b -> kobj);
    free_cpumask_var (b -> cpus);
    kfree (b);
    per_cpu (threshold_banks, cpu)[bank] = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="645" endline="651">
{
    if (i == cpu)
        continue;
    sysfs_remove_link (& per_cpu (mce_dev, i).kobj, name);
    per_cpu (threshold_banks, i)[bank] = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="664" endline="672">
{
    unsigned int bank;
    for (bank = 0; bank < NR_BANKS; ++bank) {
        if (!(per_cpu (bank_map, cpu) & (1 << bank)))
            continue;
        threshold_remove_bank (cpu, bank);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="667" endline="671">
{
    if (!(per_cpu (bank_map, cpu) & (1 << bank)))
        continue;
    threshold_remove_bank (cpu, bank);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="677" endline="690">
{
    switch (action) {
    case CPU_ONLINE :
    case CPU_ONLINE_FROZEN :
        threshold_create_device (cpu);
        break;
    case CPU_DEAD :
    case CPU_DEAD_FROZEN :
        threshold_remove_device (cpu);
        break;
    default :
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="678" endline="689">
{
case CPU_ONLINE :
case CPU_ONLINE_FROZEN :
    threshold_create_device (cpu);
    break;
case CPU_DEAD :
case CPU_DEAD_FROZEN :
    threshold_remove_device (cpu);
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="693" endline="706">
{
    unsigned lcpu = 0;

    for_each_online_cpu (lcpu) {
        int err = threshold_create_device (lcpu);
        if (err)
            return err;
    }

    threshold_cpu_callback = amd_64_threshold_cpu_callback;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_amd.c.ifdefed" startline="697" endline="702">
{
    int err = threshold_create_device (lcpu);
    if (err)
        return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/threshold.c.ifdefed" startline="13" endline="16">
{
    printk (KERN_ERR "Unexpected threshold interrupt at vector %x\n", THRESHOLD_APIC_VECTOR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/threshold.c.ifdefed" startline="21" endline="29">
{
    exit_idle ();
    irq_enter ();
    inc_irq_stat (irq_threshold_count);
    mce_threshold_vector ();
    irq_exit ();
    ack_APIC_irq ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="110" endline="146">
{
    struct thermal_state *state;
    unsigned int this_cpu;
    bool was_throttled;
    u64 now;
    this_cpu = smp_processor_id ();
    now = get_jiffies_64 ();
    state = &per_cpu (thermal_state, this_cpu);
    was_throttled = state->is_throttled;
    state->is_throttled = is_throttled;
    if (is_throttled)
        state->throttle_count++;
    if (time_before64 (now, state->next_check) && state->throttle_count != state->last_throttle_count)
        return 0;
    state->next_check = now + CHECK_INTERVAL;
    state->last_throttle_count = state->throttle_count;
    if (is_throttled) {
        printk (KERN_CRIT "CPU%d: Temperature above threshold, cpu clock throttled (total events = %lu)\n", this_cpu, state -> throttle_count);
        add_taint (TAINT_MACHINE_CHECK);
        return 1;
    }
    if (was_throttled) {
        printk (KERN_INFO "CPU%d: Temperature/speed normal\n", this_cpu);
        return 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="134" endline="139">
{
    printk (KERN_CRIT "CPU%d: Temperature above threshold, cpu clock throttled (total events = %lu)\n", this_cpu, state -> throttle_count);
    add_taint (TAINT_MACHINE_CHECK);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="140" endline="143">
{
    printk (KERN_INFO "CPU%d: Temperature/speed normal\n", this_cpu);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="231" endline="237">
{
    __u64 msr_val;
    rdmsrl (MSR_IA32_THERM_STATUS, msr_val);
    if (therm_throt_process ((msr_val & THERM_STATUS_PROCHOT) != 0))
        mce_log_therm_throt_event (msr_val);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="240" endline="244">
{
    printk (KERN_ERR "CPU%d: Unexpected LVT TMR interrupt!\n", smp_processor_id ());
    add_taint (TAINT_MACHINE_CHECK);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="249" endline="257">
{
    exit_idle ();
    irq_enter ();
    inc_irq_stat (irq_thermal_count);
    smp_thermal_vector ();
    irq_exit ();
    ack_APIC_irq ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="261" endline="267">
{
    if (!cpu_has_apic)
        return 0;
    if (!cpu_has (c, X86_FEATURE_ACPI) || !cpu_has (c, X86_FEATURE_ACC))
        return 0;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="270" endline="278">
{
    if (intel_thermal_supported (&boot_cpu_data))
        lvtthmr_init = apic_read (APIC_LVTTHMR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="281" endline="355">
{
    unsigned int cpu = smp_processor_id ();
    int tm2 = 0;
    u32 l, h;
    if (!intel_thermal_supported (c))
        return;
    rdmsr (MSR_IA32_MISC_ENABLE, l, h);
    apic_write (APIC_LVTTHMR, lvtthmr_init);
    h = lvtthmr_init;
    if ((l & MSR_IA32_MISC_ENABLE_TM1) && (h & APIC_DM_SMI)) {
        printk (KERN_DEBUG "CPU%d: Thermal monitoring handled by SMI\n", cpu);
        return;
    }
    if (h & APIC_VECTOR_MASK) {
        printk (KERN_DEBUG "CPU%d: Thermal LVT vector (%#x) already installed\n", cpu, (h & APIC_VECTOR_MASK));
        return;
    }
    if (cpu_has (c, X86_FEATURE_TM2)) {
        if (c->x86 == 6 && (c->x86_model == 9 || c->x86_model == 13)) {
            rdmsr (MSR_THERM2_CTL, l, h);
            if (l & MSR_THERM2_CTL_TM_SELECT)
                tm2 = 1;
        }
        else if (l & MSR_IA32_MISC_ENABLE_TM2)
            tm2 = 1;
    }
    h = THERMAL_APIC_VECTOR | APIC_DM_FIXED | APIC_LVT_MASKED;
    apic_write (APIC_LVTTHMR, h);
    rdmsr (MSR_IA32_THERM_INTERRUPT, l, h);
    wrmsr (MSR_IA32_THERM_INTERRUPT, l | (THERM_INT_LOW_ENABLE | THERM_INT_HIGH_ENABLE), h);
    smp_thermal_vector = intel_thermal_interrupt;
    rdmsr (MSR_IA32_MISC_ENABLE, l, h);
    wrmsr (MSR_IA32_MISC_ENABLE, l | MSR_IA32_MISC_ENABLE_TM1, h);
    l = apic_read (APIC_LVTTHMR);
    apic_write (APIC_LVTTHMR, l & ~ APIC_LVT_MASKED);
    printk_once (KERN_INFO "CPU0: Thermal monitoring enabled (%s)\n", tm2 ? "TM2" : "TM1");
    atomic_set (& therm_throt_en, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="309" endline="313">
{
    printk (KERN_DEBUG "CPU%d: Thermal monitoring handled by SMI\n", cpu);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="316" endline="321">
{
    printk (KERN_DEBUG "CPU%d: Thermal LVT vector (%#x) already installed\n", cpu, (h & APIC_VECTOR_MASK));
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="324" endline="331">
{
    if (c->x86 == 6 && (c->x86_model == 9 || c->x86_model == 13)) {
        rdmsr (MSR_THERM2_CTL, l, h);
        if (l & MSR_THERM2_CTL_TM_SELECT)
            tm2 = 1;
    }
    else if (l & MSR_IA32_MISC_ENABLE_TM2)
        tm2 = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/therm_throt.c.ifdefed" startline="325" endline="329">
{
    rdmsr (MSR_THERM2_CTL, l, h);
    if (l & MSR_THERM2_CTL_TM_SELECT)
        tm2 = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce-severity.c.ifdefed" startline="108" endline="113">
{
    if (m->mcgstatus & MCG_STATUS_EIPV)
        return (m->ip && (m->cs & 3) == 3) ? IN_USER : IN_KERNEL;
    return IN_KERNEL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce-severity.c.ifdefed" startline="116" endline="140">
{
    enum context ctx = error_context (a);
    struct severity *s;
    for (s = severities;; s++) {
        if ((a->status & s->mask) != s->result)
            continue;
        if ((a->mcgstatus & s->mcgmask) != s->mcgres)
            continue;
        if (s->ser == SER_REQUIRED && !mce_ser)
            continue;
        if (s->ser == NO_SER && mce_ser)
            continue;
        if (s->context && ctx != s->context)
            continue;
        if (msg)
            *msg = s->msg;
        s->covered = 1;
        if (s->sev >= MCE_UC_SEVERITY && ctx == IN_KERNEL) {
            if (panic_on_oops || tolerant < 1)
                return MCE_PANIC_SEVERITY;
        }
        return s->sev;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce-severity.c.ifdefed" startline="120" endline="139">
{
    if ((a->status & s->mask) != s->result)
        continue;
    if ((a->mcgstatus & s->mcgmask) != s->mcgres)
        continue;
    if (s->ser == SER_REQUIRED && !mce_ser)
        continue;
    if (s->ser == NO_SER && mce_ser)
        continue;
    if (s->context && ctx != s->context)
        continue;
    if (msg)
        *msg = s->msg;
    s->covered = 1;
    if (s->sev >= MCE_UC_SEVERITY && ctx == IN_KERNEL) {
        if (panic_on_oops || tolerant < 1)
            return MCE_PANIC_SEVERITY;
    }
    return s->sev;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce-severity.c.ifdefed" startline="134" endline="137">
{
    if (panic_on_oops || tolerant < 1)
        return MCE_PANIC_SEVERITY;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="36" endline="54">
{
    u64 cap;
    if (mce_cmci_disabled || mce_ignore_ce)
        return 0;
    if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)
        return 0;
    if (!cpu_has_apic || lapic_get_maxlvt () < 6)
        return 0;
    rdmsrl (MSR_IA32_MCG_CAP, cap);
    *banks = min_t (unsigned, MAX_NR_BANKS, cap &0xff);
    return !!(cap & MCG_CMCI_P);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="63" endline="66">
{
    machine_check_poll (MCP_TIMESTAMP, & __get_cpu_var (mce_banks_owned));
    mce_notify_irq ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="69" endline="74">
{
    if (*hdr == 0)
        printk (KERN_INFO "CPU %d MCA banks", smp_processor_id ());
    *hdr = 1;
    printk (KERN_CONT " %s:%d", type, num);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="82" endline="121">
{
    unsigned long *owned = (void *) &__get_cpu_var (mce_banks_owned);
    unsigned long flags;
    int hdr = 0;
    int i;
    spin_lock_irqsave (& cmci_discover_lock, flags);
    for (i = 0; i < banks; i++) {
        u64 val;
        if (test_bit (i, owned))
            continue;
        rdmsrl (MSR_IA32_MCx_CTL2 (i), val);
        if (val & CMCI_EN) {
            if (test_and_clear_bit (i, owned) && !boot)
                print_update ("SHD", &hdr, i);
            __clear_bit (i, __get_cpu_var (mce_poll_banks));
            continue;
        }
        val |= CMCI_EN | CMCI_THRESHOLD;
        wrmsrl (MSR_IA32_MCx_CTL2 (i), val);
        rdmsrl (MSR_IA32_MCx_CTL2 (i), val);
        if (val & CMCI_EN) {
            if (!test_and_set_bit (i, owned) && !boot)
                print_update ("CMCI", &hdr, i);
            __clear_bit (i, __get_cpu_var (mce_poll_banks));
        }
        else {
            WARN_ON (! test_bit (i, __get_cpu_var (mce_poll_banks)));
        }
    }
    spin_unlock_irqrestore (& cmci_discover_lock, flags);
    if (hdr)
        printk (KERN_CONT "\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="89" endline="117">
{
    u64 val;
    if (test_bit (i, owned))
        continue;
    rdmsrl (MSR_IA32_MCx_CTL2 (i), val);
    if (val & CMCI_EN) {
        if (test_and_clear_bit (i, owned) && !boot)
            print_update ("SHD", &hdr, i);
        __clear_bit (i, __get_cpu_var (mce_poll_banks));
        continue;
    }
    val |= CMCI_EN | CMCI_THRESHOLD;
    wrmsrl (MSR_IA32_MCx_CTL2 (i), val);
    rdmsrl (MSR_IA32_MCx_CTL2 (i), val);
    if (val & CMCI_EN) {
        if (!test_and_set_bit (i, owned) && !boot)
            print_update ("CMCI", &hdr, i);
        __clear_bit (i, __get_cpu_var (mce_poll_banks));
    }
    else {
        WARN_ON (! test_bit (i, __get_cpu_var (mce_poll_banks)));
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="98" endline="103">
{
    if (test_and_clear_bit (i, owned) && !boot)
        print_update ("SHD", &hdr, i);
    __clear_bit (i, __get_cpu_var (mce_poll_banks));
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="110" endline="114">
{
    if (!test_and_set_bit (i, owned) && !boot)
        print_update ("CMCI", &hdr, i);
    __clear_bit (i, __get_cpu_var (mce_poll_banks));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="114" endline="116">
{
    WARN_ON (! test_bit (i, __get_cpu_var (mce_poll_banks)));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="128" endline="137">
{
    unsigned long flags;
    int banks;
    if (!mce_available (&current_cpu_data) || !cmci_supported (&banks))
        return;
    local_irq_save (flags);
    machine_check_poll (MCP_TIMESTAMP, & __get_cpu_var (mce_banks_owned));
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="144" endline="163">
{
    unsigned long flags;
    int i;
    int banks;
    u64 val;
    if (!cmci_supported (&banks))
        return;
    spin_lock_irqsave (& cmci_discover_lock, flags);
    for (i = 0; i < banks; i++) {
        if (!test_bit (i, __get_cpu_var (mce_banks_owned)))
            continue;
        rdmsrl (MSR_IA32_MCx_CTL2 (i), val);
        val &= ~(CMCI_EN | CMCI_THRESHOLD_MASK);
        wrmsrl (MSR_IA32_MCx_CTL2 (i), val);
        __clear_bit (i, __get_cpu_var (mce_banks_owned));
    }
    spin_unlock_irqrestore (& cmci_discover_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="153" endline="161">
{
    if (!test_bit (i, __get_cpu_var (mce_banks_owned)))
        continue;
    rdmsrl (MSR_IA32_MCx_CTL2 (i), val);
    val &= ~(CMCI_EN | CMCI_THRESHOLD_MASK);
    wrmsrl (MSR_IA32_MCx_CTL2 (i), val);
    __clear_bit (i, __get_cpu_var (mce_banks_owned));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="170" endline="193">
{
    int banks;
    int cpu;
    cpumask_var_t old;
    if (!cmci_supported (&banks))
        return;
    if (!alloc_cpumask_var (&old, GFP_KERNEL))
        return;
    cpumask_copy (old, & current -> cpus_allowed);

    for_each_online_cpu (cpu) {
        if (cpu == dying)
            continue;
        if (set_cpus_allowed_ptr (current, cpumask_of (cpu)))
            continue;
        if (cmci_supported (&banks))
            cmci_discover (banks, 0);
    }

    set_cpus_allowed_ptr (current, old);
    free_cpumask_var (old);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="181" endline="189">
{
    if (cpu == dying)
        continue;
    if (set_cpus_allowed_ptr (current, cpumask_of (cpu)))
        continue;
    if (cmci_supported (&banks))
        cmci_discover (banks, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="199" endline="203">
{
    int banks;
    if (cmci_supported (&banks))
        cmci_discover (banks, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="206" endline="222">
{
    int banks;
    if (!cmci_supported (&banks))
        return;
    mce_threshold_vector = intel_threshold_interrupt;
    cmci_discover (banks, 1);
    apic_write (APIC_LVTCMCI, THRESHOLD_APIC_VECTOR | APIC_DM_FIXED);
    cmci_recheck ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/mcheck/mce_intel.c.ifdefed" startline="225" endline="228">
{
    intel_init_thermal (c);
    intel_init_cmci ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/hypervisor.c.ifdefed" startline="30" endline="35">
{
    if (vmware_platform ())
        c->x86_hyper_vendor = X86_HYPER_VENDOR_VMWARE;
    else
        c->x86_hyper_vendor = X86_HYPER_VENDOR_NONE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/hypervisor.c.ifdefed" startline="39" endline="44">
{
    if (boot_cpu_data.x86_hyper_vendor == X86_HYPER_VENDOR_VMWARE) {
        vmware_set_feature_bits (c);
        return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/hypervisor.c.ifdefed" startline="40" endline="43">
{
    vmware_set_feature_bits (c);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/hypervisor.c.ifdefed" startline="47" endline="50">
{
    detect_hypervisor_vendor (c);
    hypervisor_set_feature_bits (c);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/hypervisor.c.ifdefed" startline="53" endline="57">
{
    init_hypervisor (& boot_cpu_data);
    if (boot_cpu_data.x86_hyper_vendor == X86_HYPER_VENDOR_VMWARE)
        vmware_platform_setup ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/proc.c.ifdefed" startline="12" endline="24">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/proc.c.ifdefed" startline="54" endline="61">
{
    seq_printf (m, "fpu\t\t: yes\n" "fpu_exception\t: yes\n" "cpuid level\t: %d\n" "wp\t\t: yes\n", c -> cpuid_level);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/proc.c.ifdefed" startline="65" endline="139">
{
    struct cpuinfo_x86 *c = v;
    unsigned int cpu = 0;
    int i;
    seq_printf (m, "processor\t: %u\n" "vendor_id\t: %s\n" "cpu family\t: %d\n" "model\t\t: %u\n" "model name\t: %s\n", cpu, c -> x86_vendor_id [0] ? c -> x86_vendor_id : "unknown", c -> x86, c -> x86_model, c -> x86_model_id [0] ? c -> x86_model_id : "unknown");
    if (c->x86_mask || c->cpuid_level >= 0)
        seq_printf (m, "stepping\t: %d\n", c->x86_mask);
    else
        seq_printf (m, "stepping\t: unknown\n");
    if (cpu_has (c, X86_FEATURE_TSC)) {
        unsigned int freq = cpufreq_quick_get (cpu);
        if (!freq)
            freq = cpu_khz;
        seq_printf (m, "cpu MHz\t\t: %u.%03u\n", freq / 1000, (freq % 1000));
    }
    if (c->x86_cache_size >= 0)
        seq_printf (m, "cache size\t: %d KB\n", c->x86_cache_size);
    show_cpuinfo_core (m, c, cpu);
    show_cpuinfo_misc (m, c);
    seq_printf (m, "flags\t\t:");
    for (i = 0; i < 32 * NCAPINTS; i++)
        if (cpu_has (c, i) && x86_cap_flags[i] != NULL)
            seq_printf (m, " %s", x86_cap_flags[i]);
    seq_printf (m, "\nbogomips\t: %lu.%02lu\n", c -> loops_per_jiffy / (500000 / HZ), (c -> loops_per_jiffy / (5000 / HZ)) % 100);
    seq_printf (m, "clflush size\t: %u\n", c -> x86_clflush_size);
    seq_printf (m, "cache_alignment\t: %d\n", c -> x86_cache_alignment);
    seq_printf (m, "address sizes\t: %u bits physical, %u bits virtual\n", c -> x86_phys_bits, c -> x86_virt_bits);
    seq_printf (m, "power management:");
    for (i = 0; i < 32; i++) {
        if (c->x86_power & (1 << i)) {
            if (i < ARRAY_SIZE (x86_power_flags) && x86_power_flags[i])
                seq_printf (m, "%s%s", x86_power_flags[i][0] ? " " : "", x86_power_flags[i]);
            else
                seq_printf (m, " [%d]", i);
        }
    }
    seq_printf (m, "\n\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/proc.c.ifdefed" startline="89" endline="96">
{
    unsigned int freq = cpufreq_quick_get (cpu);
    if (!freq)
        freq = cpu_khz;
    seq_printf (m, "cpu MHz\t\t: %u.%03u\n", freq / 1000, (freq % 1000));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/proc.c.ifdefed" startline="124" endline="134">
{
    if (c->x86_power & (1 << i)) {
        if (i < ARRAY_SIZE (x86_power_flags) && x86_power_flags[i])
            seq_printf (m, "%s%s", x86_power_flags[i][0] ? " " : "", x86_power_flags[i]);
        else
            seq_printf (m, " [%d]", i);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/proc.c.ifdefed" startline="125" endline="133">
{
    if (i < ARRAY_SIZE (x86_power_flags) && x86_power_flags[i])
        seq_printf (m, "%s%s", x86_power_flags[i][0] ? " " : "", x86_power_flags[i]);
    else
        seq_printf (m, " [%d]", i);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/proc.c.ifdefed" startline="142" endline="150">
{
    if (*pos == 0)
        *pos = cpumask_first (cpu_online_mask);
    else
        *pos = cpumask_next (*pos - 1, cpu_online_mask);
    if ((*pos) < nr_cpu_ids)
        return &cpu_data (*pos);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/proc.c.ifdefed" startline="153" endline="156">
{
    (*pos)++;
    return c_start (m, pos);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/cpu/proc.c.ifdefed" startline="159" endline="160">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/topology.c.ifdefed" startline="63" endline="65">
{
    return register_cpu (&per_cpu (cpu_devices, num).cpu, num);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/topology.c.ifdefed" startline="69" endline="81">
{
    int i;
    for_each_present_cpu (i)
    arch_register_cpu (i);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/xsave.c.ifdefed" startline="31" endline="70">
{
    int min_xstate_size = sizeof (struct i387_fxsave_struct) + sizeof (struct xsave_hdr_struct);
    unsigned int magic2;
    int err;
    err = __copy_from_user (fx_sw_user, &buf->sw_reserved[0], sizeof (struct _fpx_sw_bytes));
    if (err)
        return err;
    if (fx_sw_user->magic1 != FP_XSTATE_MAGIC1)
        return -1;
    if (fx_sw_user->xstate_size < min_xstate_size || fx_sw_user->xstate_size > xstate_size || fx_sw_user->xstate_size > fx_sw_user->extended_size)
        return -1;
    err = __get_user (magic2, (__u32 *) (((void *) fpstate) + fx_sw_user->extended_size - FP_XSTATE_MAGIC2_SIZE));
    if (err || magic2 != FP_XSTATE_MAGIC2)
        return -1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/xsave.c.ifdefed" startline="254" endline="275">
{
    int size_extended = (xstate_size - sizeof (struct i387_fxsave_struct)) + FP_XSTATE_MAGIC2_SIZE;
    sig_xstate_size = sizeof (struct _fpstate) + size_extended;
    memset (& fx_sw_reserved, 0, sizeof (fx_sw_reserved));
    fx_sw_reserved.magic1 = FP_XSTATE_MAGIC1;
    fx_sw_reserved.extended_size = sig_xstate_size;
    fx_sw_reserved.xstate_bv = pcntxt_mask;
    fx_sw_reserved.xstate_size = xstate_size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/xsave.c.ifdefed" startline="290" endline="301">
{
    if (!cpu_has_xsave)
        return;
    set_in_cr4 (X86_CR4_OSXSAVE);
    xsetbv (XCR_XFEATURE_ENABLED_MASK, pcntxt_mask);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/xsave.c.ifdefed" startline="307" endline="310">
{
    init_xstate_buf = alloc_bootmem (xstate_size);
    init_xstate_buf->i387.mxcsr = MXCSR_DEFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/xsave.c.ifdefed" startline="316" endline="348">
{
    unsigned int eax, ebx, ecx, edx;
    cpuid_count (0xd, 0, & eax, & ebx, & ecx, & edx);
    pcntxt_mask = eax + ((u64) edx << 32);
    if ((pcntxt_mask & XSTATE_FPSSE) != XSTATE_FPSSE) {
        printk (KERN_ERR "FP/SSE not shown under xsave features 0x%llx\n", pcntxt_mask);
        BUG ();
    }
    pcntxt_mask = pcntxt_mask & XCNTXT_MASK;
    xsave_init ();
    cpuid_count (0xd, 0, & eax, & ebx, & ecx, & edx);
    xstate_size = ebx;
    update_regset_xstate_info (xstate_size, pcntxt_mask);
    prepare_fx_sw_frame ();
    setup_xstate_init ();
    printk (KERN_INFO "xsave/xrstor: enabled xstate_bv 0x%llx, " "cntxt size 0x%x\n", pcntxt_mask, xstate_size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/xsave.c.ifdefed" startline="322" endline="326">
{
    printk (KERN_ERR "FP/SSE not shown under xsave features 0x%llx\n", pcntxt_mask);
    BUG ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup_percpu.c.ifdefed" startline="106" endline="128">
{
    const unsigned long goal = __pa (MAX_DMA_ADDRESS);
    return __alloc_bootmem_nopanic (size, align, goal);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup_percpu.c.ifdefed" startline="134" endline="136">
{
    return pcpu_alloc_bootmem (cpu, size, align);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup_percpu.c.ifdefed" startline="139" endline="147">
{
    free_bootmem (__pa (ptr), size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup_percpu.c.ifdefed" startline="150" endline="159">
{
    return LOCAL_DISTANCE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup_percpu.c.ifdefed" startline="162" endline="164">
{
    populate_extra_pte (addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup_percpu.c.ifdefed" startline="167" endline="177">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup_percpu.c.ifdefed" startline="180" endline="279">
{
    unsigned int cpu;
    unsigned long delta;
    int rc;
    pr_info ("NR_CPUS:%d nr_cpumask_bits:%d nr_cpu_ids:%d nr_node_ids:%d\n", NR_CPUS, nr_cpumask_bits, nr_cpu_ids, nr_node_ids);
    rc = -EINVAL;
    if (pcpu_chosen_fc != PCPU_FC_PAGE) {
        const size_t atom_size = cpu_has_pse ? PMD_SIZE : PAGE_SIZE;
        const size_t dyn_size = PERCPU_MODULE_RESERVE + PERCPU_DYNAMIC_RESERVE - PERCPU_FIRST_CHUNK_RESERVE;
        rc = pcpu_embed_first_chunk (PERCPU_FIRST_CHUNK_RESERVE, dyn_size, atom_size, pcpu_cpu_distance, pcpu_fc_alloc, pcpu_fc_free);
        if (rc < 0)
            pr_warning ("%s allocator failed (%d), falling back to page size\n", pcpu_fc_names[pcpu_chosen_fc], rc);
    }
    if (rc < 0)
        rc = pcpu_page_first_chunk (PERCPU_FIRST_CHUNK_RESERVE, pcpu_fc_alloc, pcpu_fc_free, pcpup_populate_pte);
    if (rc < 0)
        panic ("cannot initialize percpu area (err=%d)", rc);
    delta = (unsigned long) pcpu_base_addr - (unsigned long) __per_cpu_start;

    for_each_possible_cpu (cpu) {
        per_cpu_offset (cpu) = delta + pcpu_unit_offsets[cpu];
        per_cpu (this_cpu_off, cpu) = per_cpu_offset (cpu);
        per_cpu (cpu_number, cpu) = cpu;
        setup_percpu_segment (cpu);
        setup_stack_canary_segment (cpu);
        if (cpu == boot_cpu_id)
            switch_to_new_gdt (cpu);
    }

    setup_node_to_cpumask_map ();
    setup_cpu_local_masks ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup_percpu.c.ifdefed" startline="199" endline="211">
{
    const size_t atom_size = cpu_has_pse ? PMD_SIZE : PAGE_SIZE;
    const size_t dyn_size = PERCPU_MODULE_RESERVE + PERCPU_DYNAMIC_RESERVE - PERCPU_FIRST_CHUNK_RESERVE;
    rc = pcpu_embed_first_chunk (PERCPU_FIRST_CHUNK_RESERVE, dyn_size, atom_size, pcpu_cpu_distance, pcpu_fc_alloc, pcpu_fc_free);
    if (rc < 0)
        pr_warning ("%s allocator failed (%d), falling back to page size\n", pcpu_fc_names[pcpu_chosen_fc], rc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/setup_percpu.c.ifdefed" startline="221" endline="255">
{
    per_cpu_offset (cpu) = delta + pcpu_unit_offsets[cpu];
    per_cpu (this_cpu_off, cpu) = per_cpu_offset (cpu);
    per_cpu (cpu_number, cpu) = cpu;
    setup_percpu_segment (cpu);
    setup_stack_canary_segment (cpu);
    if (cpu == boot_cpu_id)
        switch_to_new_gdt (cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="52" endline="65">
{
    int i;
    for (i = 0; i < e820.nr_map; i++) {
        struct e820entry *ei = &e820.map[i];
        if (type && ei->type != type)
            continue;
        if (ei->addr >= end || ei->addr + ei->size <= start)
            continue;
        return 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="55" endline="63">
{
    struct e820entry *ei = &e820.map[i];
    if (type && ei->type != type)
        continue;
    if (ei->addr >= end || ei->addr + ei->size <= start)
        continue;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="75" endline="100">
{
    int i;
    for (i = 0; i < e820.nr_map; i++) {
        struct e820entry *ei = &e820.map[i];
        if (type && ei->type != type)
            continue;
        if (ei->addr >= end || ei->addr + ei->size <= start)
            continue;
        if (ei->addr <= start)
            start = ei->addr + ei->size;
        if (start >= end)
            return 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="78" endline="98">
{
    struct e820entry *ei = &e820.map[i];
    if (type && ei->type != type)
        continue;
    if (ei->addr >= end || ei->addr + ei->size <= start)
        continue;
    if (ei->addr <= start)
        start = ei->addr + ei->size;
    if (start >= end)
        return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="107" endline="119">
{
    int x = e820x->nr_map;
    if (x >= ARRAY_SIZE (e820x->map)) {
        printk (KERN_ERR "Ooops! Too many entries in the memory map!\n");
        return;
    }
    e820x->map[x].addr = start;
    e820x->map[x].size = size;
    e820x->map[x].type = type;
    e820x->nr_map++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="110" endline="113">
{
    printk (KERN_ERR "Ooops! Too many entries in the memory map!\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="122" endline="124">
{
    __e820_add_region (& e820, start, size, type);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="127" endline="149">
{
    switch (type) {
    case E820_RAM :
    case E820_RESERVED_KERN :
        printk (KERN_CONT "(usable)");
        break;
    case E820_RESERVED :
        printk (KERN_CONT "(reserved)");
        break;
    case E820_ACPI :
        printk (KERN_CONT "(ACPI data)");
        break;
    case E820_NVS :
        printk (KERN_CONT "(ACPI NVS)");
        break;
    case E820_UNUSABLE :
        printk (KERN_CONT "(unusable)");
        break;
    default :
        printk (KERN_CONT "type %u", type);
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="128" endline="148">
{
case E820_RAM :
case E820_RESERVED_KERN :
    printk (KERN_CONT "(usable)");
    break;
case E820_RESERVED :
    printk (KERN_CONT "(reserved)");
    break;
case E820_ACPI :
    printk (KERN_CONT "(ACPI data)");
    break;
case E820_NVS :
    printk (KERN_CONT "(ACPI NVS)");
    break;
case E820_UNUSABLE :
    printk (KERN_CONT "(unusable)");
    break;
default :
    printk (KERN_CONT "type %u", type);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="152" endline="163">
{
    int i;
    for (i = 0; i < e820.nr_map; i++) {
        printk (KERN_INFO " %s: %016Lx - %016Lx ", who, (unsigned long long) e820.map [i].addr, (unsigned long long) (e820.map [i].addr + e820.map [i].size));
        e820_print_type (e820.map [i].type);
        printk (KERN_CONT "\n");
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="155" endline="162">
{
    printk (KERN_INFO " %s: %016Lx - %016Lx ", who, (unsigned long long) e820.map [i].addr, (unsigned long long) (e820.map [i].addr + e820.map [i].size));
    e820_print_type (e820.map [i].type);
    printk (KERN_CONT "\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="229" endline="384">
{
    struct change_member {
        struct e820entry *pbios;
        unsigned long long addr;
    };
    static struct change_member change_point_list [2 * E820_X_MAX] __initdata;
    static struct change_member *change_point [2 * E820_X_MAX] __initdata;
    static struct e820entry *overlap_list [E820_X_MAX] __initdata;
    static struct e820entry new_bios [E820_X_MAX] __initdata;
    struct change_member *change_tmp;
    unsigned long current_type, last_type;
    unsigned long long last_addr;
    int chgidx, still_changing;
    int overlap_entries;
    int new_bios_entry;
    int old_nr, new_nr, chg_nr;
    int i;
    if (*pnr_map < 2)
        return -1;
    old_nr = *pnr_map;
    BUG_ON (old_nr > max_nr_map);
    for (i = 0; i < old_nr; i++)
        if (biosmap[i].addr + biosmap[i].size < biosmap[i].addr)
            return -1;
    for (i = 0; i < 2 * old_nr; i++)
        change_point[i] = &change_point_list[i];
    chgidx = 0;
    for (i = 0; i < old_nr; i++) {
        if (biosmap[i].size != 0) {
            change_point[chgidx]->addr = biosmap[i].addr;
            change_point[chgidx++]->pbios = &biosmap[i];
            change_point[chgidx]->addr = biosmap[i].addr + biosmap[i].size;
            change_point[chgidx++]->pbios = &biosmap[i];
        }
    }
    chg_nr = chgidx;
    still_changing = 1;
    while (still_changing) {
        still_changing = 0;
        for (i = 1; i < chg_nr; i++) {
            unsigned long long curaddr, lastaddr;
            unsigned long long curpbaddr, lastpbaddr;
            curaddr = change_point[i]->addr;
            lastaddr = change_point[i - 1]->addr;
            curpbaddr = change_point[i]->pbios->addr;
            lastpbaddr = change_point[i - 1]->pbios->addr;
            if (curaddr < lastaddr || (curaddr == lastaddr && curaddr == curpbaddr && lastaddr != lastpbaddr)) {
                change_tmp = change_point[i];
                change_point[i] = change_point[i - 1];
                change_point[i - 1] = change_tmp;
                still_changing = 1;
            }
        }
    }
    overlap_entries = 0;
    new_bios_entry = 0;
    last_type = 0;
    last_addr = 0;
    for (chgidx = 0; chgidx < chg_nr; chgidx++) {
        if (change_point[chgidx]->addr == change_point[chgidx]->pbios->addr) {
            overlap_list[overlap_entries++] = change_point[chgidx]->pbios;
        }
        else {
            for (i = 0; i < overlap_entries; i++) {
                if (overlap_list[i] == change_point[chgidx]->pbios)
                    overlap_list[i] = overlap_list[overlap_entries - 1];
            }
            overlap_entries--;
        }
        current_type = 0;
        for (i = 0; i < overlap_entries; i++)
            if (overlap_list[i]->type > current_type)
                current_type = overlap_list[i]->type;
        if (current_type != last_type) {
            if (last_type != 0) {
                new_bios[new_bios_entry].size = change_point[chgidx]->addr - last_addr;
                if (new_bios[new_bios_entry].size != 0)
                    if (++new_bios_entry >= max_nr_map)
                        break;
            }
            if (current_type != 0) {
                new_bios[new_bios_entry].addr = change_point[chgidx]->addr;
                new_bios[new_bios_entry].type = current_type;
                last_addr = change_point[chgidx]->addr;
            }
            last_type = current_type;
        }
    }
    new_nr = new_bios_entry;
    memcpy (biosmap, new_bios, new_nr * sizeof (struct e820entry));
    *pnr_map = new_nr;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="266" endline="274">
{
    if (biosmap[i].size != 0) {
        change_point[chgidx]->addr = biosmap[i].addr;
        change_point[chgidx++]->pbios = &biosmap[i];
        change_point[chgidx]->addr = biosmap[i].addr + biosmap[i].size;
        change_point[chgidx++]->pbios = &biosmap[i];
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="267" endline="273">
{
    change_point[chgidx]->addr = biosmap[i].addr;
    change_point[chgidx++]->pbios = &biosmap[i];
    change_point[chgidx]->addr = biosmap[i].addr + biosmap[i].size;
    change_point[chgidx++]->pbios = &biosmap[i];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="279" endline="306">
{
    still_changing = 0;
    for (i = 1; i < chg_nr; i++) {
        unsigned long long curaddr, lastaddr;
        unsigned long long curpbaddr, lastpbaddr;
        curaddr = change_point[i]->addr;
        lastaddr = change_point[i - 1]->addr;
        curpbaddr = change_point[i]->pbios->addr;
        lastpbaddr = change_point[i - 1]->pbios->addr;
        if (curaddr < lastaddr || (curaddr == lastaddr && curaddr == curpbaddr && lastaddr != lastpbaddr)) {
            change_tmp = change_point[i];
            change_point[i] = change_point[i - 1];
            change_point[i - 1] = change_tmp;
            still_changing = 1;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="281" endline="305">
{
    unsigned long long curaddr, lastaddr;
    unsigned long long curpbaddr, lastpbaddr;
    curaddr = change_point[i]->addr;
    lastaddr = change_point[i - 1]->addr;
    curpbaddr = change_point[i]->pbios->addr;
    lastpbaddr = change_point[i - 1]->pbios->addr;
    if (curaddr < lastaddr || (curaddr == lastaddr && curaddr == curpbaddr && lastaddr != lastpbaddr)) {
        change_tmp = change_point[i];
        change_point[i] = change_point[i - 1];
        change_point[i - 1] = change_tmp;
        still_changing = 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="299" endline="304">
{
    change_tmp = change_point[i];
    change_point[i] = change_point[i - 1];
    change_point[i - 1] = change_tmp;
    still_changing = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="315" endline="375">
{
    if (change_point[chgidx]->addr == change_point[chgidx]->pbios->addr) {
        overlap_list[overlap_entries++] = change_point[chgidx]->pbios;
    }
    else {
        for (i = 0; i < overlap_entries; i++) {
            if (overlap_list[i] == change_point[chgidx]->pbios)
                overlap_list[i] = overlap_list[overlap_entries - 1];
        }
        overlap_entries--;
    }
    current_type = 0;
    for (i = 0; i < overlap_entries; i++)
        if (overlap_list[i]->type > current_type)
            current_type = overlap_list[i]->type;
    if (current_type != last_type) {
        if (last_type != 0) {
            new_bios[new_bios_entry].size = change_point[chgidx]->addr - last_addr;
            if (new_bios[new_bios_entry].size != 0)
                if (++new_bios_entry >= max_nr_map)
                    break;
        }
        if (current_type != 0) {
            new_bios[new_bios_entry].addr = change_point[chgidx]->addr;
            new_bios[new_bios_entry].type = current_type;
            last_addr = change_point[chgidx]->addr;
        }
        last_type = current_type;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="318" endline="325">
{
    overlap_list[overlap_entries++] = change_point[chgidx]->pbios;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="325" endline="337">
{
    for (i = 0; i < overlap_entries; i++) {
        if (overlap_list[i] == change_point[chgidx]->pbios)
            overlap_list[i] = overlap_list[overlap_entries - 1];
    }
    overlap_entries--;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="330" endline="335">
{
    if (overlap_list[i] == change_point[chgidx]->pbios)
        overlap_list[i] = overlap_list[overlap_entries - 1];
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="351" endline="374">
{
    if (last_type != 0) {
        new_bios[new_bios_entry].size = change_point[chgidx]->addr - last_addr;
        if (new_bios[new_bios_entry].size != 0)
            if (++new_bios_entry >= max_nr_map)
                break;
    }
    if (current_type != 0) {
        new_bios[new_bios_entry].addr = change_point[chgidx]->addr;
        new_bios[new_bios_entry].type = current_type;
        last_addr = change_point[chgidx]->addr;
    }
    last_type = current_type;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="352" endline="366">
{
    new_bios[new_bios_entry].size = change_point[chgidx]->addr - last_addr;
    if (new_bios[new_bios_entry].size != 0)
        if (++new_bios_entry >= max_nr_map)
            break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="367" endline="372">
{
    new_bios[new_bios_entry].addr = change_point[chgidx]->addr;
    new_bios[new_bios_entry].type = current_type;
    last_addr = change_point[chgidx]->addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="387" endline="404">
{
    while (nr_map) {
        u64 start = biosmap->addr;
        u64 size = biosmap->size;
        u64 end = start + size;
        u32 type = biosmap->type;
        if (start > end)
            return -1;
        e820_add_region (start, size, type);
        biosmap++;
        nr_map--;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="388" endline="402">
{
    u64 start = biosmap->addr;
    u64 size = biosmap->size;
    u64 end = start + size;
    u32 type = biosmap->type;
    if (start > end)
        return -1;
    e820_add_region (start, size, type);
    biosmap++;
    nr_map--;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="416" endline="422">
{
    if (nr_map < 2)
        return -1;
    return __append_e820_map (biosmap, nr_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="427" endline="492">
{
    u64 end;
    unsigned int i;
    u64 real_updated_size = 0;
    BUG_ON (old_type == new_type);
    if (size > (ULLONG_MAX - start))
        size = ULLONG_MAX - start;
    end = start + size;
    printk (KERN_DEBUG "e820 update range: %016Lx - %016Lx ", (unsigned long long) start, (unsigned long long) end);
    e820_print_type (old_type);
    printk (KERN_CONT " ==> ");
    e820_print_type (new_type);
    printk (KERN_CONT "\n");
    for (i = 0; i < e820x->nr_map; i++) {
        struct e820entry *ei = &e820x->map[i];
        u64 final_start, final_end;
        u64 ei_end;
        if (ei->type != old_type)
            continue;
        ei_end = ei->addr + ei->size;
        if (ei->addr >= start && ei_end <= end) {
            ei->type = new_type;
            real_updated_size += ei->size;
            continue;
        }
        if (ei->addr < start && ei_end > end) {
            __e820_add_region (e820x, start, size, new_type);
            __e820_add_region (e820x, end, ei_end - end, ei -> type);
            ei->size = start - ei->addr;
            real_updated_size += size;
            continue;
        }
        final_start = max (start, ei->addr);
        final_end = min (end, ei_end);
        if (final_start >= final_end)
            continue;
        __e820_add_region (e820x, final_start, final_end - final_start, new_type);
        real_updated_size += final_end - final_start;
        ei->size -= final_end - final_start;
        if (ei->addr < final_start)
            continue;
        ei->addr = final_end;
    }
    return real_updated_size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="446" endline="490">
{
    struct e820entry *ei = &e820x->map[i];
    u64 final_start, final_end;
    u64 ei_end;
    if (ei->type != old_type)
        continue;
    ei_end = ei->addr + ei->size;
    if (ei->addr >= start && ei_end <= end) {
        ei->type = new_type;
        real_updated_size += ei->size;
        continue;
    }
    if (ei->addr < start && ei_end > end) {
        __e820_add_region (e820x, start, size, new_type);
        __e820_add_region (e820x, end, ei_end - end, ei -> type);
        ei->size = start - ei->addr;
        real_updated_size += size;
        continue;
    }
    final_start = max (start, ei->addr);
    final_end = min (end, ei_end);
    if (final_start >= final_end)
        continue;
    __e820_add_region (e820x, final_start, final_end - final_start, new_type);
    real_updated_size += final_end - final_start;
    ei->size -= final_end - final_start;
    if (ei->addr < final_start)
        continue;
    ei->addr = final_end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="456" endline="460">
{
    ei->type = new_type;
    real_updated_size += ei->size;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="463" endline="469">
{
    __e820_add_region (e820x, start, size, new_type);
    __e820_add_region (e820x, end, ei_end - end, ei -> type);
    ei->size = start - ei->addr;
    real_updated_size += size;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="496" endline="498">
{
    return __e820_update_range (&e820, start, size, old_type, new_type);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="502" endline="505">
{
    return __e820_update_range (&e820_saved, start, size, old_type, new_type);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="510" endline="567">
{
    int i;
    u64 end;
    u64 real_removed_size = 0;
    if (size > (ULLONG_MAX - start))
        size = ULLONG_MAX - start;
    end = start + size;
    printk (KERN_DEBUG "e820 remove range: %016Lx - %016Lx ", (unsigned long long) start, (unsigned long long) end);
    if (checktype)
        e820_print_type (old_type);
    printk (KERN_CONT "\n");
    for (i = 0; i < e820.nr_map; i++) {
        struct e820entry *ei = &e820.map[i];
        u64 final_start, final_end;
        u64 ei_end;
        if (checktype && ei->type != old_type)
            continue;
        ei_end = ei->addr + ei->size;
        if (ei->addr >= start && ei_end <= end) {
            real_removed_size += ei->size;
            memset (ei, 0, sizeof (struct e820entry));
            continue;
        }
        if (ei->addr < start && ei_end > end) {
            e820_add_region (end, ei_end - end, ei -> type);
            ei->size = start - ei->addr;
            real_removed_size += size;
            continue;
        }
        final_start = max (start, ei->addr);
        final_end = min (end, ei_end);
        if (final_start >= final_end)
            continue;
        real_removed_size += final_end - final_start;
        ei->size -= final_end - final_start;
        if (ei->addr < final_start)
            continue;
        ei->addr = final_end;
    }
    return real_removed_size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="526" endline="565">
{
    struct e820entry *ei = &e820.map[i];
    u64 final_start, final_end;
    u64 ei_end;
    if (checktype && ei->type != old_type)
        continue;
    ei_end = ei->addr + ei->size;
    if (ei->addr >= start && ei_end <= end) {
        real_removed_size += ei->size;
        memset (ei, 0, sizeof (struct e820entry));
        continue;
    }
    if (ei->addr < start && ei_end > end) {
        e820_add_region (end, ei_end - end, ei -> type);
        ei->size = start - ei->addr;
        real_removed_size += size;
        continue;
    }
    final_start = max (start, ei->addr);
    final_end = min (end, ei_end);
    if (final_start >= final_end)
        continue;
    real_removed_size += final_end - final_start;
    ei->size -= final_end - final_start;
    if (ei->addr < final_start)
        continue;
    ei->addr = final_end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="536" endline="540">
{
    real_removed_size += ei->size;
    memset (ei, 0, sizeof (struct e820entry));
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="543" endline="548">
{
    e820_add_region (end, ei_end - end, ei -> type);
    ei->size = start - ei->addr;
    real_removed_size += size;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="570" endline="579">
{
    u32 nr_map;
    nr_map = e820.nr_map;
    if (sanitize_e820_map (e820.map, ARRAY_SIZE (e820.map), &nr_map))
        return;
    e820.nr_map = nr_map;
    printk (KERN_INFO "modified physical RAM map:\n");
    e820_print_map ("modified");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="581" endline="588">
{
    u32 nr_map;
    nr_map = e820_saved.nr_map;
    if (sanitize_e820_map (e820_saved.map, ARRAY_SIZE (e820_saved.map), &nr_map))
        return;
    e820_saved.nr_map = nr_map;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="595" endline="626">
{
    unsigned long long last;
    int i = e820.nr_map;
    int found = 0;
    last = (end_addr && end_addr < MAX_GAP_END) ? end_addr : MAX_GAP_END;
    while (--i >= 0) {
        unsigned long long start = e820.map[i].addr;
        unsigned long long end = start + e820.map[i].size;
        if (end < start_addr)
            continue;
        if (last > end) {
            unsigned long gap = last - end;
            if (gap >= *gapsize) {
                *gapsize = gap;
                *gapstart = end;
                found = 1;
            }
        }
        if (start < last)
            last = start;
    }
    return found;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="602" endline="624">
{
    unsigned long long start = e820.map[i].addr;
    unsigned long long end = start + e820.map[i].size;
    if (end < start_addr)
        continue;
    if (last > end) {
        unsigned long gap = last - end;
        if (gap >= *gapsize) {
            *gapsize = gap;
            *gapstart = end;
            found = 1;
        }
    }
    if (start < last)
        last = start;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="613" endline="621">
{
    unsigned long gap = last - end;
    if (gap >= *gapsize) {
        *gapsize = gap;
        *gapstart = end;
        found = 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="616" endline="620">
{
    *gapsize = gap;
    *gapstart = end;
    found = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="635" endline="660">
{
    unsigned long gapstart, gapsize;
    int found;
    gapstart = 0x10000000;
    gapsize = 0x400000;
    found = e820_search_gap (&gapstart, &gapsize, 0, MAX_GAP_END);
    pci_mem_start = gapstart;
    printk (KERN_INFO "Allocating PCI resources starting at %lx (gap: %lx:%lx)\n", pci_mem_start, gapstart, gapsize);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="669" endline="685">
{
    u32 map_len;
    int entries;
    struct e820entry *extmap;
    entries = sdata->len / sizeof (struct e820entry);
    map_len = sdata->len + sizeof (struct setup_data);
    if (map_len > PAGE_SIZE)
        sdata = early_ioremap (pa_data, map_len);
    extmap = (struct e820entry *) (sdata->data);
    __append_e820_map (extmap, entries);
    sanitize_e820_map (e820.map, ARRAY_SIZE (e820.map), & e820.nr_map);
    if (map_len > PAGE_SIZE)
        early_iounmap (sdata, map_len);
    printk (KERN_INFO "extended physical RAM map:\n");
    e820_print_map ("extended");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="744" endline="764">
{
    int i;
    for (i = 0; i < e820.nr_map; i++) {
        struct e820entry *ei = &e820.map[i];
        u64 addr;
        u64 ei_start, ei_last;
        if (ei->type != E820_RAM)
            continue;
        ei_last = ei->addr + ei->size;
        ei_start = ei->addr;
        addr = find_early_area (ei_start, ei_last, start, end, size, align);
        if (addr != -1ULL)
            return addr;
    }
    return -1ULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="747" endline="762">
{
    struct e820entry *ei = &e820.map[i];
    u64 addr;
    u64 ei_start, ei_last;
    if (ei->type != E820_RAM)
        continue;
    ei_last = ei->addr + ei->size;
    ei_start = ei->addr;
    addr = find_early_area (ei_start, ei_last, start, end, size, align);
    if (addr != -1ULL)
        return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="767" endline="769">
{
    return find_e820_area (start, end, size, align);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="772" endline="778">
{
    u64 end = max_pfn_mapped;
    end <<= PAGE_SHIFT;
    return end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="783" endline="804">
{
    int i;
    for (i = 0; i < e820.nr_map; i++) {
        struct e820entry *ei = &e820.map[i];
        u64 addr;
        u64 ei_start, ei_last;
        if (ei->type != E820_RAM)
            continue;
        ei_last = ei->addr + ei->size;
        ei_start = ei->addr;
        addr = find_early_area_size (ei_start, ei_last, start, sizep, align);
        if (addr != -1ULL)
            return addr;
    }
    return -1ULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="786" endline="801">
{
    struct e820entry *ei = &e820.map[i];
    u64 addr;
    u64 ei_start, ei_last;
    if (ei->type != E820_RAM)
        continue;
    ei_last = ei->addr + ei->size;
    ei_start = ei->addr;
    addr = find_early_area_size (ei_start, ei_last, start, sizep, align);
    if (addr != -1ULL)
        return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="810" endline="840">
{
    u64 size = 0;
    u64 addr;
    u64 start;
    for (start = startt;; start += size) {
        start = find_e820_area_size (start, &size, align);
        if (!(start + 1))
            return 0;
        if (size >= sizet)
            break;
    }
    addr = round_down (start +size - sizet, align);
    if (addr < start)
        return 0;
    e820_update_range (addr, sizet, E820_RAM, E820_RESERVED);
    e820_update_range_saved (addr, sizet, E820_RAM, E820_RESERVED);
    printk (KERN_INFO "update e820 for early_reserve_e820\n");
    update_e820 ();
    update_e820_saved ();
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="815" endline="821">
{
    start = find_e820_area_size (start, &size, align);
    if (!(start + 1))
        return 0;
    if (size >= sizet)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="856" endline="888">
{
    int i;
    unsigned long last_pfn = 0;
    unsigned long max_arch_pfn = MAX_ARCH_PFN;
    for (i = 0; i < e820.nr_map; i++) {
        struct e820entry *ei = &e820.map[i];
        unsigned long start_pfn;
        unsigned long end_pfn;
        if (ei->type != type)
            continue;
        start_pfn = ei->addr >> PAGE_SHIFT;
        end_pfn = (ei->addr + ei->size) >> PAGE_SHIFT;
        if (start_pfn >= limit_pfn)
            continue;
        if (end_pfn > limit_pfn) {
            last_pfn = limit_pfn;
            break;
        }
        if (end_pfn > last_pfn)
            last_pfn = end_pfn;
    }
    if (last_pfn > max_arch_pfn)
        last_pfn = max_arch_pfn;
    printk (KERN_INFO "last_pfn = %#lx max_arch_pfn = %#lx\n", last_pfn, max_arch_pfn);
    return last_pfn;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="861" endline="880">
{
    struct e820entry *ei = &e820.map[i];
    unsigned long start_pfn;
    unsigned long end_pfn;
    if (ei->type != type)
        continue;
    start_pfn = ei->addr >> PAGE_SHIFT;
    end_pfn = (ei->addr + ei->size) >> PAGE_SHIFT;
    if (start_pfn >= limit_pfn)
        continue;
    if (end_pfn > limit_pfn) {
        last_pfn = limit_pfn;
        break;
    }
    if (end_pfn > last_pfn)
        last_pfn = end_pfn;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="874" endline="877">
{
    last_pfn = limit_pfn;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="890" endline="892">
{
    return e820_end_pfn (MAX_ARCH_PFN, E820_RAM);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="895" endline="897">
{
    return e820_end_pfn (1UL << (32 - PAGE_SHIFT), E820_RAM);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="907" endline="929">
{
    u64 align = PAGE_SIZE;
    *ei_startpfn = round_up (ei->addr, align) >> PAGE_SHIFT;
    *ei_endpfn = round_down (ei->addr + ei->size, align) >> PAGE_SHIFT;
    if (*ei_startpfn >= *ei_endpfn)
        return 0;
    if (ei->type != E820_RAM || *ei_endpfn <= start_pfn || *ei_startpfn >= last_pfn)
        return 0;
    if (*ei_startpfn < start_pfn)
        *ei_startpfn = start_pfn;
    if (*ei_endpfn > last_pfn)
        *ei_endpfn = last_pfn;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="934" endline="944">
{
    unsigned long ei_startpfn;
    unsigned long ei_endpfn;
    int i;
    for (i = 0; i < e820.nr_map; i++)
        if (e820_find_active_region (&e820.map[i], start_pfn, last_pfn, &ei_startpfn, &ei_endpfn))
            add_active_range (nid, ei_startpfn, ei_endpfn);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="952" endline="965">
{
    unsigned long start_pfn = start >> PAGE_SHIFT;
    unsigned long last_pfn = end >> PAGE_SHIFT;
    unsigned long ei_startpfn, ei_endpfn, ram = 0;
    int i;
    for (i = 0; i < e820.nr_map; i++) {
        if (e820_find_active_region (&e820.map[i], start_pfn, last_pfn, &ei_startpfn, &ei_endpfn))
            ram += ei_endpfn - ei_startpfn;
    }
    return end - start - ((u64) ram << PAGE_SHIFT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="958" endline="963">
{
    if (e820_find_active_region (&e820.map[i], start_pfn, last_pfn, &ei_startpfn, &ei_endpfn))
        ram += ei_endpfn - ei_startpfn;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="968" endline="971">
{
    early_printk (msg);
    panic (msg);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="977" endline="995">
{
    u64 mem_size;
    if (!p)
        return -EINVAL;
    userdef = 1;
    mem_size = memparse (p, &p);
    e820_remove_range (mem_size, ULLONG_MAX - mem_size, E820_RAM, 1);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="999" endline="1039">
{
    char *oldp;
    u64 start_at, mem_size;
    if (!p)
        return -EINVAL;
    if (!strncmp (p, "exactmap", 8)) {
        e820.nr_map = 0;
        userdef = 1;
        return 0;
    }
    oldp = p;
    mem_size = memparse (p, &p);
    if (p == oldp)
        return -EINVAL;
    userdef = 1;
    if (*p == '@') {
        start_at = memparse (p +1, &p);
        e820_add_region (start_at, mem_size, E820_RAM);
    }
    else if (*p == '#') {
        start_at = memparse (p +1, &p);
        e820_add_region (start_at, mem_size, E820_ACPI);
    }
    else if (*p == '$') {
        start_at = memparse (p +1, &p);
        e820_add_region (start_at, mem_size, E820_RESERVED);
    }
    else
        e820_remove_range (mem_size, ULLONG_MAX -mem_size, E820_RAM, 1);
    return *p == '\0' ? 0 : -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1006" endline="1018">
{
    e820.nr_map = 0;
    userdef = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1026" endline="1029">
{
    start_at = memparse (p +1, &p);
    e820_add_region (start_at, mem_size, E820_RAM);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1029" endline="1032">
{
    start_at = memparse (p +1, &p);
    e820_add_region (start_at, mem_size, E820_ACPI);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1032" endline="1035">
{
    start_at = memparse (p +1, &p);
    e820_add_region (start_at, mem_size, E820_RESERVED);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1043" endline="1054">
{
    if (userdef) {
        u32 nr = e820.nr_map;
        if (sanitize_e820_map (e820.map, ARRAY_SIZE (e820.map), &nr) < 0)
            early_panic ("Invalid user supplied memory map");
        e820.nr_map = nr;
        printk (KERN_INFO "user-defined physical RAM map:\n");
        e820_print_map ("user");
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1044" endline="1053">
{
    u32 nr = e820.nr_map;
    if (sanitize_e820_map (e820.map, ARRAY_SIZE (e820.map), &nr) < 0)
        early_panic ("Invalid user supplied memory map");
    e820.nr_map = nr;
    printk (KERN_INFO "user-defined physical RAM map:\n");
    e820_print_map ("user");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1057" endline="1066">
{
    switch (e820_type) {
    case E820_RESERVED_KERN :
    case E820_RAM :
        return "System RAM";
    case E820_ACPI :
        return "ACPI Tables";
    case E820_NVS :
        return "ACPI Non-volatile Storage";
    case E820_UNUSABLE :
        return "Unusable memory";
    default :
        return "reserved";
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1058" endline="1065">
{
case E820_RESERVED_KERN :
case E820_RAM :
    return "System RAM";
case E820_ACPI :
    return "ACPI Tables";
case E820_NVS :
    return "ACPI Non-volatile Storage";
case E820_UNUSABLE :
    return "Unusable memory";
default :
    return "reserved";
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1073" endline="1110">
{
    int i;
    struct resource *res;
    u64 end;
    res = alloc_bootmem (sizeof (struct resource) * e820.nr_map);
    e820_res = res;
    for (i = 0; i < e820.nr_map; i++) {
        end = e820.map[i].addr + e820.map[i].size - 1;
        if (end != (resource_size_t) end) {
            res++;
            continue;
        }
        res->name = e820_type_to_string (e820.map[i].type);
        res->start = e820.map[i].addr;
        res->end = end;
        res->flags = IORESOURCE_MEM;
        if (e820.map[i].type != E820_RESERVED || res->start < (1ULL << 20)) {
            res->flags |= IORESOURCE_BUSY;
            insert_resource (& iomem_resource, res);
        }
        res++;
    }
    for (i = 0; i < e820_saved.nr_map; i++) {
        struct e820entry *entry = &e820_saved.map[i];
        firmware_map_add_early (entry -> addr, entry -> addr + entry -> size - 1, e820_type_to_string (entry -> type));
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1080" endline="1102">
{
    end = e820.map[i].addr + e820.map[i].size - 1;
    if (end != (resource_size_t) end) {
        res++;
        continue;
    }
    res->name = e820_type_to_string (e820.map[i].type);
    res->start = e820.map[i].addr;
    res->end = end;
    res->flags = IORESOURCE_MEM;
    if (e820.map[i].type != E820_RESERVED || res->start < (1ULL << 20)) {
        res->flags |= IORESOURCE_BUSY;
        insert_resource (& iomem_resource, res);
    }
    res++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1082" endline="1085">
{
    res++;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1097" endline="1100">
{
    res->flags |= IORESOURCE_BUSY;
    insert_resource (& iomem_resource, res);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1104" endline="1109">
{
    struct e820entry *entry = &e820_saved.map[i];
    firmware_map_add_early (entry -> addr, entry -> addr + entry -> size - 1, e820_type_to_string (entry -> type));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1114" endline="1127">
{
    unsigned long mb = pos >> 20;
    if (!mb)
        return 64 * 1024;
    if (mb < 16)
        return 1024 * 1024;
    return 64 * 1024 * 1024;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1132" endline="1164">
{
    int i;
    struct resource *res;
    res = e820_res;
    for (i = 0; i < e820.nr_map; i++) {
        if (!res->parent && res->end)
            insert_resource_expand_to_fit (&iomem_resource, res);
        res++;
    }
    for (i = 0; i < e820.nr_map; i++) {
        struct e820entry *entry = &e820.map[i];
        u64 start, end;
        if (entry->type != E820_RAM)
            continue;
        start = entry->addr + entry->size;
        end = round_up (start, ram_alignment (start)) - 1;
        if (end > MAX_RESOURCE_SIZE)
            end = MAX_RESOURCE_SIZE;
        if (start >= end)
            continue;
        printk (KERN_DEBUG "reserve RAM buffer: %016llx - %016llx ", start, end);
        reserve_region_with_split (& iomem_resource, start, end, "RAM buffer");
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1137" endline="1141">
{
    if (!res->parent && res->end)
        insert_resource_expand_to_fit (&iomem_resource, res);
    res++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1147" endline="1163">
{
    struct e820entry *entry = &e820.map[i];
    u64 start, end;
    if (entry->type != E820_RAM)
        continue;
    start = entry->addr + entry->size;
    end = round_up (start, ram_alignment (start)) - 1;
    if (end > MAX_RESOURCE_SIZE)
        end = MAX_RESOURCE_SIZE;
    if (start >= end)
        continue;
    printk (KERN_DEBUG "reserve RAM buffer: %016llx - %016llx ", start, end);
    reserve_region_with_split (& iomem_resource, start, end, "RAM buffer");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1167" endline="1202">
{
    char *who = "BIOS-e820";
    u32 new_nr;
    new_nr = boot_params.e820_entries;
    sanitize_e820_map (boot_params.e820_map, ARRAY_SIZE (boot_params.e820_map), & new_nr);
    boot_params.e820_entries = new_nr;
    if (append_e820_map (boot_params.e820_map, boot_params.e820_entries) < 0) {
        u64 mem_size;
        if (boot_params.alt_mem_k < boot_params.screen_info.ext_mem_k) {
            mem_size = boot_params.screen_info.ext_mem_k;
            who = "BIOS-88";
        }
        else {
            mem_size = boot_params.alt_mem_k;
            who = "BIOS-e801";
        }
        e820.nr_map = 0;
        e820_add_region (0, LOWMEMSIZE (), E820_RAM);
        e820_add_region (HIGH_MEMORY, mem_size << 10, E820_RAM);
    }
    return who;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1182" endline="1198">
{
    u64 mem_size;
    if (boot_params.alt_mem_k < boot_params.screen_info.ext_mem_k) {
        mem_size = boot_params.screen_info.ext_mem_k;
        who = "BIOS-88";
    }
    else {
        mem_size = boot_params.alt_mem_k;
        who = "BIOS-e801";
    }
    e820.nr_map = 0;
    e820_add_region (0, LOWMEMSIZE (), E820_RAM);
    e820_add_region (HIGH_MEMORY, mem_size << 10, E820_RAM);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1187" endline="1190">
{
    mem_size = boot_params.screen_info.ext_mem_k;
    who = "BIOS-88";
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1190" endline="1193">
{
    mem_size = boot_params.alt_mem_k;
    who = "BIOS-e801";
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/e820.c.ifdefed" startline="1205" endline="1212">
{
    char *who;
    who = x86_init.resources.memory_setup ();
    memcpy (& e820_saved, & e820, sizeof (struct e820map));
    printk (KERN_INFO "BIOS-provided physical RAM map:\n");
    e820_print_map (who);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="33" endline="33">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="34" endline="34">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="35" endline="35">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="36" endline="36">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="37" endline="37">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="38" endline="38">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="39" endline="39">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="40" endline="40">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="43" endline="45">
{
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="48" endline="50">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="53" endline="55">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="58" endline="60">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="63" endline="65">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="68" endline="70">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="73" endline="79">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="82" endline="90">
{
    return physid_isset (0, phys_cpu_present_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="93" endline="96">
{
    return cpumask_of (0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="99" endline="101">
{
    return physid_isset (apicid, *map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="104" endline="106">
{
    return physid_isset (bit, phys_cpu_present_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="109" endline="114">
{
    if (cpu != 0)
        pr_warning ("APIC: Vector allocated for non-BSP cpu\n");
    cpumask_clear (retmask);
    cpumask_set_cpu (cpu, retmask);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="117" endline="120">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="123" endline="126">
{
    WARN_ON_ONCE ((cpu_has_apic && ! disable_apic));
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_noop.c.ifdefed" startline="129" endline="131">
{
    WARN_ON_ONCE (cpu_has_apic && ! disable_apic);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="209" endline="211">
{
    return GET_APIC_VERSION (apic_read (APIC_LVR));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="217" endline="223">
{
    return APIC_INTEGRATED (lapic_get_version ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="229" endline="235">
{
    if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD && boot_cpu_data.x86 >= 0xf)
        return 1;
    return lapic_get_version () >= 0x14;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="242" endline="245">
{
    pr_info ("APIC: switched to apic NOOP\n");
    apic = &apic_noop;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="248" endline="251">
{
    while (apic_read (APIC_ICR) & APIC_ICR_BUSY)
        cpu_relax ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="254" endline="267">
{
    u32 send_status;
    int timeout;
    timeout = 0;
    do {
        send_status = apic_read (APIC_ICR) & APIC_ICR_BUSY;
        if (!send_status)
            break;
        udelay (100);
    }
    while (timeout++ < 1000);
    return send_status;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="259" endline="264">
{
    send_status = apic_read (APIC_ICR) & APIC_ICR_BUSY;
    if (!send_status)
        break;
    udelay (100);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="270" endline="273">
{
    apic_write (APIC_ICR2, SET_APIC_DEST_FIELD (id));
    apic_write (APIC_ICR, low);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="276" endline="283">
{
    u32 icr1, icr2;
    icr2 = apic_read (APIC_ICR2);
    icr1 = apic_read (APIC_ICR);
    return icr1 | ((u64) icr2 << 32);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="289" endline="300">
{
    unsigned int v;
    v = APIC_DM_NMI;
    if (!lapic_is_integrated ())
        v |= APIC_LVT_LEVEL_TRIGGER;
    apic_write (APIC_LVT0, v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="316" endline="325">
{
    unsigned int v;
    v = apic_read (APIC_LVR);
    return APIC_INTEGRATED (GET_APIC_VERSION (v)) ? GET_APIC_MAXLVT (v) : 2;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="345" endline="369">
{
    unsigned int lvtt_value, tmp_value;
    lvtt_value = LOCAL_TIMER_VECTOR;
    if (!oneshot)
        lvtt_value |= APIC_LVT_TIMER_PERIODIC;
    if (!lapic_is_integrated ())
        lvtt_value |= SET_APIC_TIMER_BASE (APIC_TIMER_BASE_DIV);
    if (!irqen)
        lvtt_value |= APIC_LVT_MASKED;
    apic_write (APIC_LVTT, lvtt_value);
    tmp_value = apic_read (APIC_TDCR);
    apic_write (APIC_TDCR, (tmp_value & ~ (APIC_TDR_DIV_1 | APIC_TDR_DIV_TMBASE)) | APIC_TDR_DIV_16);
    if (!oneshot)
        apic_write (APIC_TMICT, clocks / APIC_DIVISOR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="385" endline="390">
{
    unsigned long reg = (lvt_off << 4) + APIC_EILVTn (0);
    unsigned int v = (mask << 16) | (msg_type << 8) | vector;
    apic_write (reg, v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="393" endline="396">
{
    setup_APIC_eilvt (APIC_EILVT_LVTOFF_MCE, vector, msg_type, mask);
    return APIC_EILVT_LVTOFF_MCE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="399" endline="402">
{
    setup_APIC_eilvt (APIC_EILVT_LVTOFF_IBS, vector, msg_type, mask);
    return APIC_EILVT_LVTOFF_IBS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="410" endline="413">
{
    apic_write (APIC_TMICT, delta);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="420" endline="449">
{
    unsigned long flags;
    unsigned int v;
    if (evt->features & CLOCK_EVT_FEAT_DUMMY)
        return;
    local_irq_save (flags);
    switch (mode) {
    case CLOCK_EVT_MODE_PERIODIC :
    case CLOCK_EVT_MODE_ONESHOT :
        __setup_APIC_LVTT (calibration_result, mode != CLOCK_EVT_MODE_PERIODIC, 1);
        break;
    case CLOCK_EVT_MODE_UNUSED :
    case CLOCK_EVT_MODE_SHUTDOWN :
        v = apic_read (APIC_LVTT);
        v |= (APIC_LVT_MASKED | LOCAL_TIMER_VECTOR);
        apic_write (APIC_LVTT, v);
        apic_write (APIC_TMICT, 0);
        break;
    case CLOCK_EVT_MODE_RESUME :
        break;
    }
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="430" endline="446">
{
case CLOCK_EVT_MODE_PERIODIC :
case CLOCK_EVT_MODE_ONESHOT :
    __setup_APIC_LVTT (calibration_result, mode != CLOCK_EVT_MODE_PERIODIC, 1);
    break;
case CLOCK_EVT_MODE_UNUSED :
case CLOCK_EVT_MODE_SHUTDOWN :
    v = apic_read (APIC_LVTT);
    v |= (APIC_LVT_MASKED | LOCAL_TIMER_VECTOR);
    apic_write (APIC_LVTT, v);
    apic_write (APIC_TMICT, 0);
    break;
case CLOCK_EVT_MODE_RESUME :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="455" endline="459">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="466" endline="479">
{
    struct clock_event_device *levt = &__get_cpu_var (lapic_events);
    if (cpu_has (&current_cpu_data, X86_FEATURE_ARAT)) {
        lapic_clockevent.features &= ~CLOCK_EVT_FEAT_C3STOP;
        lapic_clockevent.rating = 150;
    }
    memcpy (levt, & lapic_clockevent, sizeof (* levt));
    levt->cpumask = cpumask_of (smp_processor_id ());
    clockevents_register_device (levt);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="469" endline="473">
{
    lapic_clockevent.features &= ~CLOCK_EVT_FEAT_C3STOP;
    lapic_clockevent.rating = 150;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="514" endline="539">
{
    unsigned long long tsc = 0;
    long tapic = apic_read (APIC_TMCCT);
    unsigned long pm = acpi_pm_read_early ();
    if (cpu_has_tsc)
        rdtscll (tsc);
    switch (lapic_cal_loops++) {
    case 0 :
        lapic_cal_t1 = tapic;
        lapic_cal_tsc1 = tsc;
        lapic_cal_pm1 = pm;
        lapic_cal_j1 = jiffies;
        break;
    case LAPIC_CAL_LOOPS :
        lapic_cal_t2 = tapic;
        lapic_cal_tsc2 = tsc;
        if (pm < lapic_cal_pm1)
            pm += ACPI_PM_OVRRUN;
        lapic_cal_pm2 = pm;
        lapic_cal_j2 = jiffies;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="522" endline="538">
{
case 0 :
    lapic_cal_t1 = tapic;
    lapic_cal_tsc1 = tsc;
    lapic_cal_pm1 = pm;
    lapic_cal_j1 = jiffies;
    break;
case LAPIC_CAL_LOOPS :
    lapic_cal_t2 = tapic;
    lapic_cal_tsc2 = tsc;
    if (pm < lapic_cal_pm1)
        pm += ACPI_PM_OVRRUN;
    lapic_cal_pm2 = pm;
    lapic_cal_j2 = jiffies;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="543" endline="590">
{
    const long pm_100ms = PMTMR_TICKS_PER_SEC / 10;
    const long pm_thresh = pm_100ms / 100;
    unsigned long mult;
    u64 res;
    return -1;
    apic_printk (APIC_VERBOSE, "... PM-Timer delta = %ld\n", deltapm);
    if (!deltapm)
        return -1;
    mult = clocksource_hz2mult (PMTMR_TICKS_PER_SEC, 22);
    if (deltapm > (pm_100ms - pm_thresh) && deltapm < (pm_100ms + pm_thresh)) {
        apic_printk (APIC_VERBOSE, "... PM-Timer result ok\n");
        return 0;
    }
    res = (((u64) deltapm) * mult) >> 22;
    do_div (res, 1000000);
    pr_warning ("APIC calibration not consistent " "with PM-Timer: %ldms instead of 100ms\n", (long) res);
    res = (((u64) (*delta)) * pm_100ms);
    do_div (res, deltapm);
    pr_info ("APIC delta adjusted to PM-Timer: " "%lu (%ld)\n", (unsigned long) res, * delta);
    *delta = (long) res;
    if (cpu_has_tsc) {
        res = (((u64) (*deltatsc)) * pm_100ms);
        do_div (res, deltapm);
        apic_printk (APIC_VERBOSE, "TSC delta adjusted to " "PM-Timer: %lu (%ld)\n", (unsigned long) res, * deltatsc);
        *deltatsc = (long) res;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="562" endline="565">
{
    apic_printk (APIC_VERBOSE, "... PM-Timer result ok\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="580" endline="587">
{
    res = (((u64) (*deltatsc)) * pm_100ms);
    do_div (res, deltapm);
    apic_printk (APIC_VERBOSE, "TSC delta adjusted to " "PM-Timer: %lu (%ld)\n", (unsigned long) res, * deltatsc);
    *deltatsc = (long) res;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="593" endline="712">
{
    struct clock_event_device *levt = &__get_cpu_var (lapic_events);
    void (*real_handler) (struct clock_event_device *dev);
    unsigned long deltaj;
    long delta, deltatsc;
    int pm_referenced = 0;
    local_irq_disable ();
    real_handler = global_clock_event->event_handler;
    global_clock_event->event_handler = lapic_cal_handler;
    __setup_APIC_LVTT (0xffffffff, 0, 0);
    local_irq_enable ();
    while (lapic_cal_loops <= LAPIC_CAL_LOOPS)
        cpu_relax ();
    local_irq_disable ();
    global_clock_event->event_handler = real_handler;
    delta = lapic_cal_t1 - lapic_cal_t2;
    apic_printk (APIC_VERBOSE, "... lapic delta = %ld\n", delta);
    deltatsc = (long) (lapic_cal_tsc2 - lapic_cal_tsc1);
    pm_referenced = !calibrate_by_pmtimer (lapic_cal_pm2 -lapic_cal_pm1, &delta, &deltatsc);
    lapic_clockevent.mult = div_sc (delta, TICK_NSEC *LAPIC_CAL_LOOPS, lapic_clockevent.shift);
    lapic_clockevent.max_delta_ns = clockevent_delta2ns (0x7FFFFF, &lapic_clockevent);
    lapic_clockevent.min_delta_ns = clockevent_delta2ns (0xF, &lapic_clockevent);
    calibration_result = (delta * APIC_DIVISOR) / LAPIC_CAL_LOOPS;
    apic_printk (APIC_VERBOSE, "..... delta %ld\n", delta);
    apic_printk (APIC_VERBOSE, "..... mult: %u\n", lapic_clockevent.mult);
    apic_printk (APIC_VERBOSE, "..... calibration result: %u\n", calibration_result);
    if (cpu_has_tsc) {
        apic_printk (APIC_VERBOSE, "..... CPU clock speed is " "%ld.%04ld MHz.\n", (deltatsc / LAPIC_CAL_LOOPS) / (1000000 / HZ), (deltatsc / LAPIC_CAL_LOOPS) % (1000000 / HZ));
    }
    apic_printk (APIC_VERBOSE, "..... host bus clock speed is " "%u.%04u MHz.\n", calibration_result / (1000000 / HZ), calibration_result % (1000000 / HZ));
    if (calibration_result < (1000000 / HZ)) {
        local_irq_enable ();
        pr_warning ("APIC frequency too slow, disabling apic timer\n");
        return -1;
    }
    levt->features &= ~CLOCK_EVT_FEAT_DUMMY;
    if (!pm_referenced) {
        apic_printk (APIC_VERBOSE, "... verify APIC timer\n");
        levt->event_handler = lapic_cal_handler;
        lapic_timer_setup (CLOCK_EVT_MODE_PERIODIC, levt);
        lapic_cal_loops = -1;
        local_irq_enable ();
        while (lapic_cal_loops <= LAPIC_CAL_LOOPS)
            cpu_relax ();
        lapic_timer_setup (CLOCK_EVT_MODE_SHUTDOWN, levt);
        deltaj = lapic_cal_j2 - lapic_cal_j1;
        apic_printk (APIC_VERBOSE, "... jiffies delta = %lu\n", deltaj);
        if (deltaj >= LAPIC_CAL_LOOPS - 2 && deltaj <= LAPIC_CAL_LOOPS + 2)
            apic_printk (APIC_VERBOSE, "... jiffies result ok\n");
        else
            levt->features |= CLOCK_EVT_FEAT_DUMMY;
    }
    else
        local_irq_enable ();
    if (levt->features & CLOCK_EVT_FEAT_DUMMY) {
        pr_warning ("APIC timer disabled due to verification failure\n");
        return -1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="648" endline="653">
{
    apic_printk (APIC_VERBOSE, "..... CPU clock speed is " "%ld.%04ld MHz.\n", (deltatsc / LAPIC_CAL_LOOPS) / (1000000 / HZ), (deltatsc / LAPIC_CAL_LOOPS) % (1000000 / HZ));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="663" endline="667">
{
    local_irq_enable ();
    pr_warning ("APIC frequency too slow, disabling apic timer\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="675" endline="703">
{
    apic_printk (APIC_VERBOSE, "... verify APIC timer\n");
    levt->event_handler = lapic_cal_handler;
    lapic_timer_setup (CLOCK_EVT_MODE_PERIODIC, levt);
    lapic_cal_loops = -1;
    local_irq_enable ();
    while (lapic_cal_loops <= LAPIC_CAL_LOOPS)
        cpu_relax ();
    lapic_timer_setup (CLOCK_EVT_MODE_SHUTDOWN, levt);
    deltaj = lapic_cal_j2 - lapic_cal_j1;
    apic_printk (APIC_VERBOSE, "... jiffies delta = %lu\n", deltaj);
    if (deltaj >= LAPIC_CAL_LOOPS - 2 && deltaj <= LAPIC_CAL_LOOPS + 2)
        apic_printk (APIC_VERBOSE, "... jiffies result ok\n");
    else
        levt->features |= CLOCK_EVT_FEAT_DUMMY;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="706" endline="709">
{
    pr_warning ("APIC timer disabled due to verification failure\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="720" endline="760">
{
    if (disable_apic_timer) {
        pr_info ("Disabling APIC timer\n");
        if (num_possible_cpus () > 1) {
            lapic_clockevent.mult = 1;
            setup_APIC_timer ();
        }
        return;
    }
    apic_printk (APIC_VERBOSE, "Using local APIC timer interrupts.\n" "calibrating APIC timer ...\n");
    if (calibrate_APIC_clock ()) {
        if (num_possible_cpus () > 1)
            setup_APIC_timer ();
        return;
    }
    if (nmi_watchdog != NMI_IO_APIC)
        lapic_clockevent.features &= ~CLOCK_EVT_FEAT_DUMMY;
    else
        pr_warning ("APIC timer registered as dummy," " due to nmi_watchdog=%d!\n", nmi_watchdog);
    setup_APIC_timer ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="727" endline="735">
{
    pr_info ("Disabling APIC timer\n");
    if (num_possible_cpus () > 1) {
        lapic_clockevent.mult = 1;
        setup_APIC_timer ();
    }
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="730" endline="733">
{
    lapic_clockevent.mult = 1;
    setup_APIC_timer ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="740" endline="745">
{
    if (num_possible_cpus () > 1)
        setup_APIC_timer ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="763" endline="765">
{
    setup_APIC_timer ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="771" endline="799">
{
    int cpu = smp_processor_id ();
    struct clock_event_device *evt = &per_cpu (lapic_events, cpu);
    if (!evt->event_handler) {
        pr_warning ("Spurious LAPIC timer interrupt on cpu %d\n", cpu);
        lapic_timer_setup (CLOCK_EVT_MODE_SHUTDOWN, evt);
        return;
    }
    inc_irq_stat (apic_timer_irqs);
    evt->event_handler (evt);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="786" endline="791">
{
    pr_warning ("Spurious LAPIC timer interrupt on cpu %d\n", cpu);
    lapic_timer_setup (CLOCK_EVT_MODE_SHUTDOWN, evt);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="810" endline="829">
{
    struct pt_regs *old_regs = set_irq_regs (regs);
    ack_APIC_irq ();
    exit_idle ();
    irq_enter ();
    local_apic_timer_interrupt ();
    irq_exit ();
    set_irq_regs (old_regs);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="832" endline="834">
{
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="848" endline="913">
{
    int maxlvt;
    u32 v;
    if (!x2apic_mode && !apic_phys)
        return;
    maxlvt = lapic_get_maxlvt ();
    if (maxlvt >= 3) {
        v = ERROR_APIC_VECTOR;
        apic_write (APIC_LVTERR, v | APIC_LVT_MASKED);
    }
    v = apic_read (APIC_LVTT);
    apic_write (APIC_LVTT, v | APIC_LVT_MASKED);
    v = apic_read (APIC_LVT0);
    apic_write (APIC_LVT0, v | APIC_LVT_MASKED);
    v = apic_read (APIC_LVT1);
    apic_write (APIC_LVT1, v | APIC_LVT_MASKED);
    if (maxlvt >= 4) {
        v = apic_read (APIC_LVTPC);
        apic_write (APIC_LVTPC, v | APIC_LVT_MASKED);
    }
    apic_write (APIC_LVTT, APIC_LVT_MASKED);
    apic_write (APIC_LVT0, APIC_LVT_MASKED);
    apic_write (APIC_LVT1, APIC_LVT_MASKED);
    if (maxlvt >= 3)
        apic_write (APIC_LVTERR, APIC_LVT_MASKED);
    if (maxlvt >= 4)
        apic_write (APIC_LVTPC, APIC_LVT_MASKED);
    if (lapic_is_integrated ()) {
        if (maxlvt > 3)
            apic_write (APIC_ESR, 0);
        apic_read (APIC_ESR);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="861" endline="864">
{
    v = ERROR_APIC_VECTOR;
    apic_write (APIC_LVTERR, v | APIC_LVT_MASKED);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="875" endline="878">
{
    v = apic_read (APIC_LVTPC);
    apic_write (APIC_LVTPC, v | APIC_LVT_MASKED);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="907" endline="912">
{
    if (maxlvt > 3)
        apic_write (APIC_ESR, 0);
    apic_read (APIC_ESR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="919" endline="949">
{
    unsigned int value;
    if (!apic_phys)
        return;
    clear_local_APIC ();
    value = apic_read (APIC_SPIV);
    value &= ~APIC_SPIV_APIC_ENABLED;
    apic_write (APIC_SPIV, value);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="958" endline="975">
{
    unsigned long flags;
    if (!cpu_has_apic && !apic_from_smp_config ())
        return;
    local_irq_save (flags);
    disable_local_APIC ();
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="983" endline="1036">
{
    unsigned int reg0, reg1;
    reg0 = apic_read (APIC_LVR);
    apic_printk (APIC_DEBUG, "Getting VERSION: %x\n", reg0);
    apic_write (APIC_LVR, reg0 ^ APIC_LVR_MASK);
    reg1 = apic_read (APIC_LVR);
    apic_printk (APIC_DEBUG, "Getting VERSION: %x\n", reg1);
    if (reg1 != reg0)
        return 0;
    reg1 = GET_APIC_VERSION (reg0);
    if (reg1 == 0x00 || reg1 == 0xff)
        return 0;
    reg1 = lapic_get_maxlvt ();
    if (reg1 < 0x02 || reg1 == 0xff)
        return 0;
    reg0 = apic_read (APIC_ID);
    apic_printk (APIC_DEBUG, "Getting ID: %x\n", reg0);
    apic_write (APIC_ID, reg0 ^ apic -> apic_id_mask);
    reg1 = apic_read (APIC_ID);
    apic_printk (APIC_DEBUG, "Getting ID: %x\n", reg1);
    apic_write (APIC_ID, reg0);
    if (reg1 != (reg0 ^ apic->apic_id_mask))
        return 0;
    reg0 = apic_read (APIC_LVT0);
    apic_printk (APIC_DEBUG, "Getting LVT0: %x\n", reg0);
    reg1 = apic_read (APIC_LVT1);
    apic_printk (APIC_DEBUG, "Getting LVT1: %x\n", reg1);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1042" endline="1058">
{
    if (modern_apic () || boot_cpu_data.x86_vendor == X86_VENDOR_AMD)
        return;
    apic_wait_icr_idle ();
    apic_printk (APIC_DEBUG, "Synchronizing Arb IDs.\n");
    apic_write (APIC_ICR, APIC_DEST_ALLINC | APIC_INT_LEVELTRIG | APIC_DM_INIT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1064" endline="1105">
{
    unsigned int value;
    if (smp_found_config || !cpu_has_apic)
        return;
    clear_local_APIC ();
    value = apic_read (APIC_SPIV);
    value &= ~APIC_VECTOR_MASK;
    value |= APIC_SPIV_APIC_ENABLED;
    value |= APIC_SPIV_FOCUS_DISABLED;
    value |= SPURIOUS_APIC_VECTOR;
    apic_write (APIC_SPIV, value);
    apic_write (APIC_LVT0, APIC_DM_EXTINT);
    value = APIC_DM_NMI;
    if (!lapic_is_integrated ())
        value |= APIC_LVT_LEVEL_TRIGGER;
    apic_write (APIC_LVT1, value);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1108" endline="1146">
{
    unsigned int oldvalue, value, maxlvt;
    if (!lapic_is_integrated ()) {
        pr_info ("No ESR for 82489DX.\n");
        return;
    }
    if (apic->disable_esr) {
        pr_info ("Leaving ESR disabled.\n");
        return;
    }
    maxlvt = lapic_get_maxlvt ();
    if (maxlvt > 3)
        apic_write (APIC_ESR, 0);
    oldvalue = apic_read (APIC_ESR);
    value = ERROR_APIC_VECTOR;
    apic_write (APIC_LVTERR, value);
    if (maxlvt > 3)
        apic_write (APIC_ESR, 0);
    value = apic_read (APIC_ESR);
    if (value != oldvalue)
        apic_printk (APIC_VERBOSE, "ESR value before enabling " "vector: 0x%08x  after: 0x%08x\n", oldvalue, value);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1111" endline="1114">
{
    pr_info ("No ESR for 82489DX.\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1116" endline="1125">
{
    pr_info ("Leaving ESR disabled.\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1153" endline="1300">
{
    unsigned int value;
    int i, j;
    if (disable_apic) {
        arch_disable_smp_support ();
        return;
    }
    perf_events_lapic_init ();
    preempt_disable ();
    BUG_ON (! apic -> apic_id_registered ());
    apic->init_apic_ldr ();
    value = apic_read (APIC_TASKPRI);
    value &= ~APIC_TPRI_MASK;
    apic_write (APIC_TASKPRI, value);
    for (i = APIC_ISR_NR - 1; i >= 0; i--) {
        value = apic_read (APIC_ISR +i * 0x10);
        for (j = 31; j >= 0; j--) {
            if (value & (1 << j))
                ack_APIC_irq ();
        }
    }
    value = apic_read (APIC_SPIV);
    value &= ~APIC_VECTOR_MASK;
    value |= APIC_SPIV_APIC_ENABLED;
    value |= SPURIOUS_APIC_VECTOR;
    apic_write (APIC_SPIV, value);
    value = apic_read (APIC_LVT0) & APIC_LVT_MASKED;
    if (!smp_processor_id () && (pic_mode || !value)) {
        value = APIC_DM_EXTINT;
        apic_printk (APIC_VERBOSE, "enabled ExtINT on CPU#%d\n", smp_processor_id ());
    }
    else {
        value = APIC_DM_EXTINT | APIC_LVT_MASKED;
        apic_printk (APIC_VERBOSE, "masked ExtINT on CPU#%d\n", smp_processor_id ());
    }
    apic_write (APIC_LVT0, value);
    if (!smp_processor_id ())
        value = APIC_DM_NMI;
    else
        value = APIC_DM_NMI | APIC_LVT_MASKED;
    if (!lapic_is_integrated ())
        value |= APIC_LVT_LEVEL_TRIGGER;
    apic_write (APIC_LVT1, value);
    preempt_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1157" endline="1160">
{
    arch_disable_smp_support ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1207" endline="1213">
{
    value = apic_read (APIC_ISR +i * 0x10);
    for (j = 31; j >= 0; j--) {
        if (value & (1 << j))
            ack_APIC_irq ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1209" endline="1212">
{
    if (value & (1 << j))
        ack_APIC_irq ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1271" endline="1275">
{
    value = APIC_DM_EXTINT;
    apic_printk (APIC_VERBOSE, "enabled ExtINT on CPU#%d\n", smp_processor_id ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1275" endline="1279">
{
    value = APIC_DM_EXTINT | APIC_LVT_MASKED;
    apic_printk (APIC_VERBOSE, "masked ExtINT on CPU#%d\n", smp_processor_id ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1303" endline="1318">
{
    lapic_setup_esr ();
    setup_apic_nmi_watchdog (NULL);
    apic_pm_activate ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1345" endline="1367">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1370" endline="1439">
{
    unsigned long flags;
    struct IO_APIC_route_entry **ioapic_entries = NULL;
    int ret, x2apic_enabled = 0;
    int dmar_table_init_ret;
    dmar_table_init_ret = dmar_table_init ();
    if (dmar_table_init_ret && !x2apic_supported ())
        return;
    ioapic_entries = alloc_ioapic_entries ();
    if (!ioapic_entries) {
        pr_err ("Allocate ioapic_entries failed\n");
        goto out;
    }
    ret = save_IO_APIC_setup (ioapic_entries);
    if (ret) {
        pr_info ("Saving IO-APIC state failed: %d\n", ret);
        goto out;
    }
    local_irq_save (flags);
    legacy_pic->mask_all ();
    mask_IO_APIC_setup (ioapic_entries);
    if (dmar_table_init_ret)
        ret = 0;
    else
        ret = enable_IR ();
    if (!ret) {
        if (max_physical_apicid > 255 || !kvm_para_available ())
            goto nox2apic;
        x2apic_force_phys ();
    }
    x2apic_enabled = 1;
    if (x2apic_supported () && !x2apic_mode) {
        x2apic_mode = 1;
        enable_x2apic ();
        pr_info ("Enabled x2apic\n");
    }
nox2apic :
    if (!ret)
        restore_IO_APIC_setup (ioapic_entries);
    legacy_pic->restore_mask ();
    local_irq_restore (flags);
out :
    if (ioapic_entries)
        free_ioapic_entries (ioapic_entries);
    if (x2apic_enabled)
        return;
    if (x2apic_preenabled)
        panic ("x2apic: enabled by BIOS but kernel init failed.");
    else if (cpu_has_x2apic)
        pr_info ("Not enabling x2apic, Intr-remapping init failed.\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1381" endline="1384">
{
    pr_err ("Allocate ioapic_entries failed\n");
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1387" endline="1390">
{
    pr_info ("Saving IO-APIC state failed: %d\n", ret);
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1401" endline="1412">
{
    if (max_physical_apicid > 255 || !kvm_para_available ())
        goto nox2apic;
    x2apic_force_phys ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1416" endline="1420">
{
    x2apic_mode = 1;
    enable_x2apic ();
    pr_info ("Enabled x2apic\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1463" endline="1535">
{
    u32 h, l, features;
    if (disable_apic)
        return -1;
    switch (boot_cpu_data.x86_vendor) {
    case X86_VENDOR_AMD :
        if ((boot_cpu_data.x86 == 6 && boot_cpu_data.x86_model > 1) || (boot_cpu_data.x86 >= 15))
            break;
        goto no_apic;
    case X86_VENDOR_INTEL :
        if (boot_cpu_data.x86 == 6 || boot_cpu_data.x86 == 15 || (boot_cpu_data.x86 == 5 && cpu_has_apic))
            break;
        goto no_apic;
    default :
        goto no_apic;
    }
    if (!cpu_has_apic) {
        if (!force_enable_local_apic) {
            pr_info ("Local APIC disabled by BIOS -- " "you can enable it with \"lapic\"\n");
            return -1;
        }
        rdmsr (MSR_IA32_APICBASE, l, h);
        if (!(l & MSR_IA32_APICBASE_ENABLE)) {
            pr_info ("Local APIC disabled by BIOS -- reenabling.\n");
            l &= ~MSR_IA32_APICBASE_BASE;
            l |= MSR_IA32_APICBASE_ENABLE | APIC_DEFAULT_PHYS_BASE;
            wrmsr (MSR_IA32_APICBASE, l, h);
            enabled_via_apicbase = 1;
        }
    }
    features = cpuid_edx (1);
    if (!(features & (1 << X86_FEATURE_APIC))) {
        pr_warning ("Could not enable APIC!\n");
        return -1;
    }
    set_cpu_cap (& boot_cpu_data, X86_FEATURE_APIC);
    mp_lapic_addr = APIC_DEFAULT_PHYS_BASE;
    rdmsr (MSR_IA32_APICBASE, l, h);
    if (l & MSR_IA32_APICBASE_ENABLE)
        mp_lapic_addr = l & MSR_IA32_APICBASE_BASE;
    pr_info ("Found and enabled local APIC!\n");
    apic_pm_activate ();
    return 0;
no_apic :
    pr_info ("No local APIC present or hardware disabled\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1470" endline="1483">
{
case X86_VENDOR_AMD :
    if ((boot_cpu_data.x86 == 6 && boot_cpu_data.x86_model > 1) || (boot_cpu_data.x86 >= 15))
        break;
    goto no_apic;
case X86_VENDOR_INTEL :
    if (boot_cpu_data.x86 == 6 || boot_cpu_data.x86 == 15 || (boot_cpu_data.x86 == 5 && cpu_has_apic))
        break;
    goto no_apic;
default :
    goto no_apic;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1485" endline="1508">
{
    if (!force_enable_local_apic) {
        pr_info ("Local APIC disabled by BIOS -- " "you can enable it with \"lapic\"\n");
        return -1;
    }
    rdmsr (MSR_IA32_APICBASE, l, h);
    if (!(l & MSR_IA32_APICBASE_ENABLE)) {
        pr_info ("Local APIC disabled by BIOS -- reenabling.\n");
        l &= ~MSR_IA32_APICBASE_BASE;
        l |= MSR_IA32_APICBASE_ENABLE | APIC_DEFAULT_PHYS_BASE;
        wrmsr (MSR_IA32_APICBASE, l, h);
        enabled_via_apicbase = 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1490" endline="1494">
{
    pr_info ("Local APIC disabled by BIOS -- " "you can enable it with \"lapic\"\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1501" endline="1507">
{
    pr_info ("Local APIC disabled by BIOS -- reenabling.\n");
    l &= ~MSR_IA32_APICBASE_BASE;
    l |= MSR_IA32_APICBASE_ENABLE | APIC_DEFAULT_PHYS_BASE;
    wrmsr (MSR_IA32_APICBASE, l, h);
    enabled_via_apicbase = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1514" endline="1517">
{
    pr_warning ("Could not enable APIC!\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1564" endline="1608">
{
    unsigned int new_apicid;
    if (x2apic_mode) {
        boot_cpu_physical_apicid = read_apic_id ();
        return;
    }
    if (!smp_found_config && detect_init_APIC ()) {
        pr_info ("APIC: disable apic facility\n");
        apic_disable ();
    }
    else {
        apic_phys = mp_lapic_addr;
        if (!acpi_lapic)
            set_fixmap_nocache (FIX_APIC_BASE, apic_phys);
        apic_printk (APIC_VERBOSE, "mapped APIC to %08lx (%08lx)\n", APIC_BASE, apic_phys);
    }
    new_apicid = read_apic_id ();
    if (boot_cpu_physical_apicid != new_apicid) {
        boot_cpu_physical_apicid = new_apicid;
        apic_version[new_apicid] = GET_APIC_VERSION (apic_read (APIC_LVR));
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1567" endline="1570">
{
    boot_cpu_physical_apicid = read_apic_id ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1573" endline="1577">
{
    pr_info ("APIC: disable apic facility\n");
    apic_disable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1577" endline="1589">
{
    apic_phys = mp_lapic_addr;
    if (!acpi_lapic)
        set_fixmap_nocache (FIX_APIC_BASE, apic_phys);
    apic_printk (APIC_VERBOSE, "mapped APIC to %08lx (%08lx)\n", APIC_BASE, apic_phys);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1596" endline="1607">
{
    boot_cpu_physical_apicid = new_apicid;
    apic_version[new_apicid] = GET_APIC_VERSION (apic_read (APIC_LVR));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1617" endline="1694">
{
    if (disable_apic) {
        pr_info ("Apic disabled\n");
        return -1;
    }
    if (!smp_found_config && !cpu_has_apic)
        return -1;
    if (!cpu_has_apic && APIC_INTEGRATED (apic_version[boot_cpu_physical_apicid])) {
        pr_err ("BIOS bug, local APIC 0x%x not detected!...\n", boot_cpu_physical_apicid);
        return -1;
    }
    enable_IR_x2apic ();
    default_setup_apic_routing ();
    verify_local_APIC ();
    connect_bsp_APIC ();
    physid_set_mask_of_physid (boot_cpu_physical_apicid, & phys_cpu_present_map);
    setup_local_APIC ();
    end_local_APIC_setup ();
    localise_nmi_watchdog ();
    x86_init.timers.setup_percpu_clockev ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1618" endline="1621">
{
    pr_info ("Apic disabled\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1636" endline="1640">
{
    pr_err ("BIOS bug, local APIC 0x%x not detected!...\n", boot_cpu_physical_apicid);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1704" endline="1724">
{
    u32 v;
    exit_idle ();
    irq_enter ();
    v = apic_read (APIC_ISR +((SPURIOUS_APIC_VECTOR & ~0x1f) >> 1));
    if (v & (1 << (SPURIOUS_APIC_VECTOR & 0x1f)))
        ack_APIC_irq ();
    inc_irq_stat (irq_spurious_count);
    pr_info ("spurious APIC interrupt on CPU#%d, " "should never happen.\n", smp_processor_id ());
    irq_exit ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1730" endline="1756">
{
    u32 v, v1;
    exit_idle ();
    irq_enter ();
    v = apic_read (APIC_ESR);
    apic_write (APIC_ESR, 0);
    v1 = apic_read (APIC_ESR);
    ack_APIC_irq ();
    atomic_inc (& irq_err_count);
    pr_debug ("APIC error on CPU%d: %02x(%02x)\n", smp_processor_id (), v, v1);
    irq_exit ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1762" endline="1780">
{
    if (apic->enable_apic_mode)
        apic->enable_apic_mode ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1790" endline="1845">
{
    unsigned int value;
    value = apic_read (APIC_SPIV);
    value &= ~APIC_VECTOR_MASK;
    value |= APIC_SPIV_APIC_ENABLED;
    value |= 0xf;
    apic_write (APIC_SPIV, value);
    if (!virt_wire_setup) {
        value = apic_read (APIC_LVT0);
        value &= ~(APIC_MODE_MASK | APIC_SEND_PENDING | APIC_INPUT_POLARITY | APIC_LVT_REMOTE_IRR | APIC_LVT_LEVEL_TRIGGER | APIC_LVT_MASKED);
        value |= APIC_LVT_REMOTE_IRR | APIC_SEND_PENDING;
        value = SET_APIC_DELIVERY_MODE (value, APIC_MODE_EXTINT);
        apic_write (APIC_LVT0, value);
    }
    else {
        apic_write (APIC_LVT0, APIC_LVT_MASKED);
    }
    value = apic_read (APIC_LVT1);
    value &= ~(APIC_MODE_MASK | APIC_SEND_PENDING | APIC_INPUT_POLARITY | APIC_LVT_REMOTE_IRR | APIC_LVT_LEVEL_TRIGGER | APIC_LVT_MASKED);
    value |= APIC_LVT_REMOTE_IRR | APIC_SEND_PENDING;
    value = SET_APIC_DELIVERY_MODE (value, APIC_MODE_NMI);
    apic_write (APIC_LVT1, value);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1817" endline="1829">
{
    value = apic_read (APIC_LVT0);
    value &= ~(APIC_MODE_MASK | APIC_SEND_PENDING | APIC_INPUT_POLARITY | APIC_LVT_REMOTE_IRR | APIC_LVT_LEVEL_TRIGGER | APIC_LVT_MASKED);
    value |= APIC_LVT_REMOTE_IRR | APIC_SEND_PENDING;
    value = SET_APIC_DELIVERY_MODE (value, APIC_MODE_EXTINT);
    apic_write (APIC_LVT0, value);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1829" endline="1832">
{
    apic_write (APIC_LVT0, APIC_LVT_MASKED);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1848" endline="1901">
{
    int cpu;
    if (version == 0x0) {
        pr_warning ("BIOS bug, APIC version is 0 for CPU#%d! " "fixing up to 0x10. (tell your hw vendor)\n", version);
        version = 0x10;
    }
    apic_version[apicid] = version;
    if (num_processors >= nr_cpu_ids) {
        int max = nr_cpu_ids;
        int thiscpu = max + disabled_cpus;
        pr_warning ("ACPI: NR_CPUS/possible_cpus limit of %i reached." "  Processor %d/0x%x ignored.\n", max, thiscpu, apicid);
        disabled_cpus++;
        return;
    }
    num_processors++;
    cpu = cpumask_next_zero (-1, cpu_present_mask);
    if (version != apic_version[boot_cpu_physical_apicid])
        WARN_ONCE (1, "ACPI: apic version mismatch, bootcpu: %x cpu %d: %x\n", apic_version[boot_cpu_physical_apicid], cpu, version);
    physid_set (apicid, phys_cpu_present_map);
    if (apicid == boot_cpu_physical_apicid) {
        cpu = 0;
    }
    if (apicid > max_physical_apicid)
        max_physical_apicid = apicid;
    set_cpu_possible (cpu, true);
    set_cpu_present (cpu, true);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1854" endline="1859">
{
    pr_warning ("BIOS bug, APIC version is 0 for CPU#%d! " "fixing up to 0x10. (tell your hw vendor)\n", version);
    version = 0x10;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1862" endline="1872">
{
    int max = nr_cpu_ids;
    int thiscpu = max + disabled_cpus;
    pr_warning ("ACPI: NR_CPUS/possible_cpus limit of %i reached." "  Processor %d/0x%x ignored.\n", max, thiscpu, apicid);
    disabled_cpus++;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1883" endline="1890">
{
    cpu = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1904" endline="1906">
{
    return read_apic_id ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="1909" endline="1916">
{
    unsigned long val;
    apic_write (APIC_DFR, APIC_DFR_VALUE);
    val = apic_read (APIC_LDR) & ~APIC_LDR_MASK;
    val |= SET_APIC_LOGICAL_ID (1UL << smp_processor_id ());
    apic_write (APIC_LDR, val);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="2117" endline="2117">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="2233" endline="2237">
{
    disable_apic = 1;
    setup_clear_cpu_cap (X86_FEATURE_APIC);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="2242" endline="2244">
{
    return setup_disableapic (arg);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="2248" endline="2251">
{
    local_apic_timer_c2_ok = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="2255" endline="2258">
{
    disable_apic_timer = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="2262" endline="2265">
{
    disable_apic_timer = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="2269" endline="2289">
{
    if (!arg) {
        return -EINVAL;
    }
    if (strcmp ("debug", arg) == 0)
        apic_verbosity = APIC_DEBUG;
    else if (strcmp ("verbose", arg) == 0)
        apic_verbosity = APIC_VERBOSE;
    else {
        pr_warning ("APIC Verbosity level %s not recognised" " use apic=verbose or apic=debug\n", arg);
        return -EINVAL;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="2270" endline="2276">
{
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="2282" endline="2286">
{
    pr_warning ("APIC Verbosity level %s not recognised" " use apic=verbose or apic=debug\n", arg);
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic.c.ifdefed" startline="2293" endline="2303">
{
    if (!apic_phys)
        return -1;
    lapic_resource.start = apic_phys;
    lapic_resource.end = lapic_resource.start + PAGE_SIZE - 1;
    insert_resource (& iomem_resource, & lapic_resource);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="110" endline="116">
{
    skip_ioapic_setup = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="119" endline="123">
{
    arch_disable_smp_support ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="132" endline="138">
{
    struct irq_pin_list *pin;
    pin = kzalloc_node (sizeof (*pin), GFP_ATOMIC, node);
    return pin;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="148" endline="180">
{
    struct irq_cfg *cfg;
    struct irq_desc *desc;
    int count;
    int node;
    int i;
    if (!legacy_pic->nr_legacy_irqs) {
        nr_irqs_gsi = 0;
        io_apic_irqs = ~0UL;
    }
    cfg = irq_cfgx;
    count = ARRAY_SIZE (irq_cfgx);
    node = cpu_to_node (boot_cpu_id);
    for (i = 0; i < count; i++) {
        desc = irq_to_desc (i);
        desc->chip_data = &cfg[i];
        zalloc_cpumask_var_node (& cfg [i].domain, GFP_NOWAIT, node);
        zalloc_cpumask_var_node (& cfg [i].old_domain, GFP_NOWAIT, node);
        if (i < legacy_pic->nr_legacy_irqs) {
            cfg[i].vector = IRQ0_VECTOR + i;
            cpumask_set_cpu (0, cfg [i].domain);
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="155" endline="158">
{
    nr_irqs_gsi = 0;
    io_apic_irqs = ~0UL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="164" endline="177">
{
    desc = irq_to_desc (i);
    desc->chip_data = &cfg[i];
    zalloc_cpumask_var_node (& cfg [i].domain, GFP_NOWAIT, node);
    zalloc_cpumask_var_node (& cfg [i].old_domain, GFP_NOWAIT, node);
    if (i < legacy_pic->nr_legacy_irqs) {
        cfg[i].vector = IRQ0_VECTOR + i;
        cpumask_set_cpu (0, cfg [i].domain);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="173" endline="176">
{
    cfg[i].vector = IRQ0_VECTOR + i;
    cpumask_set_cpu (0, cfg [i].domain);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="336" endline="338">
{
    return irq < nr_irqs ? irq_cfgx + irq : NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="351" endline="354">
{
    return (void __iomem *) __fix_to_virt (FIX_IO_APIC_BASE_0 +idx) + (mp_ioapics[idx].apicaddr & ~PAGE_MASK);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="357" endline="360">
{
    struct io_apic __iomem *io_apic = io_apic_base (apic);
    writel (vector, & io_apic -> eoi);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="363" endline="367">
{
    struct io_apic __iomem *io_apic = io_apic_base (apic);
    writel (reg, & io_apic -> index);
    return readl (&io_apic->data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="370" endline="374">
{
    struct io_apic __iomem *io_apic = io_apic_base (apic);
    writel (reg, & io_apic -> index);
    writel (value, & io_apic -> data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="383" endline="389">
{
    struct io_apic __iomem *io_apic = io_apic_base (apic);
    if (sis_apic_bug)
        writel (reg, &io_apic->index);
    writel (value, & io_apic -> data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="392" endline="412">
{
    struct irq_pin_list *entry;
    unsigned long flags;
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    for_each_irq_pin (entry, cfg -> irq_2_pin)
    {
        unsigned int reg;
        int pin;
        pin = entry->pin;
        reg = io_apic_read (entry->apic, 0x10 + pin * 2);
        if (reg & IO_APIC_REDIR_REMOTE_IRR) {
            raw_spin_unlock_irqrestore (& ioapic_lock, flags);
            return true;
        }
    }
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
    return false;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="397" endline="408">
{
    unsigned int reg;
    int pin;
    pin = entry->pin;
    reg = io_apic_read (entry->apic, 0x10 + pin * 2);
    if (reg & IO_APIC_REDIR_REMOTE_IRR) {
        raw_spin_unlock_irqrestore (& ioapic_lock, flags);
        return true;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="404" endline="407">
{
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
    return true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="420" endline="428">
{
    union entry_union eu;
    unsigned long flags;
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    eu.w1 = io_apic_read (apic, 0x10 + 2 * pin);
    eu.w2 = io_apic_read (apic, 0x11 + 2 * pin);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
    return eu.entry;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="438" endline="444">
{
    union entry_union eu = {{0, 0}};
    eu.entry = e;
    io_apic_write (apic, 0x11 + 2 * pin, eu.w2);
    io_apic_write (apic, 0x10 + 2 * pin, eu.w1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="447" endline="452">
{
    unsigned long flags;
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    __ioapic_write_entry (apic, pin, e);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="460" endline="468">
{
    unsigned long flags;
    union entry_union eu = {
        .entry.mask = 1
    };
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    io_apic_write (apic, 0x10 + 2 * pin, eu.w1);
    io_apic_write (apic, 0x11 + 2 * pin, eu.w2);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="477" endline="499">
{
    struct irq_pin_list **last, *entry;
    last = &cfg->irq_2_pin;
    for_each_irq_pin (entry, cfg -> irq_2_pin)
    {
        if (entry->apic == apic && entry->pin == pin)
            return 0;
        last = &entry->next;
    }
    entry = get_one_free_irq_2_pin (node);
    if (!entry) {
        printk (KERN_ERR "can not alloc irq_pin_list (%d,%d,%d)\n", node, apic, pin);
        return -ENOMEM;
    }
    entry->apic = apic;
    entry->pin = pin;
    *last = entry;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="482" endline="486">
{
    if (entry->apic == apic && entry->pin == pin)
        return 0;
    last = &entry->next;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="489" endline="493">
{
    printk (KERN_ERR "can not alloc irq_pin_list (%d,%d,%d)\n", node, apic, pin);
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="502" endline="505">
{
    if (add_pin_to_irq_node_nopanic (cfg, node, apic, pin))
        panic ("IO-APIC: failed to add irq-pin. Can not proceed\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="513" endline="527">
{
    struct irq_pin_list *entry;
    for_each_irq_pin (entry, cfg -> irq_2_pin)
    {
        if (entry->apic == oldapic && entry->pin == oldpin) {
            entry->apic = newapic;
            entry->pin = newpin;
            return;
        }
    }
    add_pin_to_irq_node (cfg, node, newapic, newpin);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="516" endline="523">
{
    if (entry->apic == oldapic && entry->pin == oldpin) {
        entry->apic = newapic;
        entry->pin = newpin;
        return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="517" endline="522">
{
    entry->apic = newapic;
    entry->pin = newpin;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="532" endline="542">
{
    unsigned int reg, pin;
    pin = entry->pin;
    reg = io_apic_read (entry->apic, 0x10 + pin * 2);
    reg &= mask_and;
    reg |= mask_or;
    io_apic_modify (entry -> apic, 0x10 + pin * 2, reg);
    if (final)
        final (entry);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="547" endline="552">
{
    struct irq_pin_list *entry;
    for_each_irq_pin (entry, cfg -> irq_2_pin)
    __io_apic_modify_irq (entry, mask_and, mask_or, final);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="555" endline="558">
{
    __io_apic_modify_irq (entry, ~ IO_APIC_REDIR_LEVEL_TRIGGER, IO_APIC_REDIR_MASKED, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="561" endline="564">
{
    __io_apic_modify_irq (entry, ~ IO_APIC_REDIR_MASKED, IO_APIC_REDIR_LEVEL_TRIGGER, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="567" endline="569">
{
    io_apic_modify_irq (cfg, ~ IO_APIC_REDIR_MASKED, 0, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="572" endline="580">
{
    struct io_apic __iomem *io_apic;
    io_apic = io_apic_base (entry->apic);
    readl (& io_apic -> data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="583" endline="585">
{
    io_apic_modify_irq (cfg, ~ 0, IO_APIC_REDIR_MASKED, & io_apic_sync);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="588" endline="597">
{
    struct irq_cfg *cfg = desc->chip_data;
    unsigned long flags;
    BUG_ON (! cfg);
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    __mask_IO_APIC_irq (cfg);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="600" endline="607">
{
    struct irq_cfg *cfg = desc->chip_data;
    unsigned long flags;
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    __unmask_IO_APIC_irq (cfg);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="610" endline="614">
{
    struct irq_desc *desc = irq_to_desc (irq);
    mask_IO_APIC_irq_desc (desc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="616" endline="620">
{
    struct irq_desc *desc = irq_to_desc (irq);
    unmask_IO_APIC_irq_desc (desc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="623" endline="634">
{
    struct IO_APIC_route_entry entry;
    entry = ioapic_read_entry (apic, pin);
    if (entry.delivery_mode == dest_SMI)
        return;
    ioapic_mask_entry (apic, pin);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="637" endline="643">
{
    int apic, pin;
    for (apic = 0; apic < nr_ioapics; apic++)
        for (pin = 0; pin < nr_ioapic_registers[apic]; pin++)
            clear_IO_APIC_pin (apic, pin);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="684" endline="709">
{
    int apic;
    struct IO_APIC_route_entry **ioapic_entries;
    ioapic_entries = kzalloc (sizeof (*ioapic_entries) * nr_ioapics, GFP_ATOMIC);
    if (!ioapic_entries)
        return 0;
    for (apic = 0; apic < nr_ioapics; apic++) {
        ioapic_entries[apic] = kzalloc (sizeof (struct IO_APIC_route_entry) * nr_ioapic_registers[apic], GFP_ATOMIC);
        if (!ioapic_entries[apic])
            goto nomem;
    }
    return ioapic_entries;
nomem :
    while (--apic >= 0)
        kfree (ioapic_entries[apic]);
    kfree (ioapic_entries);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="693" endline="699">
{
    ioapic_entries[apic] = kzalloc (sizeof (struct IO_APIC_route_entry) * nr_ioapic_registers[apic], GFP_ATOMIC);
    if (!ioapic_entries[apic])
        goto nomem;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="715" endline="731">
{
    int apic, pin;
    if (!ioapic_entries)
        return -ENOMEM;
    for (apic = 0; apic < nr_ioapics; apic++) {
        if (!ioapic_entries[apic])
            return -ENOMEM;
        for (pin = 0; pin < nr_ioapic_registers[apic]; pin++)
            ioapic_entries[apic][pin] = ioapic_read_entry (apic, pin);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="721" endline="728">
{
    if (!ioapic_entries[apic])
        return -ENOMEM;
    for (pin = 0; pin < nr_ioapic_registers[apic]; pin++)
        ioapic_entries[apic][pin] = ioapic_read_entry (apic, pin);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="737" endline="757">
{
    int apic, pin;
    if (!ioapic_entries)
        return;
    for (apic = 0; apic < nr_ioapics; apic++) {
        if (!ioapic_entries[apic])
            break;
        for (pin = 0; pin < nr_ioapic_registers[apic]; pin++) {
            struct IO_APIC_route_entry entry;
            entry = ioapic_entries[apic][pin];
            if (!entry.mask) {
                entry.mask = 1;
                ioapic_write_entry (apic, pin, entry);
            }
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="743" endline="756">
{
    if (!ioapic_entries[apic])
        break;
    for (pin = 0; pin < nr_ioapic_registers[apic]; pin++) {
        struct IO_APIC_route_entry entry;
        entry = ioapic_entries[apic][pin];
        if (!entry.mask) {
            entry.mask = 1;
            ioapic_write_entry (apic, pin, entry);
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="747" endline="755">
{
    struct IO_APIC_route_entry entry;
    entry = ioapic_entries[apic][pin];
    if (!entry.mask) {
        entry.mask = 1;
        ioapic_write_entry (apic, pin, entry);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="751" endline="754">
{
    entry.mask = 1;
    ioapic_write_entry (apic, pin, entry);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="763" endline="778">
{
    int apic, pin;
    if (!ioapic_entries)
        return -ENOMEM;
    for (apic = 0; apic < nr_ioapics; apic++) {
        if (!ioapic_entries[apic])
            return -ENOMEM;
        for (pin = 0; pin < nr_ioapic_registers[apic]; pin++)
            ioapic_write_entry (apic, pin, ioapic_entries[apic][pin]);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="769" endline="776">
{
    if (!ioapic_entries[apic])
        return -ENOMEM;
    for (pin = 0; pin < nr_ioapic_registers[apic]; pin++)
        ioapic_write_entry (apic, pin, ioapic_entries[apic][pin]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="781" endline="788">
{
    int apic;
    for (apic = 0; apic < nr_ioapics; apic++)
        kfree (ioapic_entries[apic]);
    kfree (ioapic_entries);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="794" endline="805">
{
    int i;
    for (i = 0; i < mp_irq_entries; i++)
        if (mp_irqs[i].irqtype == type && (mp_irqs[i].dstapic == mp_ioapics[apic].apicid || mp_irqs[i].dstapic == MP_APIC_ALL) && mp_irqs[i].dstirq == pin)
            return i;
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="811" endline="824">
{
    int i;
    for (i = 0; i < mp_irq_entries; i++) {
        int lbus = mp_irqs[i].srcbus;
        if (test_bit (lbus, mp_bus_not_pci) && (mp_irqs[i].irqtype == type) && (mp_irqs[i].srcbusirq == irq))
            return mp_irqs[i].dstirq;
    }
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="814" endline="822">
{
    int lbus = mp_irqs[i].srcbus;
    if (test_bit (lbus, mp_bus_not_pci) && (mp_irqs[i].irqtype == type) && (mp_irqs[i].srcbusirq == irq))
        return mp_irqs[i].dstirq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="827" endline="847">
{
    int i;
    for (i = 0; i < mp_irq_entries; i++) {
        int lbus = mp_irqs[i].srcbus;
        if (test_bit (lbus, mp_bus_not_pci) && (mp_irqs[i].irqtype == type) && (mp_irqs[i].srcbusirq == irq))
            break;
    }
    if (i < mp_irq_entries) {
        int apic;
        for (apic = 0; apic < nr_ioapics; apic++) {
            if (mp_ioapics[apic].apicid == mp_irqs[i].dstapic)
                return apic;
        }
    }
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="830" endline="837">
{
    int lbus = mp_irqs[i].srcbus;
    if (test_bit (lbus, mp_bus_not_pci) && (mp_irqs[i].irqtype == type) && (mp_irqs[i].srcbusirq == irq))
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="838" endline="844">
{
    int apic;
    for (apic = 0; apic < nr_ioapics; apic++) {
        if (mp_ioapics[apic].apicid == mp_irqs[i].dstapic)
            return apic;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="840" endline="843">
{
    if (mp_ioapics[apic].apicid == mp_irqs[i].dstapic)
        return apic;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="893" endline="932">
{
    int bus = mp_irqs[idx].srcbus;
    int polarity;
    switch (mp_irqs[idx].irqflag & 3) {
    case 0 :
        if (test_bit (bus, mp_bus_not_pci))
            polarity = default_ISA_polarity (idx);
        else
            polarity = default_PCI_polarity (idx);
        break;
    case 1 :
        {
            polarity = 0;
            break;
        }
    case 2 :
        {
            printk (KERN_WARNING "broken BIOS!!\n");
            polarity = 1;
            break;
        }
    case 3 :
        {
            polarity = 1;
            break;
        }
    default :
        {
            printk (KERN_WARNING "broken BIOS!!\n");
            polarity = 1;
            break;
        }
    }
    return polarity;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="901" endline="930">
{
case 0 :
    if (test_bit (bus, mp_bus_not_pci))
        polarity = default_ISA_polarity (idx);
    else
        polarity = default_PCI_polarity (idx);
    break;
case 1 :
    {
        polarity = 0;
        break;
    }
case 2 :
    {
        printk (KERN_WARNING "broken BIOS!!\n");
        polarity = 1;
        break;
    }
case 3 :
    {
        polarity = 1;
        break;
    }
default :
    {
        printk (KERN_WARNING "broken BIOS!!\n");
        polarity = 1;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="909" endline="912">
{
    polarity = 0;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="914" endline="918">
{
    printk (KERN_WARNING "broken BIOS!!\n");
    polarity = 1;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="920" endline="923">
{
    polarity = 1;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="925" endline="929">
{
    printk (KERN_WARNING "broken BIOS!!\n");
    polarity = 1;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="935" endline="1004">
{
    int bus = mp_irqs[idx].srcbus;
    int trigger;
    switch ((mp_irqs[idx].irqflag >> 2) & 3) {
    case 0 :
        if (test_bit (bus, mp_bus_not_pci))
            trigger = default_ISA_trigger (idx);
        else
            trigger = default_PCI_trigger (idx);
        break;
    case 1 :
        {
            trigger = 0;
            break;
        }
    case 2 :
        {
            printk (KERN_WARNING "broken BIOS!!\n");
            trigger = 1;
            break;
        }
    case 3 :
        {
            trigger = 1;
            break;
        }
    default :
        {
            printk (KERN_WARNING "broken BIOS!!\n");
            trigger = 0;
            break;
        }
    }
    return trigger;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="943" endline="1002">
{
case 0 :
    if (test_bit (bus, mp_bus_not_pci))
        trigger = default_ISA_trigger (idx);
    else
        trigger = default_PCI_trigger (idx);
    break;
case 1 :
    {
        trigger = 0;
        break;
    }
case 2 :
    {
        printk (KERN_WARNING "broken BIOS!!\n");
        trigger = 1;
        break;
    }
case 3 :
    {
        trigger = 1;
        break;
    }
default :
    {
        printk (KERN_WARNING "broken BIOS!!\n");
        trigger = 0;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="981" endline="984">
{
    trigger = 0;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="986" endline="990">
{
    printk (KERN_WARNING "broken BIOS!!\n");
    trigger = 1;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="992" endline="995">
{
    trigger = 1;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="997" endline="1001">
{
    printk (KERN_WARNING "broken BIOS!!\n");
    trigger = 0;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1007" endline="1009">
{
    return MPBIOS_polarity (idx);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1012" endline="1014">
{
    return MPBIOS_trigger (idx);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1018" endline="1065">
{
    int irq, i;
    int bus = mp_irqs[idx].srcbus;
    if (mp_irqs[idx].dstirq != pin)
        printk (KERN_ERR "broken BIOS or MPTABLE parser, ayiee!!\n");
    if (test_bit (bus, mp_bus_not_pci)) {
        irq = mp_irqs[idx].srcbusirq;
    }
    else {
        i = irq = 0;
        while (i < apic)
            irq += nr_ioapic_registers[i++];
        irq += pin;
        if (ioapic_renumber_irq)
            irq = ioapic_renumber_irq (apic, irq);
    }
    return irq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1028" endline="1030">
{
    irq = mp_irqs[idx].srcbusirq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1030" endline="1043">
{
    i = irq = 0;
    while (i < apic)
        irq += nr_ioapic_registers[i++];
    irq += pin;
    if (ioapic_renumber_irq)
        irq = ioapic_renumber_irq (apic, irq);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1073" endline="1122">
{
    int apic, i, best_guess = -1;
    apic_printk (APIC_DEBUG, "querying PCI -> IRQ mapping bus:%d, slot:%d, pin:%d.\n", bus, slot, pin);
    if (test_bit (bus, mp_bus_not_pci)) {
        apic_printk (APIC_VERBOSE, "PCI BIOS passed nonexistent PCI bus %d!\n", bus);
        return -1;
    }
    for (i = 0; i < mp_irq_entries; i++) {
        int lbus = mp_irqs[i].srcbus;
        for (apic = 0; apic < nr_ioapics; apic++)
            if (mp_ioapics[apic].apicid == mp_irqs[i].dstapic || mp_irqs[i].dstapic == MP_APIC_ALL)
                break;
        if (!test_bit (lbus, mp_bus_not_pci) && !mp_irqs[i].irqtype && (bus == lbus) && (slot == ((mp_irqs[i].srcbusirq >> 2) & 0x1f))) {
            int irq = pin_2_irq (i, apic, mp_irqs[i].dstirq);
            if (!(apic || IO_APIC_IRQ (irq)))
                continue;
            if (pin == (mp_irqs[i].srcbusirq & 3)) {
                set_io_apic_irq_attr (irq_attr, apic, mp_irqs [i].dstirq, irq_trigger (i), irq_polarity (i));
                return irq;
            }
            if (best_guess < 0) {
                set_io_apic_irq_attr (irq_attr, apic, mp_irqs [i].dstirq, irq_trigger (i), irq_polarity (i));
                best_guess = irq;
            }
        }
    }
    return best_guess;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1079" endline="1083">
{
    apic_printk (APIC_VERBOSE, "PCI BIOS passed nonexistent PCI bus %d!\n", bus);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1084" endline="1120">
{
    int lbus = mp_irqs[i].srcbus;
    for (apic = 0; apic < nr_ioapics; apic++)
        if (mp_ioapics[apic].apicid == mp_irqs[i].dstapic || mp_irqs[i].dstapic == MP_APIC_ALL)
            break;
    if (!test_bit (lbus, mp_bus_not_pci) && !mp_irqs[i].irqtype && (bus == lbus) && (slot == ((mp_irqs[i].srcbusirq >> 2) & 0x1f))) {
        int irq = pin_2_irq (i, apic, mp_irqs[i].dstirq);
        if (!(apic || IO_APIC_IRQ (irq)))
            continue;
        if (pin == (mp_irqs[i].srcbusirq & 3)) {
            set_io_apic_irq_attr (irq_attr, apic, mp_irqs [i].dstirq, irq_trigger (i), irq_polarity (i));
            return irq;
        }
        if (best_guess < 0) {
            set_io_apic_irq_attr (irq_attr, apic, mp_irqs [i].dstirq, irq_trigger (i), irq_polarity (i));
            best_guess = irq;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1095" endline="1119">
{
    int irq = pin_2_irq (i, apic, mp_irqs[i].dstirq);
    if (!(apic || IO_APIC_IRQ (irq)))
        continue;
    if (pin == (mp_irqs[i].srcbusirq & 3)) {
        set_io_apic_irq_attr (irq_attr, apic, mp_irqs [i].dstirq, irq_trigger (i), irq_polarity (i));
        return irq;
    }
    if (best_guess < 0) {
        set_io_apic_irq_attr (irq_attr, apic, mp_irqs [i].dstirq, irq_trigger (i), irq_polarity (i));
        best_guess = irq;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1101" endline="1107">
{
    set_io_apic_irq_attr (irq_attr, apic, mp_irqs [i].dstirq, irq_trigger (i), irq_polarity (i));
    return irq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1112" endline="1118">
{
    set_io_apic_irq_attr (irq_attr, apic, mp_irqs [i].dstirq, irq_trigger (i), irq_polarity (i));
    best_guess = irq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1126" endline="1131">
{
    raw_spin_lock (& vector_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1134" endline="1136">
{
    raw_spin_unlock (& vector_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1140" endline="1216">
{
    static int current_vector = FIRST_EXTERNAL_VECTOR + VECTOR_OFFSET_START;
    static int current_offset = VECTOR_OFFSET_START % 8;
    unsigned int old_vector;
    int cpu, err;
    cpumask_var_t tmp_mask;
    if (cfg->move_in_progress)
        return -EBUSY;
    if (!alloc_cpumask_var (&tmp_mask, GFP_ATOMIC))
        return -ENOMEM;
    old_vector = cfg->vector;
    if (old_vector) {
        cpumask_and (tmp_mask, mask, cpu_online_mask);
        cpumask_and (tmp_mask, cfg -> domain, tmp_mask);
        if (!cpumask_empty (tmp_mask)) {
            free_cpumask_var (tmp_mask);
            return 0;
        }
    }
    err = -ENOSPC;

    for_each_cpu_and (cpu, mask, cpu_online_mask) {
        int new_cpu;
        int vector, offset;
        apic->vector_allocation_domain (cpu, tmp_mask);
        vector = current_vector;
        offset = current_offset;
    next :
        vector += 8;
        if (vector >= first_system_vector) {
            offset = (offset + 1) % 8;
            vector = FIRST_EXTERNAL_VECTOR + offset;
        }
        if (unlikely (current_vector == vector))
            continue;
        if (test_bit (vector, used_vectors))
            goto next;
        for_each_cpu_and (new_cpu, tmp_mask, cpu_online_mask)
        if (per_cpu (vector_irq, new_cpu)[vector] != -1)
            goto next;
        current_vector = vector;
        current_offset = offset;
        if (old_vector) {
            cfg->move_in_progress = 1;
            cpumask_copy (cfg -> old_domain, cfg -> domain);
        }
        for_each_cpu_and (new_cpu, tmp_mask, cpu_online_mask)
        per_cpu (vector_irq, new_cpu) [vector] = irq;
        cfg->vector = vector;
        cpumask_copy (cfg -> domain, tmp_mask);
        err = 0;
        break;
    }

    free_cpumask_var (tmp_mask);
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1165" endline="1172">
{
    cpumask_and (tmp_mask, mask, cpu_online_mask);
    cpumask_and (tmp_mask, cfg -> domain, tmp_mask);
    if (!cpumask_empty (tmp_mask)) {
        free_cpumask_var (tmp_mask);
        return 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1168" endline="1171">
{
    free_cpumask_var (tmp_mask);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1176" endline="1213">
{
    int new_cpu;
    int vector, offset;
    apic->vector_allocation_domain (cpu, tmp_mask);
    vector = current_vector;
    offset = current_offset;
next :
    vector += 8;
    if (vector >= first_system_vector) {
        offset = (offset + 1) % 8;
        vector = FIRST_EXTERNAL_VECTOR + offset;
    }
    if (unlikely (current_vector == vector))
        continue;
    if (test_bit (vector, used_vectors))
        goto next;
    for_each_cpu_and (new_cpu, tmp_mask, cpu_online_mask)
    if (per_cpu (vector_irq, new_cpu)[vector] != -1)
        goto next;
    current_vector = vector;
    current_offset = offset;
    if (old_vector) {
        cfg->move_in_progress = 1;
        cpumask_copy (cfg -> old_domain, cfg -> domain);
    }
    for_each_cpu_and (new_cpu, tmp_mask, cpu_online_mask)
    per_cpu (vector_irq, new_cpu) [vector] = irq;
    cfg->vector = vector;
    cpumask_copy (cfg -> domain, tmp_mask);
    err = 0;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1186" endline="1190">
{
    offset = (offset + 1) % 8;
    vector = FIRST_EXTERNAL_VECTOR + offset;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1203" endline="1206">
{
    cfg->move_in_progress = 1;
    cpumask_copy (cfg -> old_domain, cfg -> domain);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1219" endline="1227">
{
    int err;
    unsigned long flags;
    raw_spin_lock_irqsave (& vector_lock, flags);
    err = __assign_irq_vector (irq, cfg, mask);
    raw_spin_unlock_irqrestore (& vector_lock, flags);
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1230" endline="1254">
{
    int cpu, vector;
    BUG_ON (! cfg -> vector);
    vector = cfg->vector;
    for_each_cpu_and (cpu, cfg -> domain, cpu_online_mask)
    per_cpu (vector_irq, cpu) [vector] = -1;
    cfg->vector = 0;
    cpumask_clear (cfg -> domain);
    if (likely (!cfg->move_in_progress))
        return;
    for_each_cpu_and (cpu, cfg -> old_domain, cpu_online_mask)
    {
        for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
            if (per_cpu (vector_irq, cpu)[vector] != irq)
                continue;
            per_cpu (vector_irq, cpu)[vector] = -1;
            break;
        }
    }
    cfg->move_in_progress = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1244" endline="1252">
{
    for (vector = FIRST_EXTERNAL_VECTOR; vector < NR_VECTORS; vector++) {
        if (per_cpu (vector_irq, cpu)[vector] != irq)
            continue;
        per_cpu (vector_irq, cpu)[vector] = -1;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1246" endline="1251">
{
    if (per_cpu (vector_irq, cpu)[vector] != irq)
        continue;
    per_cpu (vector_irq, cpu)[vector] = -1;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1257" endline="1296">
{
    int irq, vector;
    struct irq_cfg *cfg;
    struct irq_desc *desc;
    raw_spin_lock (& vector_lock);

    for_each_irq_desc (irq, desc) {
        cfg = desc->chip_data;
        if (irq < legacy_pic->nr_legacy_irqs && !IO_APIC_IRQ (irq))
            cpumask_set_cpu (cpu, cfg->domain);
        if (!cpumask_test_cpu (cpu, cfg->domain))
            continue;
        vector = cfg->vector;
        per_cpu (vector_irq, cpu)[vector] = irq;
    }

    for (vector = 0; vector < NR_VECTORS; ++vector) {
        irq = per_cpu (vector_irq, cpu)[vector];
        if (irq < 0)
            continue;
        cfg = irq_cfg (irq);
        if (!cpumask_test_cpu (cpu, cfg->domain))
            per_cpu (vector_irq, cpu)[vector] = -1;
    }
    raw_spin_unlock (& vector_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1270" endline="1284">
{
    cfg = desc->chip_data;
    if (irq < legacy_pic->nr_legacy_irqs && !IO_APIC_IRQ (irq))
        cpumask_set_cpu (cpu, cfg->domain);
    if (!cpumask_test_cpu (cpu, cfg->domain))
        continue;
    vector = cfg->vector;
    per_cpu (vector_irq, cpu)[vector] = irq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1286" endline="1294">
{
    irq = per_cpu (vector_irq, cpu)[vector];
    if (irq < 0)
        continue;
    cfg = irq_cfg (irq);
    if (!cpumask_test_cpu (cpu, cfg->domain))
        per_cpu (vector_irq, cpu)[vector] = -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1324" endline="1326">
{
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1330" endline="1358">
{
    if ((trigger == IOAPIC_AUTO && IO_APIC_irq_trigger (irq)) || trigger == IOAPIC_LEVEL)
        desc->status |= IRQ_LEVEL;
    else
        desc->status &= ~IRQ_LEVEL;
    if (irq_remapped (irq)) {
        desc->status |= IRQ_MOVE_PCNTXT;
        if (trigger)
            set_irq_chip_and_handler_name (irq, &ir_ioapic_chip, handle_fasteoi_irq, "fasteoi");
        else
            set_irq_chip_and_handler_name (irq, &ir_ioapic_chip, handle_edge_irq, "edge");
        return;
    }
    if ((trigger == IOAPIC_AUTO && IO_APIC_irq_trigger (irq)) || trigger == IOAPIC_LEVEL)
        set_irq_chip_and_handler_name (irq, &ioapic_chip, handle_fasteoi_irq, "fasteoi");
    else
        set_irq_chip_and_handler_name (irq, &ioapic_chip, handle_edge_irq, "edge");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1338" endline="1348">
{
    desc->status |= IRQ_MOVE_PCNTXT;
    if (trigger)
        set_irq_chip_and_handler_name (irq, &ir_ioapic_chip, handle_fasteoi_irq, "fasteoi");
    else
        set_irq_chip_and_handler_name (irq, &ir_ioapic_chip, handle_edge_irq, "edge");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1364" endline="1431">
{
    memset (entry, 0, sizeof (* entry));
    if (intr_remapping_enabled) {
        struct intel_iommu *iommu = map_ioapic_to_ir (apic_id);
        struct irte irte;
        struct IR_IO_APIC_route_entry *ir_entry = (struct IR_IO_APIC_route_entry *) entry;
        int index;
        if (!iommu)
            panic ("No mapping iommu for ioapic %d\n", apic_id);
        index = alloc_irte (iommu, irq, 1);
        if (index < 0)
            panic ("Failed to allocate IRTE for ioapic %d\n", apic_id);
        memset (& irte, 0, sizeof (irte));
        irte.present = 1;
        irte.dst_mode = apic->irq_dest_mode;
        irte.trigger_mode = 0;
        irte.dlvry_mode = apic->irq_delivery_mode;
        irte.vector = vector;
        irte.dest_id = IRTE_DEST (destination);
        set_ioapic_sid (& irte, apic_id);
        modify_irte (irq, & irte);
        ir_entry->index2 = (index >> 15) & 0x1;
        ir_entry->zero = 0;
        ir_entry->format = 1;
        ir_entry->index = (index & 0x7fff);
        ir_entry->vector = pin;
    }
    else {
        entry->delivery_mode = apic->irq_delivery_mode;
        entry->dest_mode = apic->irq_dest_mode;
        entry->dest = destination;
        entry->vector = vector;
    }
    entry->mask = 0;
    entry->trigger = trigger;
    entry->polarity = polarity;
    if (trigger)
        entry->mask = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1370" endline="1414">
{
    struct intel_iommu *iommu = map_ioapic_to_ir (apic_id);
    struct irte irte;
    struct IR_IO_APIC_route_entry *ir_entry = (struct IR_IO_APIC_route_entry *) entry;
    int index;
    if (!iommu)
        panic ("No mapping iommu for ioapic %d\n", apic_id);
    index = alloc_irte (iommu, irq, 1);
    if (index < 0)
        panic ("Failed to allocate IRTE for ioapic %d\n", apic_id);
    memset (& irte, 0, sizeof (irte));
    irte.present = 1;
    irte.dst_mode = apic->irq_dest_mode;
    irte.trigger_mode = 0;
    irte.dlvry_mode = apic->irq_delivery_mode;
    irte.vector = vector;
    irte.dest_id = IRTE_DEST (destination);
    set_ioapic_sid (& irte, apic_id);
    modify_irte (irq, & irte);
    ir_entry->index2 = (index >> 15) & 0x1;
    ir_entry->zero = 0;
    ir_entry->format = 1;
    ir_entry->index = (index & 0x7fff);
    ir_entry->vector = pin;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1414" endline="1419">
{
    entry->delivery_mode = apic->irq_delivery_mode;
    entry->dest_mode = apic->irq_dest_mode;
    entry->dest = destination;
    entry->vector = vector;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1435" endline="1478">
{
    struct irq_cfg *cfg;
    struct IO_APIC_route_entry entry;
    unsigned int dest;
    if (!IO_APIC_IRQ (irq))
        return;
    cfg = desc->chip_data;
    if (irq < legacy_pic->nr_legacy_irqs && cpumask_test_cpu (0, cfg->domain))
        apic->vector_allocation_domain (0, cfg->domain);
    if (assign_irq_vector (irq, cfg, apic->target_cpus ()))
        return;
    dest = apic->cpu_mask_to_apicid_and (cfg->domain, apic->target_cpus ());
    apic_printk (APIC_VERBOSE, KERN_DEBUG "IOAPIC[%d]: Set routing entry (%d-%d -> 0x%x -> " "IRQ %d Mode:%i Active:%i)\n", apic_id, mp_ioapics [apic_id].apicid, pin, cfg -> vector, irq, trigger, polarity);
    if (setup_ioapic_entry (mp_ioapics[apic_id].apicid, irq, &entry, dest, trigger, polarity, cfg->vector, pin)) {
        printk ("Failed to setup ioapic entry for ioapic  %d, pin %d\n", mp_ioapics [apic_id].apicid, pin);
        __clear_irq_vector (irq, cfg);
        return;
    }
    ioapic_register_intr (irq, desc, trigger);
    if (irq < legacy_pic->nr_legacy_irqs)
        legacy_pic->chip->mask (irq);
    ioapic_write_entry (apic_id, pin, entry);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1466" endline="1471">
{
    printk ("Failed to setup ioapic entry for ioapic  %d, pin %d\n", mp_ioapics [apic_id].apicid, pin);
    __clear_irq_vector (irq, cfg);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1485" endline="1545">
{
    int apic_id, pin, idx, irq;
    int notcon = 0;
    struct irq_desc *desc;
    struct irq_cfg *cfg;
    int node = cpu_to_node (boot_cpu_id);
    apic_printk (APIC_VERBOSE, KERN_DEBUG "init IO_APIC IRQs\n");
    for (apic_id = 0; apic_id < nr_ioapics; apic_id++)
        for (pin = 0; pin < nr_ioapic_registers[apic_id]; pin++) {
            idx = find_irq_entry (apic_id, pin, mp_INT);
            if (idx == -1) {
                if (!notcon) {
                    notcon = 1;
                    apic_printk (APIC_VERBOSE, KERN_DEBUG " %d-%d", mp_ioapics [apic_id].apicid, pin);
                }
                else
                    apic_printk (APIC_VERBOSE, " %d-%d", mp_ioapics[apic_id].apicid, pin);
                continue;
            }
            if (notcon) {
                apic_printk (APIC_VERBOSE, " (apicid-pin) not connected\n");
                notcon = 0;
            }
            irq = pin_2_irq (idx, apic_id, pin);
            if ((apic_id > 0) && (irq > 16))
                continue;
            if (apic->multi_timer_check && apic->multi_timer_check (apic_id, irq))
                continue;
            desc = irq_to_desc_alloc_node (irq, node);
            if (!desc) {
                printk (KERN_INFO "can not get irq_desc for %d\n", irq);
                continue;
            }
            cfg = desc->chip_data;
            add_pin_to_irq_node (cfg, node, apic_id, pin);
            setup_IO_APIC_irq (apic_id, pin, irq, desc, irq_trigger (idx), irq_polarity (idx));
        }
    if (notcon)
        apic_printk (APIC_VERBOSE, " (apicid-pin) not connected\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1495" endline="1540">
{
    idx = find_irq_entry (apic_id, pin, mp_INT);
    if (idx == -1) {
        if (!notcon) {
            notcon = 1;
            apic_printk (APIC_VERBOSE, KERN_DEBUG " %d-%d", mp_ioapics [apic_id].apicid, pin);
        }
        else
            apic_printk (APIC_VERBOSE, " %d-%d", mp_ioapics[apic_id].apicid, pin);
        continue;
    }
    if (notcon) {
        apic_printk (APIC_VERBOSE, " (apicid-pin) not connected\n");
        notcon = 0;
    }
    irq = pin_2_irq (idx, apic_id, pin);
    if ((apic_id > 0) && (irq > 16))
        continue;
    if (apic->multi_timer_check && apic->multi_timer_check (apic_id, irq))
        continue;
    desc = irq_to_desc_alloc_node (irq, node);
    if (!desc) {
        printk (KERN_INFO "can not get irq_desc for %d\n", irq);
        continue;
    }
    cfg = desc->chip_data;
    add_pin_to_irq_node (cfg, node, apic_id, pin);
    setup_IO_APIC_irq (apic_id, pin, irq, desc, irq_trigger (idx), irq_polarity (idx));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1497" endline="1507">
{
    if (!notcon) {
        notcon = 1;
        apic_printk (APIC_VERBOSE, KERN_DEBUG " %d-%d", mp_ioapics [apic_id].apicid, pin);
    }
    else
        apic_printk (APIC_VERBOSE, " %d-%d", mp_ioapics[apic_id].apicid, pin);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1498" endline="1503">
{
    notcon = 1;
    apic_printk (APIC_VERBOSE, KERN_DEBUG " %d-%d", mp_ioapics [apic_id].apicid, pin);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1508" endline="1512">
{
    apic_printk (APIC_VERBOSE, " (apicid-pin) not connected\n");
    notcon = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1528" endline="1531">
{
    printk (KERN_INFO "can not get irq_desc for %d\n", irq);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1553" endline="1595">
{
    int apic_id = 0, pin, idx, irq;
    int node = cpu_to_node (boot_cpu_id);
    struct irq_desc *desc;
    struct irq_cfg *cfg;
    apic_id = mp_find_ioapic (gsi);
    if (apic_id < 0)
        return;
    pin = mp_find_ioapic_pin (apic_id, gsi);
    idx = find_irq_entry (apic_id, pin, mp_INT);
    if (idx == -1)
        return;
    irq = pin_2_irq (idx, apic_id, pin);
    desc = irq_to_desc_alloc_node (irq, node);
    if (!desc) {
        printk (KERN_INFO "can not get irq_desc for %d\n", irq);
        return;
    }
    cfg = desc->chip_data;
    add_pin_to_irq_node (cfg, node, apic_id, pin);
    if (test_bit (pin, mp_ioapic_routing[apic_id].pin_programmed)) {
        pr_debug ("Pin %d-%d already programmed\n", mp_ioapics [apic_id].apicid, pin);
        return;
    }
    set_bit (pin, mp_ioapic_routing [apic_id].pin_programmed);
    setup_IO_APIC_irq (apic_id, pin, irq, desc, irq_trigger (idx), irq_polarity (idx));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1578" endline="1581">
{
    printk (KERN_INFO "can not get irq_desc for %d\n", irq);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1586" endline="1590">
{
    pr_debug ("Pin %d-%d already programmed\n", mp_ioapics [apic_id].apicid, pin);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1602" endline="1632">
{
    struct IO_APIC_route_entry entry;
    if (intr_remapping_enabled)
        return;
    memset (& entry, 0, sizeof (entry));
    entry.dest_mode = apic->irq_dest_mode;
    entry.mask = 0;
    entry.dest = apic->cpu_mask_to_apicid (apic->target_cpus ());
    entry.delivery_mode = apic->irq_delivery_mode;
    entry.polarity = 0;
    entry.trigger = 0;
    entry.vector = vector;
    set_irq_chip_and_handler_name (0, & ioapic_chip, handle_edge_irq, "edge");
    ioapic_write_entry (apic_id, pin, entry);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1636" endline="1747">
{
    int apic, i;
    union IO_APIC_reg_00 reg_00;
    union IO_APIC_reg_01 reg_01;
    union IO_APIC_reg_02 reg_02;
    union IO_APIC_reg_03 reg_03;
    unsigned long flags;
    struct irq_cfg *cfg;
    struct irq_desc *desc;
    unsigned int irq;
    printk (KERN_DEBUG "number of MP IRQ sources: %d.\n", mp_irq_entries);
    for (i = 0; i < nr_ioapics; i++)
        printk (KERN_DEBUG "number of IO-APIC #%d registers: %d.\n", mp_ioapics[i].apicid, nr_ioapic_registers[i]);
    printk (KERN_INFO "testing the IO APIC.......................\n");
    for (apic = 0; apic < nr_ioapics; apic++) {
        raw_spin_lock_irqsave (& ioapic_lock, flags);
        reg_00.raw = io_apic_read (apic, 0);
        reg_01.raw = io_apic_read (apic, 1);
        if (reg_01.bits.version >= 0x10)
            reg_02.raw = io_apic_read (apic, 2);
        if (reg_01.bits.version >= 0x20)
            reg_03.raw = io_apic_read (apic, 3);
        raw_spin_unlock_irqrestore (& ioapic_lock, flags);
        printk ("\n");
        printk (KERN_DEBUG "IO APIC #%d......\n", mp_ioapics [apic].apicid);
        printk (KERN_DEBUG ".... register #00: %08X\n", reg_00.raw);
        printk (KERN_DEBUG ".......    : physical APIC id: %02X\n", reg_00.bits.ID);
        printk (KERN_DEBUG ".......    : Delivery Type: %X\n", reg_00.bits.delivery_type);
        printk (KERN_DEBUG ".......    : LTS          : %X\n", reg_00.bits.LTS);
        printk (KERN_DEBUG ".... register #01: %08X\n", * (int *) & reg_01);
        printk (KERN_DEBUG ".......     : max redirection entries: %04X\n", reg_01.bits.entries);
        printk (KERN_DEBUG ".......     : PRQ implemented: %X\n", reg_01.bits.PRQ);
        printk (KERN_DEBUG ".......     : IO APIC version: %04X\n", reg_01.bits.version);
        if (reg_01.bits.version >= 0x10 && reg_02.raw != reg_01.raw) {
            printk (KERN_DEBUG ".... register #02: %08X\n", reg_02.raw);
            printk (KERN_DEBUG ".......     : arbitration: %02X\n", reg_02.bits.arbitration);
        }
        if (reg_01.bits.version >= 0x20 && reg_03.raw != reg_02.raw && reg_03.raw != reg_01.raw) {
            printk (KERN_DEBUG ".... register #03: %08X\n", reg_03.raw);
            printk (KERN_DEBUG ".......     : Boot DT    : %X\n", reg_03.bits.boot_DT);
        }
        printk (KERN_DEBUG ".... IRQ redirection table:\n");
        printk (KERN_DEBUG " NR Dst Mask Trig IRR Pol" " Stat Dmod Deli Vect:\n");
        for (i = 0; i <= reg_01.bits.entries; i++) {
            struct IO_APIC_route_entry entry;
            entry = ioapic_read_entry (apic, i);
            printk (KERN_DEBUG " %02x %03X ", i, entry.dest);
            printk ("%1d    %1d    %1d   %1d   %1d    %1d    %1d    %02X\n", entry.mask, entry.trigger, entry.irr, entry.polarity, entry.delivery_status, entry.dest_mode, entry.delivery_mode, entry.vector);
        }
    }
    printk (KERN_DEBUG "IRQ to pin mappings:\n");

    for_each_irq_desc (irq, desc) {
        struct irq_pin_list *entry;
        cfg = desc->chip_data;
        entry = cfg->irq_2_pin;
        if (!entry)
            continue;
        printk (KERN_DEBUG "IRQ%d ", irq);
        for_each_irq_pin (entry, cfg -> irq_2_pin)
        printk ("-> %d:%d", entry -> apic, entry -> pin);
        printk ("\n");
    }

    printk (KERN_INFO ".................................... done.\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1658" endline="1729">
{
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    reg_00.raw = io_apic_read (apic, 0);
    reg_01.raw = io_apic_read (apic, 1);
    if (reg_01.bits.version >= 0x10)
        reg_02.raw = io_apic_read (apic, 2);
    if (reg_01.bits.version >= 0x20)
        reg_03.raw = io_apic_read (apic, 3);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
    printk ("\n");
    printk (KERN_DEBUG "IO APIC #%d......\n", mp_ioapics [apic].apicid);
    printk (KERN_DEBUG ".... register #00: %08X\n", reg_00.raw);
    printk (KERN_DEBUG ".......    : physical APIC id: %02X\n", reg_00.bits.ID);
    printk (KERN_DEBUG ".......    : Delivery Type: %X\n", reg_00.bits.delivery_type);
    printk (KERN_DEBUG ".......    : LTS          : %X\n", reg_00.bits.LTS);
    printk (KERN_DEBUG ".... register #01: %08X\n", * (int *) & reg_01);
    printk (KERN_DEBUG ".......     : max redirection entries: %04X\n", reg_01.bits.entries);
    printk (KERN_DEBUG ".......     : PRQ implemented: %X\n", reg_01.bits.PRQ);
    printk (KERN_DEBUG ".......     : IO APIC version: %04X\n", reg_01.bits.version);
    if (reg_01.bits.version >= 0x10 && reg_02.raw != reg_01.raw) {
        printk (KERN_DEBUG ".... register #02: %08X\n", reg_02.raw);
        printk (KERN_DEBUG ".......     : arbitration: %02X\n", reg_02.bits.arbitration);
    }
    if (reg_01.bits.version >= 0x20 && reg_03.raw != reg_02.raw && reg_03.raw != reg_01.raw) {
        printk (KERN_DEBUG ".... register #03: %08X\n", reg_03.raw);
        printk (KERN_DEBUG ".......     : Boot DT    : %X\n", reg_03.bits.boot_DT);
    }
    printk (KERN_DEBUG ".... IRQ redirection table:\n");
    printk (KERN_DEBUG " NR Dst Mask Trig IRR Pol" " Stat Dmod Deli Vect:\n");
    for (i = 0; i <= reg_01.bits.entries; i++) {
        struct IO_APIC_route_entry entry;
        entry = ioapic_read_entry (apic, i);
        printk (KERN_DEBUG " %02x %03X ", i, entry.dest);
        printk ("%1d    %1d    %1d   %1d   %1d    %1d    %1d    %02X\n", entry.mask, entry.trigger, entry.irr, entry.polarity, entry.delivery_status, entry.dest_mode, entry.delivery_mode, entry.vector);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1687" endline="1690">
{
    printk (KERN_DEBUG ".... register #02: %08X\n", reg_02.raw);
    printk (KERN_DEBUG ".......     : arbitration: %02X\n", reg_02.bits.arbitration);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1698" endline="1701">
{
    printk (KERN_DEBUG ".... register #03: %08X\n", reg_03.raw);
    printk (KERN_DEBUG ".......     : Boot DT    : %X\n", reg_03.bits.boot_DT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1708" endline="1728">
{
    struct IO_APIC_route_entry entry;
    entry = ioapic_read_entry (apic, i);
    printk (KERN_DEBUG " %02x %03X ", i, entry.dest);
    printk ("%1d    %1d    %1d   %1d   %1d    %1d    %1d    %02X\n", entry.mask, entry.trigger, entry.irr, entry.polarity, entry.delivery_status, entry.dest_mode, entry.delivery_mode, entry.vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1731" endline="1742">
{
    struct irq_pin_list *entry;
    cfg = desc->chip_data;
    entry = cfg->irq_2_pin;
    if (!entry)
        continue;
    printk (KERN_DEBUG "IRQ%d ", irq);
    for_each_irq_pin (entry, cfg -> irq_2_pin)
    printk ("-> %d:%d", entry -> apic, entry -> pin);
    printk ("\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1750" endline="1759">
{
    int i;
    printk (KERN_DEBUG);
    for (i = 0; i < 8; i++)
        printk (KERN_CONT "%08x", apic_read (base + i * 0x10));
    printk (KERN_CONT "\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1762" endline="1861">
{
    unsigned int i, v, ver, maxlvt;
    u64 icr;
    printk (KERN_DEBUG "printing local APIC contents on CPU#%d/%d:\n", smp_processor_id (), hard_smp_processor_id ());
    v = apic_read (APIC_ID);
    printk (KERN_INFO "... APIC ID:      %08x (%01x)\n", v, read_apic_id ());
    v = apic_read (APIC_LVR);
    printk (KERN_INFO "... APIC VERSION: %08x\n", v);
    ver = GET_APIC_VERSION (v);
    maxlvt = lapic_get_maxlvt ();
    v = apic_read (APIC_TASKPRI);
    printk (KERN_DEBUG "... APIC TASKPRI: %08x (%02x)\n", v, v & APIC_TPRI_MASK);
    if (APIC_INTEGRATED (ver)) {
        if (!APIC_XAPIC (ver)) {
            v = apic_read (APIC_ARBPRI);
            printk (KERN_DEBUG "... APIC ARBPRI: %08x (%02x)\n", v, v & APIC_ARBPRI_MASK);
        }
        v = apic_read (APIC_PROCPRI);
        printk (KERN_DEBUG "... APIC PROCPRI: %08x\n", v);
    }
    if (!APIC_INTEGRATED (ver) || maxlvt == 3) {
        v = apic_read (APIC_RRR);
        printk (KERN_DEBUG "... APIC RRR: %08x\n", v);
    }
    v = apic_read (APIC_LDR);
    printk (KERN_DEBUG "... APIC LDR: %08x\n", v);
    if (!x2apic_enabled ()) {
        v = apic_read (APIC_DFR);
        printk (KERN_DEBUG "... APIC DFR: %08x\n", v);
    }
    v = apic_read (APIC_SPIV);
    printk (KERN_DEBUG "... APIC SPIV: %08x\n", v);
    printk (KERN_DEBUG "... APIC ISR field:\n");
    print_APIC_field (APIC_ISR);
    printk (KERN_DEBUG "... APIC TMR field:\n");
    print_APIC_field (APIC_TMR);
    printk (KERN_DEBUG "... APIC IRR field:\n");
    print_APIC_field (APIC_IRR);
    if (APIC_INTEGRATED (ver)) {
        if (maxlvt > 3)
            apic_write (APIC_ESR, 0);
        v = apic_read (APIC_ESR);
        printk (KERN_DEBUG "... APIC ESR: %08x\n", v);
    }
    icr = apic_icr_read ();
    printk (KERN_DEBUG "... APIC ICR: %08x\n", (u32) icr);
    printk (KERN_DEBUG "... APIC ICR2: %08x\n", (u32) (icr >> 32));
    v = apic_read (APIC_LVTT);
    printk (KERN_DEBUG "... APIC LVTT: %08x\n", v);
    if (maxlvt > 3) {
        v = apic_read (APIC_LVTPC);
        printk (KERN_DEBUG "... APIC LVTPC: %08x\n", v);
    }
    v = apic_read (APIC_LVT0);
    printk (KERN_DEBUG "... APIC LVT0: %08x\n", v);
    v = apic_read (APIC_LVT1);
    printk (KERN_DEBUG "... APIC LVT1: %08x\n", v);
    if (maxlvt > 2) {
        v = apic_read (APIC_LVTERR);
        printk (KERN_DEBUG "... APIC LVTERR: %08x\n", v);
    }
    v = apic_read (APIC_TMICT);
    printk (KERN_DEBUG "... APIC TMICT: %08x\n", v);
    v = apic_read (APIC_TMCCT);
    printk (KERN_DEBUG "... APIC TMCCT: %08x\n", v);
    v = apic_read (APIC_TDCR);
    printk (KERN_DEBUG "... APIC TDCR: %08x\n", v);
    if (boot_cpu_has (X86_FEATURE_EXTAPIC)) {
        v = apic_read (APIC_EFEAT);
        maxlvt = (v >> 16) & 0xff;
        printk (KERN_DEBUG "... APIC EFEAT: %08x\n", v);
        v = apic_read (APIC_ECTRL);
        printk (KERN_DEBUG "... APIC ECTRL: %08x\n", v);
        for (i = 0; i < maxlvt; i++) {
            v = apic_read (APIC_EILVTn (i));
            printk (KERN_DEBUG "... APIC EILVT%d: %08x\n", i, v);
        }
    }
    printk ("\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1778" endline="1786">
{
    if (!APIC_XAPIC (ver)) {
        v = apic_read (APIC_ARBPRI);
        printk (KERN_DEBUG "... APIC ARBPRI: %08x (%02x)\n", v, v & APIC_ARBPRI_MASK);
    }
    v = apic_read (APIC_PROCPRI);
    printk (KERN_DEBUG "... APIC PROCPRI: %08x\n", v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1779" endline="1783">
{
    v = apic_read (APIC_ARBPRI);
    printk (KERN_DEBUG "... APIC ARBPRI: %08x (%02x)\n", v, v & APIC_ARBPRI_MASK);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1792" endline="1795">
{
    v = apic_read (APIC_RRR);
    printk (KERN_DEBUG "... APIC RRR: %08x\n", v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1799" endline="1802">
{
    v = apic_read (APIC_DFR);
    printk (KERN_DEBUG "... APIC DFR: %08x\n", v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1813" endline="1819">
{
    if (maxlvt > 3)
        apic_write (APIC_ESR, 0);
    v = apic_read (APIC_ESR);
    printk (KERN_DEBUG "... APIC ESR: %08x\n", v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1828" endline="1831">
{
    v = apic_read (APIC_LVTPC);
    printk (KERN_DEBUG "... APIC LVTPC: %08x\n", v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1837" endline="1840">
{
    v = apic_read (APIC_LVTERR);
    printk (KERN_DEBUG "... APIC LVTERR: %08x\n", v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1849" endline="1859">
{
    v = apic_read (APIC_EFEAT);
    maxlvt = (v >> 16) & 0xff;
    printk (KERN_DEBUG "... APIC EFEAT: %08x\n", v);
    v = apic_read (APIC_ECTRL);
    printk (KERN_DEBUG "... APIC ECTRL: %08x\n", v);
    for (i = 0; i < maxlvt; i++) {
        v = apic_read (APIC_EILVTn (i));
        printk (KERN_DEBUG "... APIC EILVT%d: %08x\n", i, v);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1855" endline="1858">
{
    v = apic_read (APIC_EILVTn (i));
    printk (KERN_DEBUG "... APIC EILVT%d: %08x\n", i, v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1864" endline="1877">
{
    int cpu;
    if (!maxcpu)
        return;
    preempt_disable ();

    for_each_online_cpu (cpu) {
        if (cpu >= maxcpu)
            break;
        smp_call_function_single (cpu, print_local_APIC, NULL, 1);
    }

    preempt_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1871" endline="1875">
{
    if (cpu >= maxcpu)
        break;
    smp_call_function_single (cpu, print_local_APIC, NULL, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1880" endline="1909">
{
    unsigned int v;
    unsigned long flags;
    if (!legacy_pic->nr_legacy_irqs)
        return;
    printk (KERN_DEBUG "\nprinting PIC contents\n");
    raw_spin_lock_irqsave (& i8259A_lock, flags);
    v = inb (0xa1) << 8 | inb (0x21);
    printk (KERN_DEBUG "... PIC  IMR: %04x\n", v);
    v = inb (0xa0) << 8 | inb (0x20);
    printk (KERN_DEBUG "... PIC  IRR: %04x\n", v);
    outb (0x0b, 0xa0);
    outb (0x0b, 0x20);
    v = inb (0xa0) << 8 | inb (0x20);
    outb (0x0a, 0xa0);
    outb (0x0a, 0x20);
    raw_spin_unlock_irqrestore (& i8259A_lock, flags);
    printk (KERN_DEBUG "... PIC  ISR: %04x\n", v);
    v = inb (0x4d1) << 8 | inb (0x4d0);
    printk (KERN_DEBUG "... PIC ELCR: %04x\n", v);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1913" endline="1925">
{
    int num = -1;
    if (strcmp (arg, "all") == 0) {
        show_lapic = CONFIG_NR_CPUS;
    }
    else {
        get_option (& arg, & num);
        if (num >= 0)
            show_lapic = num;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1916" endline="1918">
{
    show_lapic = CONFIG_NR_CPUS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1918" endline="1922">
{
    get_option (& arg, & num);
    if (num >= 0)
        show_lapic = num;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1929" endline="1943">
{
    if (apic_verbosity == APIC_QUIET)
        return 0;
    print_PIC ();
    if (!cpu_has_apic && !apic_from_smp_config ())
        return 0;
    print_local_APICs (show_lapic);
    print_IO_APIC ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1952" endline="2013">
{
    union IO_APIC_reg_01 reg_01;
    int i8259_apic, i8259_pin;
    int apic;
    unsigned long flags;
    for (apic = 0; apic < nr_ioapics; apic++) {
        raw_spin_lock_irqsave (& ioapic_lock, flags);
        reg_01.raw = io_apic_read (apic, 1);
        raw_spin_unlock_irqrestore (& ioapic_lock, flags);
        nr_ioapic_registers[apic] = reg_01.bits.entries + 1;
    }
    if (!legacy_pic->nr_legacy_irqs)
        return;
    for (apic = 0; apic < nr_ioapics; apic++) {
        int pin;
        for (pin = 0; pin < nr_ioapic_registers[apic]; pin++) {
            struct IO_APIC_route_entry entry;
            entry = ioapic_read_entry (apic, pin);
            if ((entry.mask == 0) && (entry.delivery_mode == dest_ExtINT)) {
                ioapic_i8259.apic = apic;
                ioapic_i8259.pin = pin;
                goto found_i8259;
            }
        }
    }
found_i8259 :
    i8259_pin = find_isa_irq_pin (0, mp_ExtINT);
    i8259_apic = find_isa_irq_apic (0, mp_ExtINT);
    if ((ioapic_i8259.pin == -1) && (i8259_pin >= 0)) {
        printk (KERN_WARNING "ExtINT not setup in hardware but reported by MP table\n");
        ioapic_i8259.pin = i8259_pin;
        ioapic_i8259.apic = i8259_apic;
    }
    if (((ioapic_i8259.apic != i8259_apic) || (ioapic_i8259.pin != i8259_pin)) && (i8259_pin >= 0) && (ioapic_i8259.pin >= 0)) {
        printk (KERN_WARNING "ExtINT in hardware and MP table differ\n");
    }
    clear_IO_APIC ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1961" endline="1966">
{
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    reg_01.raw = io_apic_read (apic, 1);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
    nr_ioapic_registers[apic] = reg_01.bits.entries + 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1971" endline="1987">
{
    int pin;
    for (pin = 0; pin < nr_ioapic_registers[apic]; pin++) {
        struct IO_APIC_route_entry entry;
        entry = ioapic_read_entry (apic, pin);
        if ((entry.mask == 0) && (entry.delivery_mode == dest_ExtINT)) {
            ioapic_i8259.apic = apic;
            ioapic_i8259.pin = pin;
            goto found_i8259;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1974" endline="1986">
{
    struct IO_APIC_route_entry entry;
    entry = ioapic_read_entry (apic, pin);
    if ((entry.mask == 0) && (entry.delivery_mode == dest_ExtINT)) {
        ioapic_i8259.apic = apic;
        ioapic_i8259.pin = pin;
        goto found_i8259;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1981" endline="1985">
{
    ioapic_i8259.apic = apic;
    ioapic_i8259.pin = pin;
    goto found_i8259;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="1997" endline="2001">
{
    printk (KERN_WARNING "ExtINT not setup in hardware but reported by MP table\n");
    ioapic_i8259.pin = i8259_pin;
    ioapic_i8259.apic = i8259_apic;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2005" endline="2007">
{
    printk (KERN_WARNING "ExtINT in hardware and MP table differ\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2019" endline="2064">
{
    clear_IO_APIC ();
    if (!legacy_pic->nr_legacy_irqs)
        return;
    if (ioapic_i8259.pin != -1 && !intr_remapping_enabled) {
        struct IO_APIC_route_entry entry;
        memset (& entry, 0, sizeof (entry));
        entry.mask = 0;
        entry.trigger = 0;
        entry.irr = 0;
        entry.polarity = 0;
        entry.delivery_status = 0;
        entry.dest_mode = 0;
        entry.delivery_mode = dest_ExtINT;
        entry.vector = 0;
        entry.dest = read_apic_id ();
        ioapic_write_entry (ioapic_i8259.apic, ioapic_i8259.pin, entry);
    }
    if (cpu_has_apic || apic_from_smp_config ())
        disconnect_bsp_APIC (!intr_remapping_enabled && ioapic_i8259.pin != -1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2038" endline="2056">
{
    struct IO_APIC_route_entry entry;
    memset (& entry, 0, sizeof (entry));
    entry.mask = 0;
    entry.trigger = 0;
    entry.irr = 0;
    entry.polarity = 0;
    entry.delivery_status = 0;
    entry.dest_mode = 0;
    entry.delivery_mode = dest_ExtINT;
    entry.vector = 0;
    entry.dest = read_apic_id ();
    ioapic_write_entry (ioapic_i8259.apic, ioapic_i8259.pin, entry);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2186" endline="2189">
{
    no_timer_check = 1;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2201" endline="2226">
{
    unsigned long t1 = jiffies;
    unsigned long flags;
    if (no_timer_check)
        return 1;
    local_save_flags (flags);
    local_irq_enable ();
    mdelay ((10 * 1000) / HZ);
    local_irq_restore (flags);
    if (time_after (jiffies, t1 +4))
        return 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2252" endline="2268">
{
    int was_pending = 0;
    unsigned long flags;
    struct irq_cfg *cfg;
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    if (irq < legacy_pic->nr_legacy_irqs) {
        legacy_pic->chip->mask (irq);
        if (legacy_pic->irq_pending (irq))
            was_pending = 1;
    }
    cfg = irq_cfg (irq);
    __unmask_IO_APIC_irq (cfg);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
    return was_pending;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2258" endline="2262">
{
    legacy_pic->chip->mask (irq);
    if (legacy_pic->irq_pending (irq))
        was_pending = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2271" endline="2281">
{
    struct irq_cfg *cfg = irq_cfg (irq);
    unsigned long flags;
    raw_spin_lock_irqsave (& vector_lock, flags);
    apic->send_IPI_mask (cpumask_of (cpumask_first (cfg->domain)), cfg->vector);
    raw_spin_unlock_irqrestore (& vector_lock, flags);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2554" endline="2554">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2558" endline="2564">
{
    struct irq_desc *desc = irq_to_desc (irq);
    irq_complete_move (& desc);
    move_native_irq (irq);
    ack_APIC_irq ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2585" endline="2605">
{
    struct irq_pin_list *entry;
    for_each_irq_pin (entry, cfg -> irq_2_pin)
    {
        if (mp_ioapics[entry->apic].apicver >= 0x20) {
            if (irq_remapped (irq))
                io_apic_eoi (entry->apic, entry->pin);
            else
                io_apic_eoi (entry->apic, cfg->vector);
        }
        else {
            __mask_and_edge_IO_APIC_irq (entry);
            __unmask_and_level_IO_APIC_irq (entry);
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2588" endline="2604">
{
    if (mp_ioapics[entry->apic].apicver >= 0x20) {
        if (irq_remapped (irq))
            io_apic_eoi (entry->apic, entry->pin);
        else
            io_apic_eoi (entry->apic, cfg->vector);
    }
    else {
        __mask_and_edge_IO_APIC_irq (entry);
        __unmask_and_level_IO_APIC_irq (entry);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2589" endline="2600">
{
    if (irq_remapped (irq))
        io_apic_eoi (entry->apic, entry->pin);
    else
        io_apic_eoi (entry->apic, cfg->vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2600" endline="2603">
{
    __mask_and_edge_IO_APIC_irq (entry);
    __unmask_and_level_IO_APIC_irq (entry);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2608" endline="2619">
{
    struct irq_cfg *cfg;
    unsigned long flags;
    unsigned int irq;
    irq = desc->irq;
    cfg = desc->chip_data;
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    __eoi_ioapic_irq (irq, cfg);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2622" endline="2726">
{
    struct irq_desc *desc = irq_to_desc (irq);
    unsigned long v;
    int i;
    struct irq_cfg *cfg;
    int do_unmask_irq = 0;
    irq_complete_move (& desc);
    cfg = desc->chip_data;
    i = cfg->vector;
    v = apic_read (APIC_TMR +((i & ~0x1f) >> 1));
    ack_APIC_irq ();
    if (!(v & (1 << (i & 0x1f)))) {
        atomic_inc (& irq_mis_count);
        eoi_ioapic_irq (desc);
    }
    if (unlikely (do_unmask_irq)) {
        cfg = desc->chip_data;
        if (!io_apic_level_ack_pending (cfg))
            move_masked_irq (irq);
        unmask_IO_APIC_irq_desc (desc);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2687" endline="2691">
{
    atomic_inc (& irq_mis_count);
    eoi_ioapic_irq (desc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2694" endline="2725">
{
    cfg = desc->chip_data;
    if (!io_apic_level_ack_pending (cfg))
        move_masked_irq (irq);
    unmask_IO_APIC_irq_desc (desc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2772" endline="2803">
{
    int irq;
    struct irq_desc *desc;
    struct irq_cfg *cfg;

    for_each_irq_desc (irq, desc) {
        cfg = desc->chip_data;
        if (IO_APIC_IRQ (irq) && cfg && !cfg->vector) {
            if (irq < legacy_pic->nr_legacy_irqs)
                legacy_pic->make_irq (irq);
            else
                desc->chip = &no_irq_chip;
        }
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2788" endline="2802">
{
    cfg = desc->chip_data;
    if (IO_APIC_IRQ (irq) && cfg && !cfg->vector) {
        if (irq < legacy_pic->nr_legacy_irqs)
            legacy_pic->make_irq (irq);
        else
            desc->chip = &no_irq_chip;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2790" endline="2801">
{
    if (irq < legacy_pic->nr_legacy_irqs)
        legacy_pic->make_irq (irq);
    else
        desc->chip = &no_irq_chip;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2810" endline="2815">
{
    unsigned long v;
    v = apic_read (APIC_LVT0);
    apic_write (APIC_LVT0, v | APIC_LVT_MASKED);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2818" endline="2823">
{
    unsigned long v;
    v = apic_read (APIC_LVT0);
    apic_write (APIC_LVT0, v & ~ APIC_LVT_MASKED);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2826" endline="2828">
{
    ack_APIC_irq ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2838" endline="2842">
{
    desc->status &= ~IRQ_LEVEL;
    set_irq_chip_and_handler_name (irq, & lapic_chip, handle_edge_irq, "edge");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2845" endline="2860">
{
    apic_printk (APIC_VERBOSE, KERN_INFO "activating NMI Watchdog ...");
    enable_NMI_through_LVT0 ();
    apic_printk (APIC_VERBOSE, " done.\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2870" endline="2919">
{
    int apic, pin, i;
    struct IO_APIC_route_entry entry0, entry1;
    unsigned char save_control, save_freq_select;
    pin = find_isa_irq_pin (8, mp_INT);
    if (pin == -1) {
        WARN_ON_ONCE (1);
        return;
    }
    apic = find_isa_irq_apic (8, mp_INT);
    if (apic == -1) {
        WARN_ON_ONCE (1);
        return;
    }
    entry0 = ioapic_read_entry (apic, pin);
    clear_IO_APIC_pin (apic, pin);
    memset (& entry1, 0, sizeof (entry1));
    entry1.dest_mode = 0;
    entry1.mask = 0;
    entry1.dest = hard_smp_processor_id ();
    entry1.delivery_mode = dest_ExtINT;
    entry1.polarity = entry0.polarity;
    entry1.trigger = 0;
    entry1.vector = 0;
    ioapic_write_entry (apic, pin, entry1);
    save_control = CMOS_READ (RTC_CONTROL);
    save_freq_select = CMOS_READ (RTC_FREQ_SELECT);
    CMOS_WRITE ((save_freq_select & ~ RTC_RATE_SELECT) | 0x6, RTC_FREQ_SELECT);
    CMOS_WRITE (save_control | RTC_PIE, RTC_CONTROL);
    i = 100;
    while (i-- > 0) {
        mdelay (10);
        if ((CMOS_READ (RTC_INTR_FLAGS) & RTC_PF) == RTC_PF)
            i -= 10;
    }
    CMOS_WRITE (save_control, RTC_CONTROL);
    CMOS_WRITE (save_freq_select, RTC_FREQ_SELECT);
    clear_IO_APIC_pin (apic, pin);
    ioapic_write_entry (apic, pin, entry0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2876" endline="2879">
{
    WARN_ON_ONCE (1);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2881" endline="2884">
{
    WARN_ON_ONCE (1);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2908" endline="2912">
{
    mdelay (10);
    if ((CMOS_READ (RTC_INTR_FLAGS) & RTC_PF) == RTC_PF)
        i -= 10;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2924" endline="2927">
{
    disable_timer_pin_1 = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2941" endline="3113">
{
    struct irq_desc *desc = irq_to_desc (0);
    struct irq_cfg *cfg = desc->chip_data;
    int node = cpu_to_node (boot_cpu_id);
    int apic1, pin1, apic2, pin2;
    unsigned long flags;
    int no_pin1 = 0;
    local_irq_save (flags);
    legacy_pic->chip->mask (0);
    assign_irq_vector (0, cfg, apic -> target_cpus ());
    apic_write (APIC_LVT0, APIC_LVT_MASKED | APIC_DM_EXTINT);
    legacy_pic->init (1);
    pin1 = find_isa_irq_pin (0, mp_INT);
    apic1 = find_isa_irq_apic (0, mp_INT);
    pin2 = ioapic_i8259.pin;
    apic2 = ioapic_i8259.apic;
    apic_printk (APIC_QUIET, KERN_INFO "..TIMER: vector=0x%02X " "apic1=%d pin1=%d apic2=%d pin2=%d\n", cfg -> vector, apic1, pin1, apic2, pin2);
    if (pin1 == -1) {
        if (intr_remapping_enabled)
            panic ("BIOS bug: timer not connected to IO-APIC");
        pin1 = pin2;
        apic1 = apic2;
        no_pin1 = 1;
    }
    else if (pin2 == -1) {
        pin2 = pin1;
        apic2 = apic1;
    }
    if (pin1 != -1) {
        if (no_pin1) {
            add_pin_to_irq_node (cfg, node, apic1, pin1);
            setup_timer_IRQ0_pin (apic1, pin1, cfg -> vector);
        }
        else {
            int idx;
            idx = find_irq_entry (apic1, pin1, mp_INT);
            if (idx != -1 && irq_trigger (idx))
                unmask_IO_APIC_irq_desc (desc);
        }
        if (timer_irq_works ()) {
            if (nmi_watchdog == NMI_IO_APIC) {
                setup_nmi ();
                legacy_pic->chip->unmask (0);
            }
            if (disable_timer_pin_1 > 0)
                clear_IO_APIC_pin (0, pin1);
            goto out;
        }
        if (intr_remapping_enabled)
            panic ("timer doesn't work through Interrupt-remapped IO-APIC");
        local_irq_disable ();
        clear_IO_APIC_pin (apic1, pin1);
        if (!no_pin1)
            apic_printk (APIC_QUIET, KERN_ERR "..MP-BIOS bug: " "8254 timer not connected to IO-APIC\n");
        apic_printk (APIC_QUIET, KERN_INFO "...trying to set up timer " "(IRQ0) through the 8259A ...\n");
        apic_printk (APIC_QUIET, KERN_INFO "..... (found apic %d pin %d) ...\n", apic2, pin2);
        replace_pin_at_irq_node (cfg, node, apic1, pin1, apic2, pin2);
        setup_timer_IRQ0_pin (apic2, pin2, cfg -> vector);
        legacy_pic->chip->unmask (0);
        if (timer_irq_works ()) {
            apic_printk (APIC_QUIET, KERN_INFO "....... works.\n");
            timer_through_8259 = 1;
            if (nmi_watchdog == NMI_IO_APIC) {
                legacy_pic->chip->mask (0);
                setup_nmi ();
                legacy_pic->chip->unmask (0);
            }
            goto out;
        }
        local_irq_disable ();
        legacy_pic->chip->mask (0);
        clear_IO_APIC_pin (apic2, pin2);
        apic_printk (APIC_QUIET, KERN_INFO "....... failed.\n");
    }
    if (nmi_watchdog == NMI_IO_APIC) {
        apic_printk (APIC_QUIET, KERN_WARNING "timer doesn't work " "through the IO-APIC - disabling NMI Watchdog!\n");
        nmi_watchdog = NMI_NONE;
    }
    apic_printk (APIC_QUIET, KERN_INFO "...trying to set up timer as Virtual Wire IRQ...\n");
    lapic_register_intr (0, desc);
    apic_write (APIC_LVT0, APIC_DM_FIXED | cfg -> vector);
    legacy_pic->chip->unmask (0);
    if (timer_irq_works ()) {
        apic_printk (APIC_QUIET, KERN_INFO "..... works.\n");
        goto out;
    }
    local_irq_disable ();
    legacy_pic->chip->mask (0);
    apic_write (APIC_LVT0, APIC_LVT_MASKED | APIC_DM_FIXED | cfg -> vector);
    apic_printk (APIC_QUIET, KERN_INFO "..... failed.\n");
    apic_printk (APIC_QUIET, KERN_INFO "...trying to set up timer as ExtINT IRQ...\n");
    legacy_pic->init (0);
    legacy_pic->make_irq (0);
    apic_write (APIC_LVT0, APIC_DM_EXTINT);
    unlock_ExtINT_logic ();
    if (timer_irq_works ()) {
        apic_printk (APIC_QUIET, KERN_INFO "..... works.\n");
        goto out;
    }
    local_irq_disable ();
    apic_printk (APIC_QUIET, KERN_INFO "..... failed :(.\n");
    panic ("IO-APIC + timer doesn't work!  Boot with apic=debug and send a " "report.  Then try booting with the 'noapic' option.\n");
out :
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="2994" endline="3000">
{
    if (intr_remapping_enabled)
        panic ("BIOS bug: timer not connected to IO-APIC");
    pin1 = pin2;
    apic1 = apic2;
    no_pin1 = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3000" endline="3003">
{
    pin2 = pin1;
    apic2 = apic1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3005" endline="3067">
{
    if (no_pin1) {
        add_pin_to_irq_node (cfg, node, apic1, pin1);
        setup_timer_IRQ0_pin (apic1, pin1, cfg -> vector);
    }
    else {
        int idx;
        idx = find_irq_entry (apic1, pin1, mp_INT);
        if (idx != -1 && irq_trigger (idx))
            unmask_IO_APIC_irq_desc (desc);
    }
    if (timer_irq_works ()) {
        if (nmi_watchdog == NMI_IO_APIC) {
            setup_nmi ();
            legacy_pic->chip->unmask (0);
        }
        if (disable_timer_pin_1 > 0)
            clear_IO_APIC_pin (0, pin1);
        goto out;
    }
    if (intr_remapping_enabled)
        panic ("timer doesn't work through Interrupt-remapped IO-APIC");
    local_irq_disable ();
    clear_IO_APIC_pin (apic1, pin1);
    if (!no_pin1)
        apic_printk (APIC_QUIET, KERN_ERR "..MP-BIOS bug: " "8254 timer not connected to IO-APIC\n");
    apic_printk (APIC_QUIET, KERN_INFO "...trying to set up timer " "(IRQ0) through the 8259A ...\n");
    apic_printk (APIC_QUIET, KERN_INFO "..... (found apic %d pin %d) ...\n", apic2, pin2);
    replace_pin_at_irq_node (cfg, node, apic1, pin1, apic2, pin2);
    setup_timer_IRQ0_pin (apic2, pin2, cfg -> vector);
    legacy_pic->chip->unmask (0);
    if (timer_irq_works ()) {
        apic_printk (APIC_QUIET, KERN_INFO "....... works.\n");
        timer_through_8259 = 1;
        if (nmi_watchdog == NMI_IO_APIC) {
            legacy_pic->chip->mask (0);
            setup_nmi ();
            legacy_pic->chip->unmask (0);
        }
        goto out;
    }
    local_irq_disable ();
    legacy_pic->chip->mask (0);
    clear_IO_APIC_pin (apic2, pin2);
    apic_printk (APIC_QUIET, KERN_INFO "....... failed.\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3009" endline="3012">
{
    add_pin_to_irq_node (cfg, node, apic1, pin1);
    setup_timer_IRQ0_pin (apic1, pin1, cfg -> vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3012" endline="3022">
{
    int idx;
    idx = find_irq_entry (apic1, pin1, mp_INT);
    if (idx != -1 && irq_trigger (idx))
        unmask_IO_APIC_irq_desc (desc);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3023" endline="3031">
{
    if (nmi_watchdog == NMI_IO_APIC) {
        setup_nmi ();
        legacy_pic->chip->unmask (0);
    }
    if (disable_timer_pin_1 > 0)
        clear_IO_APIC_pin (0, pin1);
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3024" endline="3027">
{
    setup_nmi ();
    legacy_pic->chip->unmask (0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3050" endline="3059">
{
    apic_printk (APIC_QUIET, KERN_INFO "....... works.\n");
    timer_through_8259 = 1;
    if (nmi_watchdog == NMI_IO_APIC) {
        legacy_pic->chip->mask (0);
        setup_nmi ();
        legacy_pic->chip->unmask (0);
    }
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3053" endline="3057">
{
    legacy_pic->chip->mask (0);
    setup_nmi ();
    legacy_pic->chip->unmask (0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3069" endline="3073">
{
    apic_printk (APIC_QUIET, KERN_WARNING "timer doesn't work " "through the IO-APIC - disabling NMI Watchdog!\n");
    nmi_watchdog = NMI_NONE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3085" endline="3088">
{
    apic_printk (APIC_QUIET, KERN_INFO "..... works.\n");
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3103" endline="3106">
{
    apic_printk (APIC_QUIET, KERN_INFO "..... works.\n");
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3135" endline="3153">
{
    io_apic_irqs = legacy_pic->nr_legacy_irqs ? ~PIC_IRQS : ~0UL;
    apic_printk (APIC_VERBOSE, "ENABLING IO-APIC IRQs\n");
    x86_init.mpparse.setup_ioapic_ids ();
    sync_Arb_IDs ();
    setup_IO_APIC_irqs ();
    init_IO_APIC_traps ();
    if (legacy_pic->nr_legacy_irqs)
        check_timer ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3161" endline="3165">
{
    if (sis_apic_bug == -1)
        sis_apic_bug = 0;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3176" endline="3187">
{
    struct IO_APIC_route_entry *entry;
    struct sysfs_ioapic_data *data;
    int i;
    data = container_of (dev, struct sysfs_ioapic_data, dev);
    entry = data->entry;
    for (i = 0; i < nr_ioapic_registers[dev->id]; i++, entry++)
        *entry = ioapic_read_entry (dev->id, i);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3190" endline="3211">
{
    struct IO_APIC_route_entry *entry;
    struct sysfs_ioapic_data *data;
    unsigned long flags;
    union IO_APIC_reg_00 reg_00;
    int i;
    data = container_of (dev, struct sysfs_ioapic_data, dev);
    entry = data->entry;
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    reg_00.raw = io_apic_read (dev->id, 0);
    if (reg_00.bits.ID != mp_ioapics[dev->id].apicid) {
        reg_00.bits.ID = mp_ioapics[dev->id].apicid;
        io_apic_write (dev -> id, 0, reg_00.raw);
    }
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
    for (i = 0; i < nr_ioapic_registers[dev->id]; i++)
        ioapic_write_entry (dev->id, i, entry[i]);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3202" endline="3205">
{
    reg_00.bits.ID = mp_ioapics[dev->id].apicid;
    io_apic_write (dev -> id, 0, reg_00.raw);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3220" endline="3249">
{
    struct sys_device *dev;
    int i, size, error;
    error = sysdev_class_register (&ioapic_sysdev_class);
    if (error)
        return error;
    for (i = 0; i < nr_ioapics; i++) {
        size = sizeof (struct sys_device) + nr_ioapic_registers[i] * sizeof (struct IO_APIC_route_entry);
        mp_ioapic_data[i] = kzalloc (size, GFP_KERNEL);
        if (!mp_ioapic_data[i]) {
            printk (KERN_ERR "Can't suspend/resume IOAPIC %d\n", i);
            continue;
        }
        dev = &mp_ioapic_data[i]->dev;
        dev->id = i;
        dev->cls = &ioapic_sysdev_class;
        error = sysdev_register (dev);
        if (error) {
            kfree (mp_ioapic_data [i]);
            mp_ioapic_data[i] = NULL;
            printk (KERN_ERR "Can't suspend/resume IOAPIC %d\n", i);
            continue;
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3228" endline="3246">
{
    size = sizeof (struct sys_device) + nr_ioapic_registers[i] * sizeof (struct IO_APIC_route_entry);
    mp_ioapic_data[i] = kzalloc (size, GFP_KERNEL);
    if (!mp_ioapic_data[i]) {
        printk (KERN_ERR "Can't suspend/resume IOAPIC %d\n", i);
        continue;
    }
    dev = &mp_ioapic_data[i]->dev;
    dev->id = i;
    dev->cls = &ioapic_sysdev_class;
    error = sysdev_register (dev);
    if (error) {
        kfree (mp_ioapic_data [i]);
        mp_ioapic_data[i] = NULL;
        printk (KERN_ERR "Can't suspend/resume IOAPIC %d\n", i);
        continue;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3232" endline="3235">
{
    printk (KERN_ERR "Can't suspend/resume IOAPIC %d\n", i);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3240" endline="3245">
{
    kfree (mp_ioapic_data [i]);
    mp_ioapic_data[i] = NULL;
    printk (KERN_ERR "Can't suspend/resume IOAPIC %d\n", i);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3257" endline="3294">
{
    unsigned int irq;
    unsigned int new;
    unsigned long flags;
    struct irq_cfg *cfg_new = NULL;
    struct irq_desc *desc_new = NULL;
    irq = 0;
    if (irq_want < nr_irqs_gsi)
        irq_want = nr_irqs_gsi;
    raw_spin_lock_irqsave (& vector_lock, flags);
    for (new = irq_want; new < nr_irqs; new++) {
        desc_new = irq_to_desc_alloc_node (new, node);
        if (!desc_new) {
            printk (KERN_INFO "can not get irq_desc for %d\n", new);
            continue;
        }
        cfg_new = desc_new->chip_data;
        if (cfg_new->vector != 0)
            continue;
        desc_new = move_irq_desc (desc_new, node);
        cfg_new = desc_new->chip_data;
        if (__assign_irq_vector (new, cfg_new, apic->target_cpus ()) == 0)
            irq = new;
        break;
    }
    raw_spin_unlock_irqrestore (& vector_lock, flags);
    if (irq > 0)
        dynamic_irq_init_keep_chip_data (irq);
    return irq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3270" endline="3287">
{
    desc_new = irq_to_desc_alloc_node (new, node);
    if (!desc_new) {
        printk (KERN_INFO "can not get irq_desc for %d\n", new);
        continue;
    }
    cfg_new = desc_new->chip_data;
    if (cfg_new->vector != 0)
        continue;
    desc_new = move_irq_desc (desc_new, node);
    cfg_new = desc_new->chip_data;
    if (__assign_irq_vector (new, cfg_new, apic->target_cpus ()) == 0)
        irq = new;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3272" endline="3275">
{
    printk (KERN_INFO "can not get irq_desc for %d\n", new);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3297" endline="3309">
{
    int node = cpu_to_node (boot_cpu_id);
    unsigned int irq_want;
    int irq;
    irq_want = nr_irqs_gsi;
    irq = create_irq_nr (irq_want, node);
    if (irq == 0)
        irq = -1;
    return irq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3312" endline="3321">
{
    unsigned long flags;
    dynamic_irq_cleanup_keep_chip_data (irq);
    free_irte (irq);
    raw_spin_lock_irqsave (& vector_lock, flags);
    __clear_irq_vector (irq, get_irq_chip_data (irq));
    raw_spin_unlock_irqrestore (& vector_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3853" endline="3862">
{
    union IO_APIC_reg_01 reg_01;
    unsigned long flags;
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    reg_01.raw = io_apic_read (ioapic, 1);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
    return reg_01.bits.entries;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3865" endline="3884">
{
    int nr = 0;
    nr = acpi_probe_gsi ();
    if (nr > nr_irqs_gsi) {
        nr_irqs_gsi = nr;
    }
    else {
        int idx;
        nr = 0;
        for (idx = 0; idx < nr_ioapics; idx++)
            nr += io_apic_get_redir_entries (idx) + 1;
        if (nr > nr_irqs_gsi)
            nr_irqs_gsi = nr;
    }
    printk (KERN_DEBUG "nr_irqs_gsi: %d\n", nr_irqs_gsi);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3869" endline="3871">
{
    nr_irqs_gsi = nr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3871" endline="3881">
{
    int idx;
    nr = 0;
    for (idx = 0; idx < nr_ioapics; idx++)
        nr += io_apic_get_redir_entries (idx) + 1;
    if (nr > nr_irqs_gsi)
        nr_irqs_gsi = nr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3910" endline="3954">
{
    struct irq_desc *desc;
    struct irq_cfg *cfg;
    int node;
    int ioapic, pin;
    int trigger, polarity;
    ioapic = irq_attr->ioapic;
    if (!IO_APIC_IRQ (irq)) {
        apic_printk (APIC_QUIET, KERN_ERR "IOAPIC[%d]: Invalid reference to IRQ 0\n", ioapic);
        return -EINVAL;
    }
    if (dev)
        node = dev_to_node (dev);
    else
        node = cpu_to_node (boot_cpu_id);
    desc = irq_to_desc_alloc_node (irq, node);
    if (!desc) {
        printk (KERN_INFO "can not get irq_desc %d\n", irq);
        return 0;
    }
    pin = irq_attr->ioapic_pin;
    trigger = irq_attr->trigger;
    polarity = irq_attr->polarity;
    if (irq >= legacy_pic->nr_legacy_irqs) {
        cfg = desc->chip_data;
        if (add_pin_to_irq_node_nopanic (cfg, node, ioapic, pin)) {
            printk (KERN_INFO "can not add pin %d for irq %d\n", pin, irq);
            return 0;
        }
    }
    setup_IO_APIC_irq (ioapic, pin, irq, desc, trigger, polarity);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3918" endline="3922">
{
    apic_printk (APIC_QUIET, KERN_ERR "IOAPIC[%d]: Invalid reference to IRQ 0\n", ioapic);
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3930" endline="3933">
{
    printk (KERN_INFO "can not get irq_desc %d\n", irq);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3942" endline="3949">
{
    cfg = desc->chip_data;
    if (add_pin_to_irq_node_nopanic (cfg, node, ioapic, pin)) {
        printk (KERN_INFO "can not add pin %d for irq %d\n", pin, irq);
        return 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3944" endline="3948">
{
    printk (KERN_INFO "can not add pin %d for irq %d\n", pin, irq);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3958" endline="3975">
{
    int ioapic, pin;
    ioapic = irq_attr->ioapic;
    pin = irq_attr->ioapic_pin;
    if (test_bit (pin, mp_ioapic_routing[ioapic].pin_programmed)) {
        pr_debug ("Pin %d-%d already programmed\n", mp_ioapics [ioapic].apicid, pin);
        return 0;
    }
    set_bit (pin, mp_ioapic_routing [ioapic].pin_programmed);
    return __io_apic_set_pci_routing (dev, irq, irq_attr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3967" endline="3971">
{
    pr_debug ("Pin %d-%d already programmed\n", mp_ioapics [ioapic].apicid, pin);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3978" endline="3998">
{
    int i;
    DECLARE_BITMAP (used, 256);
    bitmap_zero (used, 256);
    for (i = 0; i < nr_ioapics; i++) {
        struct mpc_ioapic *ia = &mp_ioapics[i];
        __set_bit (ia -> apicid, used);
    }
    if (!test_bit (id, used))
        return id;
    return find_first_zero_bit (used, 256);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="3990" endline="3993">
{
    struct mpc_ioapic *ia = &mp_ioapics[i];
    __set_bit (ia -> apicid, used);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4077" endline="4086">
{
    union IO_APIC_reg_01 reg_01;
    unsigned long flags;
    raw_spin_lock_irqsave (& ioapic_lock, flags);
    reg_01.raw = io_apic_read (ioapic, 1);
    raw_spin_unlock_irqrestore (& ioapic_lock, flags);
    return reg_01.bits.version;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4089" endline="4105">
{
    int i;
    if (skip_ioapic_setup)
        return -1;
    for (i = 0; i < mp_irq_entries; i++)
        if (mp_irqs[i].irqtype == mp_INT && mp_irqs[i].srcbusirq == bus_irq)
            break;
    if (i >= mp_irq_entries)
        return -1;
    *trigger = irq_trigger (i);
    *polarity = irq_polarity (i);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4157" endline="4184">
{
    unsigned long n;
    struct resource *res;
    char *mem;
    int i;
    if (nr_ioapics <= 0)
        return NULL;
    n = IOAPIC_RESOURCE_NAME_SIZE + sizeof (struct resource);
    n *= nr_ioapics;
    mem = alloc_bootmem (n);
    res = (void *) mem;
    mem += sizeof (struct resource) * nr_ioapics;
    for (i = 0; i < nr_ioapics; i++) {
        res[i].name = mem;
        res[i].flags = IORESOURCE_MEM | IORESOURCE_BUSY;
        snprintf (mem, IOAPIC_RESOURCE_NAME_SIZE, "IOAPIC %u", i);
        mem += IOAPIC_RESOURCE_NAME_SIZE;
    }
    ioapic_resources = res;
    return res;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4174" endline="4179">
{
    res[i].name = mem;
    res[i].flags = IORESOURCE_MEM | IORESOURCE_BUSY;
    snprintf (mem, IOAPIC_RESOURCE_NAME_SIZE, "IOAPIC %u", i);
    mem += IOAPIC_RESOURCE_NAME_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4187" endline="4224">
{
    unsigned long ioapic_phys, idx = FIX_IO_APIC_BASE_0;
    struct resource *ioapic_res;
    int i;
    ioapic_res = ioapic_setup_resources (nr_ioapics);
    for (i = 0; i < nr_ioapics; i++) {
        if (smp_found_config) {
            ioapic_phys = mp_ioapics[i].apicaddr;
        }
        else {
            ioapic_phys = (unsigned long) alloc_bootmem_pages (PAGE_SIZE);
            ioapic_phys = __pa (ioapic_phys);
        }
        set_fixmap_nocache (idx, ioapic_phys);
        apic_printk (APIC_VERBOSE, "mapped IOAPIC to %08lx (%08lx)\n", __fix_to_virt (idx) + (ioapic_phys & ~ PAGE_MASK), ioapic_phys);
        idx++;
        ioapic_res->start = ioapic_phys;
        ioapic_res->end = ioapic_phys + IO_APIC_SLOT_SIZE - 1;
        ioapic_res++;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4193" endline="4223">
{
    if (smp_found_config) {
        ioapic_phys = mp_ioapics[i].apicaddr;
    }
    else {
        ioapic_phys = (unsigned long) alloc_bootmem_pages (PAGE_SIZE);
        ioapic_phys = __pa (ioapic_phys);
    }
    set_fixmap_nocache (idx, ioapic_phys);
    apic_printk (APIC_VERBOSE, "mapped IOAPIC to %08lx (%08lx)\n", __fix_to_virt (idx) + (ioapic_phys & ~ PAGE_MASK), ioapic_phys);
    idx++;
    ioapic_res->start = ioapic_phys;
    ioapic_res->end = ioapic_phys + IO_APIC_SLOT_SIZE - 1;
    ioapic_res++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4194" endline="4207">
{
    ioapic_phys = mp_ioapics[i].apicaddr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4207" endline="4213">
{
    ioapic_phys = (unsigned long) alloc_bootmem_pages (PAGE_SIZE);
    ioapic_phys = __pa (ioapic_phys);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4227" endline="4242">
{
    int i;
    struct resource *r = ioapic_resources;
    if (!r) {
        if (nr_ioapics > 0)
            printk (KERN_ERR "IO APIC resources couldn't be allocated.\n");
        return;
    }
    for (i = 0; i < nr_ioapics; i++) {
        insert_resource (& iomem_resource, r);
        r++;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4231" endline="4236">
{
    if (nr_ioapics > 0)
        printk (KERN_ERR "IO APIC resources couldn't be allocated.\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4238" endline="4241">
{
    insert_resource (& iomem_resource, r);
    r++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4245" endline="4257">
{
    int i = 0;
    for (i = 0; i < nr_ioapics; i++) {
        if ((gsi >= mp_gsi_routing[i].gsi_base) && (gsi <= mp_gsi_routing[i].gsi_end))
            return i;
    }
    printk (KERN_ERR "ERROR: Unable to locate IOAPIC for GSI %d\n", gsi);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4249" endline="4253">
{
    if ((gsi >= mp_gsi_routing[i].gsi_base) && (gsi <= mp_gsi_routing[i].gsi_end))
        return i;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4260" endline="4267">
{
    if (WARN_ON (ioapic == -1))
        return -1;
    if (WARN_ON (gsi > mp_gsi_routing[ioapic].gsi_end))
        return -1;
    return gsi - mp_gsi_routing[ioapic].gsi_base;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4270" endline="4282">
{
    if (nr_ioapics >= MAX_IO_APICS) {
        printk (KERN_WARNING "WARING: Max # of I/O APICs (%d) exceeded " "(found %d), skipping\n", MAX_IO_APICS, nr_ioapics);
        return 1;
    }
    if (!address) {
        printk (KERN_WARNING "WARNING: Bogus (zero) I/O APIC address" " found in table, skipping!\n");
        return 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4271" endline="4275">
{
    printk (KERN_WARNING "WARING: Max # of I/O APICs (%d) exceeded " "(found %d), skipping\n", MAX_IO_APICS, nr_ioapics);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4276" endline="4280">
{
    printk (KERN_WARNING "WARNING: Bogus (zero) I/O APIC address" " found in table, skipping!\n");
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4285" endline="4315">
{
    int idx = 0;
    if (bad_ioapic (address))
        return;
    idx = nr_ioapics;
    mp_ioapics[idx].type = MP_IOAPIC;
    mp_ioapics[idx].flags = MPC_APIC_USABLE;
    mp_ioapics[idx].apicaddr = address;
    set_fixmap_nocache (FIX_IO_APIC_BASE_0 + idx, address);
    mp_ioapics[idx].apicid = io_apic_unique_id (id);
    mp_ioapics[idx].apicver = io_apic_get_version (idx);
    mp_gsi_routing[idx].gsi_base = gsi_base;
    mp_gsi_routing[idx].gsi_end = gsi_base + io_apic_get_redir_entries (idx);
    printk (KERN_INFO "IOAPIC[%d]: apic_id %d, version %d, address 0x%x, " "GSI %d-%d\n", idx, mp_ioapics [idx].apicid, mp_ioapics [idx].apicver, mp_ioapics [idx].apicaddr, mp_gsi_routing [idx].gsi_base, mp_gsi_routing [idx].gsi_end);
    nr_ioapics++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/io_apic.c.ifdefed" startline="4319" endline="4336">
{
    struct irq_cfg *cfg;
    struct irq_desc *desc;
    printk (KERN_INFO "Early APIC setup for system timer0\n");
    phys_cpu_present_map = physid_mask_of_physid (boot_cpu_physical_apicid);
    desc = irq_to_desc_alloc_node (0, 0);
    setup_local_APIC ();
    cfg = irq_cfg (0);
    add_pin_to_irq_node (cfg, 0, 0, 0);
    set_irq_chip_and_handler_name (0, & ioapic_chip, handle_edge_irq, "edge");
    setup_IO_APIC_irq (0, 0, 0, desc, 0, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="28" endline="30">
{
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="33" endline="35">
{
    return cpu_online_mask;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="38" endline="49">
{
    cpumask_clear (retmask);
    cpumask_bits (retmask)[0] = APIC_ALL_CPUS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="59" endline="69">
{
    unsigned long val;
    unsigned long num, id;
    num = smp_processor_id ();
    id = 1UL << num;
    apic_write (APIC_DFR, APIC_DFR_FLAT);
    val = apic_read (APIC_LDR) & ~APIC_LDR_MASK;
    val |= SET_APIC_LOGICAL_ID (id);
    apic_write (APIC_LDR, val);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="72" endline="78">
{
    unsigned long flags;
    local_irq_save (flags);
    __default_send_IPI_dest_field (mask, vector, apic -> dest_logical);
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="81" endline="85">
{
    unsigned long mask = cpumask_bits (cpumask)[0];
    _flat_send_IPI_mask (mask, vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="89" endline="97">
{
    unsigned long mask = cpumask_bits (cpumask)[0];
    int cpu = smp_processor_id ();
    if (cpu < BITS_PER_LONG)
        clear_bit (cpu, &mask);
    _flat_send_IPI_mask (mask, vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="100" endline="120">
{
    int cpu = smp_processor_id ();
    int hotplug = 0;
    if (hotplug || vector == NMI_VECTOR) {
        if (!cpumask_equal (cpu_online_mask, cpumask_of (cpu))) {
            unsigned long mask = cpumask_bits (cpu_online_mask)[0];
            if (cpu < BITS_PER_LONG)
                clear_bit (cpu, &mask);
            _flat_send_IPI_mask (mask, vector);
        }
    }
    else if (num_online_cpus () > 1) {
        __default_send_IPI_shortcut (APIC_DEST_ALLBUT, vector, apic -> dest_logical);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="107" endline="116">
{
    if (!cpumask_equal (cpu_online_mask, cpumask_of (cpu))) {
        unsigned long mask = cpumask_bits (cpu_online_mask)[0];
        if (cpu < BITS_PER_LONG)
            clear_bit (cpu, &mask);
        _flat_send_IPI_mask (mask, vector);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="108" endline="115">
{
    unsigned long mask = cpumask_bits (cpu_online_mask)[0];
    if (cpu < BITS_PER_LONG)
        clear_bit (cpu, &mask);
    _flat_send_IPI_mask (mask, vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="116" endline="119">
{
    __default_send_IPI_shortcut (APIC_DEST_ALLBUT, vector, apic -> dest_logical);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="123" endline="130">
{
    if (vector == NMI_VECTOR) {
        flat_send_IPI_mask (cpu_online_mask, vector);
    }
    else {
        __default_send_IPI_shortcut (APIC_DEST_ALLINC, vector, apic -> dest_logical);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="124" endline="126">
{
    flat_send_IPI_mask (cpu_online_mask, vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="126" endline="129">
{
    __default_send_IPI_shortcut (APIC_DEST_ALLINC, vector, apic -> dest_logical);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="133" endline="139">
{
    unsigned int id;
    id = (((x) >> 24) & 0xFFu);
    return id;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="142" endline="147">
{
    unsigned long x;
    x = ((id & 0xFFu) << 24);
    return x;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="150" endline="155">
{
    unsigned int id;
    id = flat_get_apic_id (apic_read (APIC_ID));
    return id;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="158" endline="160">
{
    return physid_isset (read_xapic_id (), phys_cpu_present_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="163" endline="165">
{
    return initial_apic_id >> index_msb;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="231" endline="251">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="254" endline="256">
{
    return cpu_online_mask;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="259" endline="262">
{
    cpumask_clear (retmask);
    cpumask_set_cpu (cpu, retmask);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="265" endline="267">
{
    default_send_IPI_mask_sequence_phys (cpumask, vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="271" endline="273">
{
    default_send_IPI_mask_allbutself_phys (cpumask, vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="276" endline="278">
{
    default_send_IPI_mask_allbutself_phys (cpu_online_mask, vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="281" endline="283">
{
    physflat_send_IPI_mask (cpu_online_mask, vector);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="286" endline="298">
{
    int cpu;
    cpu = cpumask_first (cpumask);
    if ((unsigned) cpu < nr_cpu_ids)
        return per_cpu (x86_cpu_to_apicid, cpu);
    else
        return BAD_APICID;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="303" endline="315">
{
    int cpu;

    for_each_cpu_and (cpu, cpumask, andmask) {
        if (cpumask_test_cpu (cpu, cpu_online_mask))
            break;
    }

    return per_cpu (x86_cpu_to_apicid, cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/apic_flat_64.c.ifdefed" startline="310" endline="313">
{
    if (cpumask_test_cpu (cpu, cpu_online_mask))
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="65" endline="67">
{
    return per_cpu (irq_stat, cpu).__nmi_count;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="70" endline="75">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="82" endline="85">
{
    return per_cpu (irq_stat, cpu).apic_timer_irqs + per_cpu (irq_stat, cpu).irq0_irqs;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="110" endline="124">
{
    printk (KERN_CONT "\n");
    printk (KERN_WARNING "WARNING: CPU#%d: NMI appears to be stuck (%d->%d)!\n", cpu, prev_nmi_count [cpu], get_nmi_count (cpu));
    printk (KERN_WARNING "Please report this to bugzilla.kernel.org,\n");
    printk (KERN_WARNING "and attach the output of the 'dmesg' command.\n");
    per_cpu (wd_enabled, cpu) = 0;
    atomic_dec (& nmi_active);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="127" endline="129">
{
    apic_write (APIC_LVT0, APIC_DM_NMI | APIC_LVT_MASKED);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="132" endline="189">
{
    unsigned int *prev_nmi_count;
    int cpu;
    if (!nmi_watchdog_active () || !atomic_read (&nmi_active))
        return 0;
    prev_nmi_count = kmalloc (nr_cpu_ids * sizeof (int), GFP_KERNEL);
    if (!prev_nmi_count)
        goto error;
    printk (KERN_INFO "Testing NMI watchdog ... ");
    for_each_possible_cpu (cpu)
    prev_nmi_count [cpu] = get_nmi_count (cpu);
    local_irq_enable ();
    mdelay ((20 * 1000) / nmi_hz);

    for_each_online_cpu (cpu) {
        if (!per_cpu (wd_enabled, cpu))
            continue;
        if (get_nmi_count (cpu) - prev_nmi_count[cpu] <= 5)
            report_broken_nmi (cpu, prev_nmi_count);
    }

    endflag = 1;
    if (!atomic_read (&nmi_active)) {
        kfree (prev_nmi_count);
        atomic_set (& nmi_active, - 1);
        goto error;
    }
    printk ("OK.\n");
    if (nmi_watchdog == NMI_LOCAL_APIC)
        nmi_hz = lapic_adjust_nmi_hz (1);
    kfree (prev_nmi_count);
    return 0;
error :
    if (nmi_watchdog == NMI_IO_APIC) {
        if (!timer_through_8259)
            legacy_pic->chip->mask (0);
        on_each_cpu (__acpi_nmi_disable, NULL, 1);
    }
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="155" endline="160">
{
    if (!per_cpu (wd_enabled, cpu))
        continue;
    if (get_nmi_count (cpu) - prev_nmi_count[cpu] <= 5)
        report_broken_nmi (cpu, prev_nmi_count);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="162" endline="166">
{
    kfree (prev_nmi_count);
    atomic_set (& nmi_active, - 1);
    goto error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="179" endline="183">
{
    if (!timer_through_8259)
        legacy_pic->chip->mask (0);
    on_each_cpu (__acpi_nmi_disable, NULL, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="192" endline="215">
{
    unsigned int nmi;
    if (!strncmp (str, "panic", 5)) {
        panic_on_timeout = 1;
        str = strchr (str, ',');
        if (!str)
            return 1;
        ++str;
    }
    if (!strncmp (str, "lapic", 5))
        nmi_watchdog = NMI_LOCAL_APIC;
    else if (!strncmp (str, "ioapic", 6))
        nmi_watchdog = NMI_IO_APIC;
    else {
        get_option (& str, & nmi);
        if (nmi >= NMI_INVALID)
            return 0;
        nmi_watchdog = nmi;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="195" endline="201">
{
    panic_on_timeout = 1;
    str = strchr (str, ',');
    if (!str)
        return 1;
    ++str;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="207" endline="212">
{
    get_option (& str, & nmi);
    if (nmi >= NMI_INVALID)
        return 0;
    nmi_watchdog = nmi;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="281" endline="283">
{
    apic_write (APIC_LVT0, APIC_DM_NMI);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="289" endline="292">
{
    if (atomic_read (&nmi_active) && nmi_watchdog == NMI_IO_APIC)
        on_each_cpu (__acpi_nmi_enable, NULL, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="298" endline="301">
{
    if (atomic_read (&nmi_active) && nmi_watchdog == NMI_IO_APIC)
        on_each_cpu (__acpi_nmi_disable, NULL, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="308" endline="310">
{
    __get_cpu_var (wd_enabled) = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="313" endline="333">
{
    if (__get_cpu_var (wd_enabled))
        return;
    if (smp_processor_id () != 0 && atomic_read (&nmi_active) <= 0)
        return;
    switch (nmi_watchdog) {
    case NMI_LOCAL_APIC :
        if (lapic_watchdog_init (nmi_hz) < 0) {
            __get_cpu_var (wd_enabled) = 0;
            return;
        }
    case NMI_IO_APIC :
        __get_cpu_var (wd_enabled) = 1;
        atomic_inc (& nmi_active);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="322" endline="332">
{
case NMI_LOCAL_APIC :
    if (lapic_watchdog_init (nmi_hz) < 0) {
        __get_cpu_var (wd_enabled) = 0;
        return;
    }
case NMI_IO_APIC :
    __get_cpu_var (wd_enabled) = 1;
    atomic_inc (& nmi_active);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="324" endline="327">
{
    __get_cpu_var (wd_enabled) = 0;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="336" endline="348">
{
    if (!nmi_watchdog_active ())
        return;
    if (__get_cpu_var (wd_enabled) == 0)
        return;
    if (nmi_watchdog == NMI_LOCAL_APIC)
        lapic_watchdog_stop ();
    else
        __acpi_nmi_disable (NULL);
    __get_cpu_var (wd_enabled) = 0;
    atomic_dec (& nmi_active);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="369" endline="388">
{
    if (nmi_watchdog_active ()) {
        unsigned cpu;

        for_each_present_cpu (cpu) {
            if (per_cpu (nmi_touch, cpu) != 1)
                per_cpu (nmi_touch, cpu) = 1;
        }

    }
    touch_softlockup_watchdog ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="370" endline="382">
{
    unsigned cpu;

    for_each_present_cpu (cpu) {
        if (per_cpu (nmi_touch, cpu) != 1)
            per_cpu (nmi_touch, cpu) = 1;
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="378" endline="381">
{
    if (per_cpu (nmi_touch, cpu) != 1)
        per_cpu (nmi_touch, cpu) = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="393" endline="471">
{
    unsigned int sum;
    int touched = 0;
    int cpu = smp_processor_id ();
    int rc = 0;
    if (notify_die (DIE_NMI, "nmi", regs, reason, 2, SIGINT) == NOTIFY_STOP) {
        rc = 1;
        touched = 1;
    }
    sum = get_timer_irqs (cpu);
    if (__get_cpu_var (nmi_touch)) {
        __get_cpu_var (nmi_touch) = 0;
        touched = 1;
    }
    if (cpumask_test_cpu (cpu, to_cpumask (backtrace_mask))) {
        static DEFINE_RAW_SPINLOCK (lock);
        raw_spin_lock (& lock);
        printk (KERN_WARNING "NMI backtrace for cpu %d\n", cpu);
        show_regs (regs);
        dump_stack ();
        raw_spin_unlock (& lock);
        cpumask_clear_cpu (cpu, to_cpumask (backtrace_mask));
        rc = 1;
    }
    if (mce_in_progress ())
        touched = 1;
    if (!touched && __get_cpu_var (last_irq_sum) == sum) {
        __this_cpu_inc (alert_counter);
        if (__this_cpu_read (alert_counter) == 5 * nmi_hz)
            die_nmi ("BUG: NMI Watchdog detected LOCKUP", regs, panic_on_timeout);
    }
    else {
        __get_cpu_var (last_irq_sum) = sum;
        __this_cpu_write (alert_counter, 0);
    }
    if (!__get_cpu_var (wd_enabled))
        return rc;
    switch (nmi_watchdog) {
    case NMI_LOCAL_APIC :
        rc |= lapic_wd_event (nmi_hz);
        break;
    case NMI_IO_APIC :
        rc = 1;
        break;
    }
    return rc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="406" endline="409">
{
    rc = 1;
    touched = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="413" endline="416">
{
    __get_cpu_var (nmi_touch) = 0;
    touched = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="419" endline="430">
{
    static DEFINE_RAW_SPINLOCK (lock);
    raw_spin_lock (& lock);
    printk (KERN_WARNING "NMI backtrace for cpu %d\n", cpu);
    show_regs (regs);
    dump_stack ();
    raw_spin_unlock (& lock);
    cpumask_clear_cpu (cpu, to_cpumask (backtrace_mask));
    rc = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="437" endline="449">
{
    __this_cpu_inc (alert_counter);
    if (__this_cpu_read (alert_counter) == 5 * nmi_hz)
        die_nmi ("BUG: NMI Watchdog detected LOCKUP", regs, panic_on_timeout);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="449" endline="452">
{
    __get_cpu_var (last_irq_sum) = sum;
    __this_cpu_write (alert_counter, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="457" endline="469">
{
case NMI_LOCAL_APIC :
    rc |= lapic_wd_event (nmi_hz);
    break;
case NMI_IO_APIC :
    rc = 1;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="551" endline="557">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="560" endline="574">
{
    int i;
    cpumask_copy (to_cpumask (backtrace_mask), cpu_online_mask);
    printk (KERN_INFO "sending NMI to all CPUs:\n");
    apic->send_IPI_all (NMI_VECTOR);
    for (i = 0; i < 10 * 1000; i++) {
        if (cpumask_empty (to_cpumask (backtrace_mask)))
            break;
        mdelay (1);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/nmi.c.ifdefed" startline="569" endline="573">
{
    if (cpumask_empty (to_cpumask (backtrace_mask)))
        break;
    mdelay (1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/probe_64.c.ifdefed" startline="48" endline="50">
{
    return hard_smp_processor_id () >> index_msb;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/probe_64.c.ifdefed" startline="56" endline="86">
{
    if (apic == &apic_flat && num_possible_cpus () > 8)
        apic = &apic_physflat;
    printk (KERN_INFO "Setting APIC routing to %s\n", apic -> name);
    if (is_vsmp_box ()) {
        apic->phys_pkg_id = apicid_phys_pkg_id;
    }
    if (intr_remapping_enabled)
        enable_drhd_fault_handling ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/probe_64.c.ifdefed" startline="75" endline="78">
{
    apic->phys_pkg_id = apicid_phys_pkg_id;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/probe_64.c.ifdefed" startline="91" endline="93">
{
    __default_send_IPI_shortcut (APIC_DEST_SELF, vector, APIC_DEST_PHYSICAL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/probe_64.c.ifdefed" startline="96" endline="108">
{
    int i;
    for (i = 0; apic_probe[i]; ++i) {
        if (apic_probe[i]->acpi_madt_oem_check (oem_id, oem_table_id)) {
            apic = apic_probe[i];
            printk (KERN_INFO "Setting APIC routing to %s.\n", apic -> name);
            return 1;
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/probe_64.c.ifdefed" startline="99" endline="106">
{
    if (apic_probe[i]->acpi_madt_oem_check (oem_id, oem_table_id)) {
        apic = apic_probe[i];
        printk (KERN_INFO "Setting APIC routing to %s.\n", apic -> name);
        return 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/probe_64.c.ifdefed" startline="100" endline="105">
{
    apic = apic_probe[i];
    printk (KERN_INFO "Setting APIC routing to %s.\n", apic -> name);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/ipi.c.ifdefed" startline="23" endline="38">
{
    unsigned long query_cpu;
    unsigned long flags;
    local_irq_save (flags);

    for_each_cpu (query_cpu, mask) {
        __default_send_IPI_dest_field (per_cpu (x86_cpu_to_apicid, query_cpu), vector, APIC_DEST_PHYSICAL);
    }

    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/ipi.c.ifdefed" startline="33" endline="36">
{
    __default_send_IPI_dest_field (per_cpu (x86_cpu_to_apicid, query_cpu), vector, APIC_DEST_PHYSICAL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/ipi.c.ifdefed" startline="42" endline="57">
{
    unsigned int this_cpu = smp_processor_id ();
    unsigned int query_cpu;
    unsigned long flags;
    local_irq_save (flags);

    for_each_cpu (query_cpu, mask) {
        if (query_cpu == this_cpu)
            continue;
        __default_send_IPI_dest_field (per_cpu (x86_cpu_to_apicid, query_cpu), vector, APIC_DEST_PHYSICAL);
    }

    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/ipi.c.ifdefed" startline="50" endline="55">
{
    if (query_cpu == this_cpu)
        continue;
    __default_send_IPI_dest_field (per_cpu (x86_cpu_to_apicid, query_cpu), vector, APIC_DEST_PHYSICAL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/ipi.c.ifdefed" startline="61" endline="77">
{
    unsigned long flags;
    unsigned int query_cpu;
    local_irq_save (flags);
    for_each_cpu (query_cpu, mask)
    __default_send_IPI_dest_field (apic -> cpu_to_logical_apicid (query_cpu), vector, apic -> dest_logical);
    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/ipi.c.ifdefed" startline="81" endline="97">
{
    unsigned long flags;
    unsigned int query_cpu;
    unsigned int this_cpu = smp_processor_id ();
    local_irq_save (flags);

    for_each_cpu (query_cpu, mask) {
        if (query_cpu == this_cpu)
            continue;
        __default_send_IPI_dest_field (apic -> cpu_to_logical_apicid (query_cpu), vector, apic -> dest_logical);
    }

    local_irq_restore (flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/apic/ipi.c.ifdefed" startline="89" endline="95">
{
    if (query_cpu == this_cpu)
        continue;
    __default_send_IPI_dest_field (apic -> cpu_to_logical_apicid (query_cpu), vector, apic -> dest_logical);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="29" endline="36">
{
    do {
        dev = pci_get_device (PCI_ANY_ID, PCI_ANY_ID, dev);
        if (!dev)
            break;
    }
    while (!pci_match_id (&k8_nb_ids[0], dev));
    return dev;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="30" endline="34">
{
    dev = pci_get_device (PCI_ANY_ID, PCI_ANY_ID, dev);
    if (!dev)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="39" endline="74">
{
    int i;
    struct pci_dev *dev;
    if (num_k8_northbridges)
        return 0;
    dev = NULL;
    while ((dev = next_k8_northbridge (dev)) != NULL)
        num_k8_northbridges++;
    k8_northbridges = kmalloc ((num_k8_northbridges + 1) * sizeof (void *), GFP_KERNEL);
    if (!k8_northbridges)
        return -ENOMEM;
    if (!num_k8_northbridges) {
        k8_northbridges[0] = NULL;
        return 0;
    }
    flush_words = kmalloc (num_k8_northbridges * sizeof (u32), GFP_KERNEL);
    if (!flush_words) {
        kfree (k8_northbridges);
        return -ENOMEM;
    }
    dev = NULL;
    i = 0;
    while ((dev = next_k8_northbridge (dev)) != NULL) {
        k8_northbridges[i] = dev;
        pci_read_config_dword (dev, 0x9c, & flush_words [i ++]);
    }
    k8_northbridges[i] = NULL;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="55" endline="58">
{
    k8_northbridges[0] = NULL;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="61" endline="64">
{
    kfree (k8_northbridges);
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="68" endline="71">
{
    k8_northbridges[i] = dev;
    pci_read_config_dword (dev, 0x9c, & flush_words [i ++]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="80" endline="88">
{
    struct pci_device_id *id;
    u32 vendor = device & 0xffff;
    device >>= 16;
    for (id = k8_nb_ids; id->vendor; id++)
        if (vendor == id->vendor && device == id->device)
            return 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="91" endline="121">
{
    int flushed, i;
    unsigned long flags;
    static DEFINE_SPINLOCK (gart_lock);
    spin_lock_irqsave (& gart_lock, flags);
    flushed = 0;
    for (i = 0; i < num_k8_northbridges; i++) {
        pci_write_config_dword (k8_northbridges [i], 0x9c, flush_words [i] | 1);
        flushed++;
    }
    for (i = 0; i < num_k8_northbridges; i++) {
        u32 w;
        for (;;) {
            pci_read_config_dword (k8_northbridges [i], 0x9c, & w);
            if (!(w & 1))
                break;
            cpu_relax ();
        }
    }
    spin_unlock_irqrestore (& gart_lock, flags);
    if (!flushed)
        printk ("nothing to flush?\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="102" endline="106">
{
    pci_write_config_dword (k8_northbridges [i], 0x9c, flush_words [i] | 1);
    flushed++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="107" endline="117">
{
    u32 w;
    for (;;) {
        pci_read_config_dword (k8_northbridges [i], 0x9c, & w);
        if (!(w & 1))
            break;
        cpu_relax ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="110" endline="116">
{
    pci_read_config_dword (k8_northbridges [i], 0x9c, & w);
    if (!(w & 1))
        break;
    cpu_relax ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/k8.c.ifdefed" startline="125" endline="134">
{
    int err = 0;
    err = cache_k8_northbridges ();
    if (err < 0)
        printk (KERN_NOTICE "K8 NB: Cannot enumerate AMD northbridges.\n");
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irqinit.c.ifdefed" startline="90" endline="99">
{
    int cpu;

    for_each_online_cpu (cpu) {
        if (per_cpu (vector_irq, cpu)[vector] != -1)
            return 1;
    }

    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irqinit.c.ifdefed" startline="93" endline="96">
{
    if (per_cpu (vector_irq, cpu)[vector] != -1)
        return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irqinit.c.ifdefed" startline="102" endline="123">
{
    int i;
    legacy_pic->init (0);
    for (i = 0; i < legacy_pic->nr_legacy_irqs; i++) {
        struct irq_desc *desc = irq_to_desc (i);
        desc->status = IRQ_DISABLED;
        desc->action = NULL;
        desc->depth = 1;
        set_irq_chip_and_handler_name (i, & i8259A_chip, handle_level_irq, "XT");
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irqinit.c.ifdefed" startline="113" endline="122">
{
    struct irq_desc *desc = irq_to_desc (i);
    desc->status = IRQ_DISABLED;
    desc->action = NULL;
    desc->depth = 1;
    set_irq_chip_and_handler_name (i, & i8259A_chip, handle_level_irq, "XT");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irqinit.c.ifdefed" startline="126" endline="141">
{
    int i;
    for (i = 0; i < legacy_pic->nr_legacy_irqs; i++)
        per_cpu (vector_irq, 0)[IRQ0_VECTOR + i] = i;
    x86_init.irqs.intr_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irqinit.c.ifdefed" startline="147" endline="163">
{
    int irq;
    for (irq = 0; irq < legacy_pic->nr_legacy_irqs; irq++)
        per_cpu (vector_irq, cpu)[IRQ0_VECTOR + irq] = irq;
    __setup_vector_irq (cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irqinit.c.ifdefed" startline="166" endline="200">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irqinit.c.ifdefed" startline="203" endline="233">
{
    smp_intr_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irqinit.c.ifdefed" startline="236" endline="268">
{
    int i;
    x86_init.irqs.pre_vector_init ();
    apic_intr_init ();
    for (i = FIRST_EXTERNAL_VECTOR; i < NR_VECTORS; i++) {
        if (!test_bit (i, used_vectors))
            set_intr_gate (i, interrupt[i - FIRST_EXTERNAL_VECTOR]);
    }
    if (!acpi_ioapic)
        setup_irq (2, &irq2);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/irqinit.c.ifdefed" startline="249" endline="253">
{
    if (!test_bit (i, used_vectors))
        set_intr_gate (i, interrupt[i - FIRST_EXTERNAL_VECTOR]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="34" endline="45">
{
    *dst = *src;
    if (src->thread.xstate) {
        dst->thread.xstate = kmem_cache_alloc (task_xstate_cachep, GFP_KERNEL);
        if (!dst->thread.xstate)
            return -ENOMEM;
        WARN_ON ((unsigned long) dst -> thread.xstate & 15);
        memcpy (dst -> thread.xstate, src -> thread.xstate, xstate_size);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="36" endline="43">
{
    dst->thread.xstate = kmem_cache_alloc (task_xstate_cachep, GFP_KERNEL);
    if (!dst->thread.xstate)
        return -ENOMEM;
    WARN_ON ((unsigned long) dst -> thread.xstate & 15);
    memcpy (dst -> thread.xstate, src -> thread.xstate, xstate_size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="48" endline="55">
{
    if (tsk->thread.xstate) {
        kmem_cache_free (task_xstate_cachep, tsk -> thread.xstate);
        tsk->thread.xstate = NULL;
    }
    WARN (tsk -> thread.ds_ctx, "leaking DS context\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="49" endline="52">
{
    kmem_cache_free (task_xstate_cachep, tsk -> thread.xstate);
    tsk->thread.xstate = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="58" endline="61">
{
    free_thread_xstate (ti -> task);
    free_pages ((unsigned long) ti, get_order (THREAD_SIZE));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="64" endline="69">
{
    task_xstate_cachep = kmem_cache_create ("task_xstate", xstate_size, __alignof__ (union thread_xstate), SLAB_PANIC | SLAB_NOTRACK, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="75" endline="93">
{
    struct task_struct *me = current;
    struct thread_struct *t = &me->thread;
    unsigned long *bp = t->io_bitmap_ptr;
    if (bp) {
        struct tss_struct *tss = &per_cpu (init_tss, get_cpu ());
        t->io_bitmap_ptr = NULL;
        clear_thread_flag (TIF_IO_BITMAP);
        memset (tss -> io_bitmap, 0xff, t -> io_bitmap_max);
        t->io_bitmap_max = 0;
        put_cpu ();
        kfree (bp);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="80" endline="92">
{
    struct tss_struct *tss = &per_cpu (init_tss, get_cpu ());
    t->io_bitmap_ptr = NULL;
    clear_thread_flag (TIF_IO_BITMAP);
    memset (tss -> io_bitmap, 0xff, t -> io_bitmap_max);
    t->io_bitmap_max = 0;
    put_cpu ();
    kfree (bp);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="96" endline="100">
{
    show_registers (regs);
    show_trace (NULL, regs, (unsigned long *) kernel_stack_pointer (regs), regs -> bp);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="103" endline="119">
{
    const char *board, *product;
    board = dmi_get_system_info (DMI_BOARD_NAME);
    if (!board)
        board = "";
    product = dmi_get_system_info (DMI_PRODUCT_NAME);
    if (!product)
        product = "";
    printk (KERN_CONT "\n");
    printk (KERN_DEFAULT "Pid: %d, comm: %.20s %s %s %.*s %s/%s\n", current -> pid, current -> comm, print_tainted (), init_utsname () -> release, (int) strcspn (init_utsname () -> version, " "), init_utsname () -> version, board, product);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="122" endline="133">
{
    struct task_struct *tsk = current;
    flush_ptrace_hw_breakpoint (tsk);
    memset (tsk -> thread.tls_array, 0, sizeof (tsk -> thread.tls_array));
    tsk->fpu_counter = 0;
    clear_fpu (tsk);
    clear_used_math ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="136" endline="138">
{
    write_cr4 (read_cr4 () | X86_CR4_TSD);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="141" endline="150">
{
    preempt_disable ();
    if (!test_and_set_thread_flag (TIF_NOTSC))
        hard_disable_TSC ();
    preempt_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="153" endline="155">
{
    write_cr4 (read_cr4 () & ~ X86_CR4_TSD);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="158" endline="167">
{
    preempt_disable ();
    if (test_and_clear_thread_flag (TIF_NOTSC))
        hard_enable_TSC ();
    preempt_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="170" endline="179">
{
    unsigned int val;
    if (test_thread_flag (TIF_NOTSC))
        val = PR_TSC_SIGSEGV;
    else
        val = PR_TSC_ENABLE;
    return put_user (val, (unsigned int __user *) adr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="182" endline="191">
{
    if (val == PR_TSC_SIGSEGV)
        disable_TSC ();
    else if (val == PR_TSC_ENABLE)
        enable_TSC ();
    else
        return -EINVAL;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="195" endline="230">
{
    struct thread_struct *prev, *next;
    prev = &prev_p->thread;
    next = &next_p->thread;
    if (test_tsk_thread_flag (next_p, TIF_DS_AREA_MSR) || test_tsk_thread_flag (prev_p, TIF_DS_AREA_MSR))
        ds_switch_to (prev_p, next_p);
    else if (next->debugctlmsr != prev->debugctlmsr)
        update_debugctlmsr (next->debugctlmsr);
    if (test_tsk_thread_flag (prev_p, TIF_NOTSC) ^ test_tsk_thread_flag (next_p, TIF_NOTSC)) {
        if (test_tsk_thread_flag (next_p, TIF_NOTSC))
            hard_disable_TSC ();
        else
            hard_enable_TSC ();
    }
    if (test_tsk_thread_flag (next_p, TIF_IO_BITMAP)) {
        memcpy (tss -> io_bitmap, next -> io_bitmap_ptr, max (prev -> io_bitmap_max, next -> io_bitmap_max));
    }
    else if (test_tsk_thread_flag (prev_p, TIF_IO_BITMAP)) {
        memset (tss -> io_bitmap, 0xff, prev -> io_bitmap_max);
    }
    propagate_user_return_notify (prev_p, next_p);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="208" endline="214">
{
    if (test_tsk_thread_flag (next_p, TIF_NOTSC))
        hard_disable_TSC ();
    else
        hard_enable_TSC ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="216" endline="223">
{
    memcpy (tss -> io_bitmap, next -> io_bitmap_ptr, max (prev -> io_bitmap_max, next -> io_bitmap_max));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="223" endline="228">
{
    memset (tss -> io_bitmap, 0xff, prev -> io_bitmap_max);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="233" endline="235">
{
    return do_fork (SIGCHLD, regs->sp, regs, 0, NULL, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="248" endline="251">
{
    return do_fork (CLONE_VFORK | CLONE_VM | SIGCHLD, regs->sp, regs, 0, NULL, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="256" endline="260">
{
    if (!newsp)
        newsp = regs->sp;
    return do_fork (clone_flags, newsp, regs, 0, parent_tid, child_tid);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="273" endline="297">
{
    struct pt_regs regs;
    memset (& regs, 0, sizeof (regs));
    regs.si = (unsigned long) fn;
    regs.di = (unsigned long) arg;
    regs.ss = __KERNEL_DS;
    regs.orig_ax = -1;
    regs.ip = (unsigned long) kernel_thread_helper;
    regs.cs = __KERNEL_CS | get_kernel_rpl ();
    regs.flags = X86_EFLAGS_IF | 0x2;
    return do_fork (flags | CLONE_VM | CLONE_UNTRACED, 0, &regs, 0, NULL, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="305" endline="324">
{
    long error;
    char *filename;
    filename = getname (name);
    error = PTR_ERR (filename);
    if (IS_ERR (filename))
        return error;
    error = do_execve (filename, argv, envp, regs);
    putname (filename);
    return error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="362" endline="364">
{
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="372" endline="392">
{
    if (hlt_use_halt ()) {
        trace_power_start (POWER_CSTATE, 1);
        current_thread_info ()->status &= ~TS_POLLING;
        smp_mb ();
        if (!need_resched ())
            safe_halt ();
        else
            local_irq_enable ();
        current_thread_info ()->status |= TS_POLLING;
    }
    else {
        local_irq_enable ();
        cpu_relax ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="373" endline="387">
{
    trace_power_start (POWER_CSTATE, 1);
    current_thread_info ()->status &= ~TS_POLLING;
    smp_mb ();
    if (!need_resched ())
        safe_halt ();
    else
        local_irq_enable ();
    current_thread_info ()->status |= TS_POLLING;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="387" endline="391">
{
    local_irq_enable ();
    cpu_relax ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="398" endline="410">
{
    local_irq_disable ();
    set_cpu_online (smp_processor_id (), false);
    disable_local_APIC ();
    for (;;) {
        if (hlt_works (smp_processor_id ()))
            halt ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="406" endline="409">
{
    if (hlt_works (smp_processor_id ()))
        halt ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="413" endline="414">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="425" endline="429">
{
    smp_mb ();
    smp_call_function (do_nothing, NULL, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="443" endline="454">
{
    trace_power_start (POWER_CSTATE, (ax >> 4) + 1);
    if (!need_resched ()) {
        if (cpu_has (&current_cpu_data, X86_FEATURE_CLFLUSH_MONITOR))
            clflush ((void *) &current_thread_info ()->flags);
        __monitor ((void *) & current_thread_info () -> flags, 0, 0);
        smp_mb ();
        if (!need_resched ())
            __mwait (ax, cx);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="445" endline="453">
{
    if (cpu_has (&current_cpu_data, X86_FEATURE_CLFLUSH_MONITOR))
        clflush ((void *) &current_thread_info ()->flags);
    __monitor ((void *) & current_thread_info () -> flags, 0, 0);
    smp_mb ();
    if (!need_resched ())
        __mwait (ax, cx);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="458" endline="472">
{
    if (!need_resched ()) {
        trace_power_start (POWER_CSTATE, 1);
        if (cpu_has (&current_cpu_data, X86_FEATURE_CLFLUSH_MONITOR))
            clflush ((void *) &current_thread_info ()->flags);
        __monitor ((void *) & current_thread_info () -> flags, 0, 0);
        smp_mb ();
        if (!need_resched ())
            __sti_mwait (0, 0);
        else
            local_irq_enable ();
    }
    else
        local_irq_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="459" endline="470">
{
    trace_power_start (POWER_CSTATE, 1);
    if (cpu_has (&current_cpu_data, X86_FEATURE_CLFLUSH_MONITOR))
        clflush ((void *) &current_thread_info ()->flags);
    __monitor ((void *) & current_thread_info () -> flags, 0, 0);
    smp_mb ();
    if (!need_resched ())
        __sti_mwait (0, 0);
    else
        local_irq_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="480" endline="486">
{
    trace_power_start (POWER_CSTATE, 0);
    local_irq_enable ();
    while (!need_resched ())
        cpu_relax ();
    trace_power_end (0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="507" endline="526">
{
    u32 eax, ebx, ecx, edx;
    if (force_mwait)
        return 1;
    if (c->cpuid_level < MWAIT_INFO)
        return 0;
    cpuid (MWAIT_INFO, & eax, & ebx, & ecx, & edx);
    if (!(ecx & MWAIT_ECX_EXTENDED_INFO))
        return 1;
    return (edx & MWAIT_EDX_C1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="535" endline="562">
{
    u64 val;
    if (c->x86_vendor != X86_VENDOR_AMD)
        goto no_c1e_idle;
    if (c->x86 == 0x0F && c->x86_model >= 0x40)
        return 1;
    if (c->x86 == 0x10) {
        if (cpu_has (c, X86_FEATURE_OSVW)) {
            rdmsrl (MSR_AMD64_OSVW_ID_LENGTH, val);
            if (val >= 2) {
                rdmsrl (MSR_AMD64_OSVW_STATUS, val);
                if (!(val & BIT (1)))
                    goto no_c1e_idle;
            }
        }
        return 1;
    }
no_c1e_idle :
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="544" endline="558">
{
    if (cpu_has (c, X86_FEATURE_OSVW)) {
        rdmsrl (MSR_AMD64_OSVW_ID_LENGTH, val);
        if (val >= 2) {
            rdmsrl (MSR_AMD64_OSVW_STATUS, val);
            if (!(val & BIT (1)))
                goto no_c1e_idle;
        }
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="549" endline="556">
{
    rdmsrl (MSR_AMD64_OSVW_ID_LENGTH, val);
    if (val >= 2) {
        rdmsrl (MSR_AMD64_OSVW_STATUS, val);
        if (!(val & BIT (1)))
            goto no_c1e_idle;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="551" endline="555">
{
    rdmsrl (MSR_AMD64_OSVW_STATUS, val);
    if (!(val & BIT (1)))
        goto no_c1e_idle;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="568" endline="571">
{
    if (c1e_mask != NULL)
        cpumask_clear_cpu (cpu, c1e_mask);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="579" endline="622">
{
    if (need_resched ())
        return;
    if (!c1e_detected) {
        u32 lo, hi;
        rdmsr (MSR_K8_INT_PENDING_MSG, lo, hi);
        if (lo & K8_INTP_C1E_ACTIVE_MASK) {
            c1e_detected = 1;
            if (!boot_cpu_has (X86_FEATURE_NONSTOP_TSC))
                mark_tsc_unstable ("TSC halt in AMD C1E");
            printk (KERN_INFO "System has AMD C1E enabled\n");
            set_cpu_cap (& boot_cpu_data, X86_FEATURE_AMDC1E);
        }
    }
    if (c1e_detected) {
        int cpu = smp_processor_id ();
        if (!cpumask_test_cpu (cpu, c1e_mask)) {
            cpumask_set_cpu (cpu, c1e_mask);
            clockevents_notify (CLOCK_EVT_NOTIFY_BROADCAST_FORCE, & cpu);
            printk (KERN_INFO "Switch to broadcast mode on CPU%d\n", cpu);
        }
        clockevents_notify (CLOCK_EVT_NOTIFY_BROADCAST_ENTER, & cpu);
        default_idle ();
        local_irq_disable ();
        clockevents_notify (CLOCK_EVT_NOTIFY_BROADCAST_EXIT, & cpu);
        local_irq_enable ();
    }
    else
        default_idle ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="583" endline="594">
{
    u32 lo, hi;
    rdmsr (MSR_K8_INT_PENDING_MSG, lo, hi);
    if (lo & K8_INTP_C1E_ACTIVE_MASK) {
        c1e_detected = 1;
        if (!boot_cpu_has (X86_FEATURE_NONSTOP_TSC))
            mark_tsc_unstable ("TSC halt in AMD C1E");
        printk (KERN_INFO "System has AMD C1E enabled\n");
        set_cpu_cap (& boot_cpu_data, X86_FEATURE_AMDC1E);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="587" endline="593">
{
    c1e_detected = 1;
    if (!boot_cpu_has (X86_FEATURE_NONSTOP_TSC))
        mark_tsc_unstable ("TSC halt in AMD C1E");
    printk (KERN_INFO "System has AMD C1E enabled\n");
    set_cpu_cap (& boot_cpu_data, X86_FEATURE_AMDC1E);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="596" endline="620">
{
    int cpu = smp_processor_id ();
    if (!cpumask_test_cpu (cpu, c1e_mask)) {
        cpumask_set_cpu (cpu, c1e_mask);
        clockevents_notify (CLOCK_EVT_NOTIFY_BROADCAST_FORCE, & cpu);
        printk (KERN_INFO "Switch to broadcast mode on CPU%d\n", cpu);
    }
    clockevents_notify (CLOCK_EVT_NOTIFY_BROADCAST_ENTER, & cpu);
    default_idle ();
    local_irq_disable ();
    clockevents_notify (CLOCK_EVT_NOTIFY_BROADCAST_EXIT, & cpu);
    local_irq_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="599" endline="608">
{
    cpumask_set_cpu (cpu, c1e_mask);
    clockevents_notify (CLOCK_EVT_NOTIFY_BROADCAST_FORCE, & cpu);
    printk (KERN_INFO "Switch to broadcast mode on CPU%d\n", cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="625" endline="646">
{
    if (pm_idle)
        return;
    if (cpu_has (c, X86_FEATURE_MWAIT) && mwait_usable (c)) {
        printk (KERN_INFO "using mwait in idle threads.\n");
        pm_idle = mwait_idle;
    }
    else if (check_c1e_idle (c)) {
        printk (KERN_INFO "using C1E aware idle routine\n");
        pm_idle = c1e_idle;
    }
    else
        pm_idle = default_idle;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="635" endline="641">
{
    printk (KERN_INFO "using mwait in idle threads.\n");
    pm_idle = mwait_idle;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="641" endline="644">
{
    printk (KERN_INFO "using C1E aware idle routine\n");
    pm_idle = c1e_idle;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="649" endline="653">
{
    if (pm_idle == c1e_idle)
        zalloc_cpumask_var (&c1e_mask, GFP_KERNEL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="656" endline="690">
{
    if (!str)
        return -EINVAL;
    if (!strcmp (str, "poll")) {
        printk ("using polling idle threads.\n");
        pm_idle = poll_idle;
    }
    else if (!strcmp (str, "mwait"))
        force_mwait = 1;
    else if (!strcmp (str, "halt")) {
        pm_idle = default_idle;
        idle_halt = 1;
        return 0;
    }
    else if (!strcmp (str, "nomwait")) {
        idle_nomwait = 1;
        return 0;
    }
    else
        return -1;
    boot_option_idle_override = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="660" endline="663">
{
    printk ("using polling idle threads.\n");
    pm_idle = poll_idle;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="665" endline="676">
{
    pm_idle = default_idle;
    idle_halt = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="676" endline="685">
{
    idle_nomwait = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="694" endline="698">
{
    if (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)
        sp -= get_random_int () % 8192;
    return sp & ~0xf;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/process.c.ifdefed" startline="701" endline="704">
{
    unsigned long range_end = mm->brk + 0x02000000;
    return randomize_range (mm->brk, range_end, 0) ? : mm->brk;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kdebugfs.c.ifdefed" startline="205" endline="217">
{
    int error = 0;
    arch_debugfs_dir = debugfs_create_dir ("x86", NULL);
    if (!arch_debugfs_dir)
        return -ENOMEM;
    return error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="111" endline="120">
{
    struct __arch_relative_insn {
        u8 op;
        s32 raddr;
    } __attribute__ ((packed)) *insn;
    insn = (struct __arch_relative_insn *) from;
    insn->raddr = (s32) ((long) (to) -((long) (from) +5));
    insn->op = op;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="124" endline="126">
{
    __synthesize_relative_insn (from, to, RELATIVEJUMP_OPCODE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="133" endline="139">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="146" endline="199">
{
    kprobe_opcode_t opcode;
    kprobe_opcode_t *orig_opcodes = opcodes;
    if (search_exception_tables ((unsigned long) opcodes))
        return 0;
retry :
    if (opcodes - orig_opcodes > MAX_INSN_SIZE - 1)
        return 0;
    opcode = *(opcodes++);
    if (opcode == 0x0f) {
        if (opcodes - orig_opcodes > MAX_INSN_SIZE - 1)
            return 0;
        return test_bit (*opcodes, (unsigned long *) twobyte_is_boostable);
    }
    switch (opcode & 0xf0) {
    case 0x60 :
        if (0x63 < opcode && opcode < 0x67)
            goto retry;
        return (opcode != 0x62 && opcode != 0x67);
    case 0x70 :
        return 0;
    case 0xc0 :
        return (0xc1 < opcode && opcode < 0xcc) || opcode == 0xcf;
    case 0xd0 :
        return (opcode == 0xd4 || opcode == 0xd5 || opcode == 0xd7);
    case 0xe0 :
        return ((opcode & 0x04) || opcode == 0xea);
    case 0xf0 :
        if ((opcode & 0x0c) == 0 && opcode != 0xf1)
            goto retry;
        return (opcode == 0xf5 || (0xf7 < opcode && opcode < 0xfe));
    default :
        if (opcode == 0x26 || opcode == 0x36 || opcode == 0x3e)
            goto retry;
        return (opcode != 0x2e && opcode != 0x9a);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="159" endline="164">
{
    if (opcodes - orig_opcodes > MAX_INSN_SIZE - 1)
        return 0;
    return test_bit (*opcodes, (unsigned long *) twobyte_is_boostable);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="166" endline="198">
{
case 0x60 :
    if (0x63 < opcode && opcode < 0x67)
        goto retry;
    return (opcode != 0x62 && opcode != 0x67);
case 0x70 :
    return 0;
case 0xc0 :
    return (0xc1 < opcode && opcode < 0xcc) || opcode == 0xcf;
case 0xd0 :
    return (opcode == 0xd4 || opcode == 0xd5 || opcode == 0xd7);
case 0xe0 :
    return ((opcode & 0x04) || opcode == 0xea);
case 0xf0 :
    if ((opcode & 0x0c) == 0 && opcode != 0xf1)
        goto retry;
    return (opcode == 0xf5 || (0xf7 < opcode && opcode < 0xfe));
default :
    if (opcode == 0x26 || opcode == 0x36 || opcode == 0x3e)
        goto retry;
    return (opcode != 0x2e && opcode != 0x9a);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="203" endline="225">
{
    struct kprobe *kp;
    kp = get_kprobe ((void *) addr);
    if (!kp)
        return -EINVAL;
    memcpy (buf, kp -> addr, MAX_INSN_SIZE * sizeof (kprobe_opcode_t));
    buf[0] = kp->opcode;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="232" endline="268">
{
    int ret;
    unsigned long addr, offset = 0;
    struct insn insn;
    kprobe_opcode_t buf [MAX_INSN_SIZE];
    if (!kallsyms_lookup (paddr, NULL, &offset, NULL, __dummy_buf))
        return 0;
    addr = paddr - offset;
    while (addr < paddr) {
        kernel_insn_init (& insn, (void *) addr);
        insn_get_opcode (& insn);
        if (insn.opcode.bytes[0] == BREAKPOINT_INSTRUCTION) {
            ret = recover_probed_instruction (buf, addr);
            if (ret)
                return 0;
            kernel_insn_init (& insn, buf);
        }
        insn_get_length (& insn);
        addr += insn.length;
    }
    return (addr == paddr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="243" endline="265">
{
    kernel_insn_init (& insn, (void *) addr);
    insn_get_opcode (& insn);
    if (insn.opcode.bytes[0] == BREAKPOINT_INSTRUCTION) {
        ret = recover_probed_instruction (buf, addr);
        if (ret)
            return 0;
        kernel_insn_init (& insn, buf);
    }
    insn_get_length (& insn);
    addr += insn.length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="252" endline="262">
{
    ret = recover_probed_instruction (buf, addr);
    if (ret)
        return 0;
    kernel_insn_init (& insn, buf);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="274" endline="291">
{
    switch (*insn) {
    case 0xfa :
    case 0xfb :
    case 0xcf :
    case 0x9d :
        return 1;
    }
    if (is_REX_prefix (insn))
        return is_IF_modifier (++insn);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="275" endline="281">
{
case 0xfa :
case 0xfb :
case 0xcf :
case 0x9d :
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="301" endline="346">
{
    struct insn insn;
    int ret;
    kprobe_opcode_t buf [MAX_INSN_SIZE];
    kernel_insn_init (& insn, src);
    if (recover) {
        insn_get_opcode (& insn);
        if (insn.opcode.bytes[0] == BREAKPOINT_INSTRUCTION) {
            ret = recover_probed_instruction (buf, (unsigned long) src);
            if (ret)
                return 0;
            kernel_insn_init (& insn, buf);
        }
    }
    insn_get_length (& insn);
    memcpy (dest, insn.kaddr, insn.length);
    return insn.length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="307" endline="316">
{
    insn_get_opcode (& insn);
    if (insn.opcode.bytes[0] == BREAKPOINT_INSTRUCTION) {
        ret = recover_probed_instruction (buf, (unsigned long) src);
        if (ret)
            return 0;
        kernel_insn_init (& insn, buf);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="309" endline="315">
{
    ret = recover_probed_instruction (buf, (unsigned long) src);
    if (ret)
        return 0;
    kernel_insn_init (& insn, buf);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="349" endline="362">
{
    __copy_instruction (p -> ainsn.insn, p -> addr, 0);
    if (can_boost (p->addr))
        p->ainsn.boostable = 0;
    else
        p->ainsn.boostable = -1;
    p->opcode = *p->addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="365" endline="377">
{
    if (alternatives_text_reserved (p->addr, p->addr))
        return -EINVAL;
    if (!can_probe ((unsigned long) p->addr))
        return -EILSEQ;
    p->ainsn.insn = get_insn_slot ();
    if (!p->ainsn.insn)
        return -ENOMEM;
    arch_copy_kprobe (p);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="380" endline="382">
{
    text_poke (p -> addr, ((unsigned char []) {BREAKPOINT_INSTRUCTION}), 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="385" endline="387">
{
    text_poke (p -> addr, & p -> opcode, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="390" endline="395">
{
    if (p->ainsn.insn) {
        free_insn_slot (p -> ainsn.insn, (p -> ainsn.boostable == 1));
        p->ainsn.insn = NULL;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="391" endline="394">
{
    free_insn_slot (p -> ainsn.insn, (p -> ainsn.boostable == 1));
    p->ainsn.insn = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="398" endline="403">
{
    kcb->prev_kprobe.kp = kprobe_running ();
    kcb->prev_kprobe.status = kcb->kprobe_status;
    kcb->prev_kprobe.old_flags = kcb->kprobe_old_flags;
    kcb->prev_kprobe.saved_flags = kcb->kprobe_saved_flags;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="406" endline="411">
{
    __get_cpu_var (current_kprobe) = kcb->prev_kprobe.kp;
    kcb->kprobe_status = kcb->prev_kprobe.status;
    kcb->kprobe_old_flags = kcb->prev_kprobe.old_flags;
    kcb->kprobe_saved_flags = kcb->prev_kprobe.saved_flags;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="415" endline="421">
{
    __get_cpu_var (current_kprobe) = p;
    kcb->kprobe_saved_flags = kcb->kprobe_old_flags = (regs->flags & (X86_EFLAGS_TF | X86_EFLAGS_IF));
    if (is_IF_modifier (p->ainsn.insn))
        kcb->kprobe_saved_flags &= ~X86_EFLAGS_IF;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="424" endline="427">
{
    if (test_thread_flag (TIF_DEBUGCTLMSR))
        update_debugctlmsr (0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="430" endline="433">
{
    if (test_thread_flag (TIF_DEBUGCTLMSR))
        update_debugctlmsr (current->thread.debugctlmsr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="437" endline="444">
{
    unsigned long *sara = stack_addr (regs);
    ri->ret_addr = (kprobe_opcode_t *) *sara;
    *sara = (unsigned long) &kretprobe_trampoline;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="456" endline="490">
{
    if (setup_detour_execution (p, regs, reenter))
        return;
    if (reenter) {
        save_previous_kprobe (kcb);
        set_current_kprobe (p, regs, kcb);
        kcb->kprobe_status = KPROBE_REENTER;
    }
    else
        kcb->kprobe_status = KPROBE_HIT_SS;
    clear_btf ();
    regs->flags |= X86_EFLAGS_TF;
    regs->flags &= ~X86_EFLAGS_IF;
    if (p->opcode == BREAKPOINT_INSTRUCTION)
        regs->ip = (unsigned long) p->addr;
    else
        regs->ip = (unsigned long) p->ainsn.insn;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="475" endline="479">
{
    save_previous_kprobe (kcb);
    set_current_kprobe (p, regs, kcb);
    kcb->kprobe_status = KPROBE_REENTER;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="499" endline="524">
{
    switch (kcb->kprobe_status) {
    case KPROBE_HIT_SSDONE :
    case KPROBE_HIT_ACTIVE :
        kprobes_inc_nmissed_count (p);
        setup_singlestep (p, regs, kcb, 1);
        break;
    case KPROBE_HIT_SS :
        printk (KERN_WARNING "Unrecoverable kprobe detected at %p.\n", p->addr);
        dump_kprobe (p);
        BUG ();
    default :
        WARN_ON (1);
        return 0;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="500" endline="521">
{
case KPROBE_HIT_SSDONE :
case KPROBE_HIT_ACTIVE :
    kprobes_inc_nmissed_count (p);
    setup_singlestep (p, regs, kcb, 1);
    break;
case KPROBE_HIT_SS :
    printk (KERN_WARNING "Unrecoverable kprobe detected at %p.\n", p->addr);
    dump_kprobe (p);
    BUG ();
default :
    WARN_ON (1);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="531" endline="591">
{
    kprobe_opcode_t *addr;
    struct kprobe *p;
    struct kprobe_ctlblk *kcb;
    addr = (kprobe_opcode_t *) (regs->ip - sizeof (kprobe_opcode_t));
    preempt_disable ();
    kcb = get_kprobe_ctlblk ();
    p = get_kprobe (addr);
    if (p) {
        if (kprobe_running ()) {
            if (reenter_kprobe (p, regs, kcb))
                return 1;
        }
        else {
            set_current_kprobe (p, regs, kcb);
            kcb->kprobe_status = KPROBE_HIT_ACTIVE;
            if (!p->pre_handler || !p->pre_handler (p, regs))
                setup_singlestep (p, regs, kcb, 0);
            return 1;
        }
    }
    else if (*addr != BREAKPOINT_INSTRUCTION) {
        regs->ip = (unsigned long) addr;
        preempt_enable_no_resched ();
        return 1;
    }
    else if (kprobe_running ()) {
        p = __get_cpu_var (current_kprobe);
        if (p->break_handler && p->break_handler (p, regs)) {
            setup_singlestep (p, regs, kcb, 0);
            return 1;
        }
    }
    preempt_enable_no_resched ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="548" endline="568">
{
    if (kprobe_running ()) {
        if (reenter_kprobe (p, regs, kcb))
            return 1;
    }
    else {
        set_current_kprobe (p, regs, kcb);
        kcb->kprobe_status = KPROBE_HIT_ACTIVE;
        if (!p->pre_handler || !p->pre_handler (p, regs))
            setup_singlestep (p, regs, kcb, 0);
        return 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="549" endline="552">
{
    if (reenter_kprobe (p, regs, kcb))
        return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="552" endline="567">
{
    set_current_kprobe (p, regs, kcb);
    kcb->kprobe_status = KPROBE_HIT_ACTIVE;
    if (!p->pre_handler || !p->pre_handler (p, regs))
        setup_singlestep (p, regs, kcb, 0);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="568" endline="581">
{
    regs->ip = (unsigned long) addr;
    preempt_enable_no_resched ();
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="581" endline="587">
{
    p = __get_cpu_var (current_kprobe);
    if (p->break_handler && p->break_handler (p, regs)) {
        setup_singlestep (p, regs, kcb, 0);
        return 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="583" endline="586">
{
    setup_singlestep (p, regs, kcb, 0);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="661" endline="690">
{
    asm volatile (".global kretprobe_trampoline\n"
        "kretprobe_trampoline: \n"
        "	pushf\n"
        SAVE_REGS_STRING
        "	movl %esp, %eax\n"
        "	call trampoline_handler\n"
        "	movl 56(%esp), %edx\n"
        "	movl %edx, 52(%esp)\n"
        "	movl %eax, 56(%esp)\n"
        RESTORE_REGS_STRING
        "	popf\n"
        "	ret\n"
    )}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="696" endline="761">
{
    struct kretprobe_instance *ri = NULL;
    struct hlist_head *head, empty_rp;
    struct hlist_node *node, *tmp;
    unsigned long flags, orig_ret_address = 0;
    unsigned long trampoline_address = (unsigned long) &kretprobe_trampoline;
    INIT_HLIST_HEAD (& empty_rp);
    kretprobe_hash_lock (current, & head, & flags);
    regs->cs = __KERNEL_CS | get_kernel_rpl ();
    regs->gs = 0;
    regs->ip = trampoline_address;
    regs->orig_ax = ~0UL;
    hlist_for_each_entry_safe (ri, node, tmp, head, hlist) {
        if (ri->task != current)
            continue;
        if (ri->rp && ri->rp->handler) {
            __get_cpu_var (current_kprobe) = &ri->rp->kp;
            get_kprobe_ctlblk ()->kprobe_status = KPROBE_HIT_ACTIVE;
            ri->rp->handler (ri, regs);
            __get_cpu_var (current_kprobe) = NULL;
        }
        orig_ret_address = (unsigned long) ri->ret_addr;
        recycle_rp_inst (ri, & empty_rp);
        if (orig_ret_address != trampoline_address)
            break;
    }
    kretprobe_assert (ri, orig_ret_address, trampoline_address);
    kretprobe_hash_unlock (current, & flags);
    hlist_for_each_entry_safe (ri, node, tmp, &empty_rp, hlist) {
        hlist_del (& ri -> hlist);
        kfree (ri);
    }
    return (void *) orig_ret_address;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="728" endline="750">
{
    if (ri->task != current)
        continue;
    if (ri->rp && ri->rp->handler) {
        __get_cpu_var (current_kprobe) = &ri->rp->kp;
        get_kprobe_ctlblk ()->kprobe_status = KPROBE_HIT_ACTIVE;
        ri->rp->handler (ri, regs);
        __get_cpu_var (current_kprobe) = NULL;
    }
    orig_ret_address = (unsigned long) ri->ret_addr;
    recycle_rp_inst (ri, & empty_rp);
    if (orig_ret_address != trampoline_address)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="733" endline="738">
{
    __get_cpu_var (current_kprobe) = &ri->rp->kp;
    get_kprobe_ctlblk ()->kprobe_status = KPROBE_HIT_ACTIVE;
    ri->rp->handler (ri, regs);
    __get_cpu_var (current_kprobe) = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="756" endline="759">
{
    hlist_del (& ri -> hlist);
    kfree (ri);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="792" endline="866">
{
    unsigned long *tos = stack_addr (regs);
    unsigned long copy_ip = (unsigned long) p->ainsn.insn;
    unsigned long orig_ip = (unsigned long) p->addr;
    kprobe_opcode_t *insn = p->ainsn.insn;
    if (is_REX_prefix (insn))
        insn++;
    regs->flags &= ~X86_EFLAGS_TF;
    switch (*insn) {
    case 0x9c :
        *tos &= ~(X86_EFLAGS_TF | X86_EFLAGS_IF);
        *tos |= kcb->kprobe_old_flags;
        break;
    case 0xc2 :
    case 0xc3 :
    case 0xca :
    case 0xcb :
    case 0xcf :
    case 0xea :
        p->ainsn.boostable = 1;
        goto no_change;
    case 0xe8 :
        *tos = orig_ip + (*tos - copy_ip);
        break;
    case 0xff :
        if ((insn[1] & 0x30) == 0x10) {
            *tos = orig_ip + (*tos - copy_ip);
            goto no_change;
        }
        else if (((insn[1] & 0x31) == 0x20) || ((insn[1] & 0x31) == 0x21)) {
            p->ainsn.boostable = 1;
            goto no_change;
        }
    default :
        break;
    }
    if (p->ainsn.boostable == 0) {
        if ((regs->ip > copy_ip) && (regs->ip - copy_ip) + 5 < MAX_INSN_SIZE) {
            synthesize_reljump ((void *) regs -> ip, (void *) orig_ip + (regs -> ip - copy_ip));
            p->ainsn.boostable = 1;
        }
        else {
            p->ainsn.boostable = -1;
        }
    }
    regs->ip += orig_ip - copy_ip;
no_change :
    restore_btf ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="803" endline="845">
{
case 0x9c :
    *tos &= ~(X86_EFLAGS_TF | X86_EFLAGS_IF);
    *tos |= kcb->kprobe_old_flags;
    break;
case 0xc2 :
case 0xc3 :
case 0xca :
case 0xcb :
case 0xcf :
case 0xea :
    p->ainsn.boostable = 1;
    goto no_change;
case 0xe8 :
    *tos = orig_ip + (*tos - copy_ip);
    break;
case 0xff :
    if ((insn[1] & 0x30) == 0x10) {
        *tos = orig_ip + (*tos - copy_ip);
        goto no_change;
    }
    else if (((insn[1] & 0x31) == 0x20) || ((insn[1] & 0x31) == 0x21)) {
        p->ainsn.boostable = 1;
        goto no_change;
    }
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="826" endline="834">
{
    *tos = orig_ip + (*tos - copy_ip);
    goto no_change;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="835" endline="842">
{
    p->ainsn.boostable = 1;
    goto no_change;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="847" endline="860">
{
    if ((regs->ip > copy_ip) && (regs->ip - copy_ip) + 5 < MAX_INSN_SIZE) {
        synthesize_reljump ((void *) regs -> ip, (void *) orig_ip + (regs -> ip - copy_ip));
        p->ainsn.boostable = 1;
    }
    else {
        p->ainsn.boostable = -1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="849" endline="857">
{
    synthesize_reljump ((void *) regs -> ip, (void *) orig_ip + (regs -> ip - copy_ip));
    p->ainsn.boostable = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="857" endline="859">
{
    p->ainsn.boostable = -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="873" endline="906">
{
    struct kprobe *cur = kprobe_running ();
    struct kprobe_ctlblk *kcb = get_kprobe_ctlblk ();
    if (!cur)
        return 0;
    resume_execution (cur, regs, kcb);
    regs->flags |= kcb->kprobe_saved_flags;
    if ((kcb->kprobe_status != KPROBE_REENTER) && cur->post_handler) {
        kcb->kprobe_status = KPROBE_HIT_SSDONE;
        cur->post_handler (cur, regs, 0);
    }
    if (kcb->kprobe_status == KPROBE_REENTER) {
        restore_previous_kprobe (kcb);
        goto out;
    }
    reset_current_kprobe ();
out :
    preempt_enable_no_resched ();
    if (regs->flags & X86_EFLAGS_TF)
        return 0;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="883" endline="886">
{
    kcb->kprobe_status = KPROBE_HIT_SSDONE;
    cur->post_handler (cur, regs, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="889" endline="892">
{
    restore_previous_kprobe (kcb);
    goto out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="909" endline="966">
{
    struct kprobe *cur = kprobe_running ();
    struct kprobe_ctlblk *kcb = get_kprobe_ctlblk ();
    switch (kcb->kprobe_status) {
    case KPROBE_HIT_SS :
    case KPROBE_REENTER :
        regs->ip = (unsigned long) cur->addr;
        regs->flags |= kcb->kprobe_old_flags;
        if (kcb->kprobe_status == KPROBE_REENTER)
            restore_previous_kprobe (kcb);
        else
            reset_current_kprobe ();
        preempt_enable_no_resched ();
        break;
    case KPROBE_HIT_ACTIVE :
    case KPROBE_HIT_SSDONE :
        kprobes_inc_nmissed_count (cur);
        if (cur->fault_handler && cur->fault_handler (cur, regs, trapnr))
            return 1;
        if (fixup_exception (regs))
            return 1;
        break;
    default :
        break;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="913" endline="964">
{
case KPROBE_HIT_SS :
case KPROBE_REENTER :
    regs->ip = (unsigned long) cur->addr;
    regs->flags |= kcb->kprobe_old_flags;
    if (kcb->kprobe_status == KPROBE_REENTER)
        restore_previous_kprobe (kcb);
    else
        reset_current_kprobe ();
    preempt_enable_no_resched ();
    break;
case KPROBE_HIT_ACTIVE :
case KPROBE_HIT_SSDONE :
    kprobes_inc_nmissed_count (cur);
    if (cur->fault_handler && cur->fault_handler (cur, regs, trapnr))
        return 1;
    if (fixup_exception (regs))
        return 1;
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="973" endline="1009">
{
    struct die_args *args = data;
    int ret = NOTIFY_DONE;
    if (args->regs && user_mode_vm (args->regs))
        return ret;
    switch (val) {
    case DIE_INT3 :
        if (kprobe_handler (args->regs))
            ret = NOTIFY_STOP;
        break;
    case DIE_DEBUG :
        if (post_kprobe_handler (args->regs)) {
            (*(unsignedlong*) ERR_PTR (args->err)) &= ~DR_STEP;
            ret = NOTIFY_STOP;
        }
        break;
    case DIE_GPF :
        if (!preemptible () && kprobe_running () && kprobe_fault_handler (args->regs, args->trapnr))
            ret = NOTIFY_STOP;
        break;
    default :
        break;
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="980" endline="1007">
{
case DIE_INT3 :
    if (kprobe_handler (args->regs))
        ret = NOTIFY_STOP;
    break;
case DIE_DEBUG :
    if (post_kprobe_handler (args->regs)) {
        (*(unsignedlong*) ERR_PTR (args->err)) &= ~DR_STEP;
        ret = NOTIFY_STOP;
    }
    break;
case DIE_GPF :
    if (!preemptible () && kprobe_running () && kprobe_fault_handler (args->regs, args->trapnr))
        ret = NOTIFY_STOP;
    break;
default :
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="986" endline="993">
{
    (*(unsignedlong*) ERR_PTR (args->err)) &= ~DR_STEP;
    ret = NOTIFY_STOP;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="1012" endline="1034">
{
    struct jprobe *jp = container_of (p, struct jprobe, kp);
    unsigned long addr;
    struct kprobe_ctlblk *kcb = get_kprobe_ctlblk ();
    kcb->jprobe_saved_regs = *regs;
    kcb->jprobe_saved_sp = stack_addr (regs);
    addr = (unsigned long) (kcb->jprobe_saved_sp);
    memcpy (kcb -> jprobes_stack, (kprobe_opcode_t *) addr, MIN_STACK_SIZE (addr));
    regs->flags &= ~X86_EFLAGS_IF;
    trace_hardirqs_off ();
    regs->ip = (unsigned long) (jp->entry);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="1037" endline="1051">
{
    struct kprobe_ctlblk *kcb = get_kprobe_ctlblk ();
    asm volatile ("       xchgl   %%ebx,%%esp	\n"
        "       int3			\n"
        "       .globl jprobe_return_end\n"
        "       jprobe_return_end:	\n"
        "       nop			\n"
        :
        : "b" (kcb->jprobe_saved_sp)
        : "memory"
    )}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="1054" endline="1080">
{
    struct kprobe_ctlblk *kcb = get_kprobe_ctlblk ();
    u8 *addr = (u8 *) (regs->ip - 1);
    struct jprobe *jp = container_of (p, struct jprobe, kp);
    if ((addr > (u8 *) jprobe_return) && (addr < (u8 *) jprobe_return_end)) {
        if (stack_addr (regs) != kcb->jprobe_saved_sp) {
            struct pt_regs *saved_regs = &kcb->jprobe_saved_regs;
            printk (KERN_ERR "current sp %p does not match saved sp %p\n", stack_addr (regs), kcb -> jprobe_saved_sp);
            printk (KERN_ERR "Saved registers for jprobe %p\n", jp);
            show_registers (saved_regs);
            printk (KERN_ERR "Current registers\n");
            show_registers (regs);
            BUG ();
        }
        *regs = kcb->jprobe_saved_regs;
        memcpy ((kprobe_opcode_t *) (kcb -> jprobe_saved_sp), kcb -> jprobes_stack, MIN_STACK_SIZE (kcb -> jprobe_saved_sp));
        preempt_enable_no_resched ();
        return 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="1060" endline="1078">
{
    if (stack_addr (regs) != kcb->jprobe_saved_sp) {
        struct pt_regs *saved_regs = &kcb->jprobe_saved_regs;
        printk (KERN_ERR "current sp %p does not match saved sp %p\n", stack_addr (regs), kcb -> jprobe_saved_sp);
        printk (KERN_ERR "Saved registers for jprobe %p\n", jp);
        show_registers (saved_regs);
        printk (KERN_ERR "Current registers\n");
        show_registers (regs);
        BUG ();
    }
    *regs = kcb->jprobe_saved_regs;
    memcpy ((kprobe_opcode_t *) (kcb -> jprobe_saved_sp), kcb -> jprobes_stack, MIN_STACK_SIZE (kcb -> jprobe_saved_sp));
    preempt_enable_no_resched ();
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="1061" endline="1071">
{
    struct pt_regs *saved_regs = &kcb->jprobe_saved_regs;
    printk (KERN_ERR "current sp %p does not match saved sp %p\n", stack_addr (regs), kcb -> jprobe_saved_sp);
    printk (KERN_ERR "Saved registers for jprobe %p\n", jp);
    show_registers (saved_regs);
    printk (KERN_ERR "Current registers\n");
    show_registers (regs);
    BUG ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="1435" endline="1437">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/kprobes.c.ifdefed" startline="1440" endline="1442">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pcspeaker.c.ifdefed" startline="6" endline="12">
{
    struct platform_device *pd;
    pd = platform_device_register_simple ("pcspkr", -1, NULL, 0);
    return IS_ERR (pd) ? PTR_ERR (pd) : 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="38" endline="99">
{
    unsigned k;
    for (k = 0; k < N_EXCEPTION_STACKS; k++) {
        unsigned long end = per_cpu (orig_ist, cpu).ist[k];
        if (stack >= end)
            continue;
        if (stack >= end - EXCEPTION_STKSZ) {
            if (*usedp & (1U << k))
                break;
            *usedp |= 1U << k;
            *idp = x86_stack_ids[k];
            return (unsigned long *) end;
        }
    }
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="45" endline="97">
{
    unsigned long end = per_cpu (orig_ist, cpu).ist[k];
    if (stack >= end)
        continue;
    if (stack >= end - EXCEPTION_STKSZ) {
        if (*usedp & (1U << k))
            break;
        *usedp |= 1U << k;
        *idp = x86_stack_ids[k];
        return (unsigned long *) end;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="57" endline="69">
{
    if (*usedp & (1U << k))
        break;
    *usedp |= 1U << k;
    *idp = x86_stack_ids[k];
    return (unsigned long *) end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="104" endline="106">
{
    return (stack >= irq_stack && stack < irq_stack_end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="120" endline="134">
{
    return bp;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="146" endline="234">
{
    const unsigned cpu = get_cpu ();
    unsigned long *irq_stack_end = (unsigned long *) per_cpu (irq_stack_ptr, cpu);
    unsigned used = 0;
    struct thread_info *tinfo;
    int graph = 0;
    if (!task)
        task = current;
    if (!stack) {
        unsigned long dummy;
        stack = &dummy;
        if (task && task != current)
            stack = (unsigned long *) task->thread.sp;
    }
    tinfo = task_thread_info (task);
    for (;;) {
        char *id;
        unsigned long *estack_end;
        estack_end = in_exception_stack (cpu, (unsigned long) stack, &used, &id);
        if (estack_end) {
            if (ops->stack (data, id) < 0)
                break;
            bp = ops->walk_stack (tinfo, stack, bp, ops, data, estack_end, &graph);
            ops->stack (data, "<EOE>");
            stack = (unsigned long *) estack_end[-2];
            continue;
        }
        if (irq_stack_end) {
            unsigned long *irq_stack;
            irq_stack = irq_stack_end - (IRQ_STACK_SIZE - 64) / sizeof (*irq_stack);
            if (in_irq_stack (stack, irq_stack, irq_stack_end)) {
                if (ops->stack (data, "IRQ") < 0)
                    break;
                bp = ops->walk_stack (tinfo, stack, bp, ops, data, irq_stack_end, &graph);
                stack = (unsigned long *) (irq_stack_end[-1]);
                bp = fixup_bp_irq_link (bp, stack, irq_stack, irq_stack_end);
                irq_stack_end = NULL;
                ops->stack (data, "EOI");
                continue;
            }
        }
        break;
    }
    bp = ops->walk_stack (tinfo, stack, bp, ops, data, NULL, &graph);
    put_cpu ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="157" endline="162">
{
    unsigned long dummy;
    stack = &dummy;
    if (task && task != current)
        stack = (unsigned long *) task->thread.sp;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="182" endline="227">
{
    char *id;
    unsigned long *estack_end;
    estack_end = in_exception_stack (cpu, (unsigned long) stack, &used, &id);
    if (estack_end) {
        if (ops->stack (data, id) < 0)
            break;
        bp = ops->walk_stack (tinfo, stack, bp, ops, data, estack_end, &graph);
        ops->stack (data, "<EOE>");
        stack = (unsigned long *) estack_end[-2];
        continue;
    }
    if (irq_stack_end) {
        unsigned long *irq_stack;
        irq_stack = irq_stack_end - (IRQ_STACK_SIZE - 64) / sizeof (*irq_stack);
        if (in_irq_stack (stack, irq_stack, irq_stack_end)) {
            if (ops->stack (data, "IRQ") < 0)
                break;
            bp = ops->walk_stack (tinfo, stack, bp, ops, data, irq_stack_end, &graph);
            stack = (unsigned long *) (irq_stack_end[-1]);
            bp = fixup_bp_irq_link (bp, stack, irq_stack, irq_stack_end);
            irq_stack_end = NULL;
            ops->stack (data, "EOI");
            continue;
        }
    }
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="188" endline="202">
{
    if (ops->stack (data, id) < 0)
        break;
    bp = ops->walk_stack (tinfo, stack, bp, ops, data, estack_end, &graph);
    ops->stack (data, "<EOE>");
    stack = (unsigned long *) estack_end[-2];
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="203" endline="225">
{
    unsigned long *irq_stack;
    irq_stack = irq_stack_end - (IRQ_STACK_SIZE - 64) / sizeof (*irq_stack);
    if (in_irq_stack (stack, irq_stack, irq_stack_end)) {
        if (ops->stack (data, "IRQ") < 0)
            break;
        bp = ops->walk_stack (tinfo, stack, bp, ops, data, irq_stack_end, &graph);
        stack = (unsigned long *) (irq_stack_end[-1]);
        bp = fixup_bp_irq_link (bp, stack, irq_stack, irq_stack_end);
        irq_stack_end = NULL;
        ops->stack (data, "EOI");
        continue;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="208" endline="224">
{
    if (ops->stack (data, "IRQ") < 0)
        break;
    bp = ops->walk_stack (tinfo, stack, bp, ops, data, irq_stack_end, &graph);
    stack = (unsigned long *) (irq_stack_end[-1]);
    bp = fixup_bp_irq_link (bp, stack, irq_stack, irq_stack_end);
    irq_stack_end = NULL;
    ops->stack (data, "EOI");
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="240" endline="284">
{
    unsigned long *irq_stack_end;
    unsigned long *irq_stack;
    unsigned long *stack;
    int cpu;
    int i;
    preempt_disable ();
    cpu = smp_processor_id ();
    irq_stack_end = (unsigned long *) (per_cpu (irq_stack_ptr, cpu));
    irq_stack = (unsigned long *) (per_cpu (irq_stack_ptr, cpu) - IRQ_STACK_SIZE);
    if (sp == NULL) {
        if (task)
            sp = (unsigned long *) task->thread.sp;
        else
            sp = (unsigned long *) &sp;
    }
    stack = sp;
    for (i = 0; i < kstack_depth_to_print; i++) {
        if (stack >= irq_stack && stack <= irq_stack_end) {
            if (stack == irq_stack_end) {
                stack = (unsigned long *) (irq_stack_end[-1]);
                printk (" <EOI> ");
            }
        }
        else {
            if (((long) stack & (THREAD_SIZE - 1)) == 0)
                break;
        }
        if (i && ((i % STACKSLOTS_PER_LINE) == 0))
            printk ("\n%s", log_lvl);
        printk (" %016lx", * stack ++);
        touch_nmi_watchdog ();
    }
    preempt_enable ();
    printk ("\n");
    show_trace_log_lvl (task, regs, sp, bp, log_lvl);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="257" endline="262">
{
    if (task)
        sp = (unsigned long *) task->thread.sp;
    else
        sp = (unsigned long *) &sp;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="265" endline="279">
{
    if (stack >= irq_stack && stack <= irq_stack_end) {
        if (stack == irq_stack_end) {
            stack = (unsigned long *) (irq_stack_end[-1]);
            printk (" <EOI> ");
        }
    }
    else {
        if (((long) stack & (THREAD_SIZE - 1)) == 0)
            break;
    }
    if (i && ((i % STACKSLOTS_PER_LINE) == 0))
        printk ("\n%s", log_lvl);
    printk (" %016lx", * stack ++);
    touch_nmi_watchdog ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="266" endline="271">
{
    if (stack == irq_stack_end) {
        stack = (unsigned long *) (irq_stack_end[-1]);
        printk (" <EOI> ");
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="267" endline="270">
{
    stack = (unsigned long *) (irq_stack_end[-1]);
    printk (" <EOI> ");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="271" endline="274">
{
    if (((long) stack & (THREAD_SIZE - 1)) == 0)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="287" endline="335">
{
    int i;
    unsigned long sp;
    const int cpu = smp_processor_id ();
    struct task_struct *cur = current;
    sp = regs->sp;
    printk ("CPU %d ", cpu);
    print_modules ();
    __show_regs (regs, 1);
    printk ("Process %s (pid: %d, threadinfo %p, task %p)\n", cur -> comm, cur -> pid, task_thread_info (cur), cur);
    if (!user_mode (regs)) {
        unsigned int code_prologue = code_bytes * 43 / 64;
        unsigned int code_len = code_bytes;
        unsigned char c;
        u8 *ip;
        printk (KERN_EMERG "Stack:\n");
        show_stack_log_lvl (NULL, regs, (unsigned long *) sp, regs -> bp, KERN_EMERG);
        printk (KERN_EMERG "Code: ");
        ip = (u8 *) regs->ip - code_prologue;
        if (ip < (u8 *) PAGE_OFFSET || probe_kernel_address (ip, c)) {
            ip = (u8 *) regs->ip;
            code_len = code_len - code_prologue + 1;
        }
        for (i = 0; i < code_len; i++, ip++) {
            if (ip < (u8 *) PAGE_OFFSET || probe_kernel_address (ip, c)) {
                printk (" Bad RIP value.");
                break;
            }
            if (ip == (u8 *) regs->ip)
                printk ("<%02x> ", c);
            else
                printk ("%02x ", c);
        }
    }
    printk ("\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="304" endline="333">
{
    unsigned int code_prologue = code_bytes * 43 / 64;
    unsigned int code_len = code_bytes;
    unsigned char c;
    u8 *ip;
    printk (KERN_EMERG "Stack:\n");
    show_stack_log_lvl (NULL, regs, (unsigned long *) sp, regs -> bp, KERN_EMERG);
    printk (KERN_EMERG "Code: ");
    ip = (u8 *) regs->ip - code_prologue;
    if (ip < (u8 *) PAGE_OFFSET || probe_kernel_address (ip, c)) {
        ip = (u8 *) regs->ip;
        code_len = code_len - code_prologue + 1;
    }
    for (i = 0; i < code_len; i++, ip++) {
        if (ip < (u8 *) PAGE_OFFSET || probe_kernel_address (ip, c)) {
            printk (" Bad RIP value.");
            break;
        }
        if (ip == (u8 *) regs->ip)
            printk ("<%02x> ", c);
        else
            printk ("%02x ", c);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="317" endline="321">
{
    ip = (u8 *) regs->ip;
    code_len = code_len - code_prologue + 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="322" endline="332">
{
    if (ip < (u8 *) PAGE_OFFSET || probe_kernel_address (ip, c)) {
        printk (" Bad RIP value.");
        break;
    }
    if (ip == (u8 *) regs->ip)
        printk ("<%02x> ", c);
    else
        printk ("%02x ", c);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="324" endline="327">
{
    printk (" Bad RIP value.");
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/dumpstack_64.c.ifdefed" startline="338" endline="345">
{
    unsigned short ud2;
    if (__copy_from_user (&ud2, (const void __user *) ip, sizeof (ud2)))
        return 0;
    return ud2 == 0x0b0f;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="64" endline="72">
{
    unsigned long bp_info;
    bp_info = (len | type) & 0xf;
    bp_info <<= (DR_CONTROL_SHIFT + drnum * DR_CONTROL_SIZE);
    bp_info |= (DR_GLOBAL_ENABLE << (drnum * DR_ENABLE_SIZE));
    return bp_info;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="79" endline="81">
{
    return __encode_dr7 (drnum, len, type) | DR_GLOBAL_SLOWDOWN;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="88" endline="95">
{
    int bp_info = dr7 >> (DR_CONTROL_SHIFT + bpnum * DR_CONTROL_SIZE);
    *len = (bp_info & 0xc) | 0x40;
    *type = (bp_info & 0x3) | 0x80;
    return (dr7 >> (bpnum * DR_ENABLE_SIZE)) & 0x3;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="107" endline="133">
{
    struct arch_hw_breakpoint *info = counter_arch_bp (bp);
    unsigned long *dr7;
    int i;
    for (i = 0; i < HBP_NUM; i++) {
        struct perf_event **slot = &__get_cpu_var (bp_per_reg[i]);
        if (!*slot) {
            *slot = bp;
            break;
        }
    }
    if (WARN_ONCE (i == HBP_NUM, "Can't find any breakpoint slot"))
        return -EBUSY;
    set_debugreg (info -> address, i);
    __get_cpu_var (cpu_debugreg [i]) = info->address;
    dr7 = &__get_cpu_var (cpu_dr7);
    *dr7 |= encode_dr7 (i, info->len, info->type);
    set_debugreg (* dr7, 7);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="112" endline="119">
{
    struct perf_event **slot = &__get_cpu_var (bp_per_reg[i]);
    if (!*slot) {
        *slot = bp;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="115" endline="118">
{
    *slot = bp;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="145" endline="166">
{
    struct arch_hw_breakpoint *info = counter_arch_bp (bp);
    unsigned long *dr7;
    int i;
    for (i = 0; i < HBP_NUM; i++) {
        struct perf_event **slot = &__get_cpu_var (bp_per_reg[i]);
        if (*slot == bp) {
            *slot = NULL;
            break;
        }
    }
    if (WARN_ONCE (i == HBP_NUM, "Can't find any breakpoint slot"))
        return;
    dr7 = &__get_cpu_var (cpu_dr7);
    *dr7 &= ~__encode_dr7 (i, info->len, info->type);
    set_debugreg (* dr7, 7);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="150" endline="157">
{
    struct perf_event **slot = &__get_cpu_var (bp_per_reg[i]);
    if (*slot == bp) {
        *slot = NULL;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="153" endline="156">
{
    *slot = NULL;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="169" endline="189">
{
    unsigned int len_in_bytes = 0;
    switch (hbp_len) {
    case X86_BREAKPOINT_LEN_1 :
        len_in_bytes = 1;
        break;
    case X86_BREAKPOINT_LEN_2 :
        len_in_bytes = 2;
        break;
    case X86_BREAKPOINT_LEN_4 :
        len_in_bytes = 4;
        break;
    }
    return len_in_bytes;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="172" endline="187">
{
case X86_BREAKPOINT_LEN_1 :
    len_in_bytes = 1;
    break;
case X86_BREAKPOINT_LEN_2 :
    len_in_bytes = 2;
    break;
case X86_BREAKPOINT_LEN_4 :
    len_in_bytes = 4;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="195" endline="201">
{
    unsigned int len;
    len = get_hbp_len (hbp_len);
    return (va <= TASK_SIZE - len);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="207" endline="213">
{
    unsigned int len;
    len = get_hbp_len (hbp_len);
    return (va >= TASK_SIZE) && ((va + len - 1) >= TASK_SIZE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="217" endline="254">
{
    switch (x86_len) {
    case X86_BREAKPOINT_LEN_1 :
        *gen_len = HW_BREAKPOINT_LEN_1;
        break;
    case X86_BREAKPOINT_LEN_2 :
        *gen_len = HW_BREAKPOINT_LEN_2;
        break;
    case X86_BREAKPOINT_LEN_4 :
        *gen_len = HW_BREAKPOINT_LEN_4;
        break;
    default :
        return -EINVAL;
    }
    switch (x86_type) {
    case X86_BREAKPOINT_EXECUTE :
        *gen_type = HW_BREAKPOINT_X;
        break;
    case X86_BREAKPOINT_WRITE :
        *gen_type = HW_BREAKPOINT_W;
        break;
    case X86_BREAKPOINT_RW :
        *gen_type = HW_BREAKPOINT_W | HW_BREAKPOINT_R;
        break;
    default :
        return -EINVAL;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="219" endline="236">
{
case X86_BREAKPOINT_LEN_1 :
    *gen_len = HW_BREAKPOINT_LEN_1;
    break;
case X86_BREAKPOINT_LEN_2 :
    *gen_len = HW_BREAKPOINT_LEN_2;
    break;
case X86_BREAKPOINT_LEN_4 :
    *gen_len = HW_BREAKPOINT_LEN_4;
    break;
default :
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="239" endline="251">
{
case X86_BREAKPOINT_EXECUTE :
    *gen_type = HW_BREAKPOINT_X;
    break;
case X86_BREAKPOINT_WRITE :
    *gen_type = HW_BREAKPOINT_W;
    break;
case X86_BREAKPOINT_RW :
    *gen_type = HW_BREAKPOINT_W | HW_BREAKPOINT_R;
    break;
default :
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="258" endline="299">
{
    struct arch_hw_breakpoint *info = counter_arch_bp (bp);
    info->address = bp->attr.bp_addr;
    switch (bp->attr.bp_len) {
    case HW_BREAKPOINT_LEN_1 :
        info->len = X86_BREAKPOINT_LEN_1;
        break;
    case HW_BREAKPOINT_LEN_2 :
        info->len = X86_BREAKPOINT_LEN_2;
        break;
    case HW_BREAKPOINT_LEN_4 :
        info->len = X86_BREAKPOINT_LEN_4;
        break;
    default :
        return -EINVAL;
    }
    switch (bp->attr.bp_type) {
    case HW_BREAKPOINT_W :
        info->type = X86_BREAKPOINT_WRITE;
        break;
    case HW_BREAKPOINT_W | HW_BREAKPOINT_R :
        info->type = X86_BREAKPOINT_RW;
        break;
    case HW_BREAKPOINT_X :
        info->type = X86_BREAKPOINT_EXECUTE;
        break;
    default :
        return -EINVAL;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="264" endline="281">
{
case HW_BREAKPOINT_LEN_1 :
    info->len = X86_BREAKPOINT_LEN_1;
    break;
case HW_BREAKPOINT_LEN_2 :
    info->len = X86_BREAKPOINT_LEN_2;
    break;
case HW_BREAKPOINT_LEN_4 :
    info->len = X86_BREAKPOINT_LEN_4;
    break;
default :
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="284" endline="296">
{
case HW_BREAKPOINT_W :
    info->type = X86_BREAKPOINT_WRITE;
    break;
case HW_BREAKPOINT_W | HW_BREAKPOINT_R :
    info->type = X86_BREAKPOINT_RW;
    break;
case HW_BREAKPOINT_X :
    info->type = X86_BREAKPOINT_EXECUTE;
    break;
default :
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="305" endline="363">
{
    struct arch_hw_breakpoint *info = counter_arch_bp (bp);
    unsigned int align;
    int ret;
    ret = arch_build_bp_info (bp);
    if (ret)
        return ret;
    ret = -EINVAL;
    if (info->type == X86_BREAKPOINT_EXECUTE)
        if ((!arch_check_va_in_userspace (info->address, info->len)) && info->len != X86_BREAKPOINT_EXECUTE)
            return ret;
    switch (info->len) {
    case X86_BREAKPOINT_LEN_1 :
        align = 0;
        break;
    case X86_BREAKPOINT_LEN_2 :
        align = 1;
        break;
    case X86_BREAKPOINT_LEN_4 :
        align = 3;
        break;
    default :
        return ret;
    }
    if (info->address & align)
        return -EINVAL;
    if (tsk) {
        if (!arch_check_va_in_userspace (info->address, info->len))
            return -EFAULT;
    }
    else {
        if (!arch_check_va_in_kernelspace (info->address, info->len))
            return -EFAULT;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="327" endline="344">
{
case X86_BREAKPOINT_LEN_1 :
    align = 0;
    break;
case X86_BREAKPOINT_LEN_2 :
    align = 1;
    break;
case X86_BREAKPOINT_LEN_4 :
    align = 3;
    break;
default :
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="354" endline="357">
{
    if (!arch_check_va_in_userspace (info->address, info->len))
        return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="357" endline="360">
{
    if (!arch_check_va_in_kernelspace (info->address, info->len))
        return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="374" endline="398">
{
    int i;
    int dr7 = 0;
    struct perf_event *bp;
    struct arch_hw_breakpoint *info;
    struct thread_struct *thread = &current->thread;
    for (i = 0; i < HBP_NUM; i++) {
        bp = thread->ptrace_bps[i];
        if (bp && !bp->attr.disabled) {
            dump->u_debugreg[i] = bp->attr.bp_addr;
            info = counter_arch_bp (bp);
            dr7 |= encode_dr7 (i, info->len, info->type);
        }
        else {
            dump->u_debugreg[i] = 0;
        }
    }
    dump->u_debugreg[4] = 0;
    dump->u_debugreg[5] = 0;
    dump->u_debugreg[6] = current->thread.debugreg6;
    dump->u_debugreg[7] = dr7;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="381" endline="391">
{
    bp = thread->ptrace_bps[i];
    if (bp && !bp->attr.disabled) {
        dump->u_debugreg[i] = bp->attr.bp_addr;
        info = counter_arch_bp (bp);
        dr7 |= encode_dr7 (i, info->len, info->type);
    }
    else {
        dump->u_debugreg[i] = 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="384" endline="388">
{
    dump->u_debugreg[i] = bp->attr.bp_addr;
    info = counter_arch_bp (bp);
    dr7 |= encode_dr7 (i, info->len, info->type);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="388" endline="390">
{
    dump->u_debugreg[i] = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="405" endline="413">
{
    int i;
    struct thread_struct *t = &tsk->thread;
    for (i = 0; i < HBP_NUM; i++) {
        unregister_hw_breakpoint (t -> ptrace_bps [i]);
        t->ptrace_bps[i] = NULL;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="409" endline="412">
{
    unregister_hw_breakpoint (t -> ptrace_bps [i]);
    t->ptrace_bps[i] = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="416" endline="423">
{
    set_debugreg (__get_cpu_var (cpu_debugreg [0]), 0);
    set_debugreg (__get_cpu_var (cpu_debugreg [1]), 1);
    set_debugreg (__get_cpu_var (cpu_debugreg [2]), 2);
    set_debugreg (__get_cpu_var (cpu_debugreg [3]), 3);
    set_debugreg (current -> thread.debugreg6, 6);
    set_debugreg (__get_cpu_var (cpu_dr7), 7);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="443" endline="513">
{
    int i, cpu, rc = NOTIFY_STOP;
    struct perf_event *bp;
    unsigned long dr7, dr6;
    unsigned long *dr6_p;
    dr6_p = (unsigned long *) ERR_PTR (args->err);
    dr6 = *dr6_p;
    if ((dr6 & DR_TRAP_BITS) == 0)
        return NOTIFY_DONE;
    get_debugreg (dr7, 7);
    set_debugreg (0UL, 7);
    current->thread.debugreg6 &= ~DR_TRAP_BITS;
    cpu = get_cpu ();
    for (i = 0; i < HBP_NUM; ++i) {
        if (likely (!(dr6 & (DR_TRAP0 << i))))
            continue;
        rcu_read_lock ();
        bp = per_cpu (bp_per_reg[i], cpu);
        (*dr6_p) &= ~(DR_TRAP0 << i);
        if (!bp) {
            rcu_read_unlock ();
            break;
        }
        perf_bp_event (bp, args -> regs);
        rcu_read_unlock ();
    }
    if ((current->thread.debugreg6 & DR_TRAP_BITS) || (dr6 & (~DR_TRAP_BITS)))
        rc = NOTIFY_DONE;
    set_debugreg (dr7, 7);
    put_cpu ();
    return rc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="469" endline="499">
{
    if (likely (!(dr6 & (DR_TRAP0 << i))))
        continue;
    rcu_read_lock ();
    bp = per_cpu (bp_per_reg[i], cpu);
    (*dr6_p) &= ~(DR_TRAP0 << i);
    if (!bp) {
        rcu_read_unlock ();
        break;
    }
    perf_bp_event (bp, args -> regs);
    rcu_read_unlock ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="491" endline="494">
{
    rcu_read_unlock ();
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="520" endline="525">
{
    if (val != DIE_DEBUG)
        return NOTIFY_DONE;
    return hw_breakpoint_handler (data);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/hw_breakpoint.c.ifdefed" startline="528" endline="530">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="26" endline="32">
{
    char *end;
    memory_corruption_check = simple_strtol (arg, &end, 10);
    return (*end == 0) ? 0 : -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="36" endline="42">
{
    char *end;
    corruption_check_period = simple_strtoul (arg, &end, 10);
    return (*end == 0) ? 0 : -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="46" endline="56">
{
    char *end;
    unsigned size;
    size = memparse (arg, &end);
    if (*end == '\0')
        corruption_check_size = size;
    return (size == corruption_check_size) ? 0 : -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="61" endline="109">
{
    u64 addr = PAGE_SIZE;
    if (memory_corruption_check == -1) {
        memory_corruption_check = 0;
    }
    if (corruption_check_size == 0)
        memory_corruption_check = 0;
    if (!memory_corruption_check)
        return;
    corruption_check_size = round_up (corruption_check_size, PAGE_SIZE);
    while (addr < corruption_check_size && num_scan_areas < MAX_SCAN_AREAS) {
        u64 size;
        addr = find_e820_area_size (addr, &size, PAGE_SIZE);
        if (!(addr + 1))
            break;
        if (addr >= corruption_check_size)
            break;
        if ((addr + size) > corruption_check_size)
            size = corruption_check_size - addr;
        e820_update_range (addr, size, E820_RAM, E820_RESERVED);
        scan_areas[num_scan_areas].addr = addr;
        scan_areas[num_scan_areas].size = size;
        num_scan_areas++;
        memset (__va (addr), 0, size);
        addr += size;
    }
    printk (KERN_INFO "Scanning %d areas for low memory corruption\n", num_scan_areas);
    update_e820 ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="64" endline="72">
{
    memory_corruption_check = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="82" endline="104">
{
    u64 size;
    addr = find_e820_area_size (addr, &size, PAGE_SIZE);
    if (!(addr + 1))
        break;
    if (addr >= corruption_check_size)
        break;
    if ((addr + size) > corruption_check_size)
        size = corruption_check_size - addr;
    e820_update_range (addr, size, E820_RAM, E820_RESERVED);
    scan_areas[num_scan_areas].addr = addr;
    scan_areas[num_scan_areas].size = size;
    num_scan_areas++;
    memset (__va (addr), 0, size);
    addr += size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="113" endline="135">
{
    int i;
    int corruption = 0;
    if (!memory_corruption_check)
        return;
    for (i = 0; i < num_scan_areas; i++) {
        unsigned long *addr = __va (scan_areas[i].addr);
        unsigned long size = scan_areas[i].size;
        for (; size; addr++, size -= sizeof (unsigned long)) {
            if (!*addr)
                continue;
            printk (KERN_ERR "Corrupted low memory at %p (%lx phys) = %08lx\n", addr, __pa (addr), * addr);
            corruption = 1;
            *addr = 0;
        }
    }
    WARN_ONCE (corruption, KERN_ERR "Memory corruption detected in low memory\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="120" endline="132">
{
    unsigned long *addr = __va (scan_areas[i].addr);
    unsigned long size = scan_areas[i].size;
    for (; size; addr++, size -= sizeof (unsigned long)) {
        if (!*addr)
            continue;
        printk (KERN_ERR "Corrupted low memory at %p (%lx phys) = %08lx\n", addr, __pa (addr), * addr);
        corruption = 1;
        *addr = 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="124" endline="131">
{
    if (!*addr)
        continue;
    printk (KERN_ERR "Corrupted low memory at %p (%lx phys) = %08lx\n", addr, __pa (addr), * addr);
    corruption = 1;
    *addr = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="141" endline="145">
{
    check_for_bios_corruption ();
    schedule_delayed_work (& bios_check_work, round_jiffies_relative (corruption_check_period * HZ));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/check.c.ifdefed" startline="148" endline="158">
{
    if (!memory_corruption_check || corruption_check_period == 0)
        return 0;
    printk (KERN_INFO "Scanning for low memory corruption every %d seconds\n", corruption_check_period);
    schedule_delayed_work (& bios_check_work, 0);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="21" endline="29">
{
    struct thread_struct *t = &current->thread;
    int idx;
    for (idx = 0; idx < GDT_ENTRY_TLS_ENTRIES; idx++)
        if (desc_empty (&t->tls_array[idx]))
            return idx + GDT_ENTRY_TLS_MIN;
    return -ESRCH;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="33" endline="56">
{
    struct thread_struct *t = &p->thread;
    struct desc_struct *desc = &t->tls_array[idx - GDT_ENTRY_TLS_MIN];
    int cpu;
    cpu = get_cpu ();
    while (n-- > 0) {
        if (LDT_empty (info))
            desc->a = desc->b = 0;
        else
            fill_ldt (desc, info);
        ++info;
        ++desc;
    }
    if (t == &current->thread)
        load_TLS (t, cpu);
    put_cpu ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="43" endline="50">
{
    if (LDT_empty (info))
        desc->a = desc->b = 0;
    else
        fill_ldt (desc, info);
    ++info;
    ++desc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="64" endline="91">
{
    struct user_desc info;
    if (copy_from_user (&info, u_info, sizeof (info)))
        return -EFAULT;
    if (idx == -1)
        idx = info.entry_number;
    if (idx == -1 && can_allocate) {
        idx = get_free_idx ();
        if (idx < 0)
            return idx;
        if (put_user (idx, &u_info->entry_number))
            return -EFAULT;
    }
    if (idx < GDT_ENTRY_TLS_MIN || idx > GDT_ENTRY_TLS_MAX)
        return -EINVAL;
    set_tls_desc (p, idx, & info, 1);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="77" endline="83">
{
    idx = get_free_idx ();
    if (idx < 0)
        return idx;
    if (put_user (idx, &u_info->entry_number))
        return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="94" endline="98">
{
    int ret = do_set_thread_area (current, -1, u_info, 1);
    asmlinkage_protect (1, ret, u_info);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="108" endline="122">
{
    memset (info, 0, sizeof (* info));
    info->entry_number = idx;
    info->base_addr = get_desc_base (desc);
    info->limit = get_desc_limit (desc);
    info->seg_32bit = desc->d;
    info->contents = desc->type >> 2;
    info->read_exec_only = !(desc->type & 2);
    info->limit_in_pages = desc->g;
    info->seg_not_present = !desc->p;
    info->useable = desc->avl;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="126" endline="141">
{
    struct user_desc info;
    if (idx == -1 && get_user (idx, &u_info->entry_number))
        return -EFAULT;
    if (idx < GDT_ENTRY_TLS_MIN || idx > GDT_ENTRY_TLS_MAX)
        return -EINVAL;
    fill_user_desc (& info, idx, & p -> thread.tls_array [idx - GDT_ENTRY_TLS_MIN]);
    if (copy_to_user (u_info, &info, sizeof (info)))
        return -EFAULT;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="144" endline="148">
{
    int ret = do_get_thread_area (current, -1, u_info);
    asmlinkage_protect (1, ret, u_info);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="152" endline="158">
{
    struct thread_struct *t = &target->thread;
    int n = GDT_ENTRY_TLS_ENTRIES;
    while (n > 0 && desc_empty (&t->tls_array[n - 1]))
        --n;
    return n;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="163" endline="192">
{
    const struct desc_struct *tls;
    if (pos > GDT_ENTRY_TLS_ENTRIES * sizeof (struct user_desc) || (pos % sizeof (struct user_desc)) != 0 || (count % sizeof (struct user_desc)) != 0)
        return -EINVAL;
    pos /= sizeof (struct user_desc);
    count /= sizeof (struct user_desc);
    tls = &target->thread.tls_array[pos];
    if (kbuf) {
        struct user_desc *info = kbuf;
        while (count-- > 0)
            fill_user_desc (info++, GDT_ENTRY_TLS_MIN +pos++, tls++);
    }
    else {
        struct user_desc __user *u_info = ubuf;
        while (count-- > 0) {
            struct user_desc info;
            fill_user_desc (& info, GDT_ENTRY_TLS_MIN + pos ++, tls ++);
            if (__copy_to_user (u_info++, &info, sizeof (info)))
                return -EFAULT;
        }
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="176" endline="181">
{
    struct user_desc *info = kbuf;
    while (count-- > 0)
        fill_user_desc (info++, GDT_ENTRY_TLS_MIN +pos++, tls++);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="181" endline="189">
{
    struct user_desc __user *u_info = ubuf;
    while (count-- > 0) {
        struct user_desc info;
        fill_user_desc (& info, GDT_ENTRY_TLS_MIN + pos ++, tls ++);
        if (__copy_to_user (u_info++, &info, sizeof (info)))
            return -EFAULT;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="183" endline="188">
{
    struct user_desc info;
    fill_user_desc (& info, GDT_ENTRY_TLS_MIN + pos ++, tls ++);
    if (__copy_to_user (u_info++, &info, sizeof (info)))
        return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/tls.c.ifdefed" startline="197" endline="218">
{
    struct user_desc infobuf [GDT_ENTRY_TLS_ENTRIES];
    const struct user_desc *info;
    if (pos > GDT_ENTRY_TLS_ENTRIES * sizeof (struct user_desc) || (pos % sizeof (struct user_desc)) != 0 || (count % sizeof (struct user_desc)) != 0)
        return -EINVAL;
    if (kbuf)
        info = kbuf;
    else if (__copy_from_user (infobuf, ubuf, count))
        return -EFAULT;
    else
        info = infobuf;
    set_tls_desc (target, GDT_ENTRY_TLS_MIN + (pos / sizeof (struct user_desc)), info, count / sizeof (struct user_desc));
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8237.c.ifdefed" startline="25" endline="46">
{
    unsigned long flags;
    int i;
    flags = claim_dma_lock ();
    dma_outb (0, DMA1_RESET_REG);
    dma_outb (0, DMA2_RESET_REG);
    for (i = 0; i < 8; i++) {
        set_dma_addr (i, 0x000000);
        set_dma_count (i, 1);
    }
    enable_dma (4);
    release_dma_lock (flags);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8237.c.ifdefed" startline="34" endline="38">
{
    set_dma_addr (i, 0x000000);
    set_dma_count (i, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8237.c.ifdefed" startline="49" endline="51">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8237.c.ifdefed" startline="65" endline="70">
{
    int error = sysdev_class_register (&i8237_sysdev_class);
    if (!error)
        error = sysdev_register (&device_i8237A);
    return error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="92" endline="123">
{
    unsigned long offset, flags;
    unsigned long boundary_size;
    unsigned long base_index;
    base_index = ALIGN (iommu_bus_base &dma_get_seg_boundary (dev), PAGE_SIZE) >> PAGE_SHIFT;
    boundary_size = ALIGN ((u64) dma_get_seg_boundary (dev) + 1, PAGE_SIZE) >> PAGE_SHIFT;
    spin_lock_irqsave (& iommu_bitmap_lock, flags);
    offset = iommu_area_alloc (iommu_gart_bitmap, iommu_pages, next_bit, size, base_index, boundary_size, align_mask);
    if (offset == -1) {
        need_flush = true;
        offset = iommu_area_alloc (iommu_gart_bitmap, iommu_pages, 0, size, base_index, boundary_size, align_mask);
    }
    if (offset != -1) {
        next_bit = offset + size;
        if (next_bit >= iommu_pages) {
            next_bit = 0;
            need_flush = true;
        }
    }
    if (iommu_fullflush)
        need_flush = true;
    spin_unlock_irqrestore (& iommu_bitmap_lock, flags);
    return offset;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="105" endline="110">
{
    need_flush = true;
    offset = iommu_area_alloc (iommu_gart_bitmap, iommu_pages, 0, size, base_index, boundary_size, align_mask);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="111" endline="117">
{
    next_bit = offset + size;
    if (next_bit >= iommu_pages) {
        next_bit = 0;
        need_flush = true;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="113" endline="116">
{
    next_bit = 0;
    need_flush = true;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="126" endline="134">
{
    unsigned long flags;
    spin_lock_irqsave (& iommu_bitmap_lock, flags);
    bitmap_clear (iommu_gart_bitmap, offset, size);
    if (offset >= next_bit)
        next_bit = offset + size;
    spin_unlock_irqrestore (& iommu_bitmap_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="140" endline="149">
{
    unsigned long flags;
    spin_lock_irqsave (& iommu_bitmap_lock, flags);
    if (need_flush) {
        k8_flush_garts ();
        need_flush = false;
    }
    spin_unlock_irqrestore (& iommu_bitmap_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="144" endline="147">
{
    k8_flush_garts ();
    need_flush = false;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="170" endline="193">
{
    dev_err (dev, "PCI-DMA: Out of IOMMU space for %lu bytes\n", size);
    if (size > PAGE_SIZE * EMERGENCY_PAGES) {
        if (dir == PCI_DMA_FROMDEVICE || dir == PCI_DMA_BIDIRECTIONAL)
            panic ("PCI-DMA: Memory would be corrupted\n");
        if (dir == PCI_DMA_TODEVICE || dir == PCI_DMA_BIDIRECTIONAL)
            panic (KERN_ERR "PCI-DMA: Random memory would be DMAed\n");
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="183" endline="189">
{
    if (dir == PCI_DMA_FROMDEVICE || dir == PCI_DMA_BIDIRECTIONAL)
        panic ("PCI-DMA: Memory would be corrupted\n");
    if (dir == PCI_DMA_TODEVICE || dir == PCI_DMA_BIDIRECTIONAL)
        panic (KERN_ERR "PCI-DMA: Random memory would be DMAed\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="197" endline="199">
{
    return force_iommu || !dma_capable (dev, addr, size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="203" endline="205">
{
    return !dma_capable (dev, addr, size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="212" endline="231">
{
    unsigned long npages = iommu_num_pages (phys_mem, size, PAGE_SIZE);
    unsigned long iommu_page = alloc_iommu (dev, npages, align_mask);
    int i;
    if (iommu_page == -1) {
        if (!nonforced_iommu (dev, phys_mem, size))
            return phys_mem;
        if (panic_on_overflow)
            panic ("dma_map_area overflow %lu bytes\n", size);
        iommu_full (dev, size, dir);
        return bad_dma_addr;
    }
    for (i = 0; i < npages; i++) {
        iommu_gatt_base[iommu_page + i] = GPTE_ENCODE (phys_mem);
        phys_mem += PAGE_SIZE;
    }
    return iommu_bus_base + iommu_page * PAGE_SIZE + (phys_mem & ~PAGE_MASK);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="217" endline="224">
{
    if (!nonforced_iommu (dev, phys_mem, size))
        return phys_mem;
    if (panic_on_overflow)
        panic ("dma_map_area overflow %lu bytes\n", size);
    iommu_full (dev, size, dir);
    return bad_dma_addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="226" endline="229">
{
    iommu_gatt_base[iommu_page + i] = GPTE_ENCODE (phys_mem);
    phys_mem += PAGE_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="238" endline="252">
{
    unsigned long bus;
    phys_addr_t paddr = page_to_phys (page) + offset;
    if (!dev)
        dev = &x86_dma_fallback_dev;
    if (!need_iommu (dev, paddr, size))
        return paddr;
    bus = dma_map_area (dev, paddr, size, dir, 0);
    flush_gart ();
    return bus;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="260" endline="275">
{
    unsigned long iommu_page;
    int npages;
    int i;
    if (dma_addr < iommu_bus_base + EMERGENCY_PAGES * PAGE_SIZE || dma_addr >= iommu_bus_base + iommu_size)
        return;
    iommu_page = (dma_addr - iommu_bus_base) >> PAGE_SHIFT;
    npages = iommu_num_pages (dma_addr, size, PAGE_SIZE);
    for (i = 0; i < npages; i++) {
        iommu_gatt_base[iommu_page + i] = gart_unmapped_entry;
    }
    free_iommu (iommu_page, npages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="271" endline="273">
{
    iommu_gatt_base[iommu_page + i] = gart_unmapped_entry;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="282" endline="291">
{
    struct scatterlist *s;
    int i;

    for_each_sg (sg, s, nents, i) {
        if (!s->dma_length || !s->length)
            break;
        gart_unmap_page (dev, s -> dma_address, s -> dma_length, dir, NULL);
    }

}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="286" endline="290">
{
    if (!s->dma_length || !s->length)
        break;
    gart_unmap_page (dev, s -> dma_address, s -> dma_length, dir, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="296" endline="323">
{
    struct scatterlist *s;
    int i;

    for_each_sg (sg, s, nents, i) {
        unsigned long addr = sg_phys (s);
        if (nonforced_iommu (dev, addr, s->length)) {
            addr = dma_map_area (dev, addr, s->length, dir, 0);
            if (addr == bad_dma_addr) {
                if (i > 0)
                    gart_unmap_sg (dev, sg, i, dir, NULL);
                nents = 0;
                sg[0].dma_length = 0;
                break;
            }
        }
        s->dma_address = addr;
        s->dma_length = s->length;
    }

    flush_gart ();
    return nents;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="304" endline="319">
{
    unsigned long addr = sg_phys (s);
    if (nonforced_iommu (dev, addr, s->length)) {
        addr = dma_map_area (dev, addr, s->length, dir, 0);
        if (addr == bad_dma_addr) {
            if (i > 0)
                gart_unmap_sg (dev, sg, i, dir, NULL);
            nents = 0;
            sg[0].dma_length = 0;
            break;
        }
    }
    s->dma_address = addr;
    s->dma_length = s->length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="307" endline="316">
{
    addr = dma_map_area (dev, addr, s->length, dir, 0);
    if (addr == bad_dma_addr) {
        if (i > 0)
            gart_unmap_sg (dev, sg, i, dir, NULL);
        nents = 0;
        sg[0].dma_length = 0;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="309" endline="315">
{
    if (i > 0)
        gart_unmap_sg (dev, sg, i, dir, NULL);
    nents = 0;
    sg[0].dma_length = 0;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="329" endline="362">
{
    unsigned long iommu_start = alloc_iommu (dev, pages, 0);
    unsigned long iommu_page = iommu_start;
    struct scatterlist *s;
    int i;
    if (iommu_start == -1)
        return -1;

    for_each_sg (start, s, nelems, i) {
        unsigned long pages, addr;
        unsigned long phys_addr = s->dma_address;
        BUG_ON (s != start && s -> offset);
        if (s == start) {
            sout->dma_address = iommu_bus_base;
            sout->dma_address += iommu_page * PAGE_SIZE + s->offset;
            sout->dma_length = s->length;
        }
        else {
            sout->dma_length += s->length;
        }
        addr = phys_addr;
        pages = iommu_num_pages (s->offset, s->length, PAGE_SIZE);
        while (pages--) {
            iommu_gatt_base[iommu_page] = GPTE_ENCODE (addr);
            addr += PAGE_SIZE;
            iommu_page++;
        }
    }

    BUG_ON (iommu_page - iommu_start != pages);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="338" endline="358">
{
    unsigned long pages, addr;
    unsigned long phys_addr = s->dma_address;
    BUG_ON (s != start && s -> offset);
    if (s == start) {
        sout->dma_address = iommu_bus_base;
        sout->dma_address += iommu_page * PAGE_SIZE + s->offset;
        sout->dma_length = s->length;
    }
    else {
        sout->dma_length += s->length;
    }
    addr = phys_addr;
    pages = iommu_num_pages (s->offset, s->length, PAGE_SIZE);
    while (pages--) {
        iommu_gatt_base[iommu_page] = GPTE_ENCODE (addr);
        addr += PAGE_SIZE;
        iommu_page++;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="343" endline="347">
{
    sout->dma_address = iommu_bus_base;
    sout->dma_address += iommu_page * PAGE_SIZE + s->offset;
    sout->dma_length = s->length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="347" endline="349">
{
    sout->dma_length += s->length;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="353" endline="357">
{
    iommu_gatt_base[iommu_page] = GPTE_ENCODE (addr);
    addr += PAGE_SIZE;
    iommu_page++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="367" endline="375">
{
    if (!need) {
        BUG_ON (nelems != 1);
        sout->dma_address = start->dma_address;
        sout->dma_length = start->length;
        return 0;
    }
    return __dma_map_cont (dev, start, nelems, sout, pages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="368" endline="373">
{
    BUG_ON (nelems != 1);
    sout->dma_address = start->dma_address;
    sout->dma_length = start->length;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="383" endline="467">
{
    struct scatterlist *s, *ps, *start_sg, *sgmap;
    int need = 0, nextneed, i, out, start;
    unsigned long pages = 0;
    unsigned int seg_size;
    unsigned int max_seg_size;
    if (nents == 0)
        return 0;
    if (!dev)
        dev = &x86_dma_fallback_dev;
    out = 0;
    start = 0;
    start_sg = sg;
    sgmap = sg;
    seg_size = 0;
    max_seg_size = dma_get_max_seg_size (dev);
    ps = NULL;

    for_each_sg (sg, s, nents, i) {
        dma_addr_t addr = sg_phys (s);
        s->dma_address = addr;
        BUG_ON (s -> length == 0);
        nextneed = need_iommu (dev, addr, s->length);
        if (i > start) {
            if (!iommu_merge || !nextneed || !need || s->offset || (s->length + seg_size > max_seg_size) || (ps->offset + ps->length) % PAGE_SIZE) {
                if (dma_map_cont (dev, start_sg, i -start, sgmap, pages, need) < 0)
                    goto error;
                out++;
                seg_size = 0;
                sgmap = sg_next (sgmap);
                pages = 0;
                start = i;
                start_sg = s;
            }
        }
        seg_size += s->length;
        need = nextneed;
        pages += iommu_num_pages (s->offset, s->length, PAGE_SIZE);
        ps = s;
    }

    if (dma_map_cont (dev, start_sg, i -start, sgmap, pages, need) < 0)
        goto error;
    out++;
    flush_gart ();
    if (out < nents) {
        sgmap = sg_next (sgmap);
        sgmap->dma_length = 0;
    }
    return out;
error :
    flush_gart ();
    gart_unmap_sg (dev, sg, out, dir, NULL);
    if (force_iommu || iommu_merge) {
        out = dma_map_sg_nonforce (dev, sg, nents, dir);
        if (out > 0)
            return out;
    }
    if (panic_on_overflow)
        panic ("dma_map_sg: overflow on %lu pages\n", pages);
    iommu_full (dev, pages << PAGE_SHIFT, dir);
    for_each_sg (sg, s, nents, i)
    s->dma_address = bad_dma_addr;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="404" endline="439">
{
    dma_addr_t addr = sg_phys (s);
    s->dma_address = addr;
    BUG_ON (s -> length == 0);
    nextneed = need_iommu (dev, addr, s->length);
    if (i > start) {
        if (!iommu_merge || !nextneed || !need || s->offset || (s->length + seg_size > max_seg_size) || (ps->offset + ps->length) % PAGE_SIZE) {
            if (dma_map_cont (dev, start_sg, i -start, sgmap, pages, need) < 0)
                goto error;
            out++;
            seg_size = 0;
            sgmap = sg_next (sgmap);
            pages = 0;
            start = i;
            start_sg = s;
        }
    }
    seg_size += s->length;
    need = nextneed;
    pages += iommu_num_pages (s->offset, s->length, PAGE_SIZE);
    ps = s;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="413" endline="433">
{
    if (!iommu_merge || !nextneed || !need || s->offset || (s->length + seg_size > max_seg_size) || (ps->offset + ps->length) % PAGE_SIZE) {
        if (dma_map_cont (dev, start_sg, i -start, sgmap, pages, need) < 0)
            goto error;
        out++;
        seg_size = 0;
        sgmap = sg_next (sgmap);
        pages = 0;
        start = i;
        start_sg = s;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="421" endline="432">
{
    if (dma_map_cont (dev, start_sg, i -start, sgmap, pages, need) < 0)
        goto error;
    out++;
    seg_size = 0;
    sgmap = sg_next (sgmap);
    pages = 0;
    start = i;
    start_sg = s;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="444" endline="447">
{
    sgmap = sg_next (sgmap);
    sgmap->dma_length = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="455" endline="459">
{
    out = dma_map_sg_nonforce (dev, sg, nents, dir);
    if (out > 0)
        return out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="473" endline="498">
{
    dma_addr_t paddr;
    unsigned long align_mask;
    struct page *page;
    if (force_iommu && !(flag & GFP_DMA)) {
        flag &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
        page = alloc_pages (flag | __GFP_ZERO, get_order (size));
        if (!page)
            return NULL;
        align_mask = (1UL << get_order (size)) - 1;
        paddr = dma_map_area (dev, page_to_phys (page), size, DMA_BIDIRECTIONAL, align_mask);
        flush_gart ();
        if (paddr != bad_dma_addr) {
            *dma_addr = paddr;
            return page_address (page);
        }
        __free_pages (page, get_order (size));
    }
    else
        return dma_generic_alloc_coherent (dev, size, dma_addr, flag);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="478" endline="494">
{
    flag &= ~(__GFP_DMA | __GFP_HIGHMEM | __GFP_DMA32);
    page = alloc_pages (flag | __GFP_ZERO, get_order (size));
    if (!page)
        return NULL;
    align_mask = (1UL << get_order (size)) - 1;
    paddr = dma_map_area (dev, page_to_phys (page), size, DMA_BIDIRECTIONAL, align_mask);
    flush_gart ();
    if (paddr != bad_dma_addr) {
        *dma_addr = paddr;
        return page_address (page);
    }
    __free_pages (page, get_order (size));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="489" endline="492">
{
    *dma_addr = paddr;
    return page_address (page);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="504" endline="507">
{
    gart_unmap_page (dev, dma_addr, size, DMA_BIDIRECTIONAL, NULL);
    free_pages ((unsigned long) vaddr, get_order (size));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="510" endline="512">
{
    return (dma_addr == bad_dma_addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="517" endline="537">
{
    unsigned long a;
    if (!iommu_size) {
        iommu_size = aper_size;
        if (!no_agp)
            iommu_size /= 2;
    }
    a = aper + iommu_size;
    iommu_size -= round_up (a, PMD_PAGE_SIZE) - a;
    if (iommu_size < 64 * 1024 * 1024) {
        pr_warning ("PCI-DMA: Warning: Small IOMMU %luMB." " Consider increasing the AGP aperture in BIOS\n", iommu_size >> 20);
    }
    return iommu_size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="520" endline="524">
{
    iommu_size = aper_size;
    if (!no_agp)
        iommu_size /= 2;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="529" endline="534">
{
    pr_warning ("PCI-DMA: Warning: Small IOMMU %luMB." " Consider increasing the AGP aperture in BIOS\n", iommu_size >> 20);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="540" endline="557">
{
    unsigned aper_size = 0, aper_base_32, aper_order;
    u64 aper_base;
    pci_read_config_dword (dev, AMD64_GARTAPERTUREBASE, & aper_base_32);
    pci_read_config_dword (dev, AMD64_GARTAPERTURECTL, & aper_order);
    aper_order = (aper_order >> 1) & 7;
    aper_base = aper_base_32 & 0x7fff;
    aper_base <<= 25;
    aper_size = (32 * 1024 * 1024) << aper_order;
    if (aper_base + aper_size > 0x100000000UL || !aper_size)
        aper_base = 0;
    *size = aper_size;
    return aper_base;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="560" endline="571">
{
    int i;
    for (i = 0; i < num_k8_northbridges; i++) {
        struct pci_dev *dev = k8_northbridges[i];
        enable_gart_translation (dev, __pa (agp_gatt_table));
    }
    k8_flush_garts ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="563" endline="567">
{
    struct pci_dev *dev = k8_northbridges[i];
    enable_gart_translation (dev, __pa (agp_gatt_table));
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="582" endline="586">
{
    fix_up_north_bridges = true;
    aperture_order = aper_order;
    aperture_alloc = aper_alloc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="589" endline="607">
{
    int i;
    if (!fix_up_north_bridges)
        return;
    pr_info ("PCI-DMA: Restoring GART aperture settings\n");
    for (i = 0; i < num_k8_northbridges; i++) {
        struct pci_dev *dev = k8_northbridges[i];
        pci_write_config_dword (dev, AMD64_GARTAPERTURECTL, aperture_order << 1);
        pci_write_config_dword (dev, AMD64_GARTAPERTUREBASE, aperture_alloc >> 25);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="597" endline="606">
{
    struct pci_dev *dev = k8_northbridges[i];
    pci_write_config_dword (dev, AMD64_GARTAPERTURECTL, aperture_order << 1);
    pci_write_config_dword (dev, AMD64_GARTAPERTUREBASE, aperture_alloc >> 25);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="610" endline="618">
{
    pr_info ("PCI-DMA: Resuming GART IOMMU\n");
    gart_fixup_northbridges (dev);
    enable_gart_translations ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="621" endline="623">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="641" endline="700">
{
    unsigned aper_size, gatt_size, new_aper_size;
    unsigned aper_base, new_aper_base;
    struct pci_dev *dev;
    void *gatt;
    int i, error;
    pr_info ("PCI-DMA: Disabling AGP.\n");
    aper_size = aper_base = info->aper_size = 0;
    dev = NULL;
    for (i = 0; i < num_k8_northbridges; i++) {
        dev = k8_northbridges[i];
        new_aper_base = read_aperture (dev, &new_aper_size);
        if (!new_aper_base)
            goto nommu;
        if (!aper_base) {
            aper_size = new_aper_size;
            aper_base = new_aper_base;
        }
        if (aper_size != new_aper_size || aper_base != new_aper_base)
            goto nommu;
    }
    if (!aper_base)
        goto nommu;
    info->aper_base = aper_base;
    info->aper_size = aper_size >> 20;
    gatt_size = (aper_size >> PAGE_SHIFT) * sizeof (u32);
    gatt = (void *) __get_free_pages (GFP_KERNEL | __GFP_ZERO, get_order (gatt_size));
    if (!gatt)
        panic ("Cannot allocate GATT table");
    if (set_memory_uc ((unsigned long) gatt, gatt_size >> PAGE_SHIFT))
        panic ("Could not set GART PTEs to uncacheable pages");
    agp_gatt_table = gatt;
    error = sysdev_class_register (&gart_sysdev_class);
    if (!error)
        error = sysdev_register (&device_gart);
    if (error)
        panic ("Could not register gart_sysdev -- " "would corrupt data on next suspend");
    flush_gart ();
    pr_info ("PCI-DMA: aperture base @ %x size %u KB\n", aper_base, aper_size >> 10);
    return 0;
nommu :
    pr_warning ("PCI-DMA: More than 4GB of RAM and no IOMMU\n" "falling back to iommu=soft.\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="652" endline="664">
{
    dev = k8_northbridges[i];
    new_aper_base = read_aperture (dev, &new_aper_size);
    if (!new_aper_base)
        goto nommu;
    if (!aper_base) {
        aper_size = new_aper_size;
        aper_base = new_aper_base;
    }
    if (aper_size != new_aper_size || aper_base != new_aper_base)
        goto nommu;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="658" endline="661">
{
    aper_size = new_aper_size;
    aper_base = new_aper_base;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="713" endline="731">
{
    struct pci_dev *dev;
    int i;
    if (!no_agp)
        return;
    for (i = 0; i < num_k8_northbridges; i++) {
        u32 ctl;
        dev = k8_northbridges[i];
        pci_read_config_dword (dev, AMD64_GARTAPERTURECTL, & ctl);
        ctl &= ~GARTEN;
        pci_write_config_dword (dev, AMD64_GARTAPERTURECTL, ctl);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="721" endline="730">
{
    u32 ctl;
    dev = k8_northbridges[i];
    pci_read_config_dword (dev, AMD64_GARTAPERTURECTL, & ctl);
    ctl &= ~GARTEN;
    pci_write_config_dword (dev, AMD64_GARTAPERTURECTL, ctl);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="734" endline="858">
{
    struct agp_kern_info info;
    unsigned long iommu_start;
    unsigned long aper_base, aper_size;
    unsigned long start_pfn, end_pfn;
    unsigned long scratch;
    long i;
    if (num_k8_northbridges == 0)
        return 0;
    no_agp = 1;
    if (no_iommu || (!force_iommu && max_pfn <= MAX_DMA32_PFN) || !gart_iommu_aperture || (no_agp && init_k8_gatt (&info) < 0)) {
        if (max_pfn > MAX_DMA32_PFN) {
            pr_warning ("More than 4GB of memory but GART IOMMU not available.\n");
            pr_warning ("falling back to iommu=soft.\n");
        }
        return 0;
    }
    aper_size = info.aper_size << 20;
    aper_base = info.aper_base;
    end_pfn = (aper_base >> PAGE_SHIFT) + (aper_size >> PAGE_SHIFT);
    if (end_pfn > max_low_pfn_mapped) {
        start_pfn = (aper_base >> PAGE_SHIFT);
        init_memory_mapping (start_pfn << PAGE_SHIFT, end_pfn << PAGE_SHIFT);
    }
    pr_info ("PCI-DMA: using GART IOMMU.\n");
    iommu_size = check_iommu_size (info.aper_base, aper_size);
    iommu_pages = iommu_size >> PAGE_SHIFT;
    iommu_gart_bitmap = (void *) __get_free_pages (GFP_KERNEL | __GFP_ZERO, get_order (iommu_pages / 8));
    if (!iommu_gart_bitmap)
        panic ("Cannot allocate iommu bitmap\n");
    bitmap_set (iommu_gart_bitmap, 0, EMERGENCY_PAGES);
    pr_info ("PCI-DMA: Reserving %luMB of IOMMU area in the AGP aperture\n", iommu_size >> 20);
    agp_memory_reserved = iommu_size;
    iommu_start = aper_size - iommu_size;
    iommu_bus_base = info.aper_base + iommu_start;
    bad_dma_addr = iommu_bus_base;
    iommu_gatt_base = agp_gatt_table + (iommu_start >> PAGE_SHIFT);
    set_memory_np ((unsigned long) __va (iommu_bus_base), iommu_size >> PAGE_SHIFT);
    wbinvd ();
    enable_gart_translations ();
    scratch = get_zeroed_page (GFP_KERNEL);
    if (!scratch)
        panic ("Cannot allocate iommu scratch page");
    gart_unmapped_entry = GPTE_ENCODE (__pa (scratch));
    for (i = EMERGENCY_PAGES; i < iommu_pages; i++)
        iommu_gatt_base[i] = gart_unmapped_entry;
    flush_gart ();
    dma_ops = &gart_dma_ops;
    x86_platform.iommu_shutdown = gart_iommu_shutdown;
    swiotlb = 0;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="758" endline="764">
{
    if (max_pfn > MAX_DMA32_PFN) {
        pr_warning ("More than 4GB of memory but GART IOMMU not available.\n");
        pr_warning ("falling back to iommu=soft.\n");
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="759" endline="762">
{
    pr_warning ("More than 4GB of memory but GART IOMMU not available.\n");
    pr_warning ("falling back to iommu=soft.\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="771" endline="774">
{
    start_pfn = (aper_base >> PAGE_SHIFT);
    init_memory_mapping (start_pfn << PAGE_SHIFT, end_pfn << PAGE_SHIFT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="861" endline="898">
{
    int arg;
    if (isdigit (*p) && get_option (&p, &arg))
        iommu_size = arg;
    if (!strncmp (p, "fullflush", 9))
        iommu_fullflush = 1;
    if (!strncmp (p, "nofullflush", 11))
        iommu_fullflush = 0;
    if (!strncmp (p, "noagp", 5))
        no_agp = 1;
    if (!strncmp (p, "noaperture", 10))
        fix_aperture = 0;
    if (!strncmp (p, "force", 5))
        gart_iommu_aperture_allowed = 1;
    if (!strncmp (p, "allowed", 7))
        gart_iommu_aperture_allowed = 1;
    if (!strncmp (p, "memaper", 7)) {
        fallback_aper_force = 1;
        p += 7;
        if (*p == '=') {
            ++p;
            if (get_option (&p, &arg))
                fallback_aper_order = arg;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="889" endline="897">
{
    fallback_aper_force = 1;
    p += 7;
    if (*p == '=') {
        ++p;
        if (get_option (&p, &arg))
            fallback_aper_order = arg;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/pci-gart_64.c.ifdefed" startline="892" endline="896">
{
    ++p;
    if (get_option (&p, &arg))
        fallback_aper_order = arg;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="72" endline="83">
{
    unsigned int mask = 1 << irq;
    unsigned long flags;
    raw_spin_lock_irqsave (& i8259A_lock, flags);
    cached_irq_mask |= mask;
    if (irq & 8)
        outb (cached_slave_mask, PIC_SLAVE_IMR);
    else
        outb (cached_master_mask, PIC_MASTER_IMR);
    raw_spin_unlock_irqrestore (& i8259A_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="86" endline="97">
{
    unsigned int mask = ~(1 << irq);
    unsigned long flags;
    raw_spin_lock_irqsave (& i8259A_lock, flags);
    cached_irq_mask &= mask;
    if (irq & 8)
        outb (cached_slave_mask, PIC_SLAVE_IMR);
    else
        outb (cached_master_mask, PIC_MASTER_IMR);
    raw_spin_unlock_irqrestore (& i8259A_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="100" endline="113">
{
    unsigned int mask = 1 << irq;
    unsigned long flags;
    int ret;
    raw_spin_lock_irqsave (& i8259A_lock, flags);
    if (irq < 8)
        ret = inb (PIC_MASTER_CMD) & mask;
    else
        ret = inb (PIC_SLAVE_CMD) & (mask >> 8);
    raw_spin_unlock_irqrestore (& i8259A_lock, flags);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="116" endline="122">
{
    disable_irq_nosync (irq);
    io_apic_irqs &= ~(1 << irq);
    set_irq_chip_and_handler_name (irq, & i8259A_chip, handle_level_irq, "XT");
    enable_irq (irq);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="131" endline="145">
{
    int value;
    int irqmask = 1 << irq;
    if (irq < 8) {
        outb (0x0B, PIC_MASTER_CMD);
        value = inb (PIC_MASTER_CMD) & irqmask;
        outb (0x0A, PIC_MASTER_CMD);
        return value;
    }
    outb (0x0B, PIC_SLAVE_CMD);
    value = inb (PIC_SLAVE_CMD) & (irqmask >> 8);
    outb (0x0A, PIC_SLAVE_CMD);
    return value;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="135" endline="140">
{
    outb (0x0B, PIC_MASTER_CMD);
    value = inb (PIC_MASTER_CMD) & irqmask;
    outb (0x0A, PIC_MASTER_CMD);
    return value;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="154" endline="224">
{
    unsigned int irqmask = 1 << irq;
    unsigned long flags;
    raw_spin_lock_irqsave (& i8259A_lock, flags);
    if (cached_irq_mask & irqmask)
        goto spurious_8259A_irq;
    cached_irq_mask |= irqmask;
handle_real_irq :
    if (irq & 8) {
        inb (PIC_SLAVE_IMR);
        outb (cached_slave_mask, PIC_SLAVE_IMR);
        outb (0x60 + (irq & 7), PIC_SLAVE_CMD);
        outb (0x60 + PIC_CASCADE_IR, PIC_MASTER_CMD);
    }
    else {
        inb (PIC_MASTER_IMR);
        outb (cached_master_mask, PIC_MASTER_IMR);
        outb (0x60 + irq, PIC_MASTER_CMD);
    }
    raw_spin_unlock_irqrestore (& i8259A_lock, flags);
    return;
spurious_8259A_irq :
    if (i8259A_irq_real (irq))
        goto handle_real_irq;
    {
        static int spurious_irq_mask;
        if (!(spurious_irq_mask & irqmask)) {
            printk (KERN_DEBUG "spurious 8259A interrupt: IRQ%d.\n", irq);
            spurious_irq_mask |= irqmask;
        }
        atomic_inc (& irq_err_count);
        goto handle_real_irq;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="179" endline="186">
{
    inb (PIC_SLAVE_IMR);
    outb (cached_slave_mask, PIC_SLAVE_IMR);
    outb (0x60 + (irq & 7), PIC_SLAVE_CMD);
    outb (0x60 + PIC_CASCADE_IR, PIC_MASTER_CMD);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="186" endline="190">
{
    inb (PIC_MASTER_IMR);
    outb (cached_master_mask, PIC_MASTER_IMR);
    outb (0x60 + irq, PIC_MASTER_CMD);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="205" endline="223">
{
    static int spurious_irq_mask;
    if (!(spurious_irq_mask & irqmask)) {
        printk (KERN_DEBUG "spurious 8259A interrupt: IRQ%d.\n", irq);
        spurious_irq_mask |= irqmask;
    }
    atomic_inc (& irq_err_count);
    goto handle_real_irq;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="211" endline="215">
{
    printk (KERN_DEBUG "spurious 8259A interrupt: IRQ%d.\n", irq);
    spurious_irq_mask |= irqmask;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="231" endline="234">
{
    outb (trigger [0], 0x4d0);
    outb (trigger [1], 0x4d1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="237" endline="241">
{
    trigger[0] = inb (0x4d0) & 0xF8;
    trigger[1] = inb (0x4d1) & 0xDE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="244" endline="248">
{
    init_8259A (i8259A_auto_eoi);
    restore_ELCR (irq_trigger);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="251" endline="254">
{
    save_ELCR (irq_trigger);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="257" endline="265">
{
    outb (0xff, PIC_MASTER_IMR);
    outb (0xff, PIC_SLAVE_IMR);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="280" endline="285">
{
    int error = sysdev_class_register (&i8259_sysdev_class);
    if (!error)
        error = sysdev_register (&device_i8259A);
    return error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="290" endline="299">
{
    unsigned long flags;
    raw_spin_lock_irqsave (& i8259A_lock, flags);
    outb (0xff, PIC_MASTER_IMR);
    outb (0xff, PIC_SLAVE_IMR);
    raw_spin_unlock_irqrestore (& i8259A_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="302" endline="311">
{
    unsigned long flags;
    raw_spin_lock_irqsave (& i8259A_lock, flags);
    outb (cached_master_mask, PIC_MASTER_IMR);
    outb (cached_slave_mask, PIC_SLAVE_IMR);
    raw_spin_unlock_irqrestore (& i8259A_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="314" endline="365">
{
    unsigned long flags;
    i8259A_auto_eoi = auto_eoi;
    raw_spin_lock_irqsave (& i8259A_lock, flags);
    outb (0xff, PIC_MASTER_IMR);
    outb (0xff, PIC_SLAVE_IMR);
    outb_pic (0x11, PIC_MASTER_CMD);
    outb_pic (IRQ0_VECTOR, PIC_MASTER_IMR);
    outb_pic (1U << PIC_CASCADE_IR, PIC_MASTER_IMR);
    if (auto_eoi)
        outb_pic (MASTER_ICW4_DEFAULT | PIC_ICW4_AEOI, PIC_MASTER_IMR);
    else
        outb_pic (MASTER_ICW4_DEFAULT, PIC_MASTER_IMR);
    outb_pic (0x11, PIC_SLAVE_CMD);
    outb_pic (IRQ8_VECTOR, PIC_SLAVE_IMR);
    outb_pic (PIC_CASCADE_IR, PIC_SLAVE_IMR);
    outb_pic (SLAVE_ICW4_DEFAULT, PIC_SLAVE_IMR);
    if (auto_eoi)
        i8259A_chip.mask_ack = disable_8259A_irq;
    else
        i8259A_chip.mask_ack = mask_and_ack_8259A;
    udelay (100);
    outb (cached_master_mask, PIC_MASTER_IMR);
    outb (cached_slave_mask, PIC_SLAVE_IMR);
    raw_spin_unlock_irqrestore (& i8259A_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="373" endline="373">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="374" endline="374">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="375" endline="375">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i8259.c.ifdefed" startline="385" endline="387">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="47" endline="60">
{
    unsigned long mask = 0;
    clts ();
    if (cpu_has_fxsr) {
        memset (& fx_scratch, 0, sizeof (struct i387_fxsave_struct));
        asm volatile ("fxsave %0"
            :
            : "m" (fx_scratch)
        ) mask = fx_scratch.mxcsr_mask;
        if (mask == 0)
            mask = 0x0000ffbf;
    }
    mxcsr_feature_mask &= mask;
    stts ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="51" endline="57">
{
    memset (& fx_scratch, 0, sizeof (struct i387_fxsave_struct));
    asm volatile ("fxsave %0"
        :
        : "m" (fx_scratch)
    ) mask = fx_scratch.mxcsr_mask;
    if (mask == 0)
        mask = 0x0000ffbf;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="63" endline="80">
{
    if (!HAVE_HWFP) {
        xstate_size = sizeof (struct i387_soft_struct);
        return;
    }
    if (cpu_has_xsave) {
        xsave_cntxt_init ();
        return;
    }
    if (cpu_has_fxsr)
        xstate_size = sizeof (struct i387_fxsave_struct);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="64" endline="67">
{
    xstate_size = sizeof (struct i387_soft_struct);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="69" endline="72">
{
    xsave_cntxt_init ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="120" endline="166">
{
    if (tsk_used_math (tsk)) {
        if (HAVE_HWFP && tsk == current)
            unlazy_fpu (tsk);
        return 0;
    }
    if (!tsk->thread.xstate) {
        tsk->thread.xstate = kmem_cache_alloc (task_xstate_cachep, GFP_KERNEL);
        if (!tsk->thread.xstate)
            return -ENOMEM;
    }
    if (cpu_has_fxsr) {
        struct i387_fxsave_struct *fx = &tsk->thread.xstate->fxsave;
        memset (fx, 0, xstate_size);
        fx->cwd = 0x37f;
        if (cpu_has_xmm)
            fx->mxcsr = MXCSR_DEFAULT;
    }
    else {
        struct i387_fsave_struct *fp = &tsk->thread.xstate->fsave;
        memset (fp, 0, xstate_size);
        fp->cwd = 0xffff037fu;
        fp->swd = 0xffff0000u;
        fp->twd = 0xffffffffu;
        fp->fos = 0xffff0000u;
    }
    set_stopped_child_used_math (tsk);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="121" endline="125">
{
    if (HAVE_HWFP && tsk == current)
        unlazy_fpu (tsk);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="130" endline="135">
{
    tsk->thread.xstate = kmem_cache_alloc (task_xstate_cachep, GFP_KERNEL);
    if (!tsk->thread.xstate)
        return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="146" endline="153">
{
    struct i387_fxsave_struct *fx = &tsk->thread.xstate->fxsave;
    memset (fx, 0, xstate_size);
    fx->cwd = 0x37f;
    if (cpu_has_xmm)
        fx->mxcsr = MXCSR_DEFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="153" endline="160">
{
    struct i387_fsave_struct *fp = &tsk->thread.xstate->fsave;
    memset (fp, 0, xstate_size);
    fp->cwd = 0xffff037fu;
    fp->swd = 0xffff0000u;
    fp->twd = 0xffffffffu;
    fp->fos = 0xffff0000u;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="174" endline="176">
{
    return tsk_used_math (target) ? regset->n : 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="179" endline="181">
{
    return (cpu_has_fxsr && tsk_used_math (target)) ? regset->n : 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="186" endline="198">
{
    int ret;
    if (!cpu_has_fxsr)
        return -ENODEV;
    ret = init_fpu (target);
    if (ret)
        return ret;
    return user_regset_copyout (&pos, &count, &kbuf, &ubuf, &target->thread.xstate->fxsave, 0, -1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="203" endline="229">
{
    int ret;
    if (!cpu_has_fxsr)
        return -ENODEV;
    ret = init_fpu (target);
    if (ret)
        return ret;
    ret = user_regset_copyin (&pos, &count, &kbuf, &ubuf, &target->thread.xstate->fxsave, 0, -1);
    target->thread.xstate->fxsave.mxcsr &= mxcsr_feature_mask;
    if (cpu_has_xsave)
        target->thread.xstate->xsave.xsave_hdr.xstate_bv |= XSTATE_FPSSE;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="234" endline="258">
{
    int ret;
    if (!cpu_has_xsave)
        return -ENODEV;
    ret = init_fpu (target);
    if (ret)
        return ret;
    memcpy (& target -> thread.xstate -> fxsave.sw_reserved, xstate_fx_sw_bytes, sizeof (xstate_fx_sw_bytes));
    ret = user_regset_copyout (&pos, &count, &kbuf, &ubuf, &target->thread.xstate->xsave, 0, -1);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/i387.c.ifdefed" startline="263" endline="291">
{
    int ret;
    struct xsave_hdr_struct *xsave_hdr;
    if (!cpu_has_xsave)
        return -ENODEV;
    ret = init_fpu (target);
    if (ret)
        return ret;
    ret = user_regset_copyin (&pos, &count, &kbuf, &ubuf, &target->thread.xstate->xsave, 0, -1);
    target->thread.xstate->fxsave.mxcsr &= mxcsr_feature_mask;
    xsave_hdr = &target->thread.xstate->xsave.xsave_hdr;
    xsave_hdr->xstate_bv &= pcntxt_mask;
    xsave_hdr->reserved1[0] = xsave_hdr->reserved1[1] = 0;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="76" endline="89">
{
    struct cpuinfo_x86 *c = &cpu_data (cpu);
    u32 dummy;
    memset (csig, 0, sizeof (* csig));
    if (c->x86_vendor != X86_VENDOR_AMD || c->x86 < 0x10) {
        pr_warning ("microcode: CPU%d: AMD CPU family 0x%x not " "supported\n", cpu, c -> x86);
        return -1;
    }
    rdmsr (MSR_AMD64_PATCH_LEVEL, csig -> rev, dummy);
    pr_info ("CPU%d: patch_level=0x%x\n", cpu, csig -> rev);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="81" endline="85">
{
    pr_warning ("microcode: CPU%d: AMD CPU family 0x%x not " "supported\n", cpu, c -> x86);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="92" endline="126">
{
    struct microcode_header_amd *mc_header = mc;
    unsigned int current_cpu_id;
    u16 equiv_cpu_id = 0;
    unsigned int i = 0;
    BUG_ON (equiv_cpu_table == NULL);
    current_cpu_id = cpuid_eax (0x00000001);
    while (equiv_cpu_table[i].installed_cpu != 0) {
        if (current_cpu_id == equiv_cpu_table[i].installed_cpu) {
            equiv_cpu_id = equiv_cpu_table[i].equiv_cpu;
            break;
        }
        i++;
    }
    if (!equiv_cpu_id)
        return 0;
    if (mc_header->processor_rev_id != equiv_cpu_id)
        return 0;
    if (mc_header->nb_dev_id || mc_header->sb_dev_id) {
        pr_err ("CPU%d: loading of chipset specific code not yet supported\n", cpu);
        return 0;
    }
    if (mc_header->patch_id <= rev)
        return 0;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="101" endline="107">
{
    if (current_cpu_id == equiv_cpu_table[i].installed_cpu) {
        equiv_cpu_id = equiv_cpu_table[i].equiv_cpu;
        break;
    }
    i++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="102" endline="105">
{
    equiv_cpu_id = equiv_cpu_table[i].equiv_cpu;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="116" endline="120">
{
    pr_err ("CPU%d: loading of chipset specific code not yet supported\n", cpu);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="129" endline="156">
{
    u32 rev, dummy;
    int cpu_num = raw_smp_processor_id ();
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu_num;
    struct microcode_amd *mc_amd = uci->mc;
    BUG_ON (cpu_num != cpu);
    if (mc_amd == NULL)
        return 0;
    wrmsrl (MSR_AMD64_PATCH_LOADER, (u64) (long) & mc_amd -> hdr.data_code);
    rdmsr (MSR_AMD64_PATCH_LEVEL, rev, dummy);
    if (rev != mc_amd->hdr.patch_id) {
        pr_err ("CPU%d: update failed (for patch_level=0x%x)\n", cpu, mc_amd -> hdr.patch_id);
        return -1;
    }
    pr_info ("CPU%d: updated (new patch_level=0x%x)\n", cpu, rev);
    uci->cpu_sig.rev = rev;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="146" endline="150">
{
    pr_err ("CPU%d: update failed (for patch_level=0x%x)\n", cpu, mc_amd -> hdr.patch_id);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="159" endline="162">
{
    memcpy (to, from, n);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="166" endline="197">
{
    unsigned int total_size;
    u8 section_hdr [UCODE_CONTAINER_SECTION_HDR];
    void *mc;
    if (get_ucode_data (section_hdr, buf, UCODE_CONTAINER_SECTION_HDR))
        return NULL;
    if (section_hdr[0] != UCODE_UCODE_TYPE) {
        pr_err ("error: invalid type field in container file section header\n");
        return NULL;
    }
    total_size = (unsigned long) (section_hdr[4] + (section_hdr[5] << 8));
    if (total_size > size || total_size > UCODE_MAX_SIZE) {
        pr_err ("error: size mismatch\n");
        return NULL;
    }
    mc = vmalloc (UCODE_MAX_SIZE);
    if (mc) {
        memset (mc, 0, UCODE_MAX_SIZE);
        if (get_ucode_data (mc, buf +UCODE_CONTAINER_SECTION_HDR, total_size)) {
            vfree (mc);
            mc = NULL;
        }
        else
            *mc_size = total_size + UCODE_CONTAINER_SECTION_HDR;
    }
    return mc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="174" endline="177">
{
    pr_err ("error: invalid type field in container file section header\n");
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="181" endline="184">
{
    pr_err ("error: size mismatch\n");
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="187" endline="195">
{
    memset (mc, 0, UCODE_MAX_SIZE);
    if (get_ucode_data (mc, buf +UCODE_CONTAINER_SECTION_HDR, total_size)) {
        vfree (mc);
        mc = NULL;
    }
    else
        *mc_size = total_size + UCODE_CONTAINER_SECTION_HDR;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="190" endline="193">
{
    vfree (mc);
    mc = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="200" endline="228">
{
    u8 *container_hdr [UCODE_CONTAINER_HEADER_SIZE];
    unsigned int *buf_pos = (unsigned int *) container_hdr;
    unsigned long size;
    if (get_ucode_data (&container_hdr, buf, UCODE_CONTAINER_HEADER_SIZE))
        return 0;
    size = buf_pos[2];
    if (buf_pos[1] != UCODE_EQUIV_CPU_TABLE_TYPE || !size) {
        pr_err ("error: invalid type field in container file section header\n");
        return 0;
    }
    equiv_cpu_table = (struct equiv_cpu_entry *) vmalloc (size);
    if (!equiv_cpu_table) {
        pr_err ("failed to allocate equivalent CPU table\n");
        return 0;
    }
    buf += UCODE_CONTAINER_HEADER_SIZE;
    if (get_ucode_data (equiv_cpu_table, buf, size)) {
        vfree (equiv_cpu_table);
        return 0;
    }
    return size + UCODE_CONTAINER_HEADER_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="210" endline="213">
{
    pr_err ("error: invalid type field in container file section header\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="216" endline="219">
{
    pr_err ("failed to allocate equivalent CPU table\n");
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="222" endline="225">
{
    vfree (equiv_cpu_table);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="231" endline="234">
{
    vfree (equiv_cpu_table);
    equiv_cpu_table = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="238" endline="293">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
    const u8 *ucode_ptr = data;
    void *new_mc = NULL;
    void *mc;
    int new_rev = uci->cpu_sig.rev;
    unsigned int leftover;
    unsigned long offset;
    enum ucode_state state = UCODE_OK;
    offset = install_equiv_cpu_table (ucode_ptr);
    if (!offset) {
        pr_err ("failed to create equivalent cpu table\n");
        return UCODE_ERROR;
    }
    ucode_ptr += offset;
    leftover = size - offset;
    while (leftover) {
        unsigned int uninitialized_var (mc_size);
        struct microcode_header_amd *mc_header;
        mc = get_next_ucode (ucode_ptr, leftover, &mc_size);
        if (!mc)
            break;
        mc_header = (struct microcode_header_amd *) mc;
        if (get_matching_microcode (cpu, mc, new_rev)) {
            vfree (new_mc);
            new_rev = mc_header->patch_id;
            new_mc = mc;
        }
        else
            vfree (mc);
        ucode_ptr += mc_size;
        leftover -= mc_size;
    }
    if (new_mc) {
        if (!leftover) {
            vfree (uci -> mc);
            uci->mc = new_mc;
            pr_debug ("CPU%d found a matching microcode update with version 0x%x (current=0x%x)\n", cpu, new_rev, uci -> cpu_sig.rev);
        }
        else {
            vfree (new_mc);
            state = UCODE_ERROR;
        }
    }
    else
        state = UCODE_NFOUND;
    free_equiv_cpu_table ();
    return state;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="249" endline="252">
{
    pr_err ("failed to create equivalent cpu table\n");
    return UCODE_ERROR;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="257" endline="275">
{
    unsigned int uninitialized_var (mc_size);
    struct microcode_header_amd *mc_header;
    mc = get_next_ucode (ucode_ptr, leftover, &mc_size);
    if (!mc)
        break;
    mc_header = (struct microcode_header_amd *) mc;
    if (get_matching_microcode (cpu, mc, new_rev)) {
        vfree (new_mc);
        new_rev = mc_header->patch_id;
        new_mc = mc;
    }
    else
        vfree (mc);
    ucode_ptr += mc_size;
    leftover -= mc_size;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="266" endline="270">
{
    vfree (new_mc);
    new_rev = mc_header->patch_id;
    new_mc = mc;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="277" endline="287">
{
    if (!leftover) {
        vfree (uci -> mc);
        uci->mc = new_mc;
        pr_debug ("CPU%d found a matching microcode update with version 0x%x (current=0x%x)\n", cpu, new_rev, uci -> cpu_sig.rev);
    }
    else {
        vfree (new_mc);
        state = UCODE_ERROR;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="278" endline="283">
{
    vfree (uci -> mc);
    uci->mc = new_mc;
    pr_debug ("CPU%d found a matching microcode update with version 0x%x (current=0x%x)\n", cpu, new_rev, uci -> cpu_sig.rev);
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="283" endline="286">
{
    vfree (new_mc);
    state = UCODE_ERROR;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="296" endline="317">
{
    const char *fw_name = "amd-ucode/microcode_amd.bin";
    const struct firmware *firmware;
    enum ucode_state ret;
    if (request_firmware (&firmware, fw_name, device)) {
        printk (KERN_ERR "microcode: failed to load file %s\n", fw_name);
        return UCODE_NFOUND;
    }
    if (*(u32*) firmware->data != UCODE_MAGIC) {
        pr_err ("invalid UCODE_MAGIC (0x%08x)\n", * (u32 *) firmware -> data);
        return UCODE_ERROR;
    }
    ret = generic_load_microcode (cpu, firmware->data, firmware->size);
    release_firmware (firmware);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="301" endline="304">
{
    printk (KERN_ERR "microcode: failed to load file %s\n", fw_name);
    return UCODE_NFOUND;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="306" endline="310">
{
    pr_err ("invalid UCODE_MAGIC (0x%08x)\n", * (u32 *) firmware -> data);
    return UCODE_ERROR;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="321" endline="324">
{
    pr_info ("AMD microcode update via /dev/cpu/microcode not supported\n");
    return UCODE_ERROR;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="327" endline="332">
{
    struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
    vfree (uci -> mc);
    uci->mc = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/microcode_amd.c.ifdefed" startline="343" endline="345">
{
    return &microcode_amd_ops;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsmp_64.c.ifdefed" startline="113" endline="114">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsmp_64.c.ifdefed" startline="145" endline="146">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsmp_64.c.ifdefed" startline="148" endline="150">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/kernel/vsmp_64.c.ifdefed" startline="153" endline="160">
{
    detect_vsmp_box ();
    if (!is_vsmp_box ())
        return;
    set_vsmp_pv_ops ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="15" endline="63">
{
    return ACCESS_ONCE (*ptep);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="72" endline="99">
{
    unsigned long mask;
    pte_t *ptep;
    mask = _PAGE_PRESENT | _PAGE_USER;
    if (write)
        mask |= _PAGE_RW;
    ptep = pte_offset_map (&pmd, addr);
    do {
        pte_t pte = gup_get_pte (ptep);
        struct page *page;
        if ((pte_flags (pte) & (mask | _PAGE_SPECIAL)) != mask) {
            pte_unmap (ptep);
            return 0;
        }
        VM_BUG_ON (! pfn_valid (pte_pfn (pte)));
        page = pte_page (pte);
        get_page (page);
        pages[*nr] = page;
        (*nr)++;
    }
    while (ptep++, addr += PAGE_SIZE, addr != end);
    pte_unmap (ptep - 1);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="81" endline="95">
{
    pte_t pte = gup_get_pte (ptep);
    struct page *page;
    if ((pte_flags (pte) & (mask | _PAGE_SPECIAL)) != mask) {
        pte_unmap (ptep);
        return 0;
    }
    VM_BUG_ON (! pfn_valid (pte_pfn (pte)));
    page = pte_page (pte);
    get_page (page);
    pages[*nr] = page;
    (*nr)++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="85" endline="88">
{
    pte_unmap (ptep);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="102" endline="106">
{
    VM_BUG_ON (page != compound_head (page));
    VM_BUG_ON (page_count (page) == 0);
    atomic_add (nr, & page -> _count);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="110" endline="138">
{
    unsigned long mask;
    pte_t pte = *(pte_t*) &pmd;
    struct page *head, *page;
    int refs;
    mask = _PAGE_PRESENT | _PAGE_USER;
    if (write)
        mask |= _PAGE_RW;
    if ((pte_flags (pte) & mask) != mask)
        return 0;
    VM_BUG_ON (pte_flags (pte) & _PAGE_SPECIAL);
    VM_BUG_ON (! pfn_valid (pte_pfn (pte)));
    refs = 0;
    head = pte_page (pte);
    page = head + ((addr & ~PMD_MASK) >> PAGE_SHIFT);
    do {
        VM_BUG_ON (compound_head (page) != head);
        pages[*nr] = page;
        (*nr)++;
        page++;
        refs++;
    }
    while (addr += PAGE_SIZE, addr != end);
    get_head_page_multiple (head, refs);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="128" endline="134">
{
    VM_BUG_ON (compound_head (page) != head);
    pages[*nr] = page;
    (*nr)++;
    page++;
    refs++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="142" endline="163">
{
    unsigned long next;
    pmd_t *pmdp;
    pmdp = pmd_offset (&pud, addr);
    do {
        pmd_t pmd = *pmdp;
        next = pmd_addr_end (addr, end);
        if (pmd_none (pmd))
            return 0;
        if (unlikely (pmd_large (pmd))) {
            if (!gup_huge_pmd (pmd, addr, next, write, pages, nr))
                return 0;
        }
        else {
            if (!gup_pte_range (pmd, addr, next, write, pages, nr))
                return 0;
        }
    }
    while (pmdp++, addr = next, addr != end);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="147" endline="160">
{
    pmd_t pmd = *pmdp;
    next = pmd_addr_end (addr, end);
    if (pmd_none (pmd))
        return 0;
    if (unlikely (pmd_large (pmd))) {
        if (!gup_huge_pmd (pmd, addr, next, write, pages, nr))
            return 0;
    }
    else {
        if (!gup_pte_range (pmd, addr, next, write, pages, nr))
            return 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="153" endline="156">
{
    if (!gup_huge_pmd (pmd, addr, next, write, pages, nr))
        return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="156" endline="159">
{
    if (!gup_pte_range (pmd, addr, next, write, pages, nr))
        return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="167" endline="195">
{
    unsigned long mask;
    pte_t pte = *(pte_t*) &pud;
    struct page *head, *page;
    int refs;
    mask = _PAGE_PRESENT | _PAGE_USER;
    if (write)
        mask |= _PAGE_RW;
    if ((pte_flags (pte) & mask) != mask)
        return 0;
    VM_BUG_ON (pte_flags (pte) & _PAGE_SPECIAL);
    VM_BUG_ON (! pfn_valid (pte_pfn (pte)));
    refs = 0;
    head = pte_page (pte);
    page = head + ((addr & ~PUD_MASK) >> PAGE_SHIFT);
    do {
        VM_BUG_ON (compound_head (page) != head);
        pages[*nr] = page;
        (*nr)++;
        page++;
        refs++;
    }
    while (addr += PAGE_SIZE, addr != end);
    get_head_page_multiple (head, refs);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="185" endline="191">
{
    VM_BUG_ON (compound_head (page) != head);
    pages[*nr] = page;
    (*nr)++;
    page++;
    refs++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="199" endline="220">
{
    unsigned long next;
    pud_t *pudp;
    pudp = pud_offset (&pgd, addr);
    do {
        pud_t pud = *pudp;
        next = pud_addr_end (addr, end);
        if (pud_none (pud))
            return 0;
        if (unlikely (pud_large (pud))) {
            if (!gup_huge_pud (pud, addr, next, write, pages, nr))
                return 0;
        }
        else {
            if (!gup_pmd_range (pud, addr, next, write, pages, nr))
                return 0;
        }
    }
    while (pudp++, addr = next, addr != end);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="204" endline="217">
{
    pud_t pud = *pudp;
    next = pud_addr_end (addr, end);
    if (pud_none (pud))
        return 0;
    if (unlikely (pud_large (pud))) {
        if (!gup_huge_pud (pud, addr, next, write, pages, nr))
            return 0;
    }
    else {
        if (!gup_pmd_range (pud, addr, next, write, pages, nr))
            return 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="210" endline="213">
{
    if (!gup_huge_pud (pud, addr, next, write, pages, nr))
        return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="213" endline="216">
{
    if (!gup_pmd_range (pud, addr, next, write, pages, nr))
        return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="228" endline="276">
{
    struct mm_struct *mm = current->mm;
    unsigned long addr, len, end;
    unsigned long next;
    unsigned long flags;
    pgd_t *pgdp;
    int nr = 0;
    start &= PAGE_MASK;
    addr = start;
    len = (unsigned long) nr_pages << PAGE_SHIFT;
    end = start + len;
    if (unlikely (!access_ok (write ? VERIFY_WRITE : VERIFY_READ, (void __user *) start, len)))
        return 0;
    local_irq_save (flags);
    pgdp = pgd_offset (mm, addr);
    do {
        pgd_t pgd = *pgdp;
        next = pgd_addr_end (addr, end);
        if (pgd_none (pgd))
            break;
        if (!gup_pud_range (pgd, addr, next, write, pages, &nr))
            break;
    }
    while (pgdp++, addr = next, addr != end);
    local_irq_restore (flags);
    return nr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="264" endline="272">
{
    pgd_t pgd = *pgdp;
    next = pgd_addr_end (addr, end);
    if (pgd_none (pgd))
        break;
    if (!gup_pud_range (pgd, addr, next, write, pages, &nr))
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="296" endline="375">
{
    struct mm_struct *mm = current->mm;
    unsigned long addr, len, end;
    unsigned long next;
    pgd_t *pgdp;
    int nr = 0;
    start &= PAGE_MASK;
    addr = start;
    len = (unsigned long) nr_pages << PAGE_SHIFT;
    end = start + len;
    if (end < start)
        goto slow_irqon;
    local_irq_disable ();
    pgdp = pgd_offset (mm, addr);
    do {
        pgd_t pgd = *pgdp;
        next = pgd_addr_end (addr, end);
        if (pgd_none (pgd))
            goto slow;
        if (!gup_pud_range (pgd, addr, next, write, pages, &nr))
            goto slow;
    }
    while (pgdp++, addr = next, addr != end);
    local_irq_enable ();
    VM_BUG_ON (nr != (end - start) >> PAGE_SHIFT);
    return nr;
    {
        int ret;
    slow :
        local_irq_enable ();
    slow_irqon :
        start += nr << PAGE_SHIFT;
        pages += nr;
        down_read (& mm -> mmap_sem);
        ret = get_user_pages (current, mm, start, (end - start) >> PAGE_SHIFT, write, 0, pages, NULL);
        up_read (& mm -> mmap_sem);
        if (nr > 0) {
            if (ret < 0)
                ret = nr;
            else
                ret += nr;
        }
        return ret;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="336" endline="344">
{
    pgd_t pgd = *pgdp;
    next = pgd_addr_end (addr, end);
    if (pgd_none (pgd))
        goto slow;
    if (!gup_pud_range (pgd, addr, next, write, pages, &nr))
        goto slow;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="350" endline="374">
{
    int ret;
slow :
    local_irq_enable ();
slow_irqon :
    start += nr << PAGE_SHIFT;
    pages += nr;
    down_read (& mm -> mmap_sem);
    ret = get_user_pages (current, mm, start, (end - start) >> PAGE_SHIFT, write, 0, pages, NULL);
    up_read (& mm -> mmap_sem);
    if (nr > 0) {
        if (ret < 0)
            ret = nr;
        else
            ret += nr;
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/gup.c.ifdefed" startline="366" endline="371">
{
    if (ret < 0)
        ret = nr;
    else
        ret += nr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="60" endline="66">
{
    if (percpu_read (cpu_tlbstate.state) == TLBSTATE_OK)
        BUG ();
    cpumask_clear_cpu (cpu, mm_cpumask (percpu_read (cpu_tlbstate.active_mm)));
    load_cr3 (swapper_pg_dir);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="128" endline="167">
{
    unsigned int cpu;
    unsigned int sender;
    union smp_flush_state *f;
    cpu = smp_processor_id ();
    sender = ~regs->orig_ax - INVALIDATE_TLB_VECTOR_START;
    f = &flush_state[sender];
    if (!cpumask_test_cpu (cpu, to_cpumask (f->flush_cpumask)))
        goto out;
    if (f->flush_mm == percpu_read (cpu_tlbstate.active_mm)) {
        if (percpu_read (cpu_tlbstate.state) == TLBSTATE_OK) {
            if (f->flush_va == TLB_FLUSH_ALL)
                local_flush_tlb ();
            else
                __flush_tlb_one (f->flush_va);
        }
        else
            leave_mm (cpu);
    }
out :
    ack_APIC_irq ();
    smp_mb__before_clear_bit ();
    cpumask_clear_cpu (cpu, to_cpumask (f -> flush_cpumask));
    smp_mb__after_clear_bit ();
    inc_irq_stat (irq_tlb_count);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="152" endline="160">
{
    if (percpu_read (cpu_tlbstate.state) == TLBSTATE_OK) {
        if (f->flush_va == TLB_FLUSH_ALL)
            local_flush_tlb ();
        else
            __flush_tlb_one (f->flush_va);
    }
    else
        leave_mm (cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="153" endline="158">
{
    if (f->flush_va == TLB_FLUSH_ALL)
        local_flush_tlb ();
    else
        __flush_tlb_one (f->flush_va);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="171" endline="203">
{
    unsigned int sender;
    union smp_flush_state *f;
    sender = smp_processor_id () % NUM_INVALIDATE_TLB_VECTORS;
    f = &flush_state[sender];
    raw_spin_lock (& f -> tlbstate_lock);
    f->flush_mm = mm;
    f->flush_va = va;
    if (cpumask_andnot (to_cpumask (f->flush_cpumask), cpumask, cpumask_of (smp_processor_id ()))) {
        apic->send_IPI_mask (to_cpumask (f->flush_cpumask), INVALIDATE_TLB_VECTOR_START +sender);
        while (!cpumask_empty (to_cpumask (f->flush_cpumask)))
            cpu_relax ();
    }
    f->flush_mm = NULL;
    f->flush_va = 0;
    raw_spin_unlock (& f -> tlbstate_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="188" endline="198">
{
    apic->send_IPI_mask (to_cpumask (f->flush_cpumask), INVALIDATE_TLB_VECTOR_START +sender);
    while (!cpumask_empty (to_cpumask (f->flush_cpumask)))
        cpu_relax ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="207" endline="219">
{
    if (is_uv_system ()) {
        unsigned int cpu;
        cpu = get_cpu ();
        cpumask = uv_flush_tlb_others (cpumask, mm, va, cpu);
        if (cpumask)
            flush_tlb_others_ipi (cpumask, mm, va);
        put_cpu ();
        return;
    }
    flush_tlb_others_ipi (cpumask, mm, va);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="208" endline="217">
{
    unsigned int cpu;
    cpu = get_cpu ();
    cpumask = uv_flush_tlb_others (cpumask, mm, va, cpu);
    if (cpumask)
        flush_tlb_others_ipi (cpumask, mm, va);
    put_cpu ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="222" endline="229">
{
    int i;
    for (i = 0; i < ARRAY_SIZE (flush_state); i++)
        raw_spin_lock_init (&flush_state[i].tlbstate_lock);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="233" endline="242">
{
    struct mm_struct *mm = current->mm;
    preempt_disable ();
    local_flush_tlb ();
    if (cpumask_any_but (mm_cpumask (mm), smp_processor_id ()) < nr_cpu_ids)
        flush_tlb_others (mm_cpumask (mm), mm, TLB_FLUSH_ALL);
    preempt_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="245" endline="258">
{
    preempt_disable ();
    if (current->active_mm == mm) {
        if (current->mm)
            local_flush_tlb ();
        else
            leave_mm (smp_processor_id ());
    }
    if (cpumask_any_but (mm_cpumask (mm), smp_processor_id ()) < nr_cpu_ids)
        flush_tlb_others (mm_cpumask (mm), mm, TLB_FLUSH_ALL);
    preempt_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="248" endline="253">
{
    if (current->mm)
        local_flush_tlb ();
    else
        leave_mm (smp_processor_id ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="261" endline="277">
{
    struct mm_struct *mm = vma->vm_mm;
    preempt_disable ();
    if (current->active_mm == mm) {
        if (current->mm)
            __flush_tlb_one (va);
        else
            leave_mm (smp_processor_id ());
    }
    if (cpumask_any_but (mm_cpumask (mm), smp_processor_id ()) < nr_cpu_ids)
        flush_tlb_others (mm_cpumask (mm), mm, va);
    preempt_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="266" endline="271">
{
    if (current->mm)
        __flush_tlb_one (va);
    else
        leave_mm (smp_processor_id ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="280" endline="286">
{
    unsigned long cpu = smp_processor_id ();
    __flush_tlb_all ();
    if (percpu_read (cpu_tlbstate.state) == TLBSTATE_LAZY)
        leave_mm (cpu);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/tlb.c.ifdefed" startline="289" endline="291">
{
    on_each_cpu (do_flush_tlb_all, NULL, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/extable.c.ifdefed" startline="7" endline="37">
{
    const struct exception_table_entry *fixup;
    fixup = search_exception_tables (regs->ip);
    if (fixup) {
        if (fixup->fixup < 16) {
            current_thread_info ()->uaccess_err = -EFAULT;
            regs->ip += fixup->fixup;
            return 1;
        }
        regs->ip = fixup->fixup;
        return 1;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/extable.c.ifdefed" startline="25" endline="34">
{
    if (fixup->fixup < 16) {
        current_thread_info ()->uaccess_err = -EFAULT;
        regs->ip += fixup->fixup;
        return 1;
    }
    regs->ip = fixup->fixup;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/extable.c.ifdefed" startline="27" endline="31">
{
    current_thread_info ()->uaccess_err = -EFAULT;
    regs->ip += fixup->fixup;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="40" endline="42">
{
    return acpi_map_pxm_to_node (pxm);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="45" endline="57">
{
    int i;
    for (i = 0; i < num_node_memblks; i++) {
        struct bootnode *nd = &node_memblk_range[i];
        if (nd->start == nd->end)
            continue;
        if (nd->end > start && nd->start < end)
            return memblk_nodeid[i];
        if (nd->end == end && nd->start == start)
            return memblk_nodeid[i];
    }
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="47" endline="55">
{
    struct bootnode *nd = &node_memblk_range[i];
    if (nd->start == nd->end)
        continue;
    if (nd->end > start && nd->start < end)
        return memblk_nodeid[i];
    if (nd->end == end && nd->start == start)
        return memblk_nodeid[i];
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="60" endline="73">
{
    struct bootnode *nd = &nodes[i];
    if (nd->start < start) {
        nd->start = start;
        if (nd->end < nd->start)
            nd->start = nd->end;
    }
    if (nd->end > end) {
        nd->end = end;
        if (nd->start > nd->end)
            nd->start = nd->end;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="63" endline="67">
{
    nd->start = start;
    if (nd->end < nd->start)
        nd->start = nd->end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="68" endline="72">
{
    nd->end = end;
    if (nd->start > nd->end)
        nd->start = nd->end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="76" endline="87">
{
    int i;
    printk (KERN_ERR "SRAT: SRAT not used.\n");
    acpi_numa = -1;
    for (i = 0; i < MAX_LOCAL_APIC; i++)
        apicid_to_node[i] = NUMA_NO_NODE;
    for (i = 0; i < MAX_NUMNODES; i++) {
        nodes[i].start = nodes[i].end = 0;
        nodes_add[i].start = nodes_add[i].end = 0;
    }
    remove_all_active_ranges ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="82" endline="85">
{
    nodes[i].start = nodes[i].end = 0;
    nodes_add[i].start = nodes_add[i].end = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="90" endline="92">
{
    return numa_off || acpi_numa < 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="96" endline="110">
{
    unsigned length;
    unsigned long phys;
    length = slit->header.length;
    phys = find_e820_area (0, max_pfn_mapped << PAGE_SHIFT, length, PAGE_SIZE);
    if (phys == -1L)
        panic (" Can not save slit!\n");
    acpi_slit = __va (phys);
    memcpy (acpi_slit, slit, length);
    reserve_early (phys, phys + length, "ACPI SLIT");
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="115" endline="141">
{
    int pxm, node;
    int apic_id;
    if (srat_disabled ())
        return;
    if (pa->header.length < sizeof (struct acpi_srat_x2apic_cpu_affinity)) {
        bad_srat ();
        return;
    }
    if ((pa->flags & ACPI_SRAT_CPU_ENABLED) == 0)
        return;
    pxm = pa->proximity_domain;
    node = setup_node (pxm);
    if (node < 0) {
        printk (KERN_ERR "SRAT: Too many proximity domains %x\n", pxm);
        bad_srat ();
        return;
    }
    apic_id = pa->apic_id;
    apicid_to_node[apic_id] = node;
    node_set (node, cpu_nodes_parsed);
    acpi_numa = 1;
    printk (KERN_INFO "SRAT: PXM %u -> APIC 0x%04x -> Node %u\n", pxm, apic_id, node);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="121" endline="124">
{
    bad_srat ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="129" endline="133">
{
    printk (KERN_ERR "SRAT: Too many proximity domains %x\n", pxm);
    bad_srat ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="146" endline="175">
{
    int pxm, node;
    int apic_id;
    if (srat_disabled ())
        return;
    if (pa->header.length != sizeof (struct acpi_srat_cpu_affinity)) {
        bad_srat ();
        return;
    }
    if ((pa->flags & ACPI_SRAT_CPU_ENABLED) == 0)
        return;
    pxm = pa->proximity_domain_lo;
    node = setup_node (pxm);
    if (node < 0) {
        printk (KERN_ERR "SRAT: Too many proximity domains %x\n", pxm);
        bad_srat ();
        return;
    }
    if (get_uv_system_type () >= UV_X2APIC)
        apic_id = (pa->apic_id << 8) | pa->local_sapic_eid;
    else
        apic_id = pa->apic_id;
    apicid_to_node[apic_id] = node;
    node_set (node, cpu_nodes_parsed);
    acpi_numa = 1;
    printk (KERN_INFO "SRAT: PXM %u -> APIC 0x%02x -> Node %u\n", pxm, apic_id, node);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="152" endline="155">
{
    bad_srat ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="160" endline="164">
{
    printk (KERN_ERR "SRAT: Too many proximity domains %x\n", pxm);
    bad_srat ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="180" endline="180">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="188" endline="237">
{
    unsigned long s_pfn = start >> PAGE_SHIFT;
    unsigned long e_pfn = end >> PAGE_SHIFT;
    int changed = 0;
    struct bootnode *nd = &nodes_add[node];
    if ((signed long) (end - start) < NODE_MIN_SIZE) {
        printk (KERN_ERR "SRAT: Hotplug area too small\n");
        return;
    }
    if (absent_pages_in_range (s_pfn, e_pfn) != e_pfn - s_pfn) {
        printk (KERN_ERR "SRAT: Hotplug area %lu -> %lu has existing memory\n", s_pfn, e_pfn);
        return;
    }
    if (nd->start == nd->end) {
        nd->start = start;
        nd->end = end;
        changed = 1;
    }
    else {
        if (nd->start == end) {
            nd->start = start;
            changed = 1;
        }
        if (nd->end == start) {
            nd->end = end;
            changed = 1;
        }
        if (!changed)
            printk (KERN_ERR "SRAT: Hotplug zone not continuous. Partly ignored\n");
    }
    if (changed) {
        node_set (node, cpu_nodes_parsed);
        printk (KERN_INFO "SRAT: hot plug zone found %Lx - %Lx\n", nd -> start, nd -> end);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="200" endline="203">
{
    printk (KERN_ERR "SRAT: Hotplug area too small\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="206" endline="211">
{
    printk (KERN_ERR "SRAT: Hotplug area %lu -> %lu has existing memory\n", s_pfn, e_pfn);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="215" endline="219">
{
    nd->start = start;
    nd->end = end;
    changed = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="219" endline="230">
{
    if (nd->start == end) {
        nd->start = start;
        changed = 1;
    }
    if (nd->end == start) {
        nd->end = end;
        changed = 1;
    }
    if (!changed)
        printk (KERN_ERR "SRAT: Hotplug zone not continuous. Partly ignored\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="220" endline="223">
{
    nd->start = start;
    changed = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="224" endline="227">
{
    nd->end = end;
    changed = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="232" endline="236">
{
    node_set (node, cpu_nodes_parsed);
    printk (KERN_INFO "SRAT: hot plug zone found %Lx - %Lx\n", nd -> start, nd -> end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="242" endline="308">
{
    struct bootnode *nd, oldnode;
    unsigned long start, end;
    int node, pxm;
    int i;
    if (srat_disabled ())
        return;
    if (ma->header.length != sizeof (struct acpi_srat_mem_affinity)) {
        bad_srat ();
        return;
    }
    if ((ma->flags & ACPI_SRAT_MEM_ENABLED) == 0)
        return;
    if ((ma->flags & ACPI_SRAT_MEM_HOT_PLUGGABLE) && !save_add_info ())
        return;
    start = ma->base_address;
    end = start + ma->length;
    pxm = ma->proximity_domain;
    node = setup_node (pxm);
    if (node < 0) {
        printk (KERN_ERR "SRAT: Too many proximity domains.\n");
        bad_srat ();
        return;
    }
    i = conflicting_memblks (start, end);
    if (i == node) {
        printk (KERN_WARNING "SRAT: Warning: PXM %d (%lx-%lx) overlaps with itself (%Lx-%Lx)\n", pxm, start, end, nodes [i].start, nodes [i].end);
    }
    else if (i >= 0) {
        printk (KERN_ERR "SRAT: PXM %d (%lx-%lx) overlaps with PXM %d (%Lx-%Lx)\n", pxm, start, end, node_to_pxm (i), nodes [i].start, nodes [i].end);
        bad_srat ();
        return;
    }
    nd = &nodes[node];
    oldnode = *nd;
    if (!node_test_and_set (node, nodes_parsed)) {
        nd->start = start;
        nd->end = end;
    }
    else {
        if (start < nd->start)
            nd->start = start;
        if (nd->end < end)
            nd->end = end;
    }
    printk (KERN_INFO "SRAT: Node %u PXM %u %lx-%lx\n", node, pxm, start, end);
    if (ma->flags & ACPI_SRAT_MEM_HOT_PLUGGABLE) {
        update_nodes_add (node, start, end);
        *nd = oldnode;
        if ((nd->start | nd->end) == 0)
            node_clear (node, nodes_parsed);
    }
    node_memblk_range[num_node_memblks].start = start;
    node_memblk_range[num_node_memblks].end = end;
    memblk_nodeid[num_node_memblks] = node;
    num_node_memblks++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="250" endline="253">
{
    bad_srat ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="263" endline="267">
{
    printk (KERN_ERR "SRAT: Too many proximity domains.\n");
    bad_srat ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="269" endline="273">
{
    printk (KERN_WARNING "SRAT: Warning: PXM %d (%lx-%lx) overlaps with itself (%Lx-%Lx)\n", pxm, start, end, nodes [i].start, nodes [i].end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="273" endline="280">
{
    printk (KERN_ERR "SRAT: PXM %d (%lx-%lx) overlaps with PXM %d (%Lx-%Lx)\n", pxm, start, end, node_to_pxm (i), nodes [i].start, nodes [i].end);
    bad_srat ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="283" endline="286">
{
    nd->start = start;
    nd->end = end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="286" endline="291">
{
    if (start < nd->start)
        nd->start = start;
    if (nd->end < end)
        nd->end = end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="296" endline="302">
{
    update_nodes_add (node, start, end);
    *nd = oldnode;
    if ((nd->start | nd->end) == 0)
        node_clear (node, nodes_parsed);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="313" endline="337">
{
    int i;
    unsigned long pxmram, e820ram;
    pxmram = 0;

    for_each_node_mask (i, nodes_parsed) {
        unsigned long s = nodes[i].start >> PAGE_SHIFT;
        unsigned long e = nodes[i].end >> PAGE_SHIFT;
        pxmram += e - s;
        pxmram -= __absent_pages_in_range (i, s, e);
        if ((long) pxmram < 0)
            pxmram = 0;
    }

    e820ram = max_pfn - (e820_hole_size (0, max_pfn << PAGE_SHIFT) >> PAGE_SHIFT);
    if ((long) (e820ram - pxmram) >= (1 << (20 - PAGE_SHIFT))) {
        printk (KERN_ERR "SRAT: PXMs only cover %luMB of your %luMB e820 RAM. Not used.\n", (pxmram << PAGE_SHIFT) >> 20, (e820ram << PAGE_SHIFT) >> 20);
        return 0;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="318" endline="325">
{
    unsigned long s = nodes[i].start >> PAGE_SHIFT;
    unsigned long e = nodes[i].end >> PAGE_SHIFT;
    pxmram += e - s;
    pxmram -= __absent_pages_in_range (i, s, e);
    if ((long) pxmram < 0)
        pxmram = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="329" endline="335">
{
    printk (KERN_ERR "SRAT: PXMs only cover %luMB of your %luMB e820 RAM. Not used.\n", (pxmram << PAGE_SHIFT) >> 20, (e820ram << PAGE_SHIFT) >> 20);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="339" endline="339">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="342" endline="352">
{
    int i;
    int ret = 0;

    for_each_node_mask (i, nodes_parsed) {
        physnodes[ret].start = nodes[i].start;
        physnodes[ret].end = nodes[i].end;
        ret++;
    }

    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="346" endline="350">
{
    physnodes[ret].start = nodes[i].start;
    physnodes[ret].end = nodes[i].end;
    ret++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="356" endline="407">
{
    int i;
    if (acpi_numa <= 0)
        return -1;
    for (i = 0; i < MAX_NUMNODES; i++)
        cutoff_node (i, start, end);
    memnode_shift = compute_hash_shift (node_memblk_range, num_node_memblks, memblk_nodeid);
    if (memnode_shift < 0) {
        printk (KERN_ERR "SRAT: No NUMA node hash function found. Contact maintainer\n");
        bad_srat ();
        return -1;
    }
    for_each_node_mask (i, nodes_parsed)
    e820_register_active_regions (i, nodes [i].start >> PAGE_SHIFT, nodes [i].end >> PAGE_SHIFT);
    sort_node_map ();
    if (!nodes_cover_memory (nodes)) {
        bad_srat ();
        return -1;
    }
    nodes_or (node_possible_map, nodes_parsed, cpu_nodes_parsed);
    for_each_node_mask (i, node_possible_map)
    setup_node_bootmem (i, nodes [i].start, nodes [i].end);
    for_each_node_mask (i, node_possible_map)
    if (!node_online (i))
        setup_node_bootmem (i, nodes[i].start, nodes[i].end);
    for (i = 0; i < nr_cpu_ids; i++) {
        int node = early_cpu_to_node (i);
        if (node == NUMA_NO_NODE)
            continue;
        if (!node_online (node))
            numa_clear_node (i);
    }
    numa_init_array ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="368" endline="373">
{
    printk (KERN_ERR "SRAT: No NUMA node hash function found. Contact maintainer\n");
    bad_srat ();
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="380" endline="383">
{
    bad_srat ();
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="397" endline="404">
{
    int node = early_cpu_to_node (i);
    if (node == NUMA_NO_NODE)
        continue;
    if (!node_online (node))
        numa_clear_node (i);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="484" endline="486">
{
    return a == b;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/srat_64.c.ifdefed" startline="490" endline="498">
{
    int index;
    if (!acpi_slit)
        return null_slit_node_compare (a, b) ? LOCAL_DISTANCE : REMOTE_DISTANCE;
    index = acpi_slit->locality_count * node_to_pxm (a);
    return acpi_slit->entry[index + node_to_pxm (b)];
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="50" endline="52">
{
    (void) reason;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="59" endline="62">
{
    debug_enable = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="83" endline="131">
{
    u64 pat;
    bool boot_cpu = !boot_pat_state;
    if (!pat_enabled)
        return;
    if (!cpu_has_pat) {
        if (!boot_pat_state) {
            pat_disable ("PAT not supported by CPU.");
            return;
        }
        else {
            printk (KERN_ERR "PAT enabled, " "but not supported by secondary CPU\n");
            BUG ();
        }
    }
    pat = PAT (0, WB) | PAT (1, WC) | PAT (2, UC_MINUS) | PAT (3, UC) | PAT (4, WB) | PAT (5, WC) | PAT (6, UC_MINUS) | PAT (7, UC);
    if (!boot_pat_state)
        rdmsrl (MSR_IA32_CR_PAT, boot_pat_state);
    wrmsrl (MSR_IA32_CR_PAT, pat);
    if (boot_cpu)
        printk (KERN_INFO "x86 PAT enabled: cpu %d, old 0x%Lx, new 0x%Lx\n", smp_processor_id (), boot_pat_state, pat);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="90" endline="104">
{
    if (!boot_pat_state) {
        pat_disable ("PAT not supported by CPU.");
        return;
    }
    else {
        printk (KERN_ERR "PAT enabled, " "but not supported by secondary CPU\n");
        BUG ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="91" endline="94">
{
    pat_disable ("PAT not supported by CPU.");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="94" endline="103">
{
    printk (KERN_ERR "PAT enabled, " "but not supported by secondary CPU\n");
    BUG ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="136" endline="144">
{
    switch (flags & _PAGE_CACHE_MASK) {
    case _PAGE_CACHE_UC :
        return "uncached";
    case _PAGE_CACHE_UC_MINUS :
        return "uncached-minus";
    case _PAGE_CACHE_WB :
        return "write-back";
    case _PAGE_CACHE_WC :
        return "write-combining";
    default :
        return "broken";
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="137" endline="143">
{
case _PAGE_CACHE_UC :
    return "uncached";
case _PAGE_CACHE_UC_MINUS :
    return "uncached-minus";
case _PAGE_CACHE_WB :
    return "write-back";
case _PAGE_CACHE_WC :
    return "write-combining";
default :
    return "broken";
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="175" endline="193">
{
    struct rb_node *node = root->rb_node;
    struct memtype *last_lower = NULL;
    while (node) {
        struct memtype *data = container_of (node, struct memtype, rb);
        if (data->start < start) {
            last_lower = data;
            node = node->rb_right;
        }
        else if (data->start > start) {
            node = node->rb_left;
        }
        else
            return data;
    }
    return last_lower;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="179" endline="189">
{
    struct memtype *data = container_of (node, struct memtype, rb);
    if (data->start < start) {
        last_lower = data;
        node = node->rb_right;
    }
    else if (data->start > start) {
        node = node->rb_left;
    }
    else
        return data;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="182" endline="185">
{
    last_lower = data;
    node = node->rb_right;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="185" endline="187">
{
    node = node->rb_left;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="196" endline="212">
{
    struct rb_node **new = &(root->rb_node);
    struct rb_node *parent = NULL;
    while (*new) {
        struct memtype *this = container_of (*new, struct memtype, rb);
        parent = *new;
        if (data->start <= this->start)
            new = &((*new)->rb_left);
        else if (data->start > this->start)
            new = &((*new)->rb_right);
    }
    rb_link_node (& data -> rb, parent, new);
    rb_insert_color (& data -> rb, root);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="200" endline="208">
{
    struct memtype *this = container_of (*new, struct memtype, rb);
    parent = *new;
    if (data->start <= this->start)
        new = &((*new)->rb_left);
    else if (data->start > this->start)
        new = &((*new)->rb_right);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="222" endline="238">
{
    if (req_type == _PAGE_CACHE_WB) {
        u8 mtrr_type;
        mtrr_type = mtrr_type_lookup (start, end);
        if (mtrr_type != MTRR_TYPE_WRBACK)
            return _PAGE_CACHE_UC_MINUS;
        return _PAGE_CACHE_WB;
    }
    return req_type;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="227" endline="235">
{
    u8 mtrr_type;
    mtrr_type = mtrr_type_lookup (start, end);
    if (mtrr_type != MTRR_TYPE_WRBACK)
        return _PAGE_CACHE_UC_MINUS;
    return _PAGE_CACHE_WB;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="242" endline="265">
{
    if (new->type != entry->type) {
        if (type) {
            new->type = entry->type;
            *type = entry->type;
        }
        else
            goto conflict;
    }
    list_for_each_entry_continue (entry, &memtype_list, nd) {
        if (new->end <= entry->start)
            break;
        else if (new->type != entry->type)
            goto conflict;
    }
    return 0;
conflict :
    printk (KERN_INFO "%s:%d conflicting memory types " "%Lx-%Lx %s<->%s\n", current->comm, current->pid, new->start, new->end, cattr_name (new->type), cattr_name (entry->type));
    return -EBUSY;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="243" endline="249">
{
    if (type) {
        new->type = entry->type;
        *type = entry->type;
    }
    else
        goto conflict;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="244" endline="247">
{
    new->type = entry->type;
    *type = entry->type;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="252" endline="257">
{
    if (new->end <= entry->start)
        break;
    else if (new->type != entry->type)
        goto conflict;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="268" endline="292">
{
    int ram_page = 0, not_rampage = 0;
    unsigned long page_nr;
    for (page_nr = (start >> PAGE_SHIFT); page_nr < (end >> PAGE_SHIFT); ++page_nr) {
        if (page_nr >= (ISA_END_ADDRESS >> PAGE_SHIFT) && page_is_ram (page_nr))
            ram_page = 1;
        else
            not_rampage = 1;
        if (ram_page == not_rampage)
            return -1;
    }
    return ram_page;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="273" endline="289">
{
    if (page_nr >= (ISA_END_ADDRESS >> PAGE_SHIFT) && page_is_ram (page_nr))
        ram_page = 1;
    else
        not_rampage = 1;
    if (ram_page == not_rampage)
        return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="304" endline="338">
{
    struct page *page;
    u64 pfn;
    if (req_type == _PAGE_CACHE_UC) {
        WARN_ON_ONCE (1);
        req_type = _PAGE_CACHE_UC_MINUS;
    }
    for (pfn = (start >> PAGE_SHIFT); pfn < (end >> PAGE_SHIFT); ++pfn) {
        unsigned long type;
        page = pfn_to_page (pfn);
        type = get_page_memtype (page);
        if (type != -1) {
            printk (KERN_INFO "reserve_ram_pages_type failed " "0x%Lx-0x%Lx, track 0x%lx, req 0x%lx\n", start, end, type, req_type);
            if (new_type)
                *new_type = type;
            return -EBUSY;
        }
    }
    if (new_type)
        *new_type = req_type;
    for (pfn = (start >> PAGE_SHIFT); pfn < (end >> PAGE_SHIFT); ++pfn) {
        page = pfn_to_page (pfn);
        set_page_memtype (page, req_type);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="308" endline="312">
{
    WARN_ON_ONCE (1);
    req_type = _PAGE_CACHE_UC_MINUS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="314" endline="328">
{
    unsigned long type;
    page = pfn_to_page (pfn);
    type = get_page_memtype (page);
    if (type != -1) {
        printk (KERN_INFO "reserve_ram_pages_type failed " "0x%Lx-0x%Lx, track 0x%lx, req 0x%lx\n", start, end, type, req_type);
        if (new_type)
            *new_type = type;
        return -EBUSY;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="319" endline="327">
{
    printk (KERN_INFO "reserve_ram_pages_type failed " "0x%Lx-0x%Lx, track 0x%lx, req 0x%lx\n", start, end, type, req_type);
    if (new_type)
        *new_type = type;
    return -EBUSY;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="333" endline="336">
{
    page = pfn_to_page (pfn);
    set_page_memtype (page, req_type);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="341" endline="350">
{
    struct page *page;
    u64 pfn;
    for (pfn = (start >> PAGE_SHIFT); pfn < (end >> PAGE_SHIFT); ++pfn) {
        page = pfn_to_page (pfn);
        set_page_memtype (page, - 1);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="345" endline="348">
{
    page = pfn_to_page (pfn);
    set_page_memtype (page, - 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="366" endline="486">
{
    struct memtype *new, *entry;
    unsigned long actual_type;
    struct list_head *where;
    int is_range_ram;
    int err = 0;
    BUG_ON (start >= end);
    if (!pat_enabled) {
        if (new_type) {
            if (req_type == _PAGE_CACHE_WC)
                *new_type = _PAGE_CACHE_UC_MINUS;
            else
                *new_type = req_type & _PAGE_CACHE_MASK;
        }
        return 0;
    }
    if (x86_platform.is_untracked_pat_range (start, end)) {
        if (new_type)
            *new_type = _PAGE_CACHE_WB;
        return 0;
    }
    actual_type = pat_x_mtrr_type (start, end, req_type &_PAGE_CACHE_MASK);
    if (new_type)
        *new_type = actual_type;
    is_range_ram = pat_pagerange_is_ram (start, end);
    if (is_range_ram == 1) {
        spin_lock (& memtype_lock);
        err = reserve_ram_pages_type (start, end, req_type, new_type);
        spin_unlock (& memtype_lock);
        return err;
    }
    else if (is_range_ram < 0) {
        return -EINVAL;
    }
    new = kmalloc (sizeof (struct memtype), GFP_KERNEL);
    if (!new)
        return -ENOMEM;
    new->start = start;
    new->end = end;
    new->type = actual_type;
    spin_lock (& memtype_lock);
    where = NULL;
    list_for_each_entry (entry, &memtype_list, nd) {
        if (end <= entry->start) {
            where = entry->nd.prev;
            break;
        }
        else if (start <= entry->start) {
            err = chk_conflict (new, entry, new_type);
            if (!err) {
                dprintk ("Overlap at 0x%Lx-0x%Lx\n", entry -> start, entry -> end);
                where = entry->nd.prev;
            }
            break;
        }
        else if (start < entry->end) {
            err = chk_conflict (new, entry, new_type);
            if (!err) {
                dprintk ("Overlap at 0x%Lx-0x%Lx\n", entry -> start, entry -> end);
                list_for_each_entry_continue (entry, &memtype_list, nd) {
                    if (start <= entry->start) {
                        where = entry->nd.prev;
                        break;
                    }
                }
            }
            break;
        }
    }
    if (err) {
        printk (KERN_INFO "reserve_memtype failed 0x%Lx-0x%Lx, " "track %s, req %s\n", start, end, cattr_name (new -> type), cattr_name (req_type));
        kfree (new);
        spin_unlock (& memtype_lock);
        return err;
    }
    if (where)
        list_add (&new->nd, where);
    else
        list_add_tail (&new->nd, &memtype_list);
    memtype_rb_insert (& memtype_rbroot, new);
    spin_unlock (& memtype_lock);
    dprintk ("reserve_memtype added 0x%Lx-0x%Lx, track %s, req %s, ret %s\n", start, end, cattr_name (new -> type), cattr_name (req_type), new_type ? cattr_name (* new_type) : "-");
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="375" endline="384">
{
    if (new_type) {
        if (req_type == _PAGE_CACHE_WC)
            *new_type = _PAGE_CACHE_UC_MINUS;
        else
            *new_type = req_type & _PAGE_CACHE_MASK;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="377" endline="382">
{
    if (req_type == _PAGE_CACHE_WC)
        *new_type = _PAGE_CACHE_UC_MINUS;
    else
        *new_type = req_type & _PAGE_CACHE_MASK;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="387" endline="391">
{
    if (new_type)
        *new_type = _PAGE_CACHE_WB;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="405" endline="412">
{
    spin_lock (& memtype_lock);
    err = reserve_ram_pages_type (start, end, req_type, new_type);
    spin_unlock (& memtype_lock);
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="412" endline="414">
{
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="428" endline="460">
{
    if (end <= entry->start) {
        where = entry->nd.prev;
        break;
    }
    else if (start <= entry->start) {
        err = chk_conflict (new, entry, new_type);
        if (!err) {
            dprintk ("Overlap at 0x%Lx-0x%Lx\n", entry -> start, entry -> end);
            where = entry->nd.prev;
        }
        break;
    }
    else if (start < entry->end) {
        err = chk_conflict (new, entry, new_type);
        if (!err) {
            dprintk ("Overlap at 0x%Lx-0x%Lx\n", entry -> start, entry -> end);
            list_for_each_entry_continue (entry, &memtype_list, nd) {
                if (start <= entry->start) {
                    where = entry->nd.prev;
                    break;
                }
            }
        }
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="429" endline="432">
{
    where = entry->nd.prev;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="432" endline="440">
{
    err = chk_conflict (new, entry, new_type);
    if (!err) {
        dprintk ("Overlap at 0x%Lx-0x%Lx\n", entry -> start, entry -> end);
        where = entry->nd.prev;
    }
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="434" endline="438">
{
    dprintk ("Overlap at 0x%Lx-0x%Lx\n", entry -> start, entry -> end);
    where = entry->nd.prev;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="440" endline="459">
{
    err = chk_conflict (new, entry, new_type);
    if (!err) {
        dprintk ("Overlap at 0x%Lx-0x%Lx\n", entry -> start, entry -> end);
        list_for_each_entry_continue (entry, &memtype_list, nd) {
            if (start <= entry->start) {
                where = entry->nd.prev;
                break;
            }
        }
    }
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="442" endline="457">
{
    dprintk ("Overlap at 0x%Lx-0x%Lx\n", entry -> start, entry -> end);
    list_for_each_entry_continue (entry, &memtype_list, nd) {
        if (start <= entry->start) {
            where = entry->nd.prev;
            break;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="451" endline="456">
{
    if (start <= entry->start) {
        where = entry->nd.prev;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="452" endline="455">
{
    where = entry->nd.prev;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="462" endline="470">
{
    printk (KERN_INFO "reserve_memtype failed 0x%Lx-0x%Lx, " "track %s, req %s\n", start, end, cattr_name (new -> type), cattr_name (req_type));
    kfree (new);
    spin_unlock (& memtype_lock);
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="489" endline="564">
{
    struct memtype *entry, *saved_entry;
    int err = -EINVAL;
    int is_range_ram;
    if (!pat_enabled)
        return 0;
    if (x86_platform.is_untracked_pat_range (start, end))
        return 0;
    is_range_ram = pat_pagerange_is_ram (start, end);
    if (is_range_ram == 1) {
        spin_lock (& memtype_lock);
        err = free_ram_pages_type (start, end);
        spin_unlock (& memtype_lock);
        return err;
    }
    else if (is_range_ram < 0) {
        return -EINVAL;
    }
    spin_lock (& memtype_lock);
    entry = memtype_rb_search (&memtype_rbroot, start);
    if (unlikely (entry == NULL))
        goto unlock_ret;
    saved_entry = entry;
    list_for_each_entry_from (entry, &memtype_list, nd) {
        if (entry->start == start && entry->end == end) {
            rb_erase (& entry -> rb, & memtype_rbroot);
            list_del (& entry -> nd);
            kfree (entry);
            err = 0;
            break;
        }
        else if (entry->start > start) {
            break;
        }
    }
    if (!err)
        goto unlock_ret;
    entry = saved_entry;
    list_for_each_entry_reverse (entry, &memtype_list, nd) {
        if (entry->start == start && entry->end == end) {
            rb_erase (& entry -> rb, & memtype_rbroot);
            list_del (& entry -> nd);
            kfree (entry);
            err = 0;
            break;
        }
        else if (entry->start < start) {
            break;
        }
    }
unlock_ret :
    spin_unlock (&memtype_lock);
    if (err) {
        printk (KERN_INFO "%s:%d freeing invalid memtype %Lx-%Lx\n", current -> comm, current -> pid, start, end);
    }
    dprintk ("free_memtype request 0x%Lx-0x%Lx\n", start, end);
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="502" endline="509">
{
    spin_lock (& memtype_lock);
    err = free_ram_pages_type (start, end);
    spin_unlock (& memtype_lock);
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="509" endline="511">
{
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="526" endline="536">
{
    if (entry->start == start && entry->end == end) {
        rb_erase (& entry -> rb, & memtype_rbroot);
        list_del (& entry -> nd);
        kfree (entry);
        err = 0;
        break;
    }
    else if (entry->start > start) {
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="527" endline="533">
{
    rb_erase (& entry -> rb, & memtype_rbroot);
    list_del (& entry -> nd);
    kfree (entry);
    err = 0;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="533" endline="535">
{
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="542" endline="552">
{
    if (entry->start == start && entry->end == end) {
        rb_erase (& entry -> rb, & memtype_rbroot);
        list_del (& entry -> nd);
        kfree (entry);
        err = 0;
        break;
    }
    else if (entry->start < start) {
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="543" endline="549">
{
    rb_erase (& entry -> rb, & memtype_rbroot);
    list_del (& entry -> nd);
    kfree (entry);
    err = 0;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="549" endline="551">
{
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="556" endline="559">
{
    printk (KERN_INFO "%s:%d freeing invalid memtype %Lx-%Lx\n", current -> comm, current -> pid, start, end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="577" endline="610">
{
    int rettype = _PAGE_CACHE_WB;
    struct memtype *entry;
    if (x86_platform.is_untracked_pat_range (paddr, paddr +PAGE_SIZE))
        return rettype;
    if (pat_pagerange_is_ram (paddr, paddr +PAGE_SIZE)) {
        struct page *page;
        spin_lock (& memtype_lock);
        page = pfn_to_page (paddr >> PAGE_SHIFT);
        rettype = get_page_memtype (page);
        spin_unlock (& memtype_lock);
        if (rettype == -1)
            rettype = _PAGE_CACHE_WB;
        return rettype;
    }
    spin_lock (& memtype_lock);
    entry = memtype_rb_search (&memtype_rbroot, paddr);
    if (entry != NULL)
        rettype = entry->type;
    else
        rettype = _PAGE_CACHE_UC_MINUS;
    spin_unlock (& memtype_lock);
    return rettype;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="584" endline="598">
{
    struct page *page;
    spin_lock (& memtype_lock);
    page = pfn_to_page (paddr >> PAGE_SHIFT);
    rettype = get_page_memtype (page);
    spin_unlock (& memtype_lock);
    if (rettype == -1)
        rettype = _PAGE_CACHE_WB;
    return rettype;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="624" endline="650">
{
    resource_size_t size = end - start;
    unsigned long req_type = *type;
    unsigned long new_type;
    int ret;
    WARN_ON_ONCE (iomem_map_sanity_check (start, size));
    ret = reserve_memtype (start, end, req_type, &new_type);
    if (ret)
        goto out_err;
    if (!is_new_memtype_allowed (start, size, req_type, new_type))
        goto out_free;
    if (kernel_map_sync_memtype (start, size, new_type) < 0)
        goto out_free;
    *type = new_type;
    return 0;
out_free :
    free_memtype (start, end);
    ret = -EBUSY;
out_err :
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="658" endline="660">
{
    free_memtype (start, end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="664" endline="666">
{
    return vma_prot;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="677" endline="696">
{
    u64 from = ((u64) pfn) << PAGE_SHIFT;
    u64 to = from + size;
    u64 cursor = from;
    if (!pat_enabled)
        return 1;
    while (cursor < to) {
        if (!devmem_is_allowed (pfn)) {
            printk (KERN_INFO "Program %s tried to access /dev/mem between %Lx->%Lx.\n", current -> comm, from, to);
            return 0;
        }
        cursor += PAGE_SIZE;
        pfn++;
    }
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="685" endline="694">
{
    if (!devmem_is_allowed (pfn)) {
        printk (KERN_INFO "Program %s tried to access /dev/mem between %Lx->%Lx.\n", current -> comm, from, to);
        return 0;
    }
    cursor += PAGE_SIZE;
    pfn++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="686" endline="691">
{
    printk (KERN_INFO "Program %s tried to access /dev/mem between %Lx->%Lx.\n", current -> comm, from, to);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="701" endline="732">
{
    unsigned long flags = _PAGE_CACHE_WB;
    if (!range_is_allowed (pfn, size))
        return 0;
    if (file->f_flags & O_DSYNC)
        flags = _PAGE_CACHE_UC_MINUS;
    *vma_prot = __pgprot ((pgprot_val (*vma_prot) & ~_PAGE_CACHE_MASK) | flags);
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="739" endline="759">
{
    unsigned long id_sz;
    if (base >= __pa (high_memory))
        return 0;
    id_sz = (__pa (high_memory) < base + size) ? __pa (high_memory) - base : size;
    if (ioremap_change_attr ((unsigned long) __va (base), id_sz, flags) < 0) {
        printk (KERN_INFO "%s:%d ioremap_change_attr failed %s " "for %Lx-%Lx\n", current -> comm, current -> pid, cattr_name (flags), base, (unsigned long long) (base + size));
        return -EINVAL;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="749" endline="757">
{
    printk (KERN_INFO "%s:%d ioremap_change_attr failed %s " "for %Lx-%Lx\n", current -> comm, current -> pid, cattr_name (flags), base, (unsigned long long) (base + size));
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="768" endline="832">
{
    int is_ram = 0;
    int ret;
    unsigned long want_flags = (pgprot_val (*vma_prot) & _PAGE_CACHE_MASK);
    unsigned long flags = want_flags;
    is_ram = pat_pagerange_is_ram (paddr, paddr +size);
    if (is_ram) {
        if (!pat_enabled)
            return 0;
        flags = lookup_memtype (paddr);
        if (want_flags != flags) {
            printk (KERN_WARNING "%s:%d map pfn RAM range req %s for %Lx-%Lx, got %s\n", current -> comm, current -> pid, cattr_name (want_flags), (unsigned long long) paddr, (unsigned long long) (paddr + size), cattr_name (flags));
            *vma_prot = __pgprot ((pgprot_val (*vma_prot) & (~_PAGE_CACHE_MASK)) | flags);
        }
        return 0;
    }
    ret = reserve_memtype (paddr, paddr +size, want_flags, &flags);
    if (ret)
        return ret;
    if (flags != want_flags) {
        if (strict_prot || !is_new_memtype_allowed (paddr, size, want_flags, flags)) {
            free_memtype (paddr, paddr + size);
            printk (KERN_ERR "%s:%d map pfn expected mapping type %s" " for %Lx-%Lx, got %s\n", current -> comm, current -> pid, cattr_name (want_flags), (unsigned long long) paddr, (unsigned long long) (paddr + size), cattr_name (flags));
            return -EINVAL;
        }
        *vma_prot = __pgprot ((pgprot_val (*vma_prot) & (~_PAGE_CACHE_MASK)) | flags);
    }
    if (kernel_map_sync_memtype (paddr, size, flags) < 0) {
        free_memtype (paddr, paddr + size);
        return -EINVAL;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="781" endline="799">
{
    if (!pat_enabled)
        return 0;
    flags = lookup_memtype (paddr);
    if (want_flags != flags) {
        printk (KERN_WARNING "%s:%d map pfn RAM range req %s for %Lx-%Lx, got %s\n", current -> comm, current -> pid, cattr_name (want_flags), (unsigned long long) paddr, (unsigned long long) (paddr + size), cattr_name (flags));
        *vma_prot = __pgprot ((pgprot_val (*vma_prot) & (~_PAGE_CACHE_MASK)) | flags);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="786" endline="797">
{
    printk (KERN_WARNING "%s:%d map pfn RAM range req %s for %Lx-%Lx, got %s\n", current -> comm, current -> pid, cattr_name (want_flags), (unsigned long long) paddr, (unsigned long long) (paddr + size), cattr_name (flags));
    *vma_prot = __pgprot ((pgprot_val (*vma_prot) & (~_PAGE_CACHE_MASK)) | flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="805" endline="825">
{
    if (strict_prot || !is_new_memtype_allowed (paddr, size, want_flags, flags)) {
        free_memtype (paddr, paddr + size);
        printk (KERN_ERR "%s:%d map pfn expected mapping type %s" " for %Lx-%Lx, got %s\n", current -> comm, current -> pid, cattr_name (want_flags), (unsigned long long) paddr, (unsigned long long) (paddr + size), cattr_name (flags));
        return -EINVAL;
    }
    *vma_prot = __pgprot ((pgprot_val (*vma_prot) & (~_PAGE_CACHE_MASK)) | flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="807" endline="817">
{
    free_memtype (paddr, paddr + size);
    printk (KERN_ERR "%s:%d map pfn expected mapping type %s" " for %Lx-%Lx, got %s\n", current -> comm, current -> pid, cattr_name (want_flags), (unsigned long long) paddr, (unsigned long long) (paddr + size), cattr_name (flags));
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="827" endline="830">
{
    free_memtype (paddr, paddr + size);
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="839" endline="845">
{
    int is_ram;
    is_ram = pat_pagerange_is_ram (paddr, paddr +size);
    if (is_ram == 0)
        free_memtype (paddr, paddr +size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="855" endline="875">
{
    resource_size_t paddr;
    unsigned long prot;
    unsigned long vma_size = vma->vm_end - vma->vm_start;
    pgprot_t pgprot;
    if (is_linear_pfn_mapping (vma)) {
        if (follow_phys (vma, vma->vm_start, 0, &prot, &paddr)) {
            WARN_ON_ONCE (1);
            return -EINVAL;
        }
        pgprot = __pgprot (prot);
        return reserve_pfn_range (paddr, vma_size, &pgprot, 1);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="861" endline="872">
{
    if (follow_phys (vma, vma->vm_start, 0, &prot, &paddr)) {
        WARN_ON_ONCE (1);
        return -EINVAL;
    }
    pgprot = __pgprot (prot);
    return reserve_pfn_range (paddr, vma_size, &pgprot, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="866" endline="869">
{
    WARN_ON_ONCE (1);
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="887" endline="907">
{
    unsigned long flags;
    resource_size_t paddr;
    unsigned long vma_size = vma->vm_end - vma->vm_start;
    if (is_linear_pfn_mapping (vma)) {
        paddr = (resource_size_t) vma->vm_pgoff << PAGE_SHIFT;
        return reserve_pfn_range (paddr, vma_size, prot, 0);
    }
    if (!pat_enabled)
        return 0;
    flags = lookup_memtype (pfn << PAGE_SHIFT);
    *prot = __pgprot ((pgprot_val (vma->vm_page_prot) & (~_PAGE_CACHE_MASK)) | flags);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="892" endline="896">
{
    paddr = (resource_size_t) vma->vm_pgoff << PAGE_SHIFT;
    return reserve_pfn_range (paddr, vma_size, prot, 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="916" endline="926">
{
    resource_size_t paddr;
    unsigned long vma_size = vma->vm_end - vma->vm_start;
    if (is_linear_pfn_mapping (vma)) {
        paddr = (resource_size_t) vma->vm_pgoff << PAGE_SHIFT;
        free_pfn_range (paddr, vma_size);
        return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="920" endline="925">
{
    paddr = (resource_size_t) vma->vm_pgoff << PAGE_SHIFT;
    free_pfn_range (paddr, vma_size);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pat.c.ifdefed" startline="929" endline="934">
{
    if (pat_enabled)
        return __pgprot (pgprot_val (prot) | _PAGE_CACHE_WC);
    else
        return pgprot_noncached (prot);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/physaddr.c.ifdefed" startline="59" endline="67">
{
    if (x < PAGE_OFFSET)
        return false;
    if (__vmalloc_start_set && is_vmalloc_addr ((void *) x))
        return false;
    if (x >= FIXADDR_START)
        return false;
    return pfn_valid ((x - PAGE_OFFSET) >> PAGE_SHIFT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa.c.ifdefed" startline="26" endline="42">
{
    unsigned int node, num = 0;
    if (nr_node_ids == MAX_NUMNODES) {
        for_each_node_mask (node, node_possible_map)
        num = node;
        nr_node_ids = num + 1;
    }
    for (node = 0; node < nr_node_ids; node++)
        alloc_bootmem_cpumask_var (&node_to_cpumask_map[node]);
    pr_debug ("Node to cpumask map for %d nodes\n", nr_node_ids);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa.c.ifdefed" startline="30" endline="34">
{
    for_each_node_mask (node, node_possible_map)
    num = node;
    nr_node_ids = num + 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="54" endline="80">
{
    unsigned long addr, end;
    int i, res = -1;
    memset (memnodemap, 0xff, sizeof (s16) * memnodemapsize);
    for (i = 0; i < numnodes; i++) {
        addr = nodes[i].start;
        end = nodes[i].end;
        if (addr >= end)
            continue;
        if ((end >> shift) >= memnodemapsize)
            return 0;
        do {
            if (memnodemap[addr >> shift] != NUMA_NO_NODE)
                return -1;
            if (!nodeids)
                memnodemap[addr >> shift] = i;
            else
                memnodemap[addr >> shift] = nodeids[i];
            addr += (1UL << shift);
        }
        while (addr < end);
        res = 1;
    }
    return res;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="59" endline="78">
{
    addr = nodes[i].start;
    end = nodes[i].end;
    if (addr >= end)
        continue;
    if ((end >> shift) >= memnodemapsize)
        return 0;
    do {
        if (memnodemap[addr >> shift] != NUMA_NO_NODE)
            return -1;
        if (!nodeids)
            memnodemap[addr >> shift] = i;
        else
            memnodemap[addr >> shift] = nodeids[i];
        addr += (1UL << shift);
    }
    while (addr < end);
    res = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="66" endline="76">
{
    if (memnodemap[addr >> shift] != NUMA_NO_NODE)
        return -1;
    if (!nodeids)
        memnodemap[addr >> shift] = i;
    else
        memnodemap[addr >> shift] = nodeids[i];
    addr += (1UL << shift);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="83" endline="106">
{
    unsigned long addr;
    memnodemap = memnode.embedded_map;
    if (memnodemapsize <= ARRAY_SIZE (memnode.embedded_map))
        return 0;
    addr = 0x8000;
    nodemap_size = roundup (sizeof (s16) * memnodemapsize, L1_CACHE_BYTES);
    nodemap_addr = find_e820_area (addr, max_pfn << PAGE_SHIFT, nodemap_size, L1_CACHE_BYTES);
    if (nodemap_addr == -1UL) {
        printk (KERN_ERR "NUMA: Unable to allocate Memory to Node hash map\n");
        nodemap_addr = nodemap_size = 0;
        return -1;
    }
    memnodemap = phys_to_virt (nodemap_addr);
    reserve_early (nodemap_addr, nodemap_addr + nodemap_size, "MEMNODEMAP");
    printk (KERN_DEBUG "NUMA: Allocated memnodemap from %lx - %lx\n", nodemap_addr, nodemap_addr + nodemap_size);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="94" endline="99">
{
    printk (KERN_ERR "NUMA: Unable to allocate Memory to Node hash map\n");
    nodemap_addr = nodemap_size = 0;
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="114" endline="135">
{
    int i, nodes_used = 0;
    unsigned long start, end;
    unsigned long bitfield = 0, memtop = 0;
    for (i = 0; i < numnodes; i++) {
        start = nodes[i].start;
        end = nodes[i].end;
        if (start >= end)
            continue;
        bitfield |= start;
        nodes_used++;
        if (end > memtop)
            memtop = end;
    }
    if (nodes_used <= 1)
        i = 63;
    else
        i = find_first_bit (&bitfield, sizeof (unsigned long) * 8);
    memnodemapsize = (memtop >> i) + 1;
    return i;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="119" endline="128">
{
    start = nodes[i].start;
    end = nodes[i].end;
    if (start >= end)
        continue;
    bitfield |= start;
    nodes_used++;
    if (end > memtop)
        memtop = end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="139" endline="155">
{
    int shift;
    shift = extract_lsb_from_nodes (nodes, numnodes);
    if (allocate_cachealigned_memnodemap ())
        return -1;
    printk (KERN_DEBUG "NUMA: Using %d for the hash shift.\n", shift);
    if (populate_memnodemap (nodes, numnodes, shift, nodeids) != 1) {
        printk (KERN_INFO "Your memory is not aligned you need to " "rebuild your kernel with a bigger NODEMAPSIZE " "shift=%d\n", shift);
        return -1;
    }
    return shift;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="148" endline="153">
{
    printk (KERN_INFO "Your memory is not aligned you need to " "rebuild your kernel with a bigger NODEMAPSIZE " "shift=%d\n", shift);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="158" endline="160">
{
    return phys_to_nid (pfn << PAGE_SHIFT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="165" endline="195">
{
    unsigned long mem;
    if (start < (MAX_DMA_PFN << PAGE_SHIFT))
        start = MAX_DMA_PFN << PAGE_SHIFT;
    if (start < (MAX_DMA32_PFN << PAGE_SHIFT) && end > (MAX_DMA32_PFN << PAGE_SHIFT))
        start = MAX_DMA32_PFN << PAGE_SHIFT;
    mem = find_e820_area (start, end, size, align);
    if (mem != -1L)
        return __va (mem);
    end = max_pfn_mapped << PAGE_SHIFT;
    if (end > (MAX_DMA32_PFN << PAGE_SHIFT))
        start = MAX_DMA32_PFN << PAGE_SHIFT;
    else
        start = MAX_DMA_PFN << PAGE_SHIFT;
    mem = find_e820_area (start, end, size, align);
    if (mem != -1L)
        return __va (mem);
    printk (KERN_ERR "Cannot find %lu bytes in node %d\n", size, nodeid);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="200" endline="286">
{
    unsigned long start_pfn, last_pfn, nodedata_phys;
    const int pgdat_size = roundup (sizeof (pg_data_t), PAGE_SIZE);
    int nid;
    unsigned long bootmap_start, bootmap_pages, bootmap_size;
    void *bootmap;
    if (!end)
        return;
    if (end && (end - start) < NODE_MIN_SIZE)
        return;
    start = roundup (start, ZONE_ALIGN);
    printk (KERN_INFO "Initmem setup node %d %016lx-%016lx\n", nodeid, start, end);
    start_pfn = start >> PAGE_SHIFT;
    last_pfn = end >> PAGE_SHIFT;
    node_data[nodeid] = early_node_mem (nodeid, start, end, pgdat_size, SMP_CACHE_BYTES);
    if (node_data[nodeid] == NULL)
        return;
    nodedata_phys = __pa (node_data[nodeid]);
    reserve_early (nodedata_phys, nodedata_phys + pgdat_size, "NODE_DATA");
    printk (KERN_INFO "  NODE_DATA [%016lx - %016lx]\n", nodedata_phys, nodedata_phys + pgdat_size - 1);
    nid = phys_to_nid (nodedata_phys);
    if (nid != nodeid)
        printk (KERN_INFO "    NODE_DATA(%d) on node %d\n", nodeid, nid);
    memset (NODE_DATA (nodeid), 0, sizeof (pg_data_t));
    NODE_DATA (nodeid)->node_id = nodeid;
    NODE_DATA (nodeid)->node_start_pfn = start_pfn;
    NODE_DATA (nodeid)->node_spanned_pages = last_pfn - start_pfn;
    NODE_DATA (nodeid)->bdata = &bootmem_node_data[nodeid];
    bootmap_pages = bootmem_bootmap_pages (last_pfn -start_pfn);
    bootmap_start = roundup (nodedata_phys +pgdat_size, PAGE_SIZE);
    bootmap = early_node_mem (nodeid, bootmap_start, end, bootmap_pages << PAGE_SHIFT, PAGE_SIZE);
    if (bootmap == NULL) {
        free_early (nodedata_phys, nodedata_phys + pgdat_size);
        node_data[nodeid] = NULL;
        return;
    }
    bootmap_start = __pa (bootmap);
    reserve_early (bootmap_start, bootmap_start + (bootmap_pages << PAGE_SHIFT), "BOOTMAP");
    bootmap_size = init_bootmem_node (NODE_DATA (nodeid), bootmap_start >> PAGE_SHIFT, start_pfn, last_pfn);
    printk (KERN_INFO "  bootmap [%016lx -  %016lx] pages %lx\n", bootmap_start, bootmap_start + bootmap_size - 1, bootmap_pages);
    nid = phys_to_nid (bootmap_start);
    if (nid != nodeid)
        printk (KERN_INFO "    bootmap(%d) on node %d\n", nodeid, nid);
    free_bootmem_with_active_regions (nodeid, end);
    node_set_online (nodeid);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="262" endline="266">
{
    free_early (nodedata_phys, nodedata_phys + pgdat_size);
    node_data[nodeid] = NULL;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="296" endline="308">
{
    int rr, i;
    rr = first_node (node_online_map);
    for (i = 0; i < nr_cpu_ids; i++) {
        if (early_cpu_to_node (i) != NUMA_NO_NODE)
            continue;
        numa_set_node (i, rr);
        rr = next_node (rr, node_online_map);
        if (rr == MAX_NUMNODES)
            rr = first_node (node_online_map);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="300" endline="307">
{
    if (early_cpu_to_node (i) != NUMA_NO_NODE)
        continue;
    numa_set_node (i, rr);
    rr = next_node (rr, node_online_map);
    if (rr == MAX_NUMNODES)
        rr = first_node (node_online_map);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="656" endline="699">
{
    int i;
    nodes_clear (node_possible_map);
    nodes_clear (node_online_map);
    printk (KERN_INFO "%s\n", numa_off ? "NUMA turned off" : "No NUMA configuration found");
    printk (KERN_INFO "Faking a node at %016lx-%016lx\n", start_pfn << PAGE_SHIFT, last_pfn << PAGE_SHIFT);
    memnode_shift = 63;
    memnodemap = memnode.embedded_map;
    memnodemap[0] = 0;
    node_set_online (0);
    node_set (0, node_possible_map);
    for (i = 0; i < nr_cpu_ids; i++)
        numa_set_node (i, 0);
    e820_register_active_regions (0, start_pfn, last_pfn);
    setup_node_bootmem (0, start_pfn << PAGE_SHIFT, last_pfn << PAGE_SHIFT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="702" endline="714">
{
    unsigned long pages = 0;
    int i;
    for_each_online_node (i)
    pages += free_all_bootmem_node (NODE_DATA (i));
    return pages;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="717" endline="731">
{
    if (!opt)
        return -EINVAL;
    if (!strncmp (opt, "off", 3))
        numa_off = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="793" endline="813">
{
    int *cpu_to_node_map = early_per_cpu_ptr (x86_cpu_to_node_map);
    if (cpu_to_node_map) {
        cpu_to_node_map[cpu] = node;
        return;
    }
    per_cpu (x86_cpu_to_node_map, cpu) = node;
    if (node != NUMA_NO_NODE)
        per_cpu (node_number, cpu) = node;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="797" endline="800">
{
    cpu_to_node_map[cpu] = node;
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="816" endline="818">
{
    numa_set_node (cpu, NUMA_NO_NODE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="823" endline="825">
{
    cpumask_set_cpu (cpu, node_to_cpumask_map [early_cpu_to_node (cpu)]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/numa_64.c.ifdefed" startline="828" endline="830">
{
    cpumask_clear_cpu (cpu, node_to_cpumask_map [early_cpu_to_node (cpu)]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="31" endline="52">
{
    int num;
    for (num = 0; num < 32; num++) {
        u32 header;
        header = read_pci_config (0, num, 0, 0x00);
        if (header != (PCI_VENDOR_ID_AMD | (0x1100 << 16)) && header != (PCI_VENDOR_ID_AMD | (0x1200 << 16)) && header != (PCI_VENDOR_ID_AMD | (0x1300 << 16)))
            continue;
        header = read_pci_config (0, num, 1, 0x00);
        if (header != (PCI_VENDOR_ID_AMD | (0x1101 << 16)) && header != (PCI_VENDOR_ID_AMD | (0x1201 << 16)) && header != (PCI_VENDOR_ID_AMD | (0x1301 << 16)))
            continue;
        return num;
    }
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="34" endline="49">
{
    u32 header;
    header = read_pci_config (0, num, 0, 0x00);
    if (header != (PCI_VENDOR_ID_AMD | (0x1100 << 16)) && header != (PCI_VENDOR_ID_AMD | (0x1200 << 16)) && header != (PCI_VENDOR_ID_AMD | (0x1300 << 16)))
        continue;
    header = read_pci_config (0, num, 1, 0x00);
    if (header != (PCI_VENDOR_ID_AMD | (0x1101 << 16)) && header != (PCI_VENDOR_ID_AMD | (0x1201 << 16)) && header != (PCI_VENDOR_ID_AMD | (0x1301 << 16)))
        continue;
    return num;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="55" endline="68">
{
    early_init_lapic_mapping ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="71" endline="81">
{
    int i;
    int ret = 0;

    for_each_node_mask (i, nodes_parsed) {
        physnodes[ret].start = nodes[i].start;
        physnodes[ret].end = nodes[i].end;
        ret++;
    }

    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="75" endline="79">
{
    physnodes[ret].start = nodes[i].start;
    physnodes[ret].end = nodes[i].end;
    ret++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="84" endline="193">
{
    unsigned long start = PFN_PHYS (start_pfn);
    unsigned long end = PFN_PHYS (end_pfn);
    unsigned numnodes;
    unsigned long prevbase;
    int i, nb, found = 0;
    u32 nodeid, reg;
    if (!early_pci_allowed ())
        return -1;
    nb = find_northbridge ();
    if (nb < 0)
        return nb;
    pr_info ("Scanning NUMA topology in Northbridge %d\n", nb);
    reg = read_pci_config (0, nb, 0, 0x60);
    numnodes = ((reg >> 4) & 0xF) + 1;
    if (numnodes <= 1)
        return -1;
    pr_info ("Number of physical nodes %d\n", numnodes);
    prevbase = 0;
    for (i = 0; i < 8; i++) {
        unsigned long base, limit;
        base = read_pci_config (0, nb, 1, 0x40 + i * 8);
        limit = read_pci_config (0, nb, 1, 0x44 + i * 8);
        nodeid = limit & 7;
        if ((base & 3) == 0) {
            if (i < numnodes)
                pr_info ("Skipping disabled node %d\n", i);
            continue;
        }
        if (nodeid >= numnodes) {
            pr_info ("Ignoring excess node %d (%lx:%lx)\n", nodeid, base, limit);
            continue;
        }
        if (!limit) {
            pr_info ("Skipping node entry %d (base %lx)\n", i, base);
            continue;
        }
        if ((base >> 8) & 3 || (limit >> 8) & 3) {
            pr_err ("Node %d using interleaving mode %lx/%lx\n", nodeid, (base >> 8) & 3, (limit >> 8) & 3);
            return -1;
        }
        if (node_isset (nodeid, nodes_parsed)) {
            pr_info ("Node %d already present, skipping\n", nodeid);
            continue;
        }
        limit >>= 16;
        limit <<= 24;
        limit |= (1 << 24) - 1;
        limit++;
        if (limit > end)
            limit = end;
        if (limit <= base)
            continue;
        base >>= 16;
        base <<= 24;
        if (base < start)
            base = start;
        if (limit > end)
            limit = end;
        if (limit == base) {
            pr_err ("Empty node %d\n", nodeid);
            continue;
        }
        if (limit < base) {
            pr_err ("Node %d bogus settings %lx-%lx.\n", nodeid, base, limit);
            continue;
        }
        if (prevbase > base) {
            pr_err ("Node map not sorted %lx,%lx\n", prevbase, base);
            return -1;
        }
        pr_info ("Node %d MemBase %016lx Limit %016lx\n", nodeid, base, limit);
        found++;
        nodes[nodeid].start = base;
        nodes[nodeid].end = limit;
        prevbase = base;
        node_set (nodeid, nodes_parsed);
    }
    if (!found)
        return -1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="109" endline="188">
{
    unsigned long base, limit;
    base = read_pci_config (0, nb, 1, 0x40 + i * 8);
    limit = read_pci_config (0, nb, 1, 0x44 + i * 8);
    nodeid = limit & 7;
    if ((base & 3) == 0) {
        if (i < numnodes)
            pr_info ("Skipping disabled node %d\n", i);
        continue;
    }
    if (nodeid >= numnodes) {
        pr_info ("Ignoring excess node %d (%lx:%lx)\n", nodeid, base, limit);
        continue;
    }
    if (!limit) {
        pr_info ("Skipping node entry %d (base %lx)\n", i, base);
        continue;
    }
    if ((base >> 8) & 3 || (limit >> 8) & 3) {
        pr_err ("Node %d using interleaving mode %lx/%lx\n", nodeid, (base >> 8) & 3, (limit >> 8) & 3);
        return -1;
    }
    if (node_isset (nodeid, nodes_parsed)) {
        pr_info ("Node %d already present, skipping\n", nodeid);
        continue;
    }
    limit >>= 16;
    limit <<= 24;
    limit |= (1 << 24) - 1;
    limit++;
    if (limit > end)
        limit = end;
    if (limit <= base)
        continue;
    base >>= 16;
    base <<= 24;
    if (base < start)
        base = start;
    if (limit > end)
        limit = end;
    if (limit == base) {
        pr_err ("Empty node %d\n", nodeid);
        continue;
    }
    if (limit < base) {
        pr_err ("Node %d bogus settings %lx-%lx.\n", nodeid, base, limit);
        continue;
    }
    if (prevbase > base) {
        pr_err ("Node map not sorted %lx,%lx\n", prevbase, base);
        return -1;
    }
    pr_info ("Node %d MemBase %016lx Limit %016lx\n", nodeid, base, limit);
    found++;
    nodes[nodeid].start = base;
    nodes[nodeid].end = limit;
    prevbase = base;
    node_set (nodeid, nodes_parsed);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="116" endline="120">
{
    if (i < numnodes)
        pr_info ("Skipping disabled node %d\n", i);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="121" endline="125">
{
    pr_info ("Ignoring excess node %d (%lx:%lx)\n", nodeid, base, limit);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="127" endline="131">
{
    pr_info ("Skipping node entry %d (base %lx)\n", i, base);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="132" endline="136">
{
    pr_err ("Node %d using interleaving mode %lx/%lx\n", nodeid, (base >> 8) & 3, (limit >> 8) & 3);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="137" endline="141">
{
    pr_info ("Node %d already present, skipping\n", nodeid);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="160" endline="163">
{
    pr_err ("Empty node %d\n", nodeid);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="164" endline="168">
{
    pr_err ("Node %d bogus settings %lx-%lx.\n", nodeid, base, limit);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="171" endline="175">
{
    pr_err ("Node map not sorted %lx,%lx\n", prevbase, base);
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="196" endline="235">
{
    unsigned int bits;
    unsigned int cores;
    unsigned int apicid_base;
    int i;
    BUG_ON (nodes_empty (nodes_parsed));
    node_possible_map = nodes_parsed;
    memnode_shift = compute_hash_shift (nodes, 8, NULL);
    if (memnode_shift < 0) {
        pr_err ("No NUMA node hash function found. Contact maintainer\n");
        return -1;
    }
    pr_info ("Using node hash shift of %d\n", memnode_shift);
    bits = boot_cpu_data.x86_coreid_bits;
    cores = (1 << bits);
    apicid_base = 0;
    early_get_boot_cpu_id ();
    if (boot_cpu_physical_apicid > 0) {
        pr_info ("BSP APIC ID: %02x\n", boot_cpu_physical_apicid);
        apicid_base = boot_cpu_physical_apicid;
    }

    for_each_node_mask (i, node_possible_map) {
        int j;
        e820_register_active_regions (i, nodes [i].start >> PAGE_SHIFT, nodes [i].end >> PAGE_SHIFT);
        for (j = apicid_base; j < cores + apicid_base; j++)
            apicid_to_node[(i << bits) + j] = i;
        setup_node_bootmem (i, nodes [i].start, nodes [i].end);
    }

    numa_init_array ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="205" endline="208">
{
    pr_err ("No NUMA node hash function found. Contact maintainer\n");
    return -1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="217" endline="220">
{
    pr_info ("BSP APIC ID: %02x\n", boot_cpu_physical_apicid);
    apicid_base = boot_cpu_physical_apicid;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/k8topology_64.c.ifdefed" startline="222" endline="231">
{
    int j;
    e820_register_active_regions (i, nodes [i].start >> PAGE_SHIFT, nodes [i].end >> PAGE_SHIFT);
    for (j = apicid_base; j < cores + apicid_base; j++)
        apicid_to_node[(i << bits) + j] = i;
    setup_node_bootmem (i, nodes [i].start, nodes [i].end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="58" endline="61">
{
    direct_gbpages = 0;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="65" endline="68">
{
    direct_gbpages = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="91" endline="97">
{
    if (!strcmp (str, "on"))
        force_personality32 &= ~READ_IMPLIES_EXEC;
    else if (!strcmp (str, "off"))
        force_personality32 |= READ_IMPLIES_EXEC;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="105" endline="121">
{
    void *ptr;
    if (after_bootmem)
        ptr = (void *) get_zeroed_page (GFP_ATOMIC | __GFP_NOTRACK);
    else
        ptr = alloc_bootmem_pages (PAGE_SIZE);
    if (!ptr || ((unsigned long) ptr & ~PAGE_MASK)) {
        panic ("set_pte_phys: cannot allocate page data %s\n", after_bootmem ? "after bootmem" : "");
    }
    pr_debug ("spp_getpage %p\n", ptr);
    return ptr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="113" endline="116">
{
    panic ("set_pte_phys: cannot allocate page data %s\n", after_bootmem ? "after bootmem" : "");
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="124" endline="133">
{
    if (pgd_none (*pgd)) {
        pud_t *pud = (pud_t *) spp_getpage ();
        pgd_populate (& init_mm, pgd, pud);
        if (pud != pud_offset (pgd, 0))
            printk (KERN_ERR "PAGETABLE BUG #00! %p <-> %p\n", pud, pud_offset (pgd, 0));
    }
    return pud_offset (pgd, vaddr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="125" endline="131">
{
    pud_t *pud = (pud_t *) spp_getpage ();
    pgd_populate (& init_mm, pgd, pud);
    if (pud != pud_offset (pgd, 0))
        printk (KERN_ERR "PAGETABLE BUG #00! %p <-> %p\n", pud, pud_offset (pgd, 0));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="136" endline="145">
{
    if (pud_none (*pud)) {
        pmd_t *pmd = (pmd_t *) spp_getpage ();
        pud_populate (& init_mm, pud, pmd);
        if (pmd != pmd_offset (pud, 0))
            printk (KERN_ERR "PAGETABLE BUG #01! %p <-> %p\n", pmd, pmd_offset (pud, 0));
    }
    return pmd_offset (pud, vaddr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="137" endline="143">
{
    pmd_t *pmd = (pmd_t *) spp_getpage ();
    pud_populate (& init_mm, pud, pmd);
    if (pmd != pmd_offset (pud, 0))
        printk (KERN_ERR "PAGETABLE BUG #01! %p <-> %p\n", pmd, pmd_offset (pud, 0));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="148" endline="156">
{
    if (pmd_none (*pmd)) {
        pte_t *pte = (pte_t *) spp_getpage ();
        pmd_populate_kernel (& init_mm, pmd, pte);
        if (pte != pte_offset_kernel (pmd, 0))
            printk (KERN_ERR "PAGETABLE BUG #02!\n");
    }
    return pte_offset_kernel (pmd, vaddr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="149" endline="154">
{
    pte_t *pte = (pte_t *) spp_getpage ();
    pmd_populate_kernel (& init_mm, pmd, pte);
    if (pte != pte_offset_kernel (pmd, 0))
        printk (KERN_ERR "PAGETABLE BUG #02!\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="159" endline="175">
{
    pud_t *pud;
    pmd_t *pmd;
    pte_t *pte;
    pud = pud_page + pud_index (vaddr);
    pmd = fill_pmd (pud, vaddr);
    pte = fill_pte (pmd, vaddr);
    set_pte (pte, new_pte);
    __flush_tlb_one (vaddr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="178" endline="192">
{
    pgd_t *pgd;
    pud_t *pud_page;
    pr_debug ("set_pte_vaddr %lx to %lx\n", vaddr, native_pte_val (pteval));
    pgd = pgd_offset_k (vaddr);
    if (pgd_none (*pgd)) {
        printk (KERN_ERR "PGD FIXMAP MISSING, it should be setup in head.S!\n");
        return;
    }
    pud_page = (pud_t *) pgd_page_vaddr (*pgd);
    set_pte_vaddr_pud (pud_page, vaddr, pteval);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="185" endline="189">
{
    printk (KERN_ERR "PGD FIXMAP MISSING, it should be setup in head.S!\n");
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="195" endline="202">
{
    pgd_t *pgd;
    pud_t *pud;
    pgd = pgd_offset_k (vaddr);
    pud = fill_pud (pgd, vaddr);
    return fill_pmd (pud, vaddr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="205" endline="210">
{
    pmd_t *pmd;
    pmd = populate_extra_pmd (vaddr);
    return fill_pte (pmd, vaddr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="217" endline="240">
{
    pgd_t *pgd;
    pud_t *pud;
    pmd_t *pmd;
    BUG_ON ((phys & ~ PMD_MASK) || (size & ~ PMD_MASK));
    for (; size; phys += PMD_SIZE, size -= PMD_SIZE) {
        pgd = pgd_offset_k ((unsigned long) __va (phys));
        if (pgd_none (*pgd)) {
            pud = (pud_t *) spp_getpage ();
            set_pgd (pgd, __pgd (__pa (pud) | _KERNPG_TABLE | _PAGE_USER));
        }
        pud = pud_offset (pgd, (unsigned long) __va (phys));
        if (pud_none (*pud)) {
            pmd = (pmd_t *) spp_getpage ();
            set_pud (pud, __pud (__pa (pmd) | _KERNPG_TABLE | _PAGE_USER));
        }
        pmd = pmd_offset (pud, phys);
        BUG_ON (! pmd_none (* pmd));
        set_pmd (pmd, __pmd (phys | pgprot_val (prot)));
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="223" endline="239">
{
    pgd = pgd_offset_k ((unsigned long) __va (phys));
    if (pgd_none (*pgd)) {
        pud = (pud_t *) spp_getpage ();
        set_pgd (pgd, __pgd (__pa (pud) | _KERNPG_TABLE | _PAGE_USER));
    }
    pud = pud_offset (pgd, (unsigned long) __va (phys));
    if (pud_none (*pud)) {
        pmd = (pmd_t *) spp_getpage ();
        set_pud (pud, __pud (__pa (pmd) | _KERNPG_TABLE | _PAGE_USER));
    }
    pmd = pmd_offset (pud, phys);
    BUG_ON (! pmd_none (* pmd));
    set_pmd (pmd, __pmd (phys | pgprot_val (prot)));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="225" endline="229">
{
    pud = (pud_t *) spp_getpage ();
    set_pgd (pgd, __pgd (__pa (pud) | _KERNPG_TABLE | _PAGE_USER));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="231" endline="235">
{
    pmd = (pmd_t *) spp_getpage ();
    set_pud (pud, __pud (__pa (pmd) | _KERNPG_TABLE | _PAGE_USER));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="243" endline="245">
{
    __init_extra_mapping (phys, size, PAGE_KERNEL_LARGE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="248" endline="250">
{
    __init_extra_mapping (phys, size, PAGE_KERNEL_LARGE_NOCACHE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="266" endline="278">
{
    unsigned long vaddr = __START_KERNEL_map;
    unsigned long end = roundup ((unsigned long) _end, PMD_SIZE) - 1;
    pmd_t *pmd = level2_kernel_pgt;
    pmd_t *last_pmd = pmd + PTRS_PER_PMD;
    for (; pmd < last_pmd; pmd++, vaddr += PMD_SIZE) {
        if (pmd_none (*pmd))
            continue;
        if (vaddr < (unsigned long) _text || vaddr > end)
            set_pmd (pmd, __pmd (0));
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="272" endline="277">
{
    if (pmd_none (*pmd))
        continue;
    if (vaddr < (unsigned long) _text || vaddr > end)
        set_pmd (pmd, __pmd (0));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="281" endline="299">
{
    unsigned long pfn = e820_table_end++;
    void *adr;
    if (after_bootmem) {
        adr = (void *) get_zeroed_page (GFP_ATOMIC | __GFP_NOTRACK);
        *phys = __pa (adr);
        return adr;
    }
    if (pfn >= e820_table_top)
        panic ("alloc_low_page: ran out of memory");
    adr = early_memremap (pfn *PAGE_SIZE, PAGE_SIZE);
    memset (adr, 0, PAGE_SIZE);
    *phys = pfn * PAGE_SIZE;
    return adr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="285" endline="290">
{
    adr = (void *) get_zeroed_page (GFP_ATOMIC | __GFP_NOTRACK);
    *phys = __pa (adr);
    return adr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="302" endline="307">
{
    if (after_bootmem)
        return;
    early_iounmap (adr, PAGE_SIZE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="312" endline="351">
{
    unsigned pages = 0;
    unsigned long last_map_addr = end;
    int i;
    pte_t *pte = pte_page + pte_index (addr);
    for (i = pte_index (addr); i < PTRS_PER_PTE; i++, addr += PAGE_SIZE, pte++) {
        if (addr >= end) {
            if (!after_bootmem) {
                for (; i < PTRS_PER_PTE; i++, pte++)
                    set_pte (pte, __pte (0));
            }
            break;
        }
        if (pte_val (*pte)) {
            pages++;
            continue;
        }
        if (0)
            printk ("   pte=%p addr=%lx pte=%016lx\n", pte, addr, pfn_pte (addr >> PAGE_SHIFT, PAGE_KERNEL).pte);
        pages++;
        set_pte (pte, pfn_pte (addr >> PAGE_SHIFT, prot));
        last_map_addr = (addr & PAGE_MASK) + PAGE_SIZE;
    }
    update_page_count (PG_LEVEL_4K, pages);
    return last_map_addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="319" endline="346">
{
    if (addr >= end) {
        if (!after_bootmem) {
            for (; i < PTRS_PER_PTE; i++, pte++)
                set_pte (pte, __pte (0));
        }
        break;
    }
    if (pte_val (*pte)) {
        pages++;
        continue;
    }
    if (0)
        printk ("   pte=%p addr=%lx pte=%016lx\n", pte, addr, pfn_pte (addr >> PAGE_SHIFT, PAGE_KERNEL).pte);
    pages++;
    set_pte (pte, pfn_pte (addr >> PAGE_SHIFT, prot));
    last_map_addr = (addr & PAGE_MASK) + PAGE_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="321" endline="327">
{
    if (!after_bootmem) {
        for (; i < PTRS_PER_PTE; i++, pte++)
            set_pte (pte, __pte (0));
    }
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="322" endline="325">
{
    for (; i < PTRS_PER_PTE; i++, pte++)
        set_pte (pte, __pte (0));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="335" endline="338">
{
    pages++;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="356" endline="360">
{
    pte_t *pte = (pte_t *) pmd_page_vaddr (*pmd);
    return phys_pte_init (pte, address, end, prot);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="365" endline="433">
{
    unsigned long pages = 0;
    unsigned long last_map_addr = end;
    int i = pmd_index (address);
    for (; i < PTRS_PER_PMD; i++, address += PMD_SIZE) {
        unsigned long pte_phys;
        pmd_t *pmd = pmd_page + pmd_index (address);
        pte_t *pte;
        pgprot_t new_prot = prot;
        if (address >= end) {
            if (!after_bootmem) {
                for (; i < PTRS_PER_PMD; i++, pmd++)
                    set_pmd (pmd, __pmd (0));
            }
            break;
        }
        if (pmd_val (*pmd)) {
            if (!pmd_large (*pmd)) {
                spin_lock (& init_mm.page_table_lock);
                last_map_addr = phys_pte_update (pmd, address, end, prot);
                spin_unlock (& init_mm.page_table_lock);
                continue;
            }
            if (page_size_mask & (1 << PG_LEVEL_2M)) {
                pages++;
                continue;
            }
            new_prot = pte_pgprot (pte_clrhuge (*(pte_t*) pmd));
        }
        if (page_size_mask & (1 << PG_LEVEL_2M)) {
            pages++;
            spin_lock (& init_mm.page_table_lock);
            set_pte ((pte_t *) pmd, pfn_pte (address >> PAGE_SHIFT, __pgprot (pgprot_val (prot) | _PAGE_PSE)));
            spin_unlock (& init_mm.page_table_lock);
            last_map_addr = (address & PMD_MASK) + PMD_SIZE;
            continue;
        }
        pte = alloc_low_page (&pte_phys);
        last_map_addr = phys_pte_init (pte, address, end, new_prot);
        unmap_low_page (pte);
        spin_lock (& init_mm.page_table_lock);
        pmd_populate_kernel (& init_mm, pmd, __va (pte_phys));
        spin_unlock (& init_mm.page_table_lock);
    }
    update_page_count (PG_LEVEL_2M, pages);
    return last_map_addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="371" endline="430">
{
    unsigned long pte_phys;
    pmd_t *pmd = pmd_page + pmd_index (address);
    pte_t *pte;
    pgprot_t new_prot = prot;
    if (address >= end) {
        if (!after_bootmem) {
            for (; i < PTRS_PER_PMD; i++, pmd++)
                set_pmd (pmd, __pmd (0));
        }
        break;
    }
    if (pmd_val (*pmd)) {
        if (!pmd_large (*pmd)) {
            spin_lock (& init_mm.page_table_lock);
            last_map_addr = phys_pte_update (pmd, address, end, prot);
            spin_unlock (& init_mm.page_table_lock);
            continue;
        }
        if (page_size_mask & (1 << PG_LEVEL_2M)) {
            pages++;
            continue;
        }
        new_prot = pte_pgprot (pte_clrhuge (*(pte_t*) pmd));
    }
    if (page_size_mask & (1 << PG_LEVEL_2M)) {
        pages++;
        spin_lock (& init_mm.page_table_lock);
        set_pte ((pte_t *) pmd, pfn_pte (address >> PAGE_SHIFT, __pgprot (pgprot_val (prot) | _PAGE_PSE)));
        spin_unlock (& init_mm.page_table_lock);
        last_map_addr = (address & PMD_MASK) + PMD_SIZE;
        continue;
    }
    pte = alloc_low_page (&pte_phys);
    last_map_addr = phys_pte_init (pte, address, end, new_prot);
    unmap_low_page (pte);
    spin_lock (& init_mm.page_table_lock);
    pmd_populate_kernel (& init_mm, pmd, __va (pte_phys));
    spin_unlock (& init_mm.page_table_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="377" endline="383">
{
    if (!after_bootmem) {
        for (; i < PTRS_PER_PMD; i++, pmd++)
            set_pmd (pmd, __pmd (0));
    }
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="378" endline="381">
{
    for (; i < PTRS_PER_PMD; i++, pmd++)
        set_pmd (pmd, __pmd (0));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="385" endline="410">
{
    if (!pmd_large (*pmd)) {
        spin_lock (& init_mm.page_table_lock);
        last_map_addr = phys_pte_update (pmd, address, end, prot);
        spin_unlock (& init_mm.page_table_lock);
        continue;
    }
    if (page_size_mask & (1 << PG_LEVEL_2M)) {
        pages++;
        continue;
    }
    new_prot = pte_pgprot (pte_clrhuge (*(pte_t*) pmd));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="386" endline="392">
{
    spin_lock (& init_mm.page_table_lock);
    last_map_addr = phys_pte_update (pmd, address, end, prot);
    spin_unlock (& init_mm.page_table_lock);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="405" endline="408">
{
    pages++;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="412" endline="421">
{
    pages++;
    spin_lock (& init_mm.page_table_lock);
    set_pte ((pte_t *) pmd, pfn_pte (address >> PAGE_SHIFT, __pgprot (pgprot_val (prot) | _PAGE_PSE)));
    spin_unlock (& init_mm.page_table_lock);
    last_map_addr = (address & PMD_MASK) + PMD_SIZE;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="438" endline="445">
{
    pmd_t *pmd = pmd_offset (pud, 0);
    unsigned long last_map_addr;
    last_map_addr = phys_pmd_init (pmd, address, end, page_size_mask, prot);
    __flush_tlb_all ();
    return last_map_addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="450" endline="519">
{
    unsigned long pages = 0;
    unsigned long last_map_addr = end;
    int i = pud_index (addr);
    for (; i < PTRS_PER_PUD; i++, addr = (addr & PUD_MASK) + PUD_SIZE) {
        unsigned long pmd_phys;
        pud_t *pud = pud_page + pud_index (addr);
        pmd_t *pmd;
        pgprot_t prot = PAGE_KERNEL;
        if (addr >= end)
            break;
        if (!after_bootmem && !e820_any_mapped (addr, addr +PUD_SIZE, 0)) {
            set_pud (pud, __pud (0));
            continue;
        }
        if (pud_val (*pud)) {
            if (!pud_large (*pud)) {
                last_map_addr = phys_pmd_update (pud, addr, end, page_size_mask, prot);
                continue;
            }
            if (page_size_mask & (1 << PG_LEVEL_1G)) {
                pages++;
                continue;
            }
            prot = pte_pgprot (pte_clrhuge (*(pte_t*) pud));
        }
        if (page_size_mask & (1 << PG_LEVEL_1G)) {
            pages++;
            spin_lock (& init_mm.page_table_lock);
            set_pte ((pte_t *) pud, pfn_pte (addr >> PAGE_SHIFT, PAGE_KERNEL_LARGE));
            spin_unlock (& init_mm.page_table_lock);
            last_map_addr = (addr & PUD_MASK) + PUD_SIZE;
            continue;
        }
        pmd = alloc_low_page (&pmd_phys);
        last_map_addr = phys_pmd_init (pmd, addr, end, page_size_mask, prot);
        unmap_low_page (pmd);
        spin_lock (& init_mm.page_table_lock);
        pud_populate (& init_mm, pud, __va (pmd_phys));
        spin_unlock (& init_mm.page_table_lock);
    }
    __flush_tlb_all ();
    update_page_count (PG_LEVEL_1G, pages);
    return last_map_addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="455" endline="513">
{
    unsigned long pmd_phys;
    pud_t *pud = pud_page + pud_index (addr);
    pmd_t *pmd;
    pgprot_t prot = PAGE_KERNEL;
    if (addr >= end)
        break;
    if (!after_bootmem && !e820_any_mapped (addr, addr +PUD_SIZE, 0)) {
        set_pud (pud, __pud (0));
        continue;
    }
    if (pud_val (*pud)) {
        if (!pud_large (*pud)) {
            last_map_addr = phys_pmd_update (pud, addr, end, page_size_mask, prot);
            continue;
        }
        if (page_size_mask & (1 << PG_LEVEL_1G)) {
            pages++;
            continue;
        }
        prot = pte_pgprot (pte_clrhuge (*(pte_t*) pud));
    }
    if (page_size_mask & (1 << PG_LEVEL_1G)) {
        pages++;
        spin_lock (& init_mm.page_table_lock);
        set_pte ((pte_t *) pud, pfn_pte (addr >> PAGE_SHIFT, PAGE_KERNEL_LARGE));
        spin_unlock (& init_mm.page_table_lock);
        last_map_addr = (addr & PUD_MASK) + PUD_SIZE;
        continue;
    }
    pmd = alloc_low_page (&pmd_phys);
    last_map_addr = phys_pmd_init (pmd, addr, end, page_size_mask, prot);
    unmap_low_page (pmd);
    spin_lock (& init_mm.page_table_lock);
    pud_populate (& init_mm, pud, __va (pmd_phys));
    spin_unlock (& init_mm.page_table_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="465" endline="468">
{
    set_pud (pud, __pud (0));
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="470" endline="493">
{
    if (!pud_large (*pud)) {
        last_map_addr = phys_pmd_update (pud, addr, end, page_size_mask, prot);
        continue;
    }
    if (page_size_mask & (1 << PG_LEVEL_1G)) {
        pages++;
        continue;
    }
    prot = pte_pgprot (pte_clrhuge (*(pte_t*) pud));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="471" endline="475">
{
    last_map_addr = phys_pmd_update (pud, addr, end, page_size_mask, prot);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="488" endline="491">
{
    pages++;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="495" endline="503">
{
    pages++;
    spin_lock (& init_mm.page_table_lock);
    set_pte ((pte_t *) pud, pfn_pte (addr >> PAGE_SHIFT, PAGE_KERNEL_LARGE));
    spin_unlock (& init_mm.page_table_lock);
    last_map_addr = (addr & PUD_MASK) + PUD_SIZE;
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="524" endline="530">
{
    pud_t *pud;
    pud = (pud_t *) pgd_page_vaddr (*pgd);
    return phys_pud_init (pud, addr, end, page_size_mask);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="536" endline="570">
{
    unsigned long next, last_map_addr = end;
    start = (unsigned long) __va (start);
    end = (unsigned long) __va (end);
    for (; start < end; start = next) {
        pgd_t *pgd = pgd_offset_k (start);
        unsigned long pud_phys;
        pud_t *pud;
        next = (start + PGDIR_SIZE) & PGDIR_MASK;
        if (next > end)
            next = end;
        if (pgd_val (*pgd)) {
            last_map_addr = phys_pud_update (pgd, __pa (start), __pa (end), page_size_mask);
            continue;
        }
        pud = alloc_low_page (&pud_phys);
        last_map_addr = phys_pud_init (pud, __pa (start), __pa (next), page_size_mask);
        unmap_low_page (pud);
        spin_lock (& init_mm.page_table_lock);
        pgd_populate (& init_mm, pgd, __va (pud_phys));
        spin_unlock (& init_mm.page_table_lock);
    }
    __flush_tlb_all ();
    return last_map_addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="543" endline="566">
{
    pgd_t *pgd = pgd_offset_k (start);
    unsigned long pud_phys;
    pud_t *pud;
    next = (start + PGDIR_SIZE) & PGDIR_MASK;
    if (next > end)
        next = end;
    if (pgd_val (*pgd)) {
        last_map_addr = phys_pud_update (pgd, __pa (start), __pa (end), page_size_mask);
        continue;
    }
    pud = alloc_low_page (&pud_phys);
    last_map_addr = phys_pud_init (pud, __pa (start), __pa (next), page_size_mask);
    unmap_low_page (pud);
    spin_lock (& init_mm.page_table_lock);
    pgd_populate (& init_mm, pgd, __va (pud_phys));
    spin_unlock (& init_mm.page_table_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="552" endline="556">
{
    last_map_addr = phys_pud_update (pgd, __pa (start), __pa (end), page_size_mask);
    continue;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="575" endline="593">
{
    unsigned long bootmap_size, bootmap;
    bootmap_size = bootmem_bootmap_pages (end_pfn) << PAGE_SHIFT;
    bootmap = find_e820_area (0, end_pfn << PAGE_SHIFT, bootmap_size, PAGE_SIZE);
    if (bootmap == -1L)
        panic ("Cannot find bootmem map of size %ld\n", bootmap_size);
    reserve_early (bootmap, bootmap + bootmap_size, "BOOTMAP");
    bootmap_size = init_bootmem_node (NODE_DATA (0), bootmap >> PAGE_SHIFT, 0, end_pfn);
    e820_register_active_regions (0, start_pfn, end_pfn);
    free_bootmem_with_active_regions (0, end_pfn);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="597" endline="617">
{
    unsigned long max_zone_pfns [MAX_NR_ZONES];
    memset (max_zone_pfns, 0, sizeof (max_zone_pfns));
    max_zone_pfns[ZONE_DMA] = MAX_DMA_PFN;
    max_zone_pfns[ZONE_DMA32] = MAX_DMA32_PFN;
    max_zone_pfns[ZONE_NORMAL] = max_pfn;
    sparse_memory_present_with_active_regions (MAX_NUMNODES);
    sparse_init ();
    node_clear_state (0, N_NORMAL_MEMORY);
    free_area_init_nodes (max_zone_pfns);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="677" endline="715">
{
    long codesize, reservedpages, datasize, initsize;
    unsigned long absent_pages;
    pci_iommu_alloc ();
    reservedpages = 0;
    totalram_pages = free_all_bootmem ();
    absent_pages = absent_pages_in_range (0, max_pfn);
    reservedpages = max_pfn - totalram_pages - absent_pages;
    after_bootmem = 1;
    codesize = (unsigned long) &_etext - (unsigned long) &_text;
    datasize = (unsigned long) &_edata - (unsigned long) &_etext;
    initsize = (unsigned long) &__init_end - (unsigned long) &__init_begin;
    kclist_add (& kcore_vsyscall, (void *) VSYSCALL_START, VSYSCALL_END - VSYSCALL_START, KCORE_OTHER);
    printk (KERN_INFO "Memory: %luk/%luk available (%ldk kernel code, " "%ldk absent, %ldk reserved, %ldk data, %ldk init)\n", nr_free_pages () << (PAGE_SHIFT - 10), max_pfn << (PAGE_SHIFT - 10), codesize >> 10, absent_pages << (PAGE_SHIFT - 10), reservedpages << (PAGE_SHIFT - 10), datasize >> 10, initsize >> 10);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="804" endline="846">
{
    unsigned long pfn = phys >> PAGE_SHIFT;
    if (pfn >= max_pfn) {
        if (pfn < max_pfn_mapped)
            return -EFAULT;
        printk (KERN_ERR "reserve_bootmem: illegal reserve %lx %lu\n", phys, len);
        return -EFAULT;
    }
    reserve_bootmem (phys, len, flags);
    if (phys + len <= MAX_DMA_PFN * PAGE_SIZE) {
        dma_reserve += len / PAGE_SIZE;
        set_dma_reserve (dma_reserve);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="811" endline="822">
{
    if (pfn < max_pfn_mapped)
        return -EFAULT;
    printk (KERN_ERR "reserve_bootmem: illegal reserve %lx %lu\n", phys, len);
    return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="840" endline="843">
{
    dma_reserve += len / PAGE_SIZE;
    set_dma_reserve (dma_reserve);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="849" endline="879">
{
    unsigned long above = ((long) addr) >> __VIRTUAL_MASK_SHIFT;
    pgd_t *pgd;
    pud_t *pud;
    pmd_t *pmd;
    pte_t *pte;
    if (above != 0 && above != -1UL)
        return 0;
    pgd = pgd_offset_k (addr);
    if (pgd_none (*pgd))
        return 0;
    pud = pud_offset (pgd, addr);
    if (pud_none (*pud))
        return 0;
    pmd = pmd_offset (pud, addr);
    if (pmd_none (*pmd))
        return 0;
    if (pmd_large (*pmd))
        return pfn_valid (pmd_pfn (*pmd));
    pte = pte_offset_kernel (pmd, addr);
    if (pte_none (*pte))
        return 0;
    return pfn_valid (pte_pfn (*pte));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="894" endline="900">
{
    return &gate_vma;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="903" endline="910">
{
    struct vm_area_struct *vma = get_gate_vma (task);
    if (!vma)
        return 0;
    return (addr >= vma->vm_start) && (addr < vma->vm_end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="918" endline="920">
{
    return (addr >= VSYSCALL_START) && (addr < VSYSCALL_END);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init_64.c.ifdefed" startline="923" endline="929">
{
    if (vma->vm_mm && vma->vm_start == (long) vma->vm_mm->context.vdso)
        return "[vdso]";
    if (vma == &gate_vma)
        return "[vsyscall]";
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="33" endline="51">
{
    unsigned long nrpages = size >> PAGE_SHIFT;
    int err;
    switch (prot_val) {
    case _PAGE_CACHE_UC :
    default :
        err = _set_memory_uc (vaddr, nrpages);
        break;
    case _PAGE_CACHE_WC :
        err = _set_memory_wc (vaddr, nrpages);
        break;
    case _PAGE_CACHE_WB :
        err = _set_memory_wb (vaddr, nrpages);
        break;
    }
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="37" endline="48">
{
case _PAGE_CACHE_UC :
default :
    err = _set_memory_uc (vaddr, nrpages);
    break;
case _PAGE_CACHE_WC :
    err = _set_memory_wc (vaddr, nrpages);
    break;
case _PAGE_CACHE_WB :
    err = _set_memory_wb (vaddr, nrpages);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="64" endline="181">
{
    unsigned long pfn, offset, vaddr;
    resource_size_t last_addr;
    const resource_size_t unaligned_phys_addr = phys_addr;
    const unsigned long unaligned_size = size;
    struct vm_struct *area;
    unsigned long new_prot_val;
    pgprot_t prot;
    int retval;
    void __iomem *ret_addr;
    last_addr = phys_addr + size - 1;
    if (!size || last_addr < phys_addr)
        return NULL;
    if (!phys_addr_valid (phys_addr)) {
        printk (KERN_WARNING "ioremap: invalid physical address %llx\n", (unsigned long long) phys_addr);
        WARN_ON_ONCE (1);
        return NULL;
    }
    if (is_ISA_range (phys_addr, last_addr))
        return (__force void __iomem *) phys_to_virt (phys_addr);
    WARN_ONCE (iomem_map_sanity_check (phys_addr, size), KERN_INFO "Info: mapping multiple BARs. Your kernel is fine.");
    for (pfn = phys_addr >> PAGE_SHIFT; (pfn << PAGE_SHIFT) < (last_addr & PAGE_MASK); pfn++) {
        int is_ram = page_is_ram (pfn);
        if (is_ram && pfn_valid (pfn) && !PageReserved (pfn_to_page (pfn)))
            return NULL;
        WARN_ON_ONCE (is_ram);
    }
    offset = phys_addr & ~PAGE_MASK;
    phys_addr &= PAGE_MASK;
    size = PAGE_ALIGN (last_addr +1) - phys_addr;
    retval = reserve_memtype (phys_addr, (u64) phys_addr + size, prot_val, &new_prot_val);
    if (retval) {
        printk (KERN_ERR "ioremap reserve_memtype failed %d\n", retval);
        return NULL;
    }
    if (prot_val != new_prot_val) {
        if (!is_new_memtype_allowed (phys_addr, size, prot_val, new_prot_val)) {
            printk (KERN_ERR "ioremap error for 0x%llx-0x%llx, requested 0x%lx, got 0x%lx\n", (unsigned long long) phys_addr, (unsigned long long) (phys_addr + size), prot_val, new_prot_val);
            goto err_free_memtype;
        }
        prot_val = new_prot_val;
    }
    switch (prot_val) {
    case _PAGE_CACHE_UC :
    default :
        prot = PAGE_KERNEL_IO_NOCACHE;
        break;
    case _PAGE_CACHE_UC_MINUS :
        prot = PAGE_KERNEL_IO_UC_MINUS;
        break;
    case _PAGE_CACHE_WC :
        prot = PAGE_KERNEL_IO_WC;
        break;
    case _PAGE_CACHE_WB :
        prot = PAGE_KERNEL_IO;
        break;
    }
    area = get_vm_area_caller (size, VM_IOREMAP, caller);
    if (!area)
        goto err_free_memtype;
    area->phys_addr = phys_addr;
    vaddr = (unsigned long) area->addr;
    if (kernel_map_sync_memtype (phys_addr, size, prot_val))
        goto err_free_area;
    if (ioremap_page_range (vaddr, vaddr +size, phys_addr, prot))
        goto err_free_area;
    ret_addr = (void __iomem *) (vaddr + offset);
    mmiotrace_ioremap (unaligned_phys_addr, unaligned_size, ret_addr);
    return ret_addr;
err_free_area :
    free_vm_area (area);
err_free_memtype :
    free_memtype (phys_addr, phys_addr +size);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="80" endline="85">
{
    printk (KERN_WARNING "ioremap: invalid physical address %llx\n", (unsigned long long) phys_addr);
    WARN_ON_ONCE (1);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="105" endline="112">
{
    int is_ram = page_is_ram (pfn);
    if (is_ram && pfn_valid (pfn) && !PageReserved (pfn_to_page (pfn)))
        return NULL;
    WARN_ON_ONCE (is_ram);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="123" endline="126">
{
    printk (KERN_ERR "ioremap reserve_memtype failed %d\n", retval);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="128" endline="139">
{
    if (!is_new_memtype_allowed (phys_addr, size, prot_val, new_prot_val)) {
        printk (KERN_ERR "ioremap error for 0x%llx-0x%llx, requested 0x%lx, got 0x%lx\n", (unsigned long long) phys_addr, (unsigned long long) (phys_addr + size), prot_val, new_prot_val);
        goto err_free_memtype;
    }
    prot_val = new_prot_val;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="130" endline="137">
{
    printk (KERN_ERR "ioremap error for 0x%llx-0x%llx, requested 0x%lx, got 0x%lx\n", (unsigned long long) phys_addr, (unsigned long long) (phys_addr + size), prot_val, new_prot_val);
    goto err_free_memtype;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="141" endline="155">
{
case _PAGE_CACHE_UC :
default :
    prot = PAGE_KERNEL_IO_NOCACHE;
    break;
case _PAGE_CACHE_UC_MINUS :
    prot = PAGE_KERNEL_IO_UC_MINUS;
    break;
case _PAGE_CACHE_WC :
    prot = PAGE_KERNEL_IO_WC;
    break;
case _PAGE_CACHE_WB :
    prot = PAGE_KERNEL_IO;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="205" endline="217">
{
    unsigned long val = _PAGE_CACHE_UC_MINUS;
    return __ioremap_caller (phys_addr, size, val, __builtin_return_address (0));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="231" endline="237">
{
    if (pat_enabled)
        return __ioremap_caller (phys_addr, size, _PAGE_CACHE_WC, __builtin_return_address (0));
    else
        return ioremap_nocache (phys_addr, size);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="241" endline="244">
{
    return __ioremap_caller (phys_addr, size, _PAGE_CACHE_WB, __builtin_return_address (0));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="249" endline="252">
{
    return __ioremap_caller (phys_addr, size, (prot_val & _PAGE_CACHE_MASK), __builtin_return_address (0));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="262" endline="306">
{
    struct vm_struct *p, *o;
    if ((void __force *) addr <= high_memory)
        return;
    if ((void __force *) addr >= phys_to_virt (ISA_START_ADDRESS) && (void __force *) addr < phys_to_virt (ISA_END_ADDRESS))
        return;
    addr = (volatile void __iomem *) (PAGE_MASK & (unsigned long __force) addr);
    mmiotrace_iounmap (addr);
    read_lock (& vmlist_lock);
    for (p = vmlist; p; p = p->next) {
        if (p->addr == (void __force *) addr)
            break;
    }
    read_unlock (& vmlist_lock);
    if (!p) {
        printk (KERN_ERR "iounmap: bad address %p\n", addr);
        dump_stack ();
        return;
    }
    free_memtype (p -> phys_addr, p -> phys_addr + get_vm_area_size (p));
    o = remove_vm_area ((void __force *) addr);
    BUG_ON (p != o || o == NULL);
    kfree (p);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="288" endline="291">
{
    if (p->addr == (void __force *) addr)
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="294" endline="298">
{
    printk (KERN_ERR "iounmap: bad address %p\n", addr);
    dump_stack ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="314" endline="327">
{
    void *addr;
    unsigned long start = phys & PAGE_MASK;
    if (page_is_ram (start >> PAGE_SHIFT))
        return __va (phys);
    addr = (void __force *) ioremap_cache (start, PAGE_SIZE);
    if (addr)
        addr = (void *) ((unsigned long) addr | (phys & ~PAGE_MASK));
    return addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="330" endline="336">
{
    if (page_is_ram (phys >> PAGE_SHIFT))
        return;
    iounmap ((void __iomem *) ((unsigned long) addr & PAGE_MASK));
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="341" endline="345">
{
    early_ioremap_debug = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="352" endline="360">
{
    pgd_t *base = __va (read_cr3 ());
    pgd_t *pgd = &base[pgd_index (addr)];
    pud_t *pud = pud_offset (pgd, addr);
    pmd_t *pmd = pmd_offset (pud, addr);
    return pmd;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="363" endline="365">
{
    return &bm_pte[pte_index (addr)];
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="370" endline="405">
{
    pmd_t *pmd;
    int i;
    if (early_ioremap_debug)
        printk (KERN_INFO "early_ioremap_init()\n");
    for (i = 0; i < FIX_BTMAPS_SLOTS; i++)
        slot_virt[i] = __fix_to_virt (FIX_BTMAP_BEGIN -NR_FIX_BTMAPS * i);
    pmd = early_ioremap_pmd (fix_to_virt (FIX_BTMAP_BEGIN));
    memset (bm_pte, 0, sizeof (bm_pte));
    pmd_populate_kernel (& init_mm, pmd, bm_pte);
    BUILD_BUG_ON ((__fix_to_virt (FIX_BTMAP_BEGIN) >> PMD_SHIFT) != (__fix_to_virt (FIX_BTMAP_END) >> PMD_SHIFT));
    if (pmd != early_ioremap_pmd (fix_to_virt (FIX_BTMAP_END))) {
        WARN_ON (1);
        printk (KERN_WARNING "pmd %p != %p\n", pmd, early_ioremap_pmd (fix_to_virt (FIX_BTMAP_END)));
        printk (KERN_WARNING "fix_to_virt(FIX_BTMAP_BEGIN): %08lx\n", fix_to_virt (FIX_BTMAP_BEGIN));
        printk (KERN_WARNING "fix_to_virt(FIX_BTMAP_END):   %08lx\n", fix_to_virt (FIX_BTMAP_END));
        printk (KERN_WARNING "FIX_BTMAP_END:       %d\n", FIX_BTMAP_END);
        printk (KERN_WARNING "FIX_BTMAP_BEGIN:     %d\n", FIX_BTMAP_BEGIN);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="392" endline="404">
{
    WARN_ON (1);
    printk (KERN_WARNING "pmd %p != %p\n", pmd, early_ioremap_pmd (fix_to_virt (FIX_BTMAP_END)));
    printk (KERN_WARNING "fix_to_virt(FIX_BTMAP_BEGIN): %08lx\n", fix_to_virt (FIX_BTMAP_BEGIN));
    printk (KERN_WARNING "fix_to_virt(FIX_BTMAP_END):   %08lx\n", fix_to_virt (FIX_BTMAP_END));
    printk (KERN_WARNING "FIX_BTMAP_END:       %d\n", FIX_BTMAP_END);
    printk (KERN_WARNING "FIX_BTMAP_BEGIN:     %d\n", FIX_BTMAP_BEGIN);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="408" endline="410">
{
    after_paging_init = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="414" endline="429">
{
    unsigned long addr = __fix_to_virt (idx);
    pte_t *pte;
    if (idx >= __end_of_fixed_addresses) {
        BUG ();
        return;
    }
    pte = early_ioremap_pte (addr);
    if (pgprot_val (flags))
        set_pte (pte, pfn_pte (phys >> PAGE_SHIFT, flags));
    else
        pte_clear (&init_mm, addr, pte);
    __flush_tlb_one (addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="418" endline="421">
{
    BUG ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="433" endline="438">
{
    if (after_paging_init)
        __set_fixmap (idx, phys, prot);
    else
        __early_set_fixmap (idx, phys, prot);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="441" endline="446">
{
    if (after_paging_init)
        clear_fixmap (idx);
    else
        __early_set_fixmap (idx, 0, __pgprot (0));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="452" endline="463">
{
    int i;
    for (i = 0; i < FIX_BTMAPS_SLOTS; i++) {
        if (prev_map[i]) {
            WARN_ON (1);
            break;
        }
    }
    early_ioremap_init ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="455" endline="460">
{
    if (prev_map[i]) {
        WARN_ON (1);
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="456" endline="459">
{
    WARN_ON (1);
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="466" endline="483">
{
    int count = 0;
    int i;
    for (i = 0; i < FIX_BTMAPS_SLOTS; i++)
        if (prev_map[i])
            count++;
    if (!count)
        return 0;
    WARN (1, KERN_WARNING "Debug warning: early ioremap leak of %d areas detected.\n", count);
    printk (KERN_WARNING "please boot with early_ioremap_debug and report the dmesg.\n");
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="488" endline="558">
{
    unsigned long offset;
    resource_size_t last_addr;
    unsigned int nrpages;
    enum fixed_addresses idx0, idx;
    int i, slot;
    WARN_ON (system_state != SYSTEM_BOOTING);
    slot = -1;
    for (i = 0; i < FIX_BTMAPS_SLOTS; i++) {
        if (!prev_map[i]) {
            slot = i;
            break;
        }
    }
    if (slot < 0) {
        printk (KERN_INFO "early_iomap(%08llx, %08lx) not found slot\n", (u64) phys_addr, size);
        WARN_ON (1);
        return NULL;
    }
    if (early_ioremap_debug) {
        printk (KERN_INFO "early_ioremap(%08llx, %08lx) [%d] => ", (u64) phys_addr, size, slot);
        dump_stack ();
    }
    last_addr = phys_addr + size - 1;
    if (!size || last_addr < phys_addr) {
        WARN_ON (1);
        return NULL;
    }
    prev_size[slot] = size;
    offset = phys_addr & ~PAGE_MASK;
    phys_addr &= PAGE_MASK;
    size = PAGE_ALIGN (last_addr +1) - phys_addr;
    nrpages = size >> PAGE_SHIFT;
    if (nrpages > NR_FIX_BTMAPS) {
        WARN_ON (1);
        return NULL;
    }
    idx0 = FIX_BTMAP_BEGIN - NR_FIX_BTMAPS * slot;
    idx = idx0;
    while (nrpages > 0) {
        early_set_fixmap (idx, phys_addr, prot);
        phys_addr += PAGE_SIZE;
        --idx;
        --nrpages;
    }
    if (early_ioremap_debug)
        printk (KERN_CONT "%08lx + %08lx\n", offset, slot_virt[slot]);
    prev_map[slot] = (void __iomem *) (offset + slot_virt[slot]);
    return prev_map[slot];
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="498" endline="503">
{
    if (!prev_map[i]) {
        slot = i;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="499" endline="502">
{
    slot = i;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="505" endline="510">
{
    printk (KERN_INFO "early_iomap(%08llx, %08lx) not found slot\n", (u64) phys_addr, size);
    WARN_ON (1);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="512" endline="516">
{
    printk (KERN_INFO "early_ioremap(%08llx, %08lx) [%d] => ", (u64) phys_addr, size, slot);
    dump_stack ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="520" endline="523">
{
    WARN_ON (1);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="537" endline="540">
{
    WARN_ON (1);
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="547" endline="552">
{
    early_set_fixmap (idx, phys_addr, prot);
    phys_addr += PAGE_SIZE;
    --idx;
    --nrpages;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="563" endline="565">
{
    return __early_ioremap (phys_addr, size, PAGE_KERNEL_IO);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="570" endline="572">
{
    return __early_ioremap (phys_addr, size, PAGE_KERNEL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="575" endline="625">
{
    unsigned long virt_addr;
    unsigned long offset;
    unsigned int nrpages;
    enum fixed_addresses idx;
    int i, slot;
    slot = -1;
    for (i = 0; i < FIX_BTMAPS_SLOTS; i++) {
        if (prev_map[i] == addr) {
            slot = i;
            break;
        }
    }
    if (slot < 0) {
        printk (KERN_INFO "early_iounmap(%p, %08lx) not found slot\n", addr, size);
        WARN_ON (1);
        return;
    }
    if (prev_size[slot] != size) {
        printk (KERN_INFO "early_iounmap(%p, %08lx) [%d] size not consistent %08lx\n", addr, size, slot, prev_size [slot]);
        WARN_ON (1);
        return;
    }
    if (early_ioremap_debug) {
        printk (KERN_INFO "early_iounmap(%p, %08lx) [%d]\n", addr, size, slot);
        dump_stack ();
    }
    virt_addr = (unsigned long) addr;
    if (virt_addr < fix_to_virt (FIX_BTMAP_BEGIN)) {
        WARN_ON (1);
        return;
    }
    offset = virt_addr & ~PAGE_MASK;
    nrpages = PAGE_ALIGN (offset +size - 1) >> PAGE_SHIFT;
    idx = FIX_BTMAP_BEGIN - NR_FIX_BTMAPS * slot;
    while (nrpages > 0) {
        early_clear_fixmap (idx);
        --idx;
        --nrpages;
    }
    prev_map[slot] = NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="583" endline="588">
{
    if (prev_map[i] == addr) {
        slot = i;
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="584" endline="587">
{
    slot = i;
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="590" endline="595">
{
    printk (KERN_INFO "early_iounmap(%p, %08lx) not found slot\n", addr, size);
    WARN_ON (1);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="597" endline="602">
{
    printk (KERN_INFO "early_iounmap(%p, %08lx) [%d] size not consistent %08lx\n", addr, size, slot, prev_size [slot]);
    WARN_ON (1);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="604" endline="608">
{
    printk (KERN_INFO "early_iounmap(%p, %08lx) [%d]\n", addr, size, slot);
    dump_stack ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="611" endline="614">
{
    WARN_ON (1);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/ioremap.c.ifdefed" startline="619" endline="623">
{
    early_clear_fixmap (idx);
    --idx;
    --nrpages;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="43" endline="48">
{
    if (unlikely (is_kmmio_active ()))
        if (kmmio_handler (regs, addr) == 1)
            return -1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="51" endline="63">
{
    int ret = 0;
    if (kprobes_built_in () && !user_mode_vm (regs)) {
        preempt_disable ();
        if (kprobe_running () && kprobe_fault_handler (regs, 14))
            ret = 1;
        preempt_enable ();
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="55" endline="60">
{
    preempt_disable ();
    if (kprobe_running () && kprobe_fault_handler (regs, 14))
        ret = 1;
    preempt_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="83" endline="125">
{
    unsigned char instr_hi = opcode & 0xf0;
    unsigned char instr_lo = opcode & 0x0f;
    switch (instr_hi) {
    case 0x20 :
    case 0x30 :
        return ((instr_lo & 7) == 0x6);
    case 0x60 :
        return (instr_lo & 0xC) == 0x4;
    case 0xF0 :
        return !instr_lo || (instr_lo >> 1) == 1;
    case 0x00 :
        if (probe_kernel_address (instr, opcode))
            return 0;
        *prefetch = (instr_lo == 0xF) && (opcode == 0x0D || opcode == 0x18);
        return 0;
    default :
        return 0;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="87" endline="124">
{
case 0x20 :
case 0x30 :
    return ((instr_lo & 7) == 0x6);
case 0x60 :
    return (instr_lo & 0xC) == 0x4;
case 0xF0 :
    return !instr_lo || (instr_lo >> 1) == 1;
case 0x00 :
    if (probe_kernel_address (instr, opcode))
        return 0;
    *prefetch = (instr_lo == 0xF) && (opcode == 0x0D || opcode == 0x18);
    return 0;
default :
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="129" endline="159">
{
    unsigned char *max_instr;
    unsigned char *instr;
    int prefetch = 0;
    if (error_code & PF_INSTR)
        return 0;
    instr = (void *) convert_ip_to_linear (current, regs);
    max_instr = instr + 15;
    if (user_mode (regs) && instr >= (unsigned char *) TASK_SIZE)
        return 0;
    while (instr < max_instr) {
        unsigned char opcode;
        if (probe_kernel_address (instr, opcode))
            break;
        instr++;
        if (!check_prefetch_opcode (regs, instr, opcode, &prefetch))
            break;
    }
    return prefetch;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="147" endline="157">
{
    unsigned char opcode;
    if (probe_kernel_address (instr, opcode))
        break;
    instr++;
    if (!check_prefetch_opcode (regs, instr, opcode, &prefetch))
        break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="164" endline="174">
{
    siginfo_t info;
    info.si_signo = si_signo;
    info.si_errno = 0;
    info.si_code = si_code;
    info.si_addr = (void __user *) address;
    info.si_addr_lsb = si_code == BUS_MCEERR_AR ? PAGE_SHIFT : 0;
    force_sig_info (si_signo, & info, tsk);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="328" endline="352">
{
    unsigned long address;
    for (address = VMALLOC_START & PGDIR_MASK; address <= VMALLOC_END; address += PGDIR_SIZE) {
        const pgd_t *pgd_ref = pgd_offset_k (address);
        unsigned long flags;
        struct page *page;
        if (pgd_none (*pgd_ref))
            continue;
        spin_lock_irqsave (& pgd_lock, flags);
        list_for_each_entry (page, &pgd_list, lru) {
            pgd_t *pgd;
            pgd = (pgd_t *) page_address (page) + pgd_index (address);
            if (pgd_none (*pgd))
                set_pgd (pgd, *pgd_ref);
            else
                BUG_ON (pgd_page_vaddr (*pgd) != pgd_page_vaddr (*pgd_ref));
        }
        spin_unlock_irqrestore (& pgd_lock, flags);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="332" endline="351">
{
    const pgd_t *pgd_ref = pgd_offset_k (address);
    unsigned long flags;
    struct page *page;
    if (pgd_none (*pgd_ref))
        continue;
    spin_lock_irqsave (& pgd_lock, flags);
    list_for_each_entry (page, &pgd_list, lru) {
        pgd_t *pgd;
        pgd = (pgd_t *) page_address (page) + pgd_index (address);
        if (pgd_none (*pgd))
            set_pgd (pgd, *pgd_ref);
        else
            BUG_ON (pgd_page_vaddr (*pgd) != pgd_page_vaddr (*pgd_ref));
    }
    spin_unlock_irqrestore (& pgd_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="342" endline="349">
{
    pgd_t *pgd;
    pgd = (pgd_t *) page_address (page) + pgd_index (address);
    if (pgd_none (*pgd))
        set_pgd (pgd, *pgd_ref);
    else
        BUG_ON (pgd_page_vaddr (*pgd) != pgd_page_vaddr (*pgd_ref));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="362" endline="423">
{
    pgd_t *pgd, *pgd_ref;
    pud_t *pud, *pud_ref;
    pmd_t *pmd, *pmd_ref;
    pte_t *pte, *pte_ref;
    if (!(address >= VMALLOC_START && address < VMALLOC_END))
        return -1;
    pgd = pgd_offset (current->active_mm, address);
    pgd_ref = pgd_offset_k (address);
    if (pgd_none (*pgd_ref))
        return -1;
    if (pgd_none (*pgd))
        set_pgd (pgd, *pgd_ref);
    else
        BUG_ON (pgd_page_vaddr (*pgd) != pgd_page_vaddr (*pgd_ref));
    pud = pud_offset (pgd, address);
    pud_ref = pud_offset (pgd_ref, address);
    if (pud_none (*pud_ref))
        return -1;
    if (pud_none (*pud) || pud_page_vaddr (*pud) != pud_page_vaddr (*pud_ref))
        BUG ();
    pmd = pmd_offset (pud, address);
    pmd_ref = pmd_offset (pud_ref, address);
    if (pmd_none (*pmd_ref))
        return -1;
    if (pmd_none (*pmd) || pmd_page (*pmd) != pmd_page (*pmd_ref))
        BUG ();
    pte_ref = pte_offset_kernel (pmd_ref, address);
    if (!pte_present (*pte_ref))
        return -1;
    pte = pte_offset_kernel (pmd, address);
    if (!pte_present (*pte) || pte_pfn (*pte) != pte_pfn (*pte_ref))
        BUG ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="438" endline="439">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="442" endline="446">
{
    unsigned long dummy;
    return probe_kernel_address ((unsigned long *) p, dummy);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="449" endline="490">
{
    pgd_t *base = __va (read_cr3 () & PHYSICAL_PAGE_MASK);
    pgd_t *pgd = base + pgd_index (address);
    pud_t *pud;
    pmd_t *pmd;
    pte_t *pte;
    if (bad_address (pgd))
        goto bad;
    printk ("PGD %lx ", pgd_val (* pgd));
    if (!pgd_present (*pgd))
        goto out;
    pud = pud_offset (pgd, address);
    if (bad_address (pud))
        goto bad;
    printk ("PUD %lx ", pud_val (* pud));
    if (!pud_present (*pud) || pud_large (*pud))
        goto out;
    pmd = pmd_offset (pud, address);
    if (bad_address (pmd))
        goto bad;
    printk ("PMD %lx ", pmd_val (* pmd));
    if (!pmd_present (*pmd) || pmd_large (*pmd))
        goto out;
    pte = pte_offset_kernel (pmd, address);
    if (bad_address (pte))
        goto bad;
    printk ("PTE %lx", pte_val (* pte));
out :
    printk ("\n");
    return;
bad :
    printk ("BAD\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="509" endline="526">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="537" endline="543">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="546" endline="563">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="571" endline="595">
{
    if (!oops_may_print ())
        return;
    if (error_code & PF_INSTR) {
        unsigned int level;
        pte_t *pte = lookup_address (address, &level);
        if (pte && pte_present (*pte) && !pte_exec (*pte))
            printk (nx_warning, current_uid ());
    }
    printk (KERN_ALERT "BUG: unable to handle kernel ");
    if (address < PAGE_SIZE)
        printk (KERN_CONT "NULL pointer dereference");
    else
        printk (KERN_CONT "paging request");
    printk (KERN_CONT " at %p\n", (void *) address);
    printk (KERN_ALERT "IP:");
    printk_address (regs -> ip, 1);
    dump_pagetable (address);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="575" endline="582">
{
    unsigned int level;
    pte_t *pte = lookup_address (address, &level);
    if (pte && pte_present (*pte) && !pte_exec (*pte))
        printk (nx_warning, current_uid ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="600" endline="621">
{
    struct task_struct *tsk;
    unsigned long flags;
    int sig;
    flags = oops_begin ();
    tsk = current;
    sig = SIGKILL;
    printk (KERN_ALERT "%s: Corrupted page table at address %lx\n", tsk -> comm, address);
    dump_pagetable (address);
    tsk->thread.cr2 = address;
    tsk->thread.trap_no = 14;
    tsk->thread.error_code = error_code;
    if (__die ("Bad pagetable", regs, error_code))
        sig = 0;
    oops_end (flags, regs, sig);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="626" endline="677">
{
    struct task_struct *tsk = current;
    unsigned long *stackend;
    unsigned long flags;
    int sig;
    if (fixup_exception (regs))
        return;
    if (is_prefetch (regs, error_code, address))
        return;
    if (is_errata93 (regs, address))
        return;
    flags = oops_begin ();
    show_fault_oops (regs, error_code, address);
    stackend = end_of_stack (tsk);
    if (tsk != &init_task && *stackend != STACK_END_MAGIC)
        printk (KERN_ALERT "Thread overran stack, or stack corrupted\n");
    tsk->thread.cr2 = address;
    tsk->thread.trap_no = 14;
    tsk->thread.error_code = error_code;
    sig = SIGKILL;
    if (__die ("Oops", regs, error_code))
        sig = 0;
    printk (KERN_EMERG "CR2: %016lx\n", address);
    oops_end (flags, regs, sig);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="686" endline="701">
{
    if (!unhandled_signal (tsk, SIGSEGV))
        return;
    if (!printk_ratelimit ())
        return;
    printk ("%s%s[%d]: segfault at %lx ip %p sp %p error %lx", task_pid_nr (tsk) > 1 ? KERN_INFO : KERN_EMERG, tsk -> comm, task_pid_nr (tsk), address, (void *) regs -> ip, (void *) regs -> sp, error_code);
    print_vma_addr (KERN_CONT " in ", regs -> ip);
    printk (KERN_CONT "\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="706" endline="743">
{
    struct task_struct *tsk = current;
    if (error_code & PF_USER) {
        local_irq_enable ();
        if (is_prefetch (regs, error_code, address))
            return;
        if (is_errata100 (regs, address))
            return;
        if (unlikely (show_unhandled_signals))
            show_signal_msg (regs, error_code, address, tsk);
        tsk->thread.cr2 = address;
        tsk->thread.error_code = error_code | (address >= TASK_SIZE);
        tsk->thread.trap_no = 14;
        force_sig_info_fault (SIGSEGV, si_code, address, tsk);
        return;
    }
    if (is_f00f_bug (regs, address))
        return;
    no_context (regs, error_code, address);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="710" endline="737">
{
    local_irq_enable ();
    if (is_prefetch (regs, error_code, address))
        return;
    if (is_errata100 (regs, address))
        return;
    if (unlikely (show_unhandled_signals))
        show_signal_msg (regs, error_code, address, tsk);
    tsk->thread.cr2 = address;
    tsk->thread.error_code = error_code | (address >= TASK_SIZE);
    tsk->thread.trap_no = 14;
    force_sig_info_fault (SIGSEGV, si_code, address, tsk);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="748" endline="750">
{
    __bad_area_nosemaphore (regs, error_code, address, SEGV_MAPERR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="755" endline="765">
{
    struct mm_struct *mm = current->mm;
    up_read (& mm -> mmap_sem);
    __bad_area_nosemaphore (regs, error_code, address, si_code);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="769" endline="771">
{
    __bad_area (regs, error_code, address, SEGV_MAPERR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="776" endline="778">
{
    __bad_area (regs, error_code, address, SEGV_ACCERR);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="784" endline="792">
{
    up_read (& current -> mm -> mmap_sem);
    pagefault_out_of_memory ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="797" endline="825">
{
    struct task_struct *tsk = current;
    struct mm_struct *mm = tsk->mm;
    int code = BUS_ADRERR;
    up_read (& mm -> mmap_sem);
    if (!(error_code & PF_USER))
        no_context (regs, error_code, address);
    if (is_prefetch (regs, error_code, address))
        return;
    tsk->thread.cr2 = address;
    tsk->thread.error_code = error_code;
    tsk->thread.trap_no = 14;
    force_sig_info_fault (SIGBUS, code, address, tsk);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="830" endline="839">
{
    if (fault & VM_FAULT_OOM) {
        out_of_memory (regs, error_code, address);
    }
    else {
        if (fault & (VM_FAULT_SIGBUS | VM_FAULT_HWPOISON))
            do_sigbus (regs, error_code, address, fault);
        else
            BUG ();
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="831" endline="833">
{
    out_of_memory (regs, error_code, address);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="833" endline="838">
{
    if (fault & (VM_FAULT_SIGBUS | VM_FAULT_HWPOISON))
        do_sigbus (regs, error_code, address, fault);
    else
        BUG ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="842" endline="850">
{
    if ((error_code & PF_WRITE) && !pte_write (*pte))
        return 0;
    if ((error_code & PF_INSTR) && !pte_exec (*pte))
        return 0;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="866" endline="911">
{
    pgd_t *pgd;
    pud_t *pud;
    pmd_t *pmd;
    pte_t *pte;
    int ret;
    if (error_code & (PF_USER | PF_RSVD))
        return 0;
    pgd = init_mm.pgd + pgd_index (address);
    if (!pgd_present (*pgd))
        return 0;
    pud = pud_offset (pgd, address);
    if (!pud_present (*pud))
        return 0;
    if (pud_large (*pud))
        return spurious_fault_check (error_code, (pte_t *) pud);
    pmd = pmd_offset (pud, address);
    if (!pmd_present (*pmd))
        return 0;
    if (pmd_large (*pmd))
        return spurious_fault_check (error_code, (pte_t *) pmd);
    pte = pte_offset_kernel (pmd, address);
    if (!pte_present (*pte))
        return 0;
    ret = spurious_fault_check (error_code, pte);
    if (!ret)
        return 0;
    ret = spurious_fault_check (error_code, (pte_t *) pmd);
    WARN_ONCE (! ret, "PMD has incorrect permission bits\n");
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="917" endline="934">
{
    if (write) {
        if (unlikely (!(vma->vm_flags & VM_WRITE)))
            return 1;
        return 0;
    }
    if (unlikely (error_code &PF_PROT))
        return 1;
    if (unlikely (!(vma->vm_flags & (VM_READ | VM_EXEC | VM_WRITE))))
        return 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="918" endline="923">
{
    if (unlikely (!(vma->vm_flags & VM_WRITE)))
        return 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="937" endline="939">
{
    return address >= TASK_SIZE_MAX;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="948" endline="1140">
{
    struct vm_area_struct *vma;
    struct task_struct *tsk;
    unsigned long address;
    struct mm_struct *mm;
    int write;
    int fault;
    tsk = current;
    mm = tsk->mm;
    address = read_cr2 ();
    if (kmemcheck_active (regs))
        kmemcheck_hide (regs);
    prefetchw (& mm -> mmap_sem);
    if (unlikely (kmmio_fault (regs, address)))
        return;
    if (unlikely (fault_in_kernel_space (address))) {
        if (!(error_code & (PF_RSVD | PF_USER | PF_PROT))) {
            if (vmalloc_fault (address) >= 0)
                return;
            if (kmemcheck_fault (regs, address, error_code))
                return;
        }
        if (spurious_fault (error_code, address))
            return;
        if (notify_page_fault (regs))
            return;
        bad_area_nosemaphore (regs, error_code, address);
        return;
    }
    if (unlikely (notify_page_fault (regs)))
        return;
    if (user_mode_vm (regs)) {
        local_irq_enable ();
        error_code |= PF_USER;
    }
    else {
        if (regs->flags & X86_EFLAGS_IF)
            local_irq_enable ();
    }
    if (unlikely (error_code &PF_RSVD))
        pgtable_bad (regs, error_code, address);
    perf_sw_event (PERF_COUNT_SW_PAGE_FAULTS, 1, 0, regs, address);
    if (unlikely (in_atomic () || !mm)) {
        bad_area_nosemaphore (regs, error_code, address);
        return;
    }
    if (unlikely (!down_read_trylock (&mm->mmap_sem))) {
        if ((error_code & PF_USER) == 0 && !search_exception_tables (regs->ip)) {
            bad_area_nosemaphore (regs, error_code, address);
            return;
        }
        down_read (& mm -> mmap_sem);
    }
    else {
        might_sleep ();
    }
    vma = find_vma (mm, address);
    if (unlikely (!vma)) {
        bad_area (regs, error_code, address);
        return;
    }
    if (likely (vma->vm_start <= address))
        goto good_area;
    if (unlikely (!(vma->vm_flags & VM_GROWSDOWN))) {
        bad_area (regs, error_code, address);
        return;
    }
    if (error_code & PF_USER) {
        if (unlikely (address +65536 + 32 * sizeof (unsigned long) < regs->sp)) {
            bad_area (regs, error_code, address);
            return;
        }
    }
    if (unlikely (expand_stack (vma, address))) {
        bad_area (regs, error_code, address);
        return;
    }
good_area :
    write = error_code & PF_WRITE;
    if (unlikely (access_error (error_code, write, vma))) {
        bad_area_access_error (regs, error_code, address);
        return;
    }
    fault = handle_mm_fault (mm, vma, address, write ? FAULT_FLAG_WRITE : 0);
    if (unlikely (fault &VM_FAULT_ERROR)) {
        mm_fault_error (regs, error_code, address, fault);
        return;
    }
    if (fault & VM_FAULT_MAJOR) {
        tsk->maj_flt++;
        perf_sw_event (PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, 0, regs, address);
    }
    else {
        tsk->min_flt++;
        perf_sw_event (PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, 0, regs, address);
    }
    check_v8086_mode (regs, address, tsk);
    up_read (& mm -> mmap_sem);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="986" endline="1009">
{
    if (!(error_code & (PF_RSVD | PF_USER | PF_PROT))) {
        if (vmalloc_fault (address) >= 0)
            return;
        if (kmemcheck_fault (regs, address, error_code))
            return;
    }
    if (spurious_fault (error_code, address))
        return;
    if (notify_page_fault (regs))
        return;
    bad_area_nosemaphore (regs, error_code, address);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="987" endline="993">
{
    if (vmalloc_fault (address) >= 0)
        return;
    if (kmemcheck_fault (regs, address, error_code))
        return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1021" endline="1024">
{
    local_irq_enable ();
    error_code |= PF_USER;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1024" endline="1027">
{
    if (regs->flags & X86_EFLAGS_IF)
        local_irq_enable ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1038" endline="1041">
{
    bad_area_nosemaphore (regs, error_code, address);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1059" endline="1066">
{
    if ((error_code & PF_USER) == 0 && !search_exception_tables (regs->ip)) {
        bad_area_nosemaphore (regs, error_code, address);
        return;
    }
    down_read (& mm -> mmap_sem);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1061" endline="1064">
{
    bad_area_nosemaphore (regs, error_code, address);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1066" endline="1073">
{
    might_sleep ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1076" endline="1079">
{
    bad_area (regs, error_code, address);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1082" endline="1085">
{
    bad_area (regs, error_code, address);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1086" endline="1097">
{
    if (unlikely (address +65536 + 32 * sizeof (unsigned long) < regs->sp)) {
        bad_area (regs, error_code, address);
        return;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1093" endline="1096">
{
    bad_area (regs, error_code, address);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1098" endline="1101">
{
    bad_area (regs, error_code, address);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1110" endline="1113">
{
    bad_area_access_error (regs, error_code, address);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1122" endline="1125">
{
    mm_fault_error (regs, error_code, address, fault);
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1127" endline="1131">
{
    tsk->maj_flt++;
    perf_sw_event (PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, 0, regs, address);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/fault.c.ifdefed" startline="1131" endline="1135">
{
    tsk->min_flt++;
    perf_sw_event (PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, 0, regs, address);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="34" endline="89">
{
    unsigned long puds, pmds, ptes, tables, start;
    puds = (end + PUD_SIZE - 1) >> PUD_SHIFT;
    tables = roundup (puds * sizeof (pud_t), PAGE_SIZE);
    if (use_gbpages) {
        unsigned long extra;
        extra = end - ((end >> PUD_SHIFT) << PUD_SHIFT);
        pmds = (extra + PMD_SIZE - 1) >> PMD_SHIFT;
    }
    else
        pmds = (end + PMD_SIZE - 1) >> PMD_SHIFT;
    tables += roundup (pmds * sizeof (pmd_t), PAGE_SIZE);
    if (use_pse) {
        unsigned long extra;
        extra = end - ((end >> PMD_SHIFT) << PMD_SHIFT);
        ptes = (extra + PAGE_SIZE - 1) >> PAGE_SHIFT;
    }
    else
        ptes = (end + PAGE_SIZE - 1) >> PAGE_SHIFT;
    tables += roundup (ptes * sizeof (pte_t), PAGE_SIZE);
    start = 0x8000;
    e820_table_start = find_e820_area (start, max_pfn_mapped << PAGE_SHIFT, tables, PAGE_SIZE);
    if (e820_table_start == -1UL)
        panic ("Cannot find space for the kernel page tables");
    e820_table_start >>= PAGE_SHIFT;
    e820_table_end = e820_table_start;
    e820_table_top = e820_table_start + (tables >> PAGE_SHIFT);
    printk (KERN_DEBUG "kernel direct mapping tables up to %lx @ %lx-%lx\n", end, e820_table_start << PAGE_SHIFT, e820_table_top << PAGE_SHIFT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="40" endline="45">
{
    unsigned long extra;
    extra = end - ((end >> PUD_SHIFT) << PUD_SHIFT);
    pmds = (extra + PMD_SIZE - 1) >> PMD_SHIFT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="50" endline="58">
{
    unsigned long extra;
    extra = end - ((end >> PMD_SHIFT) << PMD_SHIFT);
    ptes = (extra + PAGE_SIZE - 1) >> PAGE_SHIFT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="106" endline="117">
{
    if (start_pfn < end_pfn) {
        if (nr_range >= NR_RANGE_MR)
            panic ("run out of range for init_memory_mapping\n");
        mr[nr_range].start = start_pfn << PAGE_SHIFT;
        mr[nr_range].end = end_pfn << PAGE_SHIFT;
        mr[nr_range].page_size_mask = page_size_mask;
        nr_range++;
    }
    return nr_range;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="107" endline="114">
{
    if (nr_range >= NR_RANGE_MR)
        panic ("run out of range for init_memory_mapping\n");
    mr[nr_range].start = start_pfn << PAGE_SHIFT;
    mr[nr_range].end = end_pfn << PAGE_SHIFT;
    mr[nr_range].page_size_mask = page_size_mask;
    nr_range++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="126" endline="309">
{
    unsigned long page_size_mask = 0;
    unsigned long start_pfn, end_pfn;
    unsigned long ret = 0;
    unsigned long pos;
    struct map_range mr [NR_RANGE_MR];
    int nr_range, i;
    int use_pse, use_gbpages;
    printk (KERN_INFO "init_memory_mapping: %016lx-%016lx\n", start, end);
    use_pse = cpu_has_pse;
    use_gbpages = direct_gbpages;
    if (cpu_has_pse)
        set_in_cr4 (X86_CR4_PSE);
    if (cpu_has_pge) {
        set_in_cr4 (X86_CR4_PGE);
        __supported_pte_mask |= _PAGE_GLOBAL;
    }
    if (use_gbpages)
        page_size_mask |= 1 << PG_LEVEL_1G;
    if (use_pse)
        page_size_mask |= 1 << PG_LEVEL_2M;
    memset (mr, 0, sizeof (mr));
    nr_range = 0;
    start_pfn = start >> PAGE_SHIFT;
    pos = start_pfn << PAGE_SHIFT;
    end_pfn = ((pos + (PMD_SIZE - 1)) >> PMD_SHIFT) << (PMD_SHIFT - PAGE_SHIFT);
    if (end_pfn > (end >> PAGE_SHIFT))
        end_pfn = end >> PAGE_SHIFT;
    if (start_pfn < end_pfn) {
        nr_range = save_mr (mr, nr_range, start_pfn, end_pfn, 0);
        pos = end_pfn << PAGE_SHIFT;
    }
    start_pfn = ((pos + (PMD_SIZE - 1)) >> PMD_SHIFT) << (PMD_SHIFT - PAGE_SHIFT);
    end_pfn = ((pos + (PUD_SIZE - 1)) >> PUD_SHIFT) << (PUD_SHIFT - PAGE_SHIFT);
    if (end_pfn > ((end >> PMD_SHIFT) << (PMD_SHIFT - PAGE_SHIFT)))
        end_pfn = ((end >> PMD_SHIFT) << (PMD_SHIFT - PAGE_SHIFT));
    if (start_pfn < end_pfn) {
        nr_range = save_mr (mr, nr_range, start_pfn, end_pfn, page_size_mask &(1 << PG_LEVEL_2M));
        pos = end_pfn << PAGE_SHIFT;
    }
    start_pfn = pos >> PAGE_SHIFT;
    end_pfn = end >> PAGE_SHIFT;
    nr_range = save_mr (mr, nr_range, start_pfn, end_pfn, 0);
    for (i = 0; nr_range > 1 && i < nr_range - 1; i++) {
        unsigned long old_start;
        if (mr[i].end != mr[i + 1].start || mr[i].page_size_mask != mr[i + 1].page_size_mask)
            continue;
        old_start = mr[i].start;
        memmove (& mr [i], & mr [i + 1], (nr_range - 1 - i) * sizeof (struct map_range));
        mr[i--].start = old_start;
        nr_range--;
    }
    for (i = 0; i < nr_range; i++)
        printk (KERN_DEBUG " %010lx - %010lx page %s\n", mr[i].start, mr[i].end, (mr[i].page_size_mask & (1 << PG_LEVEL_1G)) ? "1G" : ((mr[i].page_size_mask & (1 << PG_LEVEL_2M)) ? "2M" : "4k"));
    if (!after_bootmem)
        find_early_table_space (end, use_pse, use_gbpages);
    for (i = 0; i < nr_range; i++)
        ret = kernel_physical_mapping_init (mr[i].start, mr[i].end, mr[i].page_size_mask);
    __flush_tlb_all ();
    if (!after_bootmem && e820_table_end > e820_table_start)
        reserve_early (e820_table_start << PAGE_SHIFT, e820_table_end << PAGE_SHIFT, "PGTABLE");
    if (!after_bootmem)
        early_memtest (start, end);
    return ret >> PAGE_SHIFT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="155" endline="158">
{
    set_in_cr4 (X86_CR4_PGE);
    __supported_pte_mask |= _PAGE_GLOBAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="189" endline="192">
{
    nr_range = save_mr (mr, nr_range, start_pfn, end_pfn, 0);
    pos = end_pfn << PAGE_SHIFT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="206" endline="210">
{
    nr_range = save_mr (mr, nr_range, start_pfn, end_pfn, page_size_mask &(1 << PG_LEVEL_2M));
    pos = end_pfn << PAGE_SHIFT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="241" endline="252">
{
    unsigned long old_start;
    if (mr[i].end != mr[i + 1].start || mr[i].page_size_mask != mr[i + 1].page_size_mask)
        continue;
    old_start = mr[i].start;
    memmove (& mr [i], & mr [i + 1], (nr_range - 1 - i) * sizeof (struct map_range));
    mr[i--].start = old_start;
    nr_range--;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="323" endline="331">
{
    if (pagenr <= 256)
        return 1;
    if (iomem_is_exclusive (pagenr << PAGE_SHIFT))
        return 0;
    if (!page_is_ram (pagenr))
        return 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="334" endline="379">
{
    unsigned long addr;
    unsigned long begin_aligned, end_aligned;
    begin_aligned = PAGE_ALIGN (begin);
    end_aligned = end & PAGE_MASK;
    if (WARN_ON (begin_aligned != begin || end_aligned != end)) {
        begin = begin_aligned;
        end = end_aligned;
    }
    if (begin >= end)
        return;
    addr = begin;
    set_memory_rw (begin, (end - begin) >> PAGE_SHIFT);
    printk (KERN_INFO "Freeing %s: %luk freed\n", what, (end - begin) >> 10);
    for (; addr < end; addr += PAGE_SIZE) {
        ClearPageReserved (virt_to_page (addr));
        init_page_count (virt_to_page (addr));
        memset ((void *) addr, POISON_FREE_INITMEM, PAGE_SIZE);
        free_page (addr);
        totalram_pages++;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="342" endline="345">
{
    begin = begin_aligned;
    end = end_aligned;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="371" endline="377">
{
    ClearPageReserved (virt_to_page (addr));
    init_page_count (virt_to_page (addr));
    memset ((void *) addr, POISON_FREE_INITMEM, PAGE_SIZE);
    free_page (addr);
    totalram_pages++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/init.c.ifdefed" startline="382" endline="386">
{
    free_init_pages ("unused kernel memory", (unsigned long) (& __init_begin), (unsigned long) (& __init_end));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="19" endline="21">
{
    return (pte_t *) __get_free_page (PGALLOC_GFP);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="24" endline="31">
{
    struct page *pte;
    pte = alloc_pages (__userpte_alloc_gfp, 0);
    if (pte)
        pgtable_page_ctor (pte);
    return pte;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="34" endline="47">
{
    if (!arg)
        return -EINVAL;
    if (strcmp (arg, "nohigh") == 0)
        __userpte_alloc_gfp &= ~__GFP_HIGHMEM;
    else
        return -EINVAL;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="51" endline="55">
{
    pgtable_page_dtor (pte);
    paravirt_release_pte (page_to_pfn (pte));
    tlb_remove_page (tlb, pte);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="74" endline="78">
{
    struct page *page = virt_to_page (pgd);
    list_add (& page -> lru, & pgd_list);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="81" endline="85">
{
    struct page *page = virt_to_page (pgd);
    list_del (& page -> lru);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="91" endline="110">
{
    if (PAGETABLE_LEVELS == 2 || (PAGETABLE_LEVELS == 3 && SHARED_KERNEL_PMD) || PAGETABLE_LEVELS == 4) {
        clone_pgd_range (pgd + KERNEL_PGD_BOUNDARY, swapper_pg_dir + KERNEL_PGD_BOUNDARY, KERNEL_PGD_PTRS);
        paravirt_alloc_pmd_clone (__pa (pgd) >> PAGE_SHIFT, __pa (swapper_pg_dir) >> PAGE_SHIFT, KERNEL_PGD_BOUNDARY, KERNEL_PGD_PTRS);
    }
    if (!SHARED_KERNEL_PMD)
        pgd_list_add (pgd);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="97" endline="105">
{
    clone_pgd_range (pgd + KERNEL_PGD_BOUNDARY, swapper_pg_dir + KERNEL_PGD_BOUNDARY, KERNEL_PGD_PTRS);
    paravirt_alloc_pmd_clone (__pa (pgd) >> PAGE_SHIFT, __pa (swapper_pg_dir) >> PAGE_SHIFT, KERNEL_PGD_BOUNDARY, KERNEL_PGD_PTRS);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="113" endline="122">
{
    unsigned long flags;
    if (SHARED_KERNEL_PMD)
        return;
    spin_lock_irqsave (& pgd_lock, flags);
    pgd_list_del (pgd);
    spin_unlock_irqrestore (& pgd_lock, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="174" endline="180">
{
    int i;
    for (i = 0; i < PREALLOCATED_PMDS; i++)
        if (pmds[i])
            free_page ((unsigned long) pmds[i]);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="183" endline="200">
{
    int i;
    bool failed = false;
    for (i = 0; i < PREALLOCATED_PMDS; i++) {
        pmd_t *pmd = (pmd_t *) __get_free_page (PGALLOC_GFP);
        if (pmd == NULL)
            failed = true;
        pmds[i] = pmd;
    }
    if (failed) {
        free_pmds (pmds);
        return -ENOMEM;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="187" endline="192">
{
    pmd_t *pmd = (pmd_t *) __get_free_page (PGALLOC_GFP);
    if (pmd == NULL)
        failed = true;
    pmds[i] = pmd;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="194" endline="197">
{
    free_pmds (pmds);
    return -ENOMEM;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="209" endline="224">
{
    int i;
    for (i = 0; i < PREALLOCATED_PMDS; i++) {
        pgd_t pgd = pgdp[i];
        if (pgd_val (pgd) != 0) {
            pmd_t *pmd = (pmd_t *) pgd_page_vaddr (pgd);
            pgdp[i] = native_make_pgd (0);
            paravirt_release_pmd (pgd_val (pgd) >> PAGE_SHIFT);
            pmd_free (mm, pmd);
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="212" endline="223">
{
    pgd_t pgd = pgdp[i];
    if (pgd_val (pgd) != 0) {
        pmd_t *pmd = (pmd_t *) pgd_page_vaddr (pgd);
        pgdp[i] = native_make_pgd (0);
        paravirt_release_pmd (pgd_val (pgd) >> PAGE_SHIFT);
        pmd_free (mm, pmd);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="215" endline="222">
{
    pmd_t *pmd = (pmd_t *) pgd_page_vaddr (pgd);
    pgdp[i] = native_make_pgd (0);
    paravirt_release_pmd (pgd_val (pgd) >> PAGE_SHIFT);
    pmd_free (mm, pmd);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="227" endline="247">
{
    pud_t *pud;
    unsigned long addr;
    int i;
    if (PREALLOCATED_PMDS == 0)
        return;
    pud = pud_offset (pgd, 0);
    for (addr = i = 0; i < PREALLOCATED_PMDS; i++, pud++, addr += PUD_SIZE) {
        pmd_t *pmd = pmds[i];
        if (i >= KERNEL_PGD_BOUNDARY)
            memcpy (pmd, (pmd_t *) pgd_page_vaddr (swapper_pg_dir[i]), sizeof (pmd_t) * PTRS_PER_PMD);
        pud_populate (mm, pud, pmd);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="238" endline="246">
{
    pmd_t *pmd = pmds[i];
    if (i >= KERNEL_PGD_BOUNDARY)
        memcpy (pmd, (pmd_t *) pgd_page_vaddr (swapper_pg_dir[i]), sizeof (pmd_t) * PTRS_PER_PMD);
    pud_populate (mm, pud, pmd);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="250" endline="288">
{
    pgd_t *pgd;
    pmd_t *pmds [PREALLOCATED_PMDS];
    unsigned long flags;
    pgd = (pgd_t *) __get_free_page (PGALLOC_GFP);
    if (pgd == NULL)
        goto out;
    mm->pgd = pgd;
    if (preallocate_pmds (pmds) != 0)
        goto out_free_pgd;
    if (paravirt_pgd_alloc (mm) != 0)
        goto out_free_pmds;
    spin_lock_irqsave (& pgd_lock, flags);
    pgd_ctor (pgd);
    pgd_prepopulate_pmd (mm, pgd, pmds);
    spin_unlock_irqrestore (& pgd_lock, flags);
    return pgd;
out_free_pmds :
    free_pmds (pmds);
out_free_pgd :
    free_page ((unsigned long) pgd);
out :
    return NULL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="291" endline="296">
{
    pgd_mop_up_pmds (mm, pgd);
    pgd_dtor (pgd);
    paravirt_pgd_free (mm, pgd);
    free_page ((unsigned long) pgd);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="301" endline="311">
{
    int changed = !pte_same (*ptep, entry);
    if (changed && dirty) {
        *ptep = entry;
        pte_update_defer (vma -> vm_mm, address, ptep);
        flush_tlb_page (vma, address);
    }
    return changed;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="304" endline="308">
{
    *ptep = entry;
    pte_update_defer (vma -> vm_mm, address, ptep);
    flush_tlb_page (vma, address);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="315" endline="326">
{
    int ret = 0;
    if (pte_young (*ptep))
        ret = test_and_clear_bit (_PAGE_BIT_ACCESSED, (unsigned long *) &ptep->pte);
    if (ret)
        pte_update (vma->vm_mm, addr, ptep);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="330" endline="338">
{
    int young;
    young = ptep_test_and_clear_young (vma, address, ptep);
    if (young)
        flush_tlb_page (vma, address);
    return young;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="348" endline="355">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="360" endline="369">
{
    unsigned long address = __fix_to_virt (idx);
    if (idx >= __end_of_fixed_addresses) {
        BUG ();
        return;
    }
    set_pte_vaddr (address, pte);
    fixmaps_set++;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="363" endline="366">
{
    BUG ();
    return;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pgtable.c.ifdefed" startline="373" endline="375">
{
    __native_set_fixmap (idx, pfn_pte (phys >> PAGE_SHIFT, flags));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="91" endline="91">
{
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="116" endline="118">
{
    return addr >= start && addr < end;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="133" endline="146">
{
    void *vend = vaddr + size - 1;
    mb ();
    for (; vaddr < vend; vaddr += boot_cpu_data.x86_clflush_size)
        clflush (vaddr);
    clflush (vend);
    mb ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="150" endline="161">
{
    unsigned long cache = (unsigned long) arg;
    __flush_tlb_all ();
    if (cache && boot_cpu_data.x86 >= 4)
        wbinvd ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="164" endline="168">
{
    BUG_ON (irqs_disabled ());
    on_each_cpu (__cpa_flush_all, (void *) cache, 1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="171" endline="178">
{
    __flush_tlb_all ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="181" endline="208">
{
    unsigned int i, level;
    unsigned long addr;
    BUG_ON (irqs_disabled ());
    WARN_ON (PAGE_ALIGN (start) != start);
    on_each_cpu (__cpa_flush_range, NULL, 1);
    if (!cache)
        return;
    for (i = 0, addr = start; i < numpages; i++, addr += PAGE_SIZE) {
        pte_t *pte = lookup_address (addr, &level);
        if (pte && (pte_val (*pte) & _PAGE_PRESENT))
            clflush_cache_range ((void *) addr, PAGE_SIZE);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="199" endline="207">
{
    pte_t *pte = lookup_address (addr, &level);
    if (pte && (pte_val (*pte) & _PAGE_PRESENT))
        clflush_cache_range ((void *) addr, PAGE_SIZE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="212" endline="246">
{
    unsigned int i, level;
    unsigned long do_wbinvd = cache && numpages >= 1024;
    BUG_ON (irqs_disabled ());
    on_each_cpu (__cpa_flush_all, (void *) do_wbinvd, 1);
    if (!cache || do_wbinvd)
        return;
    for (i = 0; i < numpages; i++) {
        unsigned long addr;
        pte_t *pte;
        if (in_flags & CPA_PAGES_ARRAY)
            addr = (unsigned long) page_address (pages[i]);
        else
            addr = start[i];
        pte = lookup_address (addr, &level);
        if (pte && (pte_val (*pte) & _PAGE_PRESENT))
            clflush_cache_range ((void *) addr, PAGE_SIZE);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="229" endline="245">
{
    unsigned long addr;
    pte_t *pte;
    if (in_flags & CPA_PAGES_ARRAY)
        addr = (unsigned long) page_address (pages[i]);
    else
        addr = start[i];
    pte = lookup_address (addr, &level);
    if (pte && (pte_val (*pte) & _PAGE_PRESENT))
        clflush_cache_range ((void *) addr, PAGE_SIZE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="256" endline="322">
{
    pgprot_t forbidden = __pgprot (0);
    if (within (pfn, BIOS_BEGIN >> PAGE_SHIFT, BIOS_END >> PAGE_SHIFT))
        pgprot_val (forbidden) |= _PAGE_NX;
    if (within (address, (unsigned long) _text, (unsigned long) _etext))
        pgprot_val (forbidden) |= _PAGE_NX;
    if (within (pfn, __pa ((unsigned long) __start_rodata) >> PAGE_SHIFT, __pa ((unsigned long) __end_rodata) >> PAGE_SHIFT))
        pgprot_val (forbidden) |= _PAGE_RW;
    prot = __pgprot (pgprot_val (prot) &~pgprot_val (forbidden));
    return prot;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="333" endline="362">
{
    pgd_t *pgd = pgd_offset_k (address);
    pud_t *pud;
    pmd_t *pmd;
    *level = PG_LEVEL_NONE;
    if (pgd_none (*pgd))
        return NULL;
    pud = pud_offset (pgd, address);
    if (pud_none (*pud))
        return NULL;
    *level = PG_LEVEL_1G;
    if (pud_large (*pud) || !pud_present (*pud))
        return (pte_t *) pud;
    pmd = pmd_offset (pud, address);
    if (pmd_none (*pmd))
        return NULL;
    *level = PG_LEVEL_2M;
    if (pmd_large (*pmd) || !pmd_present (*pmd))
        return (pte_t *) pmd;
    *level = PG_LEVEL_4K;
    return pte_offset_kernel (pmd, address);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="369" endline="388">
{
    set_pte_atomic (kpte, pte);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="393" endline="501">
{
    unsigned long nextpage_addr, numpages, pmask, psize, flags, addr, pfn;
    pte_t new_pte, old_pte, *tmp;
    pgprot_t old_prot, new_prot;
    int i, do_split = 1;
    unsigned int level;
    if (cpa->force_split)
        return 1;
    spin_lock_irqsave (& pgd_lock, flags);
    tmp = lookup_address (address, &level);
    if (tmp != kpte)
        goto out_unlock;
    switch (level) {
    case PG_LEVEL_2M :
        psize = PMD_PAGE_SIZE;
        pmask = PMD_PAGE_MASK;
        break;
    default :
        do_split = -EINVAL;
        goto out_unlock;
    }
    nextpage_addr = (address + psize) & pmask;
    numpages = (nextpage_addr - address) >> PAGE_SHIFT;
    if (numpages < cpa->numpages)
        cpa->numpages = numpages;
    old_pte = *kpte;
    old_prot = new_prot = pte_pgprot (old_pte);
    pgprot_val (new_prot) &= ~pgprot_val (cpa->mask_clr);
    pgprot_val (new_prot) |= pgprot_val (cpa->mask_set);
    pfn = pte_pfn (old_pte) + ((address & (psize - 1)) >> PAGE_SHIFT);
    cpa->pfn = pfn;
    new_prot = static_protections (new_prot, address, pfn);
    addr = address + PAGE_SIZE;
    pfn++;
    for (i = 1; i < cpa->numpages; i++, addr += PAGE_SIZE, pfn++) {
        pgprot_t chk_prot = static_protections (new_prot, addr, pfn);
        if (pgprot_val (chk_prot) != pgprot_val (new_prot))
            goto out_unlock;
    }
    if (pgprot_val (new_prot) == pgprot_val (old_prot)) {
        do_split = 0;
        goto out_unlock;
    }
    if (address == (nextpage_addr - psize) && cpa->numpages == numpages) {
        new_pte = pfn_pte (pte_pfn (old_pte), canon_pgprot (new_prot));
        __set_pmd_pte (kpte, address, new_pte);
        cpa->flags |= CPA_FLUSHTLB;
        do_split = 0;
    }
out_unlock :
    spin_unlock_irqrestore (&pgd_lock, flags);
    return do_split;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="412" endline="426">
{
case PG_LEVEL_2M :
    psize = PMD_PAGE_SIZE;
    pmask = PMD_PAGE_MASK;
    break;
default :
    do_split = -EINVAL;
    goto out_unlock;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="462" endline="467">
{
    pgprot_t chk_prot = static_protections (new_prot, addr, pfn);
    if (pgprot_val (chk_prot) != pgprot_val (new_prot))
        goto out_unlock;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="473" endline="476">
{
    do_split = 0;
    goto out_unlock;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="486" endline="495">
{
    new_pte = pfn_pte (pte_pfn (old_pte), canon_pgprot (new_prot));
    __set_pmd_pte (kpte, address, new_pte);
    cpa->flags |= CPA_FLUSHTLB;
    do_split = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="504" endline="594">
{
    unsigned long flags, pfn, pfninc = 1;
    unsigned int i, level;
    pte_t *pbase, *tmp;
    pgprot_t ref_prot;
    struct page *base;
    if (!debug_pagealloc)
        spin_unlock (&cpa_lock);
    base = alloc_pages (GFP_KERNEL | __GFP_NOTRACK, 0);
    if (!debug_pagealloc)
        spin_lock (&cpa_lock);
    if (!base)
        return -ENOMEM;
    spin_lock_irqsave (& pgd_lock, flags);
    tmp = lookup_address (address, &level);
    if (tmp != kpte)
        goto out_unlock;
    pbase = (pte_t *) page_address (base);
    paravirt_alloc_pte (& init_mm, page_to_pfn (base));
    ref_prot = pte_pgprot (pte_clrhuge (*kpte));
    WARN_ON_ONCE (pgprot_val (ref_prot) & _PAGE_PAT_LARGE);
    pfn = pte_pfn (*kpte);
    for (i = 0; i < PTRS_PER_PTE; i++, pfn += pfninc)
        set_pte (&pbase[i], pfn_pte (pfn, ref_prot));
    if (address >= (unsigned long) __va (0) && address < (unsigned long) __va (max_low_pfn_mapped << PAGE_SHIFT))
        split_page_count (level);
    __set_pmd_pte (kpte, address, mk_pte (base, __pgprot (_KERNPG_TABLE)));
    __flush_tlb_all ();
    base = NULL;
out_unlock :
    if (base)
        __free_page (base);
    spin_unlock_irqrestore (& pgd_lock, flags);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="598" endline="624">
{
    if (!primary)
        return 0;
    if (within (vaddr, PAGE_OFFSET, PAGE_OFFSET +(max_pfn_mapped << PAGE_SHIFT))) {
        cpa->numpages = 1;
        cpa->pfn = __pa (vaddr) >> PAGE_SHIFT;
        return 0;
    }
    else {
        WARN (1, KERN_WARNING "CPA: called for zero pte. " "vaddr = %lx cpa->vaddr = %lx\n", vaddr, * cpa -> vaddr);
        return -EFAULT;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="613" endline="617">
{
    cpa->numpages = 1;
    cpa->pfn = __pa (vaddr) >> PAGE_SHIFT;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="617" endline="623">
{
    WARN (1, KERN_WARNING "CPA: called for zero pte. " "vaddr = %lx cpa->vaddr = %lx\n", vaddr, * cpa -> vaddr);
    return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="627" endline="720">
{
    unsigned long address;
    int do_split, err;
    unsigned int level;
    pte_t *kpte, old_pte;
    if (cpa->flags & CPA_PAGES_ARRAY) {
        struct page *page = cpa->pages[cpa->curpage];
        if (unlikely (PageHighMem (page)))
            return 0;
        address = (unsigned long) page_address (page);
    }
    else if (cpa->flags & CPA_ARRAY)
        address = cpa->vaddr[cpa->curpage];
    else
        address = *cpa->vaddr;
repeat :
    kpte = lookup_address (address, &level);
    if (!kpte)
        return __cpa_process_fault (cpa, address, primary);
    old_pte = *kpte;
    if (!pte_val (old_pte))
        return __cpa_process_fault (cpa, address, primary);
    if (level == PG_LEVEL_4K) {
        pte_t new_pte;
        pgprot_t new_prot = pte_pgprot (old_pte);
        unsigned long pfn = pte_pfn (old_pte);
        pgprot_val (new_prot) &= ~pgprot_val (cpa->mask_clr);
        pgprot_val (new_prot) |= pgprot_val (cpa->mask_set);
        new_prot = static_protections (new_prot, address, pfn);
        new_pte = pfn_pte (pfn, canon_pgprot (new_prot));
        cpa->pfn = pfn;
        if (pte_val (old_pte) != pte_val (new_pte)) {
            set_pte_atomic (kpte, new_pte);
            cpa->flags |= CPA_FLUSHTLB;
        }
        cpa->numpages = 1;
        return 0;
    }
    do_split = try_preserve_large_page (kpte, address, cpa);
    if (do_split <= 0)
        return do_split;
    err = split_large_page (kpte, address);
    if (!err) {
        flush_tlb_all ();
        goto repeat;
    }
    return err;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="633" endline="638">
{
    struct page *page = cpa->pages[cpa->curpage];
    if (unlikely (PageHighMem (page)))
        return 0;
    address = (unsigned long) page_address (page);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="651" endline="677">
{
    pte_t new_pte;
    pgprot_t new_prot = pte_pgprot (old_pte);
    unsigned long pfn = pte_pfn (old_pte);
    pgprot_val (new_prot) &= ~pgprot_val (cpa->mask_clr);
    pgprot_val (new_prot) |= pgprot_val (cpa->mask_set);
    new_prot = static_protections (new_prot, address, pfn);
    new_pte = pfn_pte (pfn, canon_pgprot (new_prot));
    cpa->pfn = pfn;
    if (pte_val (old_pte) != pte_val (new_pte)) {
        set_pte_atomic (kpte, new_pte);
        cpa->flags |= CPA_FLUSHTLB;
    }
    cpa->numpages = 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="671" endline="674">
{
    set_pte_atomic (kpte, new_pte);
    cpa->flags |= CPA_FLUSHTLB;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="696" endline="717">
{
    flush_tlb_all ();
    goto repeat;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="725" endline="787">
{
    struct cpa_data alias_cpa;
    unsigned long laddr = (unsigned long) __va (cpa->pfn << PAGE_SHIFT);
    unsigned long vaddr;
    int ret;
    if (cpa->pfn >= max_pfn_mapped)
        return 0;
    if (cpa->flags & CPA_PAGES_ARRAY) {
        struct page *page = cpa->pages[cpa->curpage];
        if (unlikely (PageHighMem (page)))
            return 0;
        vaddr = (unsigned long) page_address (page);
    }
    else if (cpa->flags & CPA_ARRAY)
        vaddr = cpa->vaddr[cpa->curpage];
    else
        vaddr = *cpa->vaddr;
    if (!(within (vaddr, PAGE_OFFSET, PAGE_OFFSET +(max_pfn_mapped << PAGE_SHIFT)))) {
        alias_cpa = *cpa;
        alias_cpa.vaddr = &laddr;
        alias_cpa.flags &= ~(CPA_PAGES_ARRAY | CPA_ARRAY);
        ret = __change_page_attr_set_clr (&alias_cpa, 0);
        if (ret)
            return ret;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="742" endline="747">
{
    struct page *page = cpa->pages[cpa->curpage];
    if (unlikely (PageHighMem (page)))
        return 0;
    vaddr = (unsigned long) page_address (page);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="753" endline="762">
{
    alias_cpa = *cpa;
    alias_cpa.vaddr = &laddr;
    alias_cpa.flags &= ~(CPA_PAGES_ARRAY | CPA_ARRAY);
    ret = __change_page_attr_set_clr (&alias_cpa, 0);
    if (ret)
        return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="790" endline="831">
{
    int ret, numpages = cpa->numpages;
    while (numpages) {
        cpa->numpages = numpages;
        if (cpa->flags & (CPA_ARRAY | CPA_PAGES_ARRAY))
            cpa->numpages = 1;
        if (!debug_pagealloc)
            spin_lock (&cpa_lock);
        ret = __change_page_attr (cpa, checkalias);
        if (!debug_pagealloc)
            spin_unlock (&cpa_lock);
        if (ret)
            return ret;
        if (checkalias) {
            ret = cpa_process_alias (cpa);
            if (ret)
                return ret;
        }
        BUG_ON (cpa -> numpages > numpages);
        numpages -= cpa->numpages;
        if (cpa->flags & (CPA_PAGES_ARRAY | CPA_ARRAY))
            cpa->curpage++;
        else
            *cpa->vaddr += cpa->numpages * PAGE_SIZE;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="793" endline="829">
{
    cpa->numpages = numpages;
    if (cpa->flags & (CPA_ARRAY | CPA_PAGES_ARRAY))
        cpa->numpages = 1;
    if (!debug_pagealloc)
        spin_lock (&cpa_lock);
    ret = __change_page_attr (cpa, checkalias);
    if (!debug_pagealloc)
        spin_unlock (&cpa_lock);
    if (ret)
        return ret;
    if (checkalias) {
        ret = cpa_process_alias (cpa);
        if (ret)
            return ret;
    }
    BUG_ON (cpa -> numpages > numpages);
    numpages -= cpa->numpages;
    if (cpa->flags & (CPA_PAGES_ARRAY | CPA_ARRAY))
        cpa->curpage++;
    else
        *cpa->vaddr += cpa->numpages * PAGE_SIZE;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="811" endline="815">
{
    ret = cpa_process_alias (cpa);
    if (ret)
        return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="834" endline="837">
{
    return pgprot_val (attr) & (_PAGE_PAT | _PAGE_PAT_LARGE | _PAGE_PWT | _PAGE_PCD);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="843" endline="936">
{
    struct cpa_data cpa;
    int ret, cache, checkalias;
    unsigned long baddr = 0;
    mask_set = canon_pgprot (mask_set);
    mask_clr = canon_pgprot (mask_clr);
    if (!pgprot_val (mask_set) && !pgprot_val (mask_clr) && !force_split)
        return 0;
    if (in_flag & CPA_ARRAY) {
        int i;
        for (i = 0; i < numpages; i++) {
            if (addr[i] & ~PAGE_MASK) {
                addr[i] &= PAGE_MASK;
                WARN_ON_ONCE (1);
            }
        }
    }
    else if (!(in_flag & CPA_PAGES_ARRAY)) {
        if (*addr & ~PAGE_MASK) {
            *addr &= PAGE_MASK;
            WARN_ON_ONCE (1);
        }
        baddr = *addr;
    }
    kmap_flush_unused ();
    vm_unmap_aliases ();
    cpa.vaddr = addr;
    cpa.pages = pages;
    cpa.numpages = numpages;
    cpa.mask_set = mask_set;
    cpa.mask_clr = mask_clr;
    cpa.flags = 0;
    cpa.curpage = 0;
    cpa.force_split = force_split;
    if (in_flag & (CPA_ARRAY | CPA_PAGES_ARRAY))
        cpa.flags |= in_flag;
    checkalias = (pgprot_val (mask_set) | pgprot_val (mask_clr)) != _PAGE_NX;
    ret = __change_page_attr_set_clr (&cpa, checkalias);
    if (!(cpa.flags & CPA_FLUSHTLB))
        goto out;
    cache = cache_attr (mask_set);
    if (!ret && cpu_has_clflush) {
        if (cpa.flags & (CPA_PAGES_ARRAY | CPA_ARRAY)) {
            cpa_flush_array (addr, numpages, cache, cpa.flags, pages);
        }
        else
            cpa_flush_range (baddr, numpages, cache);
    }
    else
        cpa_flush_all (cache);
out :
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="858" endline="866">
{
    int i;
    for (i = 0; i < numpages; i++) {
        if (addr[i] & ~PAGE_MASK) {
            addr[i] &= PAGE_MASK;
            WARN_ON_ONCE (1);
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="860" endline="865">
{
    if (addr[i] & ~PAGE_MASK) {
        addr[i] &= PAGE_MASK;
        WARN_ON_ONCE (1);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="861" endline="864">
{
    addr[i] &= PAGE_MASK;
    WARN_ON_ONCE (1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="866" endline="883">
{
    if (*addr & ~PAGE_MASK) {
        *addr &= PAGE_MASK;
        WARN_ON_ONCE (1);
    }
    baddr = *addr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="871" endline="877">
{
    *addr &= PAGE_MASK;
    WARN_ON_ONCE (1);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="925" endline="931">
{
    if (cpa.flags & (CPA_PAGES_ARRAY | CPA_ARRAY)) {
        cpa_flush_array (addr, numpages, cache, cpa.flags, pages);
    }
    else
        cpa_flush_range (baddr, numpages, cache);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="926" endline="929">
{
    cpa_flush_array (addr, numpages, cache, cpa.flags, pages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="940" endline="943">
{
    return change_page_attr_set_clr (addr, numpages, mask, __pgprot (0), 0, (array ? CPA_ARRAY : 0), NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="947" endline="950">
{
    return change_page_attr_set_clr (addr, numpages, __pgprot (0), mask, 0, (array ? CPA_ARRAY : 0), NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="954" endline="957">
{
    return change_page_attr_set_clr (NULL, numpages, mask, __pgprot (0), 0, CPA_PAGES_ARRAY, pages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="961" endline="964">
{
    return change_page_attr_set_clr (NULL, numpages, __pgprot (0), mask, 0, CPA_PAGES_ARRAY, pages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="967" endline="973">
{
    return change_page_attr_set (&addr, numpages, __pgprot (_PAGE_CACHE_UC_MINUS), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="976" endline="997">
{
    int ret;
    ret = reserve_memtype (__pa (addr), __pa (addr) +numpages * PAGE_SIZE, _PAGE_CACHE_UC_MINUS, NULL);
    if (ret)
        goto out_err;
    ret = _set_memory_uc (addr, numpages);
    if (ret)
        goto out_free;
    return 0;
out_free :
    free_memtype (__pa (addr), __pa (addr) +numpages * PAGE_SIZE);
out_err :
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1001" endline="1027">
{
    int i, j;
    int ret;
    for (i = 0; i < addrinarray; i++) {
        ret = reserve_memtype (__pa (addr[i]), __pa (addr[i]) + PAGE_SIZE, _PAGE_CACHE_UC_MINUS, NULL);
        if (ret)
            goto out_free;
    }
    ret = change_page_attr_set (addr, addrinarray, __pgprot (_PAGE_CACHE_UC_MINUS), 1);
    if (ret)
        goto out_free;
    return 0;
out_free :
    for (j = 0; j < i; j++)
        free_memtype (__pa (addr[j]), __pa (addr[j]) + PAGE_SIZE);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1008" endline="1013">
{
    ret = reserve_memtype (__pa (addr[i]), __pa (addr[i]) + PAGE_SIZE, _PAGE_CACHE_UC_MINUS, NULL);
    if (ret)
        goto out_free;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1031" endline="1044">
{
    int ret;
    unsigned long addr_copy = addr;
    ret = change_page_attr_set (&addr, numpages, __pgprot (_PAGE_CACHE_UC_MINUS), 0);
    if (!ret) {
        ret = change_page_attr_set_clr (&addr_copy, numpages, __pgprot (_PAGE_CACHE_WC), __pgprot (_PAGE_CACHE_MASK), 0, 0, NULL);
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1037" endline="1042">
{
    ret = change_page_attr_set_clr (&addr_copy, numpages, __pgprot (_PAGE_CACHE_WC), __pgprot (_PAGE_CACHE_MASK), 0, 0, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1047" endline="1068">
{
    int ret;
    if (!pat_enabled)
        return set_memory_uc (addr, numpages);
    ret = reserve_memtype (__pa (addr), __pa (addr) +numpages * PAGE_SIZE, _PAGE_CACHE_WC, NULL);
    if (ret)
        goto out_err;
    ret = _set_memory_wc (addr, numpages);
    if (ret)
        goto out_free;
    return 0;
out_free :
    free_memtype (__pa (addr), __pa (addr) +numpages * PAGE_SIZE);
out_err :
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1072" endline="1075">
{
    return change_page_attr_clear (&addr, numpages, __pgprot (_PAGE_CACHE_MASK), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1078" endline="1087">
{
    int ret;
    ret = _set_memory_wb (addr, numpages);
    if (ret)
        return ret;
    free_memtype (__pa (addr), __pa (addr) + numpages * PAGE_SIZE);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1091" endline="1104">
{
    int i;
    int ret;
    ret = change_page_attr_clear (addr, addrinarray, __pgprot (_PAGE_CACHE_MASK), 1);
    if (ret)
        return ret;
    for (i = 0; i < addrinarray; i++)
        free_memtype (__pa (addr[i]), __pa (addr[i]) + PAGE_SIZE);
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1108" endline="1113">
{
    if (!(__supported_pte_mask & _PAGE_NX))
        return 0;
    return change_page_attr_clear (&addr, numpages, __pgprot (_PAGE_NX), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1117" endline="1122">
{
    if (!(__supported_pte_mask & _PAGE_NX))
        return 0;
    return change_page_attr_set (&addr, numpages, __pgprot (_PAGE_NX), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1126" endline="1128">
{
    return change_page_attr_clear (&addr, numpages, __pgprot (_PAGE_RW), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1132" endline="1134">
{
    return change_page_attr_set (&addr, numpages, __pgprot (_PAGE_RW), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1138" endline="1140">
{
    return change_page_attr_clear (&addr, numpages, __pgprot (_PAGE_PRESENT), 0);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1143" endline="1146">
{
    return change_page_attr_set_clr (&addr, numpages, __pgprot (0), __pgprot (0), 1, 0, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1149" endline="1153">
{
    unsigned long addr = (unsigned long) page_address (page);
    return set_memory_uc (addr, numpages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1157" endline="1186">
{
    unsigned long start;
    unsigned long end;
    int i;
    int free_idx;
    for (i = 0; i < addrinarray; i++) {
        if (PageHighMem (pages[i]))
            continue;
        start = page_to_pfn (pages[i]) << PAGE_SHIFT;
        end = start + PAGE_SIZE;
        if (reserve_memtype (start, end, _PAGE_CACHE_UC_MINUS, NULL))
            goto err_out;
    }
    if (cpa_set_pages_array (pages, addrinarray, __pgprot (_PAGE_CACHE_UC_MINUS)) == 0) {
        return 0;
    }
err_out :
    free_idx = i;
    for (i = 0; i < free_idx; i++) {
        if (PageHighMem (pages[i]))
            continue;
        start = page_to_pfn (pages[i]) << PAGE_SHIFT;
        end = start + PAGE_SIZE;
        free_memtype (start, end);
    }
    return -EINVAL;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1163" endline="1170">
{
    if (PageHighMem (pages[i]))
        continue;
    start = page_to_pfn (pages[i]) << PAGE_SHIFT;
    end = start + PAGE_SIZE;
    if (reserve_memtype (start, end, _PAGE_CACHE_UC_MINUS, NULL))
        goto err_out;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1173" endline="1175">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1178" endline="1184">
{
    if (PageHighMem (pages[i]))
        continue;
    start = page_to_pfn (pages[i]) << PAGE_SHIFT;
    end = start + PAGE_SIZE;
    free_memtype (start, end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1190" endline="1194">
{
    unsigned long addr = (unsigned long) page_address (page);
    return set_memory_wb (addr, numpages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1198" endline="1218">
{
    int retval;
    unsigned long start;
    unsigned long end;
    int i;
    retval = cpa_clear_pages_array (pages, addrinarray, __pgprot (_PAGE_CACHE_MASK));
    if (retval)
        return retval;
    for (i = 0; i < addrinarray; i++) {
        if (PageHighMem (pages[i]))
            continue;
        start = page_to_pfn (pages[i]) << PAGE_SHIFT;
        end = start + PAGE_SIZE;
        free_memtype (start, end);
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1209" endline="1215">
{
    if (PageHighMem (pages[i]))
        continue;
    start = page_to_pfn (pages[i]) << PAGE_SHIFT;
    end = start + PAGE_SIZE;
    free_memtype (start, end);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1222" endline="1226">
{
    unsigned long addr = (unsigned long) page_address (page);
    return set_memory_x (addr, numpages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1230" endline="1234">
{
    unsigned long addr = (unsigned long) page_address (page);
    return set_memory_nx (addr, numpages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1238" endline="1242">
{
    unsigned long addr = (unsigned long) page_address (page);
    return set_memory_ro (addr, numpages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/pageattr.c.ifdefed" startline="1245" endline="1249">
{
    unsigned long addr = (unsigned long) page_address (page);
    return set_memory_rw (addr, numpages);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/setup_nx.c.ifdefed" startline="19" endline="29">
{
    if (!str)
        return -EINVAL;
    if (!strncmp (str, "on", 2)) {
        disable_nx = 0;
    }
    else if (!strncmp (str, "off", 3)) {
        disable_nx = 1;
    }
    x86_configure_nx ();
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/setup_nx.c.ifdefed" startline="22" endline="24">
{
    disable_nx = 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/setup_nx.c.ifdefed" startline="24" endline="26">
{
    disable_nx = 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/setup_nx.c.ifdefed" startline="33" endline="38">
{
    if (cpu_has_nx && !disable_nx)
        __supported_pte_mask |= _PAGE_NX;
    else
        __supported_pte_mask &= ~_PAGE_NX;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/setup_nx.c.ifdefed" startline="41" endline="60">
{
    if (!cpu_has_nx) {
        printk (KERN_NOTICE "Notice: NX (Execute Disable) protection " "missing in CPU or disabled in BIOS!\n");
    }
    else {
        printk (KERN_NOTICE "Notice: NX (Execute Disable) protection " "cannot be enabled: non-PAE kernel!\n");
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/setup_nx.c.ifdefed" startline="42" endline="45">
{
    printk (KERN_NOTICE "Notice: NX (Execute Disable) protection " "missing in CPU or disabled in BIOS!\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/setup_nx.c.ifdefed" startline="45" endline="59">
{
    printk (KERN_NOTICE "Notice: NX (Execute Disable) protection " "cannot be enabled: non-PAE kernel!\n");
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="22" endline="42">
{
    unsigned long saddr = ((idx - svma->vm_pgoff) << PAGE_SHIFT) + svma->vm_start;
    unsigned long sbase = saddr & PUD_MASK;
    unsigned long s_end = sbase + PUD_SIZE;
    unsigned long vm_flags = vma->vm_flags & ~VM_LOCKED;
    unsigned long svm_flags = svma->vm_flags & ~VM_LOCKED;
    if (pmd_index (addr) != pmd_index (saddr) || vm_flags != svm_flags || sbase < svma->vm_start || svma->vm_end < s_end)
        return 0;
    return saddr;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="45" endline="56">
{
    unsigned long base = addr & PUD_MASK;
    unsigned long end = base + PUD_SIZE;
    if (vma->vm_flags & VM_MAYSHARE && vma->vm_start <= base && end <= vma->vm_end)
        return 1;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="62" endline="101">
{
    struct vm_area_struct *vma = find_vma (mm, addr);
    struct address_space *mapping = vma->vm_file->f_mapping;
    pgoff_t idx = ((addr - vma->vm_start) >> PAGE_SHIFT) + vma->vm_pgoff;
    struct prio_tree_iter iter;
    struct vm_area_struct *svma;
    unsigned long saddr;
    pte_t *spte = NULL;
    if (!vma_shareable (vma, addr))
        return;
    spin_lock (& mapping -> i_mmap_lock);
    vma_prio_tree_foreach (svma, & iter, & mapping -> i_mmap, idx, idx)
    {
        if (svma == vma)
            continue;
        saddr = page_table_shareable (svma, vma, addr, idx);
        if (saddr) {
            spte = huge_pte_offset (svma->vm_mm, saddr);
            if (spte) {
                get_page (virt_to_page (spte));
                break;
            }
        }
    }
    if (!spte)
        goto out;
    spin_lock (& mm -> page_table_lock);
    if (pud_none (*pud))
        pud_populate (mm, pud, (pmd_t *) ((unsigned long) spte & PAGE_MASK));
    else
        put_page (virt_to_page (spte));
    spin_unlock (& mm -> page_table_lock);
out :
    spin_unlock (&mapping->i_mmap_lock);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="76" endline="88">
{
    if (svma == vma)
        continue;
    saddr = page_table_shareable (svma, vma, addr, idx);
    if (saddr) {
        spte = huge_pte_offset (svma->vm_mm, saddr);
        if (spte) {
            get_page (virt_to_page (spte));
            break;
        }
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="81" endline="87">
{
    spte = huge_pte_offset (svma->vm_mm, saddr);
    if (spte) {
        get_page (virt_to_page (spte));
        break;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="83" endline="86">
{
    get_page (virt_to_page (spte));
    break;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="116" endline="128">
{
    pgd_t *pgd = pgd_offset (mm, *addr);
    pud_t *pud = pud_offset (pgd, *addr);
    BUG_ON (page_count (virt_to_page (ptep)) == 0);
    if (page_count (virt_to_page (ptep)) == 1)
        return 0;
    pud_clear (pud);
    put_page (virt_to_page (ptep));
    *addr = ALIGN (*addr, HPAGE_SIZE *PTRS_PER_PTE) - HPAGE_SIZE;
    return 1;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="132" endline="152">
{
    pgd_t *pgd;
    pud_t *pud;
    pte_t *pte = NULL;
    pgd = pgd_offset (mm, addr);
    pud = pud_alloc (mm, pgd, addr);
    if (pud) {
        if (sz == PUD_SIZE) {
            pte = (pte_t *) pud;
        }
        else {
            BUG_ON (sz != PMD_SIZE);
            if (pud_none (*pud))
                huge_pmd_share (mm, addr, pud);
            pte = (pte_t *) pmd_alloc (mm, pud, addr);
        }
    }
    BUG_ON (pte && ! pte_none (* pte) && ! pte_huge (* pte));
    return pte;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="139" endline="148">
{
    if (sz == PUD_SIZE) {
        pte = (pte_t *) pud;
    }
    else {
        BUG_ON (sz != PMD_SIZE);
        if (pud_none (*pud))
            huge_pmd_share (mm, addr, pud);
        pte = (pte_t *) pmd_alloc (mm, pud, addr);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="140" endline="142">
{
    pte = (pte_t *) pud;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="142" endline="147">
{
    BUG_ON (sz != PMD_SIZE);
    if (pud_none (*pud))
        huge_pmd_share (mm, addr, pud);
    pte = (pte_t *) pmd_alloc (mm, pud, addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="155" endline="170">
{
    pgd_t *pgd;
    pud_t *pud;
    pmd_t *pmd = NULL;
    pgd = pgd_offset (mm, addr);
    if (pgd_present (*pgd)) {
        pud = pud_offset (pgd, addr);
        if (pud_present (*pud)) {
            if (pud_large (*pud))
                return (pte_t *) pud;
            pmd = pmd_offset (pud, addr);
        }
    }
    return (pte_t *) pmd;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="161" endline="168">
{
    pud = pud_offset (pgd, addr);
    if (pud_present (*pud)) {
        if (pud_large (*pud))
            return (pte_t *) pud;
        pmd = pmd_offset (pud, addr);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="163" endline="167">
{
    if (pud_large (*pud))
        return (pte_t *) pud;
    pmd = pmd_offset (pud, addr);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="219" endline="221">
{
    return ERR_PTR (-EINVAL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="224" endline="226">
{
    return !!(pmd_val (pmd) & _PAGE_PSE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="229" endline="231">
{
    return !!(pud_val (pud) & _PAGE_PSE);
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="236" endline="243">
{
    struct page *page;
    page = pte_page (*(pte_t*) pmd);
    if (page)
        page += ((address & ~PMD_MASK) >> PAGE_SHIFT);
    return page;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/hugetlbpage.c.ifdefed" startline="248" endline="255">
{
    struct page *page;
    page = pte_page (*(pte_t*) pud);
    if (page)
        page += ((address & ~PUD_MASK) >> PAGE_SHIFT);
    return page;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="35" endline="43">
{
    unsigned int max = 0;
    if ((current->flags & PF_RANDOMIZE) && !(current->personality & ADDR_NO_RANDOMIZE)) {
        max = ((-1U) & STACK_RND_MASK) << PAGE_SHIFT;
    }
    return max;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="38" endline="40">
{
    max = ((-1U) & STACK_RND_MASK) << PAGE_SHIFT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="58" endline="67">
{
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="70" endline="78">
{
    if (current->personality & ADDR_COMPAT_LAYOUT)
        return 1;
    if (rlimit (RLIMIT_STACK) == RLIM_INFINITY)
        return 1;
    return sysctl_legacy_va_layout;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="81" endline="95">
{
    unsigned long rnd = 0;
    if (current->flags & PF_RANDOMIZE) {
        if (mmap_is_ia32 ())
            rnd = (long) get_random_int () % (1 << 8);
        else
            rnd = (long) (get_random_int () % (1 << 28));
    }
    return rnd << PAGE_SHIFT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="88" endline="93">
{
    if (mmap_is_ia32 ())
        rnd = (long) get_random_int () % (1 << 8);
    else
        rnd = (long) (get_random_int () % (1 << 28));
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="98" endline="107">
{
    unsigned long gap = rlimit (RLIMIT_STACK);
    if (gap < MIN_GAP)
        gap = MIN_GAP;
    else if (gap > MAX_GAP)
        gap = MAX_GAP;
    return PAGE_ALIGN (TASK_SIZE -gap - mmap_rnd ());
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="114" endline="119">
{
    if (mmap_is_ia32 ())
        return TASK_UNMAPPED_BASE;
    else
        return TASK_UNMAPPED_BASE + mmap_rnd ();
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="126" endline="136">
{
    if (mmap_is_legacy ()) {
        mm->mmap_base = mmap_legacy_base ();
        mm->get_unmapped_area = arch_get_unmapped_area;
        mm->unmap_area = arch_unmap_area;
    }
    else {
        mm->mmap_base = mmap_base ();
        mm->get_unmapped_area = arch_get_unmapped_area_topdown;
        mm->unmap_area = arch_unmap_area_topdown;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="127" endline="131">
{
    mm->mmap_base = mmap_legacy_base ();
    mm->get_unmapped_area = arch_get_unmapped_area;
    mm->unmap_area = arch_unmap_area;
}
</source>
<source file="/cmpt816/tmp/arch/x86/mm/mmap.c.ifdefed" startline="131" endline="135">
{
    mm->mmap_base = mmap_base ();
    mm->get_unmapped_area = arch_get_unmapped_area_topdown;
    mm->unmap_area = arch_unmap_area_topdown;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="57" endline="59">
{
    return sys_truncate (filename, ((loff_t) offset_high << 32) | offset_low);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="63" endline="65">
{
    return sys_ftruncate (fd, ((loff_t) offset_high << 32) | offset_low);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="72" endline="97">
{
    typeof (ubuf->st_uid) uid = 0;
    typeof (ubuf->st_gid) gid = 0;
    SET_UID (uid, stat -> uid);
    SET_GID (gid, stat -> gid);
    if (!access_ok (VERIFY_WRITE, ubuf, sizeof (struct stat64)) || __put_user (huge_encode_dev (stat->dev), &ubuf->st_dev) || __put_user (stat->ino, &ubuf->__st_ino) || __put_user (stat->ino, &ubuf->st_ino) || __put_user (stat->mode, &ubuf->st_mode) || __put_user (stat->nlink, &ubuf->st_nlink) || __put_user (uid, &ubuf->st_uid) || __put_user (gid, &ubuf->st_gid) || __put_user (huge_encode_dev (stat->rdev), &ubuf->st_rdev) || __put_user (stat->size, &ubuf->st_size) || __put_user (stat->atime.tv_sec, &ubuf->st_atime) || __put_user (stat->atime.tv_nsec, &ubuf->st_atime_nsec) || __put_user (stat->mtime.tv_sec, &ubuf->st_mtime) || __put_user (stat->mtime.tv_nsec, &ubuf->st_mtime_nsec) || __put_user (stat->ctime.tv_sec, &ubuf->st_ctime) || __put_user (stat->ctime.tv_nsec, &ubuf->st_ctime_nsec) || __put_user (stat->blksize, &ubuf->st_blksize) || __put_user (stat->blocks, &ubuf->st_blocks))
        return -EFAULT;
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="101" endline="108">
{
    struct kstat stat;
    int ret = vfs_stat (filename, &stat);
    if (!ret)
        ret = cp_stat64 (statbuf, &stat);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="112" endline="118">
{
    struct kstat stat;
    int ret = vfs_lstat (filename, &stat);
    if (!ret)
        ret = cp_stat64 (statbuf, &stat);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="121" endline="127">
{
    struct kstat stat;
    int ret = vfs_fstat (fd, &stat);
    if (!ret)
        ret = cp_stat64 (statbuf, &stat);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="131" endline="139">
{
    struct kstat stat;
    int error;
    error = vfs_fstatat (dfd, filename, &stat, flag);
    if (error)
        return error;
    return cp_stat64 (statbuf, &stat);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="157" endline="168">
{
    struct mmap_arg_struct32 a;
    if (copy_from_user (&a, arg, sizeof (a)))
        return -EFAULT;
    if (a.offset & ~PAGE_MASK)
        return -EINVAL;
    return sys_mmap_pgoff (a.addr, a.len, a.prot, a.flags, a.fd, a.offset >> PAGE_SHIFT);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="172" endline="174">
{
    return sys_mprotect (start, len, prot);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="179" endline="250">
{
    struct k_sigaction new_ka, old_ka;
    int ret;
    compat_sigset_t set32;
    if (sigsetsize != sizeof (compat_sigset_t))
        return -EINVAL;
    if (act) {
        compat_uptr_t handler, restorer;
        if (!access_ok (VERIFY_READ, act, sizeof (*act)) || __get_user (handler, &act->sa_handler) || __get_user (new_ka.sa.sa_flags, &act->sa_flags) || __get_user (restorer, &act->sa_restorer) || __copy_from_user (&set32, &act->sa_mask, sizeof (compat_sigset_t)))
            return -EFAULT;
        new_ka.sa.sa_handler = compat_ptr (handler);
        new_ka.sa.sa_restorer = compat_ptr (restorer);
        switch (_NSIG_WORDS) {
        case 4 :
            new_ka.sa.sa_mask.sig[3] = set32.sig[6] | (((long) set32.sig[7]) << 32);
        case 3 :
            new_ka.sa.sa_mask.sig[2] = set32.sig[4] | (((long) set32.sig[5]) << 32);
        case 2 :
            new_ka.sa.sa_mask.sig[1] = set32.sig[2] | (((long) set32.sig[3]) << 32);
        case 1 :
            new_ka.sa.sa_mask.sig[0] = set32.sig[0] | (((long) set32.sig[1]) << 32);
        }
    }
    ret = do_sigaction (sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);
    if (!ret && oact) {
        switch (_NSIG_WORDS) {
        case 4 :
            set32.sig[7] = (old_ka.sa.sa_mask.sig[3] >> 32);
            set32.sig[6] = old_ka.sa.sa_mask.sig[3];
        case 3 :
            set32.sig[5] = (old_ka.sa.sa_mask.sig[2] >> 32);
            set32.sig[4] = old_ka.sa.sa_mask.sig[2];
        case 2 :
            set32.sig[3] = (old_ka.sa.sa_mask.sig[1] >> 32);
            set32.sig[2] = old_ka.sa.sa_mask.sig[1];
        case 1 :
            set32.sig[1] = (old_ka.sa.sa_mask.sig[0] >> 32);
            set32.sig[0] = old_ka.sa.sa_mask.sig[0];
        }
        if (!access_ok (VERIFY_WRITE, oact, sizeof (*oact)) || __put_user (ptr_to_compat (old_ka.sa.sa_handler), &oact->sa_handler) || __put_user (ptr_to_compat (old_ka.sa.sa_restorer), &oact->sa_restorer) || __put_user (old_ka.sa.sa_flags, &oact->sa_flags) || __copy_to_user (&oact->sa_mask, &set32, sizeof (compat_sigset_t)))
            return -EFAULT;
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="188" endline="215">
{
    compat_uptr_t handler, restorer;
    if (!access_ok (VERIFY_READ, act, sizeof (*act)) || __get_user (handler, &act->sa_handler) || __get_user (new_ka.sa.sa_flags, &act->sa_flags) || __get_user (restorer, &act->sa_restorer) || __copy_from_user (&set32, &act->sa_mask, sizeof (compat_sigset_t)))
        return -EFAULT;
    new_ka.sa.sa_handler = compat_ptr (handler);
    new_ka.sa.sa_restorer = compat_ptr (restorer);
    switch (_NSIG_WORDS) {
    case 4 :
        new_ka.sa.sa_mask.sig[3] = set32.sig[6] | (((long) set32.sig[7]) << 32);
    case 3 :
        new_ka.sa.sa_mask.sig[2] = set32.sig[4] | (((long) set32.sig[5]) << 32);
    case 2 :
        new_ka.sa.sa_mask.sig[1] = set32.sig[2] | (((long) set32.sig[3]) << 32);
    case 1 :
        new_ka.sa.sa_mask.sig[0] = set32.sig[0] | (((long) set32.sig[1]) << 32);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="205" endline="214">
{
case 4 :
    new_ka.sa.sa_mask.sig[3] = set32.sig[6] | (((long) set32.sig[7]) << 32);
case 3 :
    new_ka.sa.sa_mask.sig[2] = set32.sig[4] | (((long) set32.sig[5]) << 32);
case 2 :
    new_ka.sa.sa_mask.sig[1] = set32.sig[2] | (((long) set32.sig[3]) << 32);
case 1 :
    new_ka.sa.sa_mask.sig[0] = set32.sig[0] | (((long) set32.sig[1]) << 32);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="219" endline="247">
{
    switch (_NSIG_WORDS) {
    case 4 :
        set32.sig[7] = (old_ka.sa.sa_mask.sig[3] >> 32);
        set32.sig[6] = old_ka.sa.sa_mask.sig[3];
    case 3 :
        set32.sig[5] = (old_ka.sa.sa_mask.sig[2] >> 32);
        set32.sig[4] = old_ka.sa.sa_mask.sig[2];
    case 2 :
        set32.sig[3] = (old_ka.sa.sa_mask.sig[1] >> 32);
        set32.sig[2] = old_ka.sa.sa_mask.sig[1];
    case 1 :
        set32.sig[1] = (old_ka.sa.sa_mask.sig[0] >> 32);
        set32.sig[0] = old_ka.sa.sa_mask.sig[0];
    }
    if (!access_ok (VERIFY_WRITE, oact, sizeof (*oact)) || __put_user (ptr_to_compat (old_ka.sa.sa_handler), &oact->sa_handler) || __put_user (ptr_to_compat (old_ka.sa.sa_restorer), &oact->sa_restorer) || __put_user (old_ka.sa.sa_flags, &oact->sa_flags) || __copy_to_user (&oact->sa_mask, &set32, sizeof (compat_sigset_t)))
        return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="224" endline="237">
{
case 4 :
    set32.sig[7] = (old_ka.sa.sa_mask.sig[3] >> 32);
    set32.sig[6] = old_ka.sa.sa_mask.sig[3];
case 3 :
    set32.sig[5] = (old_ka.sa.sa_mask.sig[2] >> 32);
    set32.sig[4] = old_ka.sa.sa_mask.sig[2];
case 2 :
    set32.sig[3] = (old_ka.sa.sa_mask.sig[1] >> 32);
    set32.sig[2] = old_ka.sa.sa_mask.sig[1];
case 1 :
    set32.sig[1] = (old_ka.sa.sa_mask.sig[0] >> 32);
    set32.sig[0] = old_ka.sa.sa_mask.sig[0];
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="254" endline="289">
{
    struct k_sigaction new_ka, old_ka;
    int ret;
    if (act) {
        compat_old_sigset_t mask;
        compat_uptr_t handler, restorer;
        if (!access_ok (VERIFY_READ, act, sizeof (*act)) || __get_user (handler, &act->sa_handler) || __get_user (new_ka.sa.sa_flags, &act->sa_flags) || __get_user (restorer, &act->sa_restorer) || __get_user (mask, &act->sa_mask))
            return -EFAULT;
        new_ka.sa.sa_handler = compat_ptr (handler);
        new_ka.sa.sa_restorer = compat_ptr (restorer);
        siginitset (& new_ka.sa.sa_mask, mask);
    }
    ret = do_sigaction (sig, act ? &new_ka : NULL, oact ? &old_ka : NULL);
    if (!ret && oact) {
        if (!access_ok (VERIFY_WRITE, oact, sizeof (*oact)) || __put_user (ptr_to_compat (old_ka.sa.sa_handler), &oact->sa_handler) || __put_user (ptr_to_compat (old_ka.sa.sa_restorer), &oact->sa_restorer) || __put_user (old_ka.sa.sa_flags, &oact->sa_flags) || __put_user (old_ka.sa.sa_mask.sig[0], &oact->sa_mask))
            return -EFAULT;
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="258" endline="273">
{
    compat_old_sigset_t mask;
    compat_uptr_t handler, restorer;
    if (!access_ok (VERIFY_READ, act, sizeof (*act)) || __get_user (handler, &act->sa_handler) || __get_user (new_ka.sa.sa_flags, &act->sa_flags) || __get_user (restorer, &act->sa_restorer) || __get_user (mask, &act->sa_mask))
        return -EFAULT;
    new_ka.sa.sa_handler = compat_ptr (handler);
    new_ka.sa.sa_restorer = compat_ptr (restorer);
    siginitset (& new_ka.sa.sa_mask, mask);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="277" endline="286">
{
    if (!access_ok (VERIFY_WRITE, oact, sizeof (*oact)) || __put_user (ptr_to_compat (old_ka.sa.sa_handler), &oact->sa_handler) || __put_user (ptr_to_compat (old_ka.sa.sa_restorer), &oact->sa_restorer) || __put_user (old_ka.sa.sa_flags, &oact->sa_flags) || __put_user (old_ka.sa.sa_mask.sig[0], &oact->sa_mask))
        return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="294" endline="329">
{
    sigset_t s;
    compat_sigset_t s32;
    int ret;
    mm_segment_t old_fs = get_fs ();
    if (set) {
        if (copy_from_user (&s32, set, sizeof (compat_sigset_t)))
            return -EFAULT;
        switch (_NSIG_WORDS) {
        case 4 :
            s.sig[3] = s32.sig[6] | (((long) s32.sig[7]) << 32);
        case 3 :
            s.sig[2] = s32.sig[4] | (((long) s32.sig[5]) << 32);
        case 2 :
            s.sig[1] = s32.sig[2] | (((long) s32.sig[3]) << 32);
        case 1 :
            s.sig[0] = s32.sig[0] | (((long) s32.sig[1]) << 32);
        }
    }
    set_fs (KERNEL_DS);
    ret = sys_rt_sigprocmask (how, set ? (sigset_t __user *) &s : NULL, oset ? (sigset_t __user *) &s : NULL, sigsetsize);
    set_fs (old_fs);
    if (ret)
        return ret;
    if (oset) {
        switch (_NSIG_WORDS) {
        case 4 :
            s32.sig[7] = (s.sig[3] >> 32);
            s32.sig[6] = s.sig[3];
        case 3 :
            s32.sig[5] = (s.sig[2] >> 32);
            s32.sig[4] = s.sig[2];
        case 2 :
            s32.sig[3] = (s.sig[1] >> 32);
            s32.sig[2] = s.sig[1];
        case 1 :
            s32.sig[1] = (s.sig[0] >> 32);
            s32.sig[0] = s.sig[0];
        }
        if (copy_to_user (oset, &s32, sizeof (compat_sigset_t)))
            return -EFAULT;
    }
    return 0;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="300" endline="309">
{
    if (copy_from_user (&s32, set, sizeof (compat_sigset_t)))
        return -EFAULT;
    switch (_NSIG_WORDS) {
    case 4 :
        s.sig[3] = s32.sig[6] | (((long) s32.sig[7]) << 32);
    case 3 :
        s.sig[2] = s32.sig[4] | (((long) s32.sig[5]) << 32);
    case 2 :
        s.sig[1] = s32.sig[2] | (((long) s32.sig[3]) << 32);
    case 1 :
        s.sig[0] = s32.sig[0] | (((long) s32.sig[1]) << 32);
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="303" endline="308">
{
case 4 :
    s.sig[3] = s32.sig[6] | (((long) s32.sig[7]) << 32);
case 3 :
    s.sig[2] = s32.sig[4] | (((long) s32.sig[5]) << 32);
case 2 :
    s.sig[1] = s32.sig[2] | (((long) s32.sig[3]) << 32);
case 1 :
    s.sig[0] = s32.sig[0] | (((long) s32.sig[1]) << 32);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="318" endline="327">
{
    switch (_NSIG_WORDS) {
    case 4 :
        s32.sig[7] = (s.sig[3] >> 32);
        s32.sig[6] = s.sig[3];
    case 3 :
        s32.sig[5] = (s.sig[2] >> 32);
        s32.sig[4] = s.sig[2];
    case 2 :
        s32.sig[3] = (s.sig[1] >> 32);
        s32.sig[2] = s.sig[1];
    case 1 :
        s32.sig[1] = (s.sig[0] >> 32);
        s32.sig[0] = s.sig[0];
    }
    if (copy_to_user (oset, &s32, sizeof (compat_sigset_t)))
        return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="319" endline="324">
{
case 4 :
    s32.sig[7] = (s.sig[3] >> 32);
    s32.sig[6] = s.sig[3];
case 3 :
    s32.sig[5] = (s.sig[2] >> 32);
    s32.sig[4] = s.sig[2];
case 2 :
    s32.sig[3] = (s.sig[1] >> 32);
    s32.sig[2] = s.sig[1];
case 1 :
    s32.sig[1] = (s.sig[0] >> 32);
    s32.sig[0] = s.sig[0];
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="332" endline="334">
{
    return alarm_setitimer (seconds);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="338" endline="340">
{
    return compat_sys_wait4 (pid, stat_addr, options, NULL);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="345" endline="347">
{
    return sys_sysfs (option, arg1, arg2);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="351" endline="362">
{
    struct timespec t;
    int ret;
    mm_segment_t old_fs = get_fs ();
    set_fs (KERNEL_DS);
    ret = sys_sched_rr_get_interval (pid, (struct timespec __user *) &t);
    set_fs (old_fs);
    if (put_compat_timespec (&t, interval))
        return -EFAULT;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="366" endline="386">
{
    sigset_t s;
    compat_sigset_t s32;
    int ret;
    mm_segment_t old_fs = get_fs ();
    set_fs (KERNEL_DS);
    ret = sys_rt_sigpending ((sigset_t __user *) &s, sigsetsize);
    set_fs (old_fs);
    if (!ret) {
        switch (_NSIG_WORDS) {
        case 4 :
            s32.sig[7] = (s.sig[3] >> 32);
            s32.sig[6] = s.sig[3];
        case 3 :
            s32.sig[5] = (s.sig[2] >> 32);
            s32.sig[4] = s.sig[2];
        case 2 :
            s32.sig[3] = (s.sig[1] >> 32);
            s32.sig[2] = s.sig[1];
        case 1 :
            s32.sig[1] = (s.sig[0] >> 32);
            s32.sig[0] = s.sig[0];
        }
        if (copy_to_user (set, &s32, sizeof (compat_sigset_t)))
            return -EFAULT;
    }
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="375" endline="384">
{
    switch (_NSIG_WORDS) {
    case 4 :
        s32.sig[7] = (s.sig[3] >> 32);
        s32.sig[6] = s.sig[3];
    case 3 :
        s32.sig[5] = (s.sig[2] >> 32);
        s32.sig[4] = s.sig[2];
    case 2 :
        s32.sig[3] = (s.sig[1] >> 32);
        s32.sig[2] = s.sig[1];
    case 1 :
        s32.sig[1] = (s.sig[0] >> 32);
        s32.sig[0] = s.sig[0];
    }
    if (copy_to_user (set, &s32, sizeof (compat_sigset_t)))
        return -EFAULT;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="376" endline="381">
{
case 4 :
    s32.sig[7] = (s.sig[3] >> 32);
    s32.sig[6] = s.sig[3];
case 3 :
    s32.sig[5] = (s.sig[2] >> 32);
    s32.sig[4] = s.sig[2];
case 2 :
    s32.sig[3] = (s.sig[1] >> 32);
    s32.sig[2] = s.sig[1];
case 1 :
    s32.sig[1] = (s.sig[0] >> 32);
    s32.sig[0] = s.sig[0];
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="390" endline="401">
{
    siginfo_t info;
    int ret;
    mm_segment_t old_fs = get_fs ();
    if (copy_siginfo_from_user32 (&info, uinfo))
        return -EFAULT;
    set_fs (KERNEL_DS);
    ret = sys_rt_sigqueueinfo (pid, sig, (siginfo_t __user *) &info);
    set_fs (old_fs);
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="406" endline="409">
{
    return sys_pread64 (fd, ubuf, count, ((loff_t) AA (poshi) << 32) | AA (poslo));
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="413" endline="416">
{
    return sys_pwrite64 (fd, ubuf, count, ((loff_t) AA (poshi) << 32) | AA (poslo));
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="420" endline="430">
{
    int ret;
    if (personality (current->personality) == PER_LINUX32 && personality == PER_LINUX)
        personality = PER_LINUX32;
    ret = sys_personality (personality);
    if (ret == PER_LINUX32)
        ret = PER_LINUX;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="434" endline="450">
{
    mm_segment_t old_fs = get_fs ();
    int ret;
    off_t of;
    if (offset && get_user (of, offset))
        return -EFAULT;
    set_fs (KERNEL_DS);
    ret = sys_sendfile (out_fd, in_fd, offset ? (off_t __user *) &of : NULL, count);
    set_fs (old_fs);
    if (offset && put_user (of, offset))
        return -EFAULT;
    return ret;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="454" endline="465">
{
    long error;
    char *filename;
    filename = getname (name);
    error = PTR_ERR (filename);
    if (IS_ERR (filename))
        return error;
    error = compat_do_execve (filename, argv, envp, regs);
    putname (filename);
    return error;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="469" endline="476">
{
    void __user *parent_tid = (void __user *) regs->dx;
    void __user *child_tid = (void __user *) regs->di;
    if (!newsp)
        newsp = regs->sp;
    return do_fork (clone_flags, newsp, regs, 0, parent_tid, child_tid);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="483" endline="485">
{
    return sys_lseek (fd, offset, whence);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="488" endline="490">
{
    return sys_kill (pid, sig);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="494" endline="499">
{
    return sys_fadvise64_64 (fd, (((u64) offset_high) << 32) | offset_low, (((u64) len_high) << 32) | len_low, advice);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="502" endline="513">
{
    struct task_struct *me = current;
    static char lastcomm [sizeof (me->comm)];
    if (strncmp (lastcomm, me->comm, sizeof (lastcomm))) {
        compat_printk (KERN_INFO "%s: vm86 mode not supported on 64 bit kernel\n", me -> comm);
        strncpy (lastcomm, me -> comm, sizeof (lastcomm));
    }
    return -ENOSYS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="506" endline="511">
{
    compat_printk (KERN_INFO "%s: vm86 mode not supported on 64 bit kernel\n", me -> comm);
    strncpy (lastcomm, me -> comm, sizeof (lastcomm));
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="517" endline="519">
{
    return sys_lookup_dcookie (((u64) addr_high << 32) | addr_low, buf, len);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="523" endline="525">
{
    return sys_readahead (fd, ((u64) off_hi << 32) | off_lo, count);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="529" endline="533">
{
    return sys_sync_file_range (fd, ((u64) off_hi << 32) | off_low, ((u64) n_hi << 32) | n_low, flags);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="537" endline="540">
{
    return sys_fadvise64_64 (fd, ((u64) offset_hi << 32) | offset_lo, len, advice);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/sys_ia32.c.ifdefed" startline="545" endline="548">
{
    return sys_fallocate (fd, mode, ((u64) offset_hi << 32) | offset_lo, ((u64) len_hi << 32) | len_lo);
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/ipc32.c.ifdefed" startline="15" endline="54">
{
    int version;
    version = call >> 16;
    call &= 0xffff;
    switch (call) {
    case SEMOP :
        return sys_semtimedop (first, compat_ptr (ptr), second, NULL);
    case SEMTIMEDOP :
        return compat_sys_semtimedop (first, compat_ptr (ptr), second, compat_ptr (fifth));
    case SEMGET :
        return sys_semget (first, second, third);
    case SEMCTL :
        return compat_sys_semctl (first, second, third, compat_ptr (ptr));
    case MSGSND :
        return compat_sys_msgsnd (first, second, third, compat_ptr (ptr));
    case MSGRCV :
        return compat_sys_msgrcv (first, second, fifth, third, version, compat_ptr (ptr));
    case MSGGET :
        return sys_msgget ((key_t) first, second);
    case MSGCTL :
        return compat_sys_msgctl (first, second, compat_ptr (ptr));
    case SHMAT :
        return compat_sys_shmat (first, second, third, version, compat_ptr (ptr));
    case SHMDT :
        return sys_shmdt (compat_ptr (ptr));
    case SHMGET :
        return sys_shmget (first, (unsigned) second, third);
    case SHMCTL :
        return compat_sys_shmctl (first, second, compat_ptr (ptr));
    }
    return -ENOSYS;
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/ipc32.c.ifdefed" startline="21" endline="52">
{
case SEMOP :
    return sys_semtimedop (first, compat_ptr (ptr), second, NULL);
case SEMTIMEDOP :
    return compat_sys_semtimedop (first, compat_ptr (ptr), second, compat_ptr (fifth));
case SEMGET :
    return sys_semget (first, second, third);
case SEMCTL :
    return compat_sys_semctl (first, second, third, compat_ptr (ptr));
case MSGSND :
    return compat_sys_msgsnd (first, second, third, compat_ptr (ptr));
case MSGRCV :
    return compat_sys_msgrcv (first, second, fifth, third, version, compat_ptr (ptr));
case MSGGET :
    return sys_msgget ((key_t) first, second);
case MSGCTL :
    return compat_sys_msgctl (first, second, compat_ptr (ptr));
case SHMAT :
    return compat_sys_shmat (first, second, third, version, compat_ptr (ptr));
case SHMDT :
    return sys_shmdt (compat_ptr (ptr));
case SHMGET :
    return sys_shmget (first, (unsigned) second, third);
case SHMCTL :
    return compat_sys_shmctl (first, second, compat_ptr (ptr));
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/audit.c.ifdefed" startline="29" endline="42">
{
    switch (syscall) {
    case __NR_open :
        return 2;
    case __NR_openat :
        return 3;
    case __NR_socketcall :
        return 4;
    case __NR_execve :
        return 5;
    default :
        return 1;
    }
}
</source>
<source file="/cmpt816/tmp/arch/x86/ia32/audit.c.ifdefed" startline="30" endline="41">
{
case __NR_open :
    return 2;
case __NR_openat :
    return 3;
case __NR_socketcall :
    return 4;
case __NR_execve :
    return 5;
default :
    return 1;
}
</source>
